Clustering algorithm selected: kmeans
=====================================

------------------------------------
------ Classification results ------
------------------------------------

====== Cluster 0 ======
Base classifier: SVC(probability=True)
Accuracy: 0.6296296296296297
Recall: 0.625
Precision: 0.4166666666666667
F1: 0.5

====== Cluster 1 ======
Base classifier: SVC(probability=True)
Accuracy: 0.5555555555555556
Recall: 0.0
Precision: 0.0
F1: 0.0

====== Cluster 2 ======
Base classifier: RandomForestClassifier()
Accuracy: 0.4444444444444444
Recall: 0.4444444444444444
Precision: 1.0
F1: 0.6153846153846154

====== Cluster 3 ======
Base classifier: LogisticRegression()
Accuracy: 0.7037037037037037
Recall: 0.6
Precision: 1.0
F1: 0.75

====== Cluster 4 ======
Base classifier: GaussianNB()
Accuracy: 0.18518518518518517
Recall: 0.25
Precision: 0.4166666666666667
F1: 0.3125

====== Cluster 5 ======
Base classifier: RandomForestClassifier()
Accuracy: 0.4074074074074074
Recall: 0.4230769230769231
Precision: 0.9166666666666666
F1: 0.5789473684210527

====== Total ======
Accuracy: 0.4444444444444444
Recall: 0.4444444444444444
Precision: 1.0
F1: 0.6153846153846154

Clustering evaluation metric: silhouette
Clustering evaluation value: 0.2252857892814133

========= Predictions by sample =========

Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 1 1 1], Weights: [0.15 0.1  0.13 0.08 0.36 0.18]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 1 1 1], Weights: [0.1  0.2  0.1  0.07 0.4  0.13]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 1 1 1], Weights: [0.16 0.45 0.07 0.09 0.14 0.09]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.13 0.19 0.12 0.08 0.33 0.14]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.1  0.2  0.08 0.06 0.45 0.11]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 1 1 1], Weights: [0.39 0.12 0.08 0.15 0.1  0.15]
Prediction: 1, Real label: 0, Votes by cluster: [1 0 1 1 1 1], Weights: [0.25 0.11 0.12 0.2  0.1  0.22]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.48 0.16 0.06 0.08 0.13 0.08]
Prediction: 1, Real label: 0, Votes by cluster: [1 0 1 1 1 1], Weights: [0.36 0.11 0.1  0.18 0.09 0.16]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.45 0.16 0.07 0.1  0.13 0.09]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 1 1], Weights: [0.18 0.26 0.12 0.13 0.17 0.13]
Prediction: 1, Real label: 0, Votes by cluster: [1 0 1 1 1 1], Weights: [0.39 0.11 0.09 0.17 0.09 0.14]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 0 1], Weights: [0.04 0.03 0.75 0.08 0.04 0.07]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.16 0.1  0.09 0.07 0.44 0.14]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.17 0.13 0.12 0.09 0.31 0.19]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 0 1 1], Weights: [0.46 0.17 0.06 0.09 0.14 0.08]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 1 0 1], Weights: [0.1  0.05 0.11 0.64 0.04 0.06]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 0 1], Weights: [0.11 0.09 0.36 0.14 0.17 0.13]
Prediction: 1, Real label: 0, Votes by cluster: [0 0 1 1 1 1], Weights: [0.14 0.08 0.15 0.09 0.17 0.37]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 0 1], Weights: [0.12 0.08 0.35 0.17 0.12 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 1 1 1], Weights: [0.07 0.04 0.08 0.05 0.07 0.69]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 0 1], Weights: [0.11 0.09 0.37 0.14 0.19 0.12]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 1 1 1], Weights: [0.14 0.08 0.15 0.09 0.16 0.39]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 1 0 1], Weights: [0.13 0.08 0.19 0.4  0.08 0.12]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 1 0], Weights: [0.28 0.13 0.11 0.18 0.11 0.19]
Prediction: 1, Real label: 1, Votes by cluster: [0 0 1 1 0 1], Weights: [0.15 0.17 0.19 0.23 0.12 0.14]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 1 1 1], Weights: [0.15 0.12 0.18 0.11 0.23 0.23]
