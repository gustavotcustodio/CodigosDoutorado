============== Classifiers Parameters ==============
[{'n_estimators': 205, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 5}, {'n_estimators': 118, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}, {'n_estimators': 204, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}, {'n_estimators': 127, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 8}, {'n_estimators': 100, 'max_depth': 1, 'min_samples_split': 6, 'min_samples_leaf': 2}]

Optimal clusterer: kmeans

External clustering metrics:
adjusted_rand_score: 0.3244410966142569
normalized_mutual_info_score: 0.25287948281520756
v_measure_score: 0.2528794828152075
fowlkes_mallows_score: 0.6630589311183568

Internal clustering metrics:
silhouette: 0.2103666918354199
davies_bouldin: 1.8590518425938678
calinski_harabasz_score: 66.94996409331964

Base classifier: extra_tree
========== Cluster 0 ==========

Labels: [1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0
 1 1 1]

========== Cluster 1 ==========

Labels: [1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1
 0 1 1 1 1 0 0 0 0 1 0 0 0 0]

========== Cluster 2 ==========

Labels: [0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0
 1 0 1 0 1 1 1 1 1 1 0 0 1]

========== Cluster 3 ==========

Labels: [0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0]

========== Cluster 4 ==========

Labels: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0]

