Clustering algorithm selected: kmeans
=====================================

------------------------------------
------ Classification results ------
------------------------------------

====== Cluster 0 ======
Base classifier: LogisticRegression()
Accuracy: 0.6666666666666666
Recall: 0.6153846153846154
Precision: 0.6666666666666666
F1: 0.64

====== Cluster 1 ======
Base classifier: GaussianNB()
Accuracy: 0.4074074074074074
Recall: 0.375
Precision: 0.5
F1: 0.42857142857142855

====== Cluster 2 ======
Base classifier: GaussianNB()
Accuracy: 0.7777777777777778
Recall: 0.8
Precision: 0.6666666666666666
F1: 0.7272727272727273

====== Cluster 3 ======
Base classifier: LogisticRegression()
Accuracy: 0.5555555555555556
Recall: 0.0
Precision: 0.0
F1: 0.0

====== Cluster 4 ======
Base classifier: DecisionTreeClassifier()
Accuracy: 0.4444444444444444
Recall: 0.44
Precision: 0.9166666666666666
F1: 0.5945945945945946

====== Cluster 5 ======
Base classifier: SVC(probability=True)
Accuracy: 0.7777777777777778
Recall: 1.0
Precision: 0.5
F1: 0.6666666666666666

====== Total ======
Accuracy: 0.7037037037037037
Recall: 0.75
Precision: 0.5
F1: 0.6

AUC: 0.7666666666666666

Clustering evaluation metric: silhouette
Clustering evaluation value: 0.21736479544603665

========= Predictions by sample =========

Prediction: 1, Real label: 1, Votes by cluster: [1 1 0 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [0 0 1 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [0 1 1 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [1 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [1 0 1 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [0 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [0 1 0 0 0 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 0, Votes by cluster: [1 1 1 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 1, Votes by cluster: [1 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [1 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 0, Votes by cluster: [1 1 1 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 0 1 1], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [1 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 1 0 0 1 0], Weights: [0.21 0.1  0.15 0.26 0.13 0.16]
