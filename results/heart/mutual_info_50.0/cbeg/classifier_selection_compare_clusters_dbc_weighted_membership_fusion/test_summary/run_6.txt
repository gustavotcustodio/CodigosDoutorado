Clustering algorithm selected: fcm
=====================================

------------------------------------
------ Classification results ------
------------------------------------

====== Cluster 0 ======
Base classifier: SVC(probability=True)
Accuracy: 0.8148148148148148
Recall: 1.0
Precision: 0.5833333333333334
F1: 0.7368421052631579

====== Cluster 1 ======
Base classifier: SVC(probability=True)
Accuracy: 0.9629629629629629
Recall: 1.0
Precision: 0.9166666666666666
F1: 0.9565217391304348

====== Cluster 2 ======
Base classifier: LogisticRegression()
Accuracy: 0.9629629629629629
Recall: 1.0
Precision: 0.9166666666666666
F1: 0.9565217391304348

====== Cluster 3 ======
Base classifier: LogisticRegression()
Accuracy: 0.9259259259259259
Recall: 1.0
Precision: 0.8333333333333334
F1: 0.9090909090909091

====== Cluster 4 ======
Base classifier: LogisticRegression()
Accuracy: 0.8888888888888888
Recall: 0.8
Precision: 1.0
F1: 0.8888888888888888

====== Cluster 5 ======
Base classifier: GaussianNB()
Accuracy: 0.9259259259259259
Recall: 0.8571428571428571
Precision: 1.0
F1: 0.9230769230769231

====== Total ======
Accuracy: 1.0
Recall: 1.0
Precision: 1.0
F1: 1.0

Clustering evaluation metric: dbc
Clustering evaluation value: 0.37906623623866276

========= Predictions by sample =========

Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.19 0.19 0.19 0.14 0.1  0.19]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.18 0.18 0.18 0.2  0.1  0.18]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.18 0.18 0.18 0.18 0.12 0.18]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 0], Weights: [0.18 0.18 0.18 0.13 0.14 0.18]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.17 0.17 0.17 0.21 0.09 0.17]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.13 0.13 0.13 0.4  0.08 0.13]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.13 0.13 0.13 0.4  0.08 0.13]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 0], Weights: [0.17 0.17 0.17 0.17 0.16 0.17]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.19 0.19 0.19 0.13 0.11 0.19]
Prediction: 1, Real label: 1, Votes by cluster: [0 1 0 1 1 1], Weights: [0.18 0.18 0.18 0.11 0.18 0.18]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.13 0.13 0.13 0.39 0.08 0.13]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.19 0.19 0.19 0.14 0.11 0.19]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.14 0.14 0.14 0.07 0.36 0.14]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 1], Weights: [0.16 0.16 0.16 0.22 0.13 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.15 0.15 0.15 0.07 0.32 0.15]
Prediction: 1, Real label: 1, Votes by cluster: [0 1 1 1 1 1], Weights: [0.16 0.16 0.16 0.15 0.2  0.16]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.17 0.17 0.17 0.21 0.1  0.17]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 0 0], Weights: [0.12 0.12 0.12 0.43 0.07 0.12]
Prediction: 0, Real label: 0, Votes by cluster: [0 0 0 0 1 1], Weights: [0.17 0.17 0.17 0.14 0.17 0.17]
Prediction: 1, Real label: 1, Votes by cluster: [0 1 1 1 1 1], Weights: [0.16 0.16 0.16 0.12 0.22 0.16]
Prediction: 1, Real label: 1, Votes by cluster: [0 1 1 1 1 1], Weights: [0.18 0.18 0.18 0.12 0.18 0.18]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.15 0.15 0.15 0.09 0.29 0.15]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.15 0.15 0.15 0.07 0.35 0.15]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.15 0.15 0.15 0.07 0.34 0.15]
Prediction: 1, Real label: 1, Votes by cluster: [1 0 1 0 1 1], Weights: [0.17 0.17 0.17 0.18 0.14 0.17]
Prediction: 1, Real label: 1, Votes by cluster: [1 1 1 1 1 1], Weights: [0.15 0.15 0.15 0.09 0.29 0.15]
Prediction: 1, Real label: 1, Votes by cluster: [0 1 1 0 1 1], Weights: [0.18 0.18 0.18 0.12 0.16 0.18]
