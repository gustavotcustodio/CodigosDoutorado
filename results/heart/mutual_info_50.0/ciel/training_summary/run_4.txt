============== Classifiers Parameters ==============
[{'n_estimators': 429, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 2}, {'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}, {'n_estimators': 435, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}, {'n_estimators': 206, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 7}, {'n_estimators': 301, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}, {'n_estimators': 289, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 3}]

Optimal clusterer: kmeans

External clustering metrics:
adjusted_rand_score: 0.39394569677890834
normalized_mutual_info_score: 0.30866950527588594
v_measure_score: 0.30866950527588594
fowlkes_mallows_score: 0.698035377342542

Internal clustering metrics:
silhouette: 0.21209567386218528
davies_bouldin: 1.8514653064244668
calinski_harabasz_score: 67.46151752371354

Base classifier: extra_tree
========== Cluster 0 ==========

Labels: [0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1
 0 1 0 1 1 1 1 1 1 0 0 1]

========== Cluster 1 ==========

Labels: [0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0]

========== Cluster 2 ==========

Labels: [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0]

========== Cluster 3 ==========

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1]

========== Cluster 4 ==========

Labels: [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]

========== Cluster 5 ==========

Labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0
 0]

