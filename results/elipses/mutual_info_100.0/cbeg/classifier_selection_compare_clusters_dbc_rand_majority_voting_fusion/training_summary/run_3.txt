Clustering algorithm selected: kmeans
=====================================

Clustering evaluation metric: dbc_rand
Clustering evaluation value: 0.37494663780020115

========== Cluster 0 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 1

Selected Features: [0 1]

Labels: [2 2 1 2 2 2 1 2 1 2 2 2 1 2 2 2 1 1 2 2 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 1 2
 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 2 1 2 2 2 1 2 2]

========== Cluster 1 ==========

Base classifier: LogisticRegression()

Minority Class: 2

Selected Features: [0 1]

Labels: [2 0 0 1 1 0 0 1 0 2 1 1 0 1 0 0 0 0 2 0 1 2 0 0 0 0 2 2 1 2 2 1 2 2 0 1 0
 0 0 0 0 1 0 0 1 1 2 1 2 2 1 2 1 0 0 0 0 1 0 1 0 0 2 0 0 2 2 0 2 0 1 1 2 1
 2 0 1 1 0]

========== Cluster 2 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 0

Selected Features: [0 1]

Labels: [0 2 0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 0 0 2 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2
 0 0 2 2 2 2 2 2 0 2 0 0 0 0 0 0 2 2 0 0 2 2 0]

========== Cluster 3 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 1

Selected Features: [0 1]

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]

========== Cluster 4 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 1

Selected Features: [0 1]

Labels: [2 2 2 1 2 1 1 1 0 2 0 2 0 1 0 0 2 2 1 1 0 2 0 2 2 2 2 2 2 2 2 2 0 2 2 0 0
 2 2 0 2 2 2 0 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 0 0 1 0 1 1]

========== Cluster 5 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 0

Selected Features: [0 1]

Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]

========== Cluster 6 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 0

Selected Features: [0 1]

Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0]

========== Cluster 7 ==========

Base classifier: LogisticRegression()

Minority Class: 2

Selected Features: [0 1]

Labels: [1 1 0 0 0 1 1 1 1 0 0 2 0 1 0 0 2 0 1 2 0 1 2 1 0 1 1 0 2 2 2 0 2 0 2 1 1
 1 1 1 0 2 2 1 1 2 2 0 1 1 1 1 0 0 0 2 2 1 0 0 1 0 2 2 1 0 1 0 2 1 1 2 1 1
 1 0 0 2 1 0 0 0 1 1 2 1 1 1 2 1 1 1 1 1 0 2]

========== Cluster 8 ==========

Base classifier: DecisionTreeClassifier()

Minority Class: 2

Selected Features: [0 1]

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2]

========== Cluster 9 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 2

Selected Features: [0 1]

Labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]

========== Cluster 10 ==========

Base classifier: LogisticRegression()

Minority Class: 0

Selected Features: [0 1]

Labels: [1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0
 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0]

