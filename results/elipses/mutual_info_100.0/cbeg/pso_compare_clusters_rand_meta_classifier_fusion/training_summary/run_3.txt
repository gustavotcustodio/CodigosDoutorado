Clustering algorithm selected: kmeans
=====================================

Clustering evaluation metric: rand
Clustering evaluation value: 0.37494663780020115

========== Cluster 0 ==========

Base classifier: KNeighborsClassifier(n_neighbors=7)

Minority Class: 1

Selected Features: [0 1]

Labels: [2 2 1 2 2 2 1 2 1 2 2 2 1 2 2 2 1 1 2 2 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 1 2
 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 2 1 2 2 2 1 2 2]

========== Cluster 1 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 2

Selected Features: [0 1]

Labels: [2 0 0 1 1 0 0 1 0 2 1 1 0 1 0 0 0 0 2 0 1 2 0 0 0 0 2 2 1 2 2 1 2 2 0 1 0
 0 0 0 0 1 0 0 1 1 2 1 2 2 1 2 1 0 0 0 0 1 0 1 0 0 2 0 0 2 2 0 2 0 1 1 2 1
 2 0 1 1 0]

========== Cluster 2 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 0

Selected Features: [0 1]

Labels: [0 2 0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 0 0 2 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2
 0 0 2 2 2 2 2 2 0 2 0 0 0 0 0 0 2 2 0 0 2 2 0]

========== Cluster 3 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 1

Selected Features: [0 1]

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]

========== Cluster 4 ==========

Base classifier: DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=4)

Minority Class: 1

Selected Features: [0 1]

Labels: [2 2 2 1 2 1 1 1 0 2 0 2 0 1 0 0 2 2 1 1 0 2 0 2 2 2 2 2 2 2 2 2 0 2 2 0 0
 2 2 0 2 2 2 0 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 0 0 1 0 1 1]

========== Cluster 5 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 0

Selected Features: [0 1]

Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]

========== Cluster 6 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 0

Selected Features: [0 1]

Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0]

========== Cluster 7 ==========

Base classifier: DecisionTreeClassifier(max_depth=9, min_samples_leaf=5, min_samples_split=3)

Minority Class: 2

Selected Features: [0 1]

Labels: [1 1 0 0 0 1 1 1 1 0 0 2 0 1 0 0 2 0 1 2 0 1 2 1 0 1 1 0 2 2 2 0 2 0 2 1 1
 1 1 1 0 2 2 1 1 2 2 0 1 1 1 1 0 0 0 2 2 1 0 0 1 0 2 2 1 0 1 0 2 1 1 2 1 1
 1 0 0 2 1 0 0 0 1 1 2 1 1 1 2 1 1 1 1 1 0 2]

========== Cluster 8 ==========

Base classifier: SVC(C=67.75102199527618, gamma=438.00226118307637, probability=True)

Minority Class: 2

Selected Features: [0 1]

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2]

========== Cluster 9 ==========

Base classifier: DummyClassifier(strategy='most_frequent')

Minority Class: 2

Selected Features: [0 1]

Labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]

========== Cluster 10 ==========

Base classifier: KNeighborsClassifier(n_neighbors=7)

Minority Class: 0

Selected Features: [0 1]

Labels: [1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0
 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0]

