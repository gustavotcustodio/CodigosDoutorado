Clustering algorithm selected: kmeans
=====================================

Clustering evaluation metric: dbc_ss
Clustering evaluation value: 0.22682886863845625

========== Cluster 0 ==========

Base classifier: KNeighborsClassifier()

Minority Class: 1

Selected Features: [0 1 2 3 4 5 6 7 8]

Labels: [1 2 2 0 1 1 0 2 1 2 0 1 1 2 1 0 2 2 0 0 1 2 0 0 2 1 2 0 1 2 1 1 1 1 0 1 1
 1 0 2 1 1 2 2 2 0 1 1 0 0 2 0 0 2 2 1 2 1 2 0 0 1 0 1 1 2 1 2 0 0 1 0 0 1
 0 0 0 0 1 0 1 2 2 0 2 2 2 0 0 2 0 0 1 2 0 1 1 2 2 1 1 0 0 0 2 2 2 1 2 0 0
 1 2 2 2 0 0 0 2 1 2 2 1 1 1 2 0 2 2 2 1 2 2 1 2 1 0 1 0 2 0 0 2 2 0 1 0 1
 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 2 2 2 0 0 0 0 1 2 0 1 1 1 1 2 0 2 0 1 0 1
 1 0 1 2 0 0 1 2 2 2 0 2 1 2 1 1 0 2 1 0 0 2 1 0 2 1 2 2 2 2 1 1 2 0 1 2 1
 0 1 1 1 1 1 2 0 0 2 1 2 0 1 1 2 2 1 2 0 1 1 1 0 0 2 0 1 2 0 1 2 2 2 2 2 0
 0 0 2 2 1 2 0 2 0 1 1 0 0 0 2 1 1 2 0 1 2 0 2 1 2 2 1 2 2 2 2 2 0 0 2 2 0
 1 2 1 2 0 1 2 2 2 2 0 0 0 1 2 1 1 1 1 0 1 0 0 2 1 1 1 1 1 2 1 0 1 0 0 1 1
 0 2 1 2 0 0 2 0 0 1 1 2 1 0 2 0 1 0 2 1 0 0 2 0 1 2 1 0 2 0 0 1 1 2 1 2 0
 1 1 2 0 1 1 0 2 2 0 1 1 2 0 2 1 2 0 2 0 2 0 2 1 0 1 1 2 0 2 1 1 0 2 0 1 2
 1 2 2 0 0 1 2 2 2 0 1 0 0 0 2 1 1 2 2 0 0 0 2 0 1 2 2 2 2 1 0 1 1 2 2 0 1
 0 0 2 0 0 1 0 0 2 0 2 1 1 0 0 0 2 0 0 2 2 0 0 0]

Synthetic samples indexes: [  0   4   8  11  12  13  14  16  17  20  28  31  32  35  39  40  43  54
  56  58  66  70  80  85  92  95  98 100 104 106 112 119 121 122 123 129
 132 133 139 150 155 159 161 174 175 182 191 192 193 196 199 203 206 212
 213 214 216 219 221 223 224 225 228 232 235 238 240 244 249 250 252 255
 256 257 261 266 269 273 274 276 278 279 283 285 288 289 290 297 298 299
 301 303 305 311 312 314 321 322 323 324 326 328 331 335 342 343 349 357
 359 364 370 381 382 385 386 388 395 396 399 405 407 409 413 414 415 424
 431 432 435 438 463]

========== Cluster 1 ==========

Base classifier: KNeighborsClassifier(n_neighbors=7)

Minority Class: 1

Selected Features: [0 1 2 3 4 5 6 7 8]

Labels: [0 1 0 ... 2 2 1]

Synthetic samples indexes: [   6    9   12   16   27   28   30   31   34   44   48   49   54   56
   71   74   75   79   81   82   92   93   94  100  103  105  110  119
  131  143  152  153  157  158  160  167  173  187  194  196  198  199
  201  209  213  216  217  219  224  226  238  244  254  263  266  277
  289  292  293  298  300  305  307  312  318  320  323  324  327  338
  341  345  346  362  363  365  368  371  377  383  390  400  401  409
  411  415  417  421  422  438  463  465  481  484  492  496  504  515
  517  525  527  529  545  546  547  553  559  562  565  576  586  587
  588  590  591  592  596  606  614  622  625  638  639  640  655  656
  661  673  676  680  697  698  701  704  705  710  711  715  722  723
  724  734  747  751  754  756  757  761  770  771  784  788  789  790
  805  810  815  816  820  831  832  837  839  845  857  864  867  879
  881  886  888  891  894  903  907  910  914  937  940  948  949  953
  958  962  970  974  978  980  986  987  996 1003 1004 1006 1010 1011
 1013 1017 1020 1023 1024 1031 1037 1040 1047 1055 1060 1064 1071 1072
 1079 1088 1090 1093 1097 1099 1104 1108 1113 1117 1124 1129 1133 1134
 1135 1144 1153 1156 1163 1165 1166 1175 1179 1196 1199 1204 1211 1212
 1214 1216 1220 1221 1228 1229 1232]

