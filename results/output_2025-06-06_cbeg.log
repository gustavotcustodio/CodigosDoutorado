======================================================
Running australian_credit 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4875281546126558
0.4875281546126558
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.81      0.85        42
           1       0.74      0.85      0.79        27

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [317, 199, 105]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5002510752650209
0.49591580429356447
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [303, 308, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6531853052803556
0.6531853052803556
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.84      0.89        43
           1       0.77      0.92      0.84        26

    accuracy                           0.87        69
   macro avg       0.86      0.88      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [321, 284, 16]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5139394530690523
0.5253290853288693
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [20, 325, 284]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4815971652310438
0.4840916369303551
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.97      0.90        33
           1       0.97      0.83      0.90        36

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [301, 21, 304]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.49587968391987486
0.49246151552310097
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), KNeighborsClassifier(), RandomForestClassifier()]
Number of samples by cluster: [330, 208, 84]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4898913741051234
0.48097897904861303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [313, 296, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4840057143134876
0.4840057143134876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        39
           1       0.77      0.77      0.77        30

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [326, 295]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        42
           1       0.83      0.93      0.88        27

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5774272272966645
0.5774272272966645
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.88        34
           1       0.93      0.80      0.86        35

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [51, 11, 269, 290]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8565217391304347
F1: 0.8391480715691321
======================================================
Running australian_credit 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.92      0.91        37
           1       0.90      0.88      0.89        32

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.85      0.85        39
           1       0.80      0.80      0.80        30

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.87      0.86        38
           1       0.83      0.81      0.82        31

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8652173913043478
F1: 0.8499372142796657
======================================================
Running australian_credit 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.82      0.84        40
           1       0.77      0.79      0.78        29

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8579710144927535
F1: 0.8389504601713466
======================================================
Running australian_credit 100 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.58      0.68        53
           1       0.29      0.56      0.38        16

    accuracy                           0.58        69
   macro avg       0.55      0.57      0.53        69
weighted avg       0.69      0.58      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.64      0.73        50
           1       0.42      0.68      0.52        19

    accuracy                           0.65        69
   macro avg       0.63      0.66      0.62        69
weighted avg       0.73      0.65      0.67        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.74      0.90      0.81        31
           1       0.90      0.74      0.81        38

    accuracy                           0.81        69
   macro avg       0.82      0.82      0.81        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.76      0.94      0.84        31
           1       0.94      0.76      0.84        38

    accuracy                           0.84        69
   macro avg       0.85      0.85      0.84        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.71      0.90      0.79        30
           1       0.90      0.72      0.80        39

    accuracy                           0.80        69
   macro avg       0.81      0.81      0.80        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        40
           1       0.74      0.79      0.77        29

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.70      0.80        53
           1       0.47      0.88      0.61        16

    accuracy                           0.74        69
   macro avg       0.71      0.79      0.71        69
weighted avg       0.84      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.67      0.77        52
           1       0.43      0.76      0.55        17

    accuracy                           0.70        69
   macro avg       0.67      0.72      0.66        69
weighted avg       0.78      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7347826086956522
F1: 0.6442039777983349
======================================================
Running australian_credit 100 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        39
           1       0.87      0.90      0.89        30

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.84      0.77        32
           1       0.84      0.70      0.76        37

    accuracy                           0.77        69
   macro avg       0.77      0.77      0.77        69
weighted avg       0.78      0.77      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        39
           1       0.83      0.83      0.83        30

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8623188405797102
F1: 0.8445823086818036
======================================================
Running australian_credit 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.88      0.82        33
           1       0.87      0.75      0.81        36

    accuracy                           0.81        69
   macro avg       0.82      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.97      0.87        32
           1       0.97      0.78      0.87        37

    accuracy                           0.87        69
   macro avg       0.88      0.88      0.87        69
weighted avg       0.89      0.87      0.87        69

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8521739130434783
F1: 0.833316052337619
======================================================
Running australian_credit 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.86      0.91        43
           1       0.81      0.96      0.88        26

    accuracy                           0.90        69
   macro avg       0.89      0.91      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.92      0.91        37
           1       0.90      0.88      0.89        32

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        41
           1       0.83      0.89      0.86        28

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8710144927536232
F1: 0.851693766578814
======================================================
Running australian_credit 100 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.37      0.50      0.42        28
           1       0.55      0.41      0.47        41

    accuracy                           0.45        69
   macro avg       0.46      0.46      0.45        69
weighted avg       0.48      0.45      0.45        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.53      0.56      0.54        36
           1       0.48      0.45      0.47        33

    accuracy                           0.51        69
   macro avg       0.51      0.51      0.50        69
weighted avg       0.51      0.51      0.51        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.76      0.72      0.74        40
           1       0.65      0.69      0.67        29

    accuracy                           0.71        69
   macro avg       0.70      0.71      0.71        69
weighted avg       0.71      0.71      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.68      0.68        38
           1       0.61      0.61      0.61        31

    accuracy                           0.65        69
   macro avg       0.65      0.65      0.65        69
weighted avg       0.65      0.65      0.65        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.74      0.71        35
           1       0.71      0.65      0.68        34

    accuracy                           0.70        69
   macro avg       0.70      0.69      0.69        69
weighted avg       0.70      0.70      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.65      0.76        52
           1       0.42      0.76      0.54        17

    accuracy                           0.68        69
   macro avg       0.66      0.71      0.65        69
weighted avg       0.78      0.68      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.53      0.46        30
           1       0.53      0.41      0.46        39

    accuracy                           0.46        69
   macro avg       0.47      0.47      0.46        69
weighted avg       0.48      0.46      0.46        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.64      0.76        56
           1       0.33      0.77      0.47        13

    accuracy                           0.67        69
   macro avg       0.63      0.71      0.61        69
weighted avg       0.81      0.67      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6246376811594204
F1: 0.5479127364407992
======================================================
Running australian_credit 100 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.70      0.81        53
           1       0.48      0.94      0.64        16

    accuracy                           0.75        69
   macro avg       0.73      0.82      0.73        69
weighted avg       0.86      0.75      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.61      0.75        61
           1       0.23      0.88      0.36         8

    accuracy                           0.64        69
   macro avg       0.60      0.74      0.55        69
weighted avg       0.89      0.64      0.70        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.86        45
           1       0.70      0.88      0.78        24

    accuracy                           0.83        69
   macro avg       0.81      0.84      0.82        69
weighted avg       0.85      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        60
           1       0.30      1.00      0.46         9

    accuracy                           0.70        69
   macro avg       0.65      0.82      0.62        69
weighted avg       0.91      0.70      0.75        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        41
           1       0.83      0.89      0.86        28

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8130434782608695
F1: 0.7327248808478294
======================================================
Running australian_credit 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        47
           1       0.61      0.86      0.72        22

    accuracy                           0.78        69
   macro avg       0.77      0.80      0.77        69
weighted avg       0.82      0.78      0.79        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.87        49
           1       0.65      1.00      0.78        20

    accuracy                           0.84        69
   macro avg       0.82      0.89      0.83        69
weighted avg       0.90      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        38
           1       0.77      0.77      0.77        31

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.79      0.84        43
           1       0.71      0.85      0.77        26

    accuracy                           0.81        69
   macro avg       0.80      0.82      0.81        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.84      0.89        43
           1       0.77      0.92      0.84        26

    accuracy                           0.87        69
   macro avg       0.86      0.88      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        48
           1       0.68      1.00      0.81        21

    accuracy                           0.86        69
   macro avg       0.84      0.90      0.85        69
weighted avg       0.90      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.74      0.81        47
           1       0.60      0.82      0.69        22

    accuracy                           0.77        69
   macro avg       0.75      0.78      0.75        69
weighted avg       0.80      0.77      0.78        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.80      0.89        49
           1       0.67      1.00      0.80        20

    accuracy                           0.86        69
   macro avg       0.83      0.90      0.84        69
weighted avg       0.90      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8391304347826087
F1: 0.7972227379824225
======================================================
Running australian_credit 100 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.87        49
           1       0.65      1.00      0.78        20

    accuracy                           0.84        69
   macro avg       0.82      0.89      0.83        69
weighted avg       0.90      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.81      0.78        36
           1       0.77      0.73      0.75        33

    accuracy                           0.77        69
   macro avg       0.77      0.77      0.77        69
weighted avg       0.77      0.77      0.77        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        40
           1       0.74      0.79      0.77        29

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.84        44
           1       0.70      0.84      0.76        25

    accuracy                           0.81        69
   macro avg       0.80      0.82      0.80        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        50
           1       0.63      1.00      0.78        19

    accuracy                           0.84        69
   macro avg       0.82      0.89      0.83        69
weighted avg       0.90      0.84      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.827536231884058
F1: 0.7903959951335711
======================================================
Running australian_credit 100 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.70      0.81        53
           1       0.48      0.94      0.64        16

    accuracy                           0.75        69
   macro avg       0.73      0.82      0.73        69
weighted avg       0.86      0.75      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.61      0.75        61
           1       0.23      0.88      0.36         8

    accuracy                           0.64        69
   macro avg       0.60      0.74      0.55        69
weighted avg       0.89      0.64      0.70        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        47
           1       0.68      0.95      0.79        22

    accuracy                           0.84        69
   macro avg       0.83      0.87      0.83        69
weighted avg       0.88      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.83      0.85        41
           1       0.77      0.82      0.79        28

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        60
           1       0.30      1.00      0.46         9

    accuracy                           0.70        69
   macro avg       0.65      0.82      0.62        69
weighted avg       0.91      0.70      0.75        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.90      0.90        39
           1       0.87      0.87      0.87        30

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8072463768115942
F1: 0.7269389075650237
======================================================
Running australian_credit 100 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
CBEG               precision    recall  f1-score   support

           0       0.82      0.58      0.68        53
           1       0.29      0.56      0.38        16

    accuracy                           0.58        69
   macro avg       0.55      0.57      0.53        69
weighted avg       0.69      0.58      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.67        60
           1       0.13      0.44      0.20         9

    accuracy                           0.54        69
   macro avg       0.50      0.50      0.44        69
weighted avg       0.77      0.54      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        64
           1       0.10      0.60      0.17         5

    accuracy                           0.58        69
   macro avg       0.52      0.59      0.44        69
weighted avg       0.89      0.58      0.68        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6579710144927536
F1: 0.4360211475637007
======================================================
Running australian_credit 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        57
           1       0.39      1.00      0.56        12

    accuracy                           0.72        69
   macro avg       0.69      0.83      0.68        69
weighted avg       0.89      0.72      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
CBEG               precision    recall  f1-score   support

           0       0.95      0.68      0.79        53
           1       0.45      0.88      0.60        16

    accuracy                           0.72        69
   macro avg       0.70      0.78      0.69        69
weighted avg       0.83      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        50
           1       0.58      0.95      0.72        19

    accuracy                           0.80        69
   macro avg       0.78      0.84      0.78        69
weighted avg       0.87      0.80      0.81        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
CBEG               precision    recall  f1-score   support

           0       0.95      0.70      0.80        53
           1       0.47      0.88      0.61        16

    accuracy                           0.74        69
   macro avg       0.71      0.79      0.71        69
weighted avg       0.84      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7246376811594204
F1: 0.5839825796583198
======================================================
Running australian_credit 100 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        57
           1       0.39      1.00      0.56        12

    accuracy                           0.72        69
   macro avg       0.69      0.83      0.68        69
weighted avg       0.89      0.72      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
CBEG               precision    recall  f1-score   support

           0       0.95      0.68      0.79        53
           1       0.45      0.88      0.60        16

    accuracy                           0.72        69
   macro avg       0.70      0.78      0.69        69
weighted avg       0.83      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        50
           1       0.58      0.95      0.72        19

    accuracy                           0.80        69
   macro avg       0.78      0.84      0.78        69
weighted avg       0.87      0.80      0.81        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
CBEG               precision    recall  f1-score   support

           0       0.95      0.70      0.80        53
           1       0.47      0.88      0.61        16

    accuracy                           0.74        69
   macro avg       0.71      0.79      0.71        69
weighted avg       0.84      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7246376811594204
F1: 0.5839825796583198
======================================================
Running australian_credit 100 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.58      0.68        53
           1       0.29      0.56      0.38        16

    accuracy                           0.58        69
   macro avg       0.55      0.57      0.53        69
weighted avg       0.69      0.58      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.67        60
           1       0.13      0.44      0.20         9

    accuracy                           0.54        69
   macro avg       0.50      0.50      0.44        69
weighted avg       0.77      0.54      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        64
           1       0.10      0.60      0.17         5

    accuracy                           0.58        69
   macro avg       0.52      0.59      0.44        69
weighted avg       0.89      0.58      0.68        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6579710144927536
F1: 0.4360211475637007
======================================================
Running australian_credit 100 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4875281546126558
0.4875281546126558
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [317, 199, 105]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5002510752650209
0.49591580429356447
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [303, 308, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6531853052803556
0.6531853052803556
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [321, 284, 16]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5139394530690523
0.5253290853288693
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.88      0.83        34
           1       0.87      0.77      0.82        35

    accuracy                           0.83        69
   macro avg       0.83      0.83      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [20, 325, 284]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4815971652310438
0.4840916369303551
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        34
           1       0.97      0.86      0.91        35

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [301, 21, 304]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.49587968391987486
0.49246151552310097
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.84      0.84        38
           1       0.81      0.81      0.81        31

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [330, 208, 84]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4898913741051234
0.48097897904861303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [313, 296, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4840057143134876
0.4840057143134876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [326, 295]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        42
           1       0.83      0.93      0.88        27

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5774272272966645
0.5774272272966645
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [51, 11, 269, 290]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8623188405797102
F1: 0.8439739932894266
======================================================
Running australian_credit 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.92        36
           1       0.94      0.88      0.91        33

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.83      0.85        41
           1       0.77      0.82      0.79        28

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.88        34
           1       0.93      0.80      0.86        35

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8608695652173912
F1: 0.842421565574535
======================================================
Running australian_credit 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.84      0.90        44
           1       0.77      0.96      0.86        25

    accuracy                           0.88        69
   macro avg       0.87      0.90      0.88        69
weighted avg       0.90      0.88      0.89        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.82      0.84        40
           1       0.77      0.79      0.78        29

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8608695652173914
F1: 0.8409729045866102
======================================================
Running australian_credit 75 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.88      0.80        32
           1       0.87      0.73      0.79        37

    accuracy                           0.80        69
   macro avg       0.80      0.80      0.80        69
weighted avg       0.81      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.97      0.90        33
           1       0.97      0.83      0.90        36

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.88      0.89        40
           1       0.83      0.86      0.85        29

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8637681159420291
F1: 0.846820836136789
======================================================
Running australian_credit 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8637681159420291
F1: 0.8454442907164268
======================================================
Running australian_credit 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.80      0.82        41
           1       0.73      0.79      0.76        28

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        37
           1       0.83      0.78      0.81        32

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8594202898550725
F1: 0.8409704211972192
======================================================
Running australian_credit 75 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.73      0.83        51
           1       0.55      0.94      0.69        18

    accuracy                           0.78        69
   macro avg       0.76      0.83      0.76        69
weighted avg       0.86      0.78      0.80        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.74        65
           1       0.13      1.00      0.23         4

    accuracy                           0.61        69
   macro avg       0.56      0.79      0.48        69
weighted avg       0.95      0.61      0.71        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        39
           1       0.87      0.90      0.89        30

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.84        44
           1       0.70      0.84      0.76        25

    accuracy                           0.81        69
   macro avg       0.80      0.82      0.80        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.59      0.74        66
           1       0.10      1.00      0.18         3

    accuracy                           0.61        69
   macro avg       0.55      0.80      0.46        69
weighted avg       0.96      0.61      0.72        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.90      0.90        39
           1       0.87      0.87      0.87        30

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8
F1: 0.6939117442149174
======================================================
Running australian_credit 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.78      0.86        46
           1       0.68      0.91      0.78        23

    accuracy                           0.83        69
   macro avg       0.81      0.85      0.82        69
weighted avg       0.86      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        48
           1       0.65      0.95      0.77        21

    accuracy                           0.83        69
   macro avg       0.81      0.86      0.81        69
weighted avg       0.87      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.84      0.89        43
           1       0.77      0.92      0.84        26

    accuracy                           0.87        69
   macro avg       0.86      0.88      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.84      0.89        43
           1       0.77      0.92      0.84        26

    accuracy                           0.87        69
   macro avg       0.86      0.88      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        47
           1       0.68      0.95      0.79        22

    accuracy                           0.84        69
   macro avg       0.83      0.87      0.83        69
weighted avg       0.88      0.84      0.85        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.71      0.80        49
           1       0.53      0.80      0.64        20

    accuracy                           0.74        69
   macro avg       0.72      0.76      0.72        69
weighted avg       0.79      0.74      0.75        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        44
           1       0.67      0.80      0.73        25

    accuracy                           0.78        69
   macro avg       0.77      0.79      0.77        69
weighted avg       0.80      0.78      0.79        69

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.90      0.90        39
           1       0.87      0.87      0.87        30

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8347826086956521
F1: 0.7922789868880982
======================================================
Running australian_credit 75 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.77      0.85        47
           1       0.65      0.91      0.75        22

    accuracy                           0.81        69
   macro avg       0.80      0.84      0.80        69
weighted avg       0.85      0.81      0.82        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        49
           1       0.61      0.95      0.75        20

    accuracy                           0.81        69
   macro avg       0.79      0.85      0.80        69
weighted avg       0.87      0.81      0.82        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        45
           1       0.67      0.83      0.74        24

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.79        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        38
           1       0.87      0.84      0.85        31

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8362318840579709
F1: 0.7970951979115084
======================================================
Running australian_credit 75 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.57      0.67        54
           1       0.26      0.53      0.35        15

    accuracy                           0.57        69
   macro avg       0.54      0.55      0.51        69
weighted avg       0.69      0.57      0.60        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        62
           1       0.16      0.71      0.26         7

    accuracy                           0.59        69
   macro avg       0.55      0.65      0.49        69
weighted avg       0.87      0.59      0.67        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.67      0.77        52
           1       0.43      0.76      0.55        17

    accuracy                           0.70        69
   macro avg       0.67      0.72      0.66        69
weighted avg       0.78      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.58      0.73        65
           1       0.10      0.75      0.18         4

    accuracy                           0.59        69
   macro avg       0.54      0.67      0.45        69
weighted avg       0.92      0.59      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.64      0.76        58
           1       0.30      0.82      0.44        11

    accuracy                           0.67        69
   macro avg       0.62      0.73      0.60        69
weighted avg       0.85      0.67      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6565217391304348
F1: 0.42304962753600883
======================================================
Running australian_credit 75 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4875281546126558
0.4875281546126558
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [317, 199, 105]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5002510752650209
0.49591580429356447
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [303, 308, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6531853052803556
0.6531853052803556
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [321, 284, 16]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5139394530690523
0.5253290853288693
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [20, 325, 284]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4815971652310438
0.4840916369303551
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.90      0.94        41
           1       0.87      0.96      0.92        28

    accuracy                           0.93        69
   macro avg       0.92      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [301, 21, 304]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.49587968391987486
0.49246151552310097
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [330, 208, 84]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4898913741051234
0.48097897904861303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [313, 296, 20]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4840057143134876
0.4840057143134876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.82      0.84        40
           1       0.77      0.79      0.78        29

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [326, 295]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        42
           1       0.83      0.93      0.88        27

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5774272272966645
0.5774272272966645
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [51, 11, 269, 290]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.863768115942029
F1: 0.8444990694274163
======================================================
Running australian_credit 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.92      0.94        39
           1       0.90      0.93      0.92        30

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.94      0.89        34
           1       0.94      0.83      0.88        35

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8681159420289856
F1: 0.8513699146238981
======================================================
Running australian_credit 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.88      0.82        33
           1       0.87      0.75      0.81        36

    accuracy                           0.81        69
   macro avg       0.82      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.95      0.93        37
           1       0.94      0.91      0.92        32

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        40
           1       0.87      0.90      0.88        29

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8782608695652175
F1: 0.8622843768732882
======================================================
Running australian_credit 50 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.90      0.79        30
           1       0.90      0.72      0.80        39

    accuracy                           0.80        69
   macro avg       0.81      0.81      0.80        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.94      0.89        34
           1       0.94      0.83      0.88        35

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.88      0.89        40
           1       0.83      0.86      0.85        29

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8666666666666668
F1: 0.8510037914948386
======================================================
Running australian_credit 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.94      0.89        34
           1       0.94      0.83      0.88        35

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8608695652173914
F1: 0.8449488714402852
======================================================
Running australian_credit 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.92      0.94        39
           1       0.90      0.93      0.92        30

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        42
           1       0.73      0.81      0.77        27

    accuracy                           0.81        69
   macro avg       0.80      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8681159420289856
F1: 0.8492684900927415
======================================================
Running australian_credit 50 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.71      0.82        52
           1       0.52      0.94      0.67        17

    accuracy                           0.77        69
   macro avg       0.74      0.83      0.74        69
weighted avg       0.86      0.77      0.78        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.65      0.78        57
           1       0.35      0.92      0.51        12

    accuracy                           0.70        69
   macro avg       0.66      0.78      0.65        69
weighted avg       0.87      0.70      0.73        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.84      0.90        44
           1       0.77      0.96      0.86        25

    accuracy                           0.88        69
   macro avg       0.87      0.90      0.88        69
weighted avg       0.90      0.88      0.89        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.85        46
           1       0.67      0.87      0.75        23

    accuracy                           0.81        69
   macro avg       0.79      0.83      0.80        69
weighted avg       0.84      0.81      0.82        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        64
           1       0.17      1.00      0.29         5

    accuracy                           0.64        69
   macro avg       0.58      0.80      0.52        69
weighted avg       0.94      0.64      0.72        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        40
           1       0.87      0.90      0.88        29

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8101449275362318
F1: 0.7299641934374017
======================================================
Running australian_credit 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        40
           1       0.87      0.90      0.88        29

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.844927536231884
F1: 0.811284754033571
======================================================
Running australian_credit 50 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        45
           1       0.67      0.83      0.74        24

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.79        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        48
           1       0.67      0.95      0.78        21

    accuracy                           0.84        69
   macro avg       0.82      0.87      0.83        69
weighted avg       0.88      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        40
           1       0.87      0.90      0.88        29

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8507246376811594
F1: 0.8190767850811801
======================================================
Running australian_credit 50 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.57      0.67        54
           1       0.26      0.53      0.35        15

    accuracy                           0.57        69
   macro avg       0.54      0.55      0.51        69
weighted avg       0.69      0.57      0.60        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        62
           1       0.16      0.71      0.26         7

    accuracy                           0.59        69
   macro avg       0.55      0.65      0.49        69
weighted avg       0.87      0.59      0.67        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.65      0.78        57
           1       0.35      0.92      0.51        12

    accuracy                           0.70        69
   macro avg       0.66      0.78      0.65        69
weighted avg       0.87      0.70      0.73        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.67      0.77        52
           1       0.43      0.76      0.55        17

    accuracy                           0.70        69
   macro avg       0.67      0.72      0.66        69
weighted avg       0.78      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.74        64
           1       0.13      0.80      0.23         5

    accuracy                           0.61        69
   macro avg       0.55      0.70      0.48        69
weighted avg       0.91      0.61      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.64      0.76        58
           1       0.30      0.82      0.44        11

    accuracy                           0.67        69
   macro avg       0.62      0.73      0.60        69
weighted avg       0.85      0.67      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6550724637681159
F1: 0.4216447244895189
======================================================
Running australian_credit 50 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.48672476231296663
0.4795378809274016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.84      0.88        76
           1       0.60      0.75      0.67        24

    accuracy                           0.82       100
   macro avg       0.76      0.80      0.77       100
weighted avg       0.84      0.82      0.83       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [408, 36, 459]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.47469196540571695
0.4708297386642019
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True), SVC(probability=True), SVC(probability=True), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [327, 20, 20, 461, 66, 24]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4884257001455196
0.49478629410605013
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        77
           1       0.43      0.57      0.49        23

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.65       100
weighted avg       0.76      0.73      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [426, 20, 463]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.4796614732686855
0.4765905981679584
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.78      0.84        82
           1       0.40      0.67      0.50        18

    accuracy                           0.76       100
   macro avg       0.66      0.72      0.67       100
weighted avg       0.82      0.76      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [424, 24, 454]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.48276300434148933
0.47441835275671274
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        72
           1       0.47      0.50      0.48        28

    accuracy                           0.70       100
   macro avg       0.63      0.64      0.64       100
weighted avg       0.71      0.70      0.70       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [126, 290, 20, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.46793719405749856
0.4650650102952572
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.71      0.77        83
           1       0.20      0.35      0.26        17

    accuracy                           0.65       100
   macro avg       0.52      0.53      0.51       100
weighted avg       0.73      0.65      0.68       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [20, 418, 469]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4765426630678307
0.47731018491516
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [409, 21, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.478089728773841
0.49142745648719743
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.79      0.84        78
           1       0.47      0.64      0.54        22

    accuracy                           0.76       100
   macro avg       0.68      0.72      0.69       100
weighted avg       0.79      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [412, 20, 478]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4917777795431861
0.4986150697447421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.77      0.82        81
           1       0.37      0.58      0.45        19

    accuracy                           0.73       100
   macro avg       0.63      0.67      0.64       100
weighted avg       0.79      0.73      0.75       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [20, 21, 407, 471]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.4903896802145927
0.4899742123972434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        81
           1       0.40      0.63      0.49        19

    accuracy                           0.75       100
   macro avg       0.65      0.70      0.66       100
weighted avg       0.81      0.75      0.77       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [40, 441, 27, 397]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7370000000000001
F1: 0.48652747954212333
======================================================
Running german_credit 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        72
           1       0.57      0.61      0.59        28

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.71       100
weighted avg       0.77      0.76      0.76       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.76      0.81        79
           1       0.37      0.52      0.43        21

    accuracy                           0.71       100
   macro avg       0.61      0.64      0.62       100
weighted avg       0.75      0.71      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.74      0.82        87
           1       0.23      0.54      0.33        13

    accuracy                           0.71       100
   macro avg       0.57      0.64      0.57       100
weighted avg       0.83      0.71      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.73      0.78        81
           1       0.27      0.42      0.33        19

    accuracy                           0.67       100
   macro avg       0.55      0.57      0.55       100
weighted avg       0.73      0.67      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.81      0.88        84
           1       0.47      0.88      0.61        16

    accuracy                           0.82       100
   macro avg       0.72      0.84      0.75       100
weighted avg       0.89      0.82      0.84       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.81      0.84        77
           1       0.50      0.65      0.57        23

    accuracy                           0.77       100
   macro avg       0.69      0.73      0.70       100
weighted avg       0.80      0.77      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.749
F1: 0.4939639473513532
======================================================
Running german_credit 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        72
           1       0.57      0.61      0.59        28

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.71       100
weighted avg       0.77      0.76      0.76       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.76      0.81        79
           1       0.37      0.52      0.43        21

    accuracy                           0.71       100
   macro avg       0.61      0.64      0.62       100
weighted avg       0.75      0.71      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.80      0.87        84
           1       0.43      0.81      0.57        16

    accuracy                           0.80       100
   macro avg       0.70      0.81      0.72       100
weighted avg       0.87      0.80      0.82       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.74      0.82        87
           1       0.23      0.54      0.33        13

    accuracy                           0.71       100
   macro avg       0.57      0.64      0.57       100
weighted avg       0.83      0.71      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.72      0.78        83
           1       0.23      0.41      0.30        17

    accuracy                           0.67       100
   macro avg       0.55      0.57      0.54       100
weighted avg       0.75      0.67      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.79        81
           1       0.30      0.47      0.37        19

    accuracy                           0.69       100
   macro avg       0.58      0.61      0.58       100
weighted avg       0.75      0.69      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.81      0.88        84
           1       0.47      0.88      0.61        16

    accuracy                           0.82       100
   macro avg       0.72      0.84      0.75       100
weighted avg       0.89      0.82      0.84       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.81      0.84        77
           1       0.50      0.65      0.57        23

    accuracy                           0.77       100
   macro avg       0.69      0.73      0.70       100
weighted avg       0.80      0.77      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7459999999999999
F1: 0.4864822127518703
======================================================
Running german_credit 100 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.69      0.81        98
           1       0.00      0.00      0.00         2

    accuracy                           0.68       100
   macro avg       0.49      0.35      0.40       100
weighted avg       0.95      0.68      0.79       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6980000000000001
F1: 0.0
======================================================
Running german_credit 100 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        83
           1       0.40      0.71      0.51        17

    accuracy                           0.77       100
   macro avg       0.66      0.74      0.68       100
weighted avg       0.84      0.77      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        88
           1       0.17      0.42      0.24        12

    accuracy                           0.68       100
   macro avg       0.53      0.57      0.52       100
weighted avg       0.81      0.68      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.83      0.82        69
           1       0.60      0.58      0.59        31

    accuracy                           0.75       100
   macro avg       0.71      0.70      0.71       100
weighted avg       0.75      0.75      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.73      0.77        78
           1       0.30      0.41      0.35        22

    accuracy                           0.66       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.70      0.66      0.68       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.74      0.76        74
           1       0.37      0.42      0.39        26

    accuracy                           0.66       100
   macro avg       0.58      0.58      0.58       100
weighted avg       0.68      0.66      0.67       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        77
           1       0.47      0.61      0.53        23

    accuracy                           0.75       100
   macro avg       0.67      0.70      0.68       100
weighted avg       0.78      0.75      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        77
           1       0.43      0.57      0.49        23

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.65       100
weighted avg       0.76      0.73      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.78      0.80        73
           1       0.47      0.52      0.49        27

    accuracy                           0.71       100
   macro avg       0.64      0.65      0.64       100
weighted avg       0.72      0.71      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7250000000000001
F1: 0.46496711207752045
======================================================
Running german_credit 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.79        81
           1       0.30      0.47      0.37        19

    accuracy                           0.69       100
   macro avg       0.58      0.61      0.58       100
weighted avg       0.75      0.69      0.71       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.80      0.88        86
           1       0.43      0.93      0.59        14

    accuracy                           0.82       100
   macro avg       0.71      0.87      0.74       100
weighted avg       0.91      0.82      0.84       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.79      0.80        72
           1       0.50      0.54      0.52        28

    accuracy                           0.72       100
   macro avg       0.66      0.66      0.66       100
weighted avg       0.73      0.72      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.70      0.75        81
           1       0.20      0.32      0.24        19

    accuracy                           0.63       100
   macro avg       0.51      0.51      0.50       100
weighted avg       0.70      0.63      0.66       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        80
           1       0.30      0.45      0.36        20

    accuracy                           0.68       100
   macro avg       0.57      0.59      0.57       100
weighted avg       0.73      0.68      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.82      0.88        82
           1       0.50      0.83      0.62        18

    accuracy                           0.82       100
   macro avg       0.73      0.83      0.75       100
weighted avg       0.87      0.82      0.84       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.742
F1: 0.48795969585504223
======================================================
Running german_credit 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        76
           1       0.57      0.71      0.63        24

    accuracy                           0.80       100
   macro avg       0.73      0.77      0.75       100
weighted avg       0.82      0.80      0.81       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.79        81
           1       0.30      0.47      0.37        19

    accuracy                           0.69       100
   macro avg       0.58      0.61      0.58       100
weighted avg       0.75      0.69      0.71       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.80      0.88        86
           1       0.43      0.93      0.59        14

    accuracy                           0.82       100
   macro avg       0.71      0.87      0.74       100
weighted avg       0.91      0.82      0.84       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.78      0.80        73
           1       0.47      0.52      0.49        27

    accuracy                           0.71       100
   macro avg       0.64      0.65      0.64       100
weighted avg       0.72      0.71      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.71      0.77        83
           1       0.20      0.35      0.26        17

    accuracy                           0.65       100
   macro avg       0.52      0.53      0.51       100
weighted avg       0.73      0.65      0.68       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.74      0.76        74
           1       0.37      0.42      0.39        26

    accuracy                           0.66       100
   macro avg       0.58      0.58      0.58       100
weighted avg       0.68      0.66      0.67       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.82      0.88        82
           1       0.50      0.83      0.62        18

    accuracy                           0.82       100
   macro avg       0.73      0.83      0.75       100
weighted avg       0.87      0.82      0.84       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7419999999999999
F1: 0.4973300122293084
======================================================
Running german_credit 100 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.29      0.74      0.41        27
           1       0.77      0.32      0.45        73

    accuracy                           0.43       100
   macro avg       0.53      0.53      0.43       100
weighted avg       0.64      0.43      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.68      0.36        25
           1       0.73      0.29      0.42        75

    accuracy                           0.39       100
   macro avg       0.49      0.49      0.39       100
weighted avg       0.61      0.39      0.40       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.65      0.35        26
           1       0.70      0.28      0.40        74

    accuracy                           0.38       100
   macro avg       0.47      0.47      0.38       100
weighted avg       0.58      0.38      0.39       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.63      0.35        27
           1       0.67      0.27      0.39        73

    accuracy                           0.37       100
   macro avg       0.45      0.45      0.37       100
weighted avg       0.55      0.37      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.31      0.76      0.44        29
           1       0.77      0.32      0.46        71

    accuracy                           0.45       100
   macro avg       0.54      0.54      0.45       100
weighted avg       0.64      0.45      0.45       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.88      0.48        26
           1       0.90      0.36      0.52        74

    accuracy                           0.50       100
   macro avg       0.61      0.62      0.50       100
weighted avg       0.75      0.50      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.79      0.40        24
           1       0.83      0.33      0.47        76

    accuracy                           0.44       100
   macro avg       0.55      0.56      0.44       100
weighted avg       0.70      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.20      0.61      0.30        23
           1       0.70      0.27      0.39        77

    accuracy                           0.35       100
   macro avg       0.45      0.44      0.35       100
weighted avg       0.58      0.35      0.37       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.14      0.91      0.25        11
           1       0.97      0.33      0.49        89

    accuracy                           0.39       100
   macro avg       0.55      0.62      0.37       100
weighted avg       0.88      0.39      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.23      0.70      0.34        23
           1       0.77      0.30      0.43        77

    accuracy                           0.39       100
   macro avg       0.50      0.50      0.39       100
weighted avg       0.64      0.39      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.409
F1: 0.4414044520722474
======================================================
Running german_credit 100 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        86
           1       0.33      0.71      0.45        14

    accuracy                           0.76       100
   macro avg       0.64      0.74      0.65       100
weighted avg       0.86      0.76      0.79       100

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.75      0.84        89
           1       0.27      0.73      0.39        11

    accuracy                           0.75       100
   macro avg       0.61      0.74      0.62       100
weighted avg       0.88      0.75      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.71      0.83        97
           1       0.07      0.67      0.12         3

    accuracy                           0.71       100
   macro avg       0.53      0.69      0.47       100
weighted avg       0.96      0.71      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.75      0.84        91
           1       0.23      0.78      0.36         9

    accuracy                           0.75       100
   macro avg       0.60      0.76      0.60       100
weighted avg       0.91      0.75      0.80       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        85
           1       0.20      0.40      0.27        15

    accuracy                           0.67       100
   macro avg       0.54      0.56      0.53       100
weighted avg       0.77      0.67      0.71       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.73      0.81        86
           1       0.23      0.50      0.32        14

    accuracy                           0.70       100
   macro avg       0.57      0.62      0.56       100
weighted avg       0.81      0.70      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.76      0.86        91
           1       0.27      0.89      0.41         9

    accuracy                           0.77       100
   macro avg       0.63      0.82      0.63       100
weighted avg       0.92      0.77      0.82       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.86        89
           1       0.30      0.82      0.44        11

    accuracy                           0.77       100
   macro avg       0.64      0.79      0.65       100
weighted avg       0.90      0.77      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.734
F1: 0.36552252727074913
======================================================
Running german_credit 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.72      0.83        96
           1       0.10      0.75      0.18         4

    accuracy                           0.72       100
   macro avg       0.54      0.73      0.50       100
weighted avg       0.95      0.72      0.81       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.75      0.81        83
           1       0.30      0.53      0.38        17

    accuracy                           0.71       100
   macro avg       0.59      0.64      0.60       100
weighted avg       0.79      0.71      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        86
           1       0.13      0.29      0.18        14

    accuracy                           0.64       100
   macro avg       0.50      0.49      0.48       100
weighted avg       0.76      0.64      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        91
           1       0.17      0.56      0.26         9

    accuracy                           0.71       100
   macro avg       0.55      0.64      0.54       100
weighted avg       0.87      0.71      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6980000000000001
F1: 0.09976777498679876
======================================================
Running german_credit 100 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.72      0.83        96
           1       0.10      0.75      0.18         4

    accuracy                           0.72       100
   macro avg       0.54      0.73      0.50       100
weighted avg       0.95      0.72      0.81       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.74      0.80        82
           1       0.30      0.50      0.38        18

    accuracy                           0.70       100
   macro avg       0.59      0.62      0.59       100
weighted avg       0.77      0.70      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.69      0.76        85
           1       0.13      0.27      0.18        15

    accuracy                           0.63       100
   macro avg       0.49      0.48      0.47       100
weighted avg       0.74      0.63      0.67       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.73      0.81        86
           1       0.23      0.50      0.32        14

    accuracy                           0.70       100
   macro avg       0.57      0.62      0.56       100
weighted avg       0.81      0.70      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6950000000000001
F1: 0.104743018419489
======================================================
Running german_credit 100 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        85
           1       0.40      0.80      0.53        15

    accuracy                           0.79       100
   macro avg       0.68      0.79      0.70       100
weighted avg       0.87      0.79      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        92
           1       0.20      0.75      0.32         8

    accuracy                           0.74       100
   macro avg       0.59      0.74      0.58       100
weighted avg       0.91      0.74      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.73      0.82        89
           1       0.20      0.55      0.29        11

    accuracy                           0.71       100
   macro avg       0.56      0.64      0.56       100
weighted avg       0.85      0.71      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.74      0.85        94
           1       0.20      1.00      0.33         6

    accuracy                           0.76       100
   macro avg       0.60      0.87      0.59       100
weighted avg       0.95      0.76      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.76      0.82        82
           1       0.33      0.56      0.42        18

    accuracy                           0.72       100
   macro avg       0.61      0.66      0.62       100
weighted avg       0.79      0.72      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        82
           1       0.23      0.39      0.29        18

    accuracy                           0.66       100
   macro avg       0.54      0.55      0.53       100
weighted avg       0.73      0.66      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        91
           1       0.17      0.56      0.26         9

    accuracy                           0.71       100
   macro avg       0.55      0.64      0.54       100
weighted avg       0.87      0.71      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        89
           1       0.37      1.00      0.54        11

    accuracy                           0.81       100
   macro avg       0.68      0.89      0.71       100
weighted avg       0.93      0.81      0.84       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.84        88
           1       0.27      0.67      0.38        12

    accuracy                           0.74       100
   macro avg       0.60      0.71      0.61       100
weighted avg       0.86      0.74      0.78       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.74      0.81        84
           1       0.27      0.50      0.35        16

    accuracy                           0.70       100
   macro avg       0.58      0.62      0.58       100
weighted avg       0.79      0.70      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7340000000000001
F1: 0.3705246490686297
======================================================
Running german_credit 100 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
CBEG               precision    recall  f1-score   support

           0       0.50      0.70      0.58        50
           1       0.50      0.30      0.38        50

    accuracy                           0.50       100
   macro avg       0.50      0.50      0.48       100
weighted avg       0.50      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
CBEG               precision    recall  f1-score   support

           0       0.47      0.65      0.55        51
           1       0.40      0.24      0.30        49

    accuracy                           0.45       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
CBEG               precision    recall  f1-score   support

           0       0.40      0.68      0.50        41
           1       0.57      0.29      0.38        59

    accuracy                           0.45       100
   macro avg       0.48      0.49      0.44       100
weighted avg       0.50      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48200000000000004
F1: 0.3958830841974384
======================================================
Running german_credit 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6300000000000001
F1: 0.17661300012014897
======================================================
Running german_credit 100 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6300000000000001
F1: 0.17661300012014897
======================================================
Running german_credit 100 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.69      0.57        49
           1       0.50      0.29      0.37        51

    accuracy                           0.49       100
   macro avg       0.49      0.49      0.47       100
weighted avg       0.49      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.40      0.68      0.50        41
           1       0.57      0.29      0.38        59

    accuracy                           0.45       100
   macro avg       0.48      0.49      0.44       100
weighted avg       0.50      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.479
F1: 0.3979815508696206
======================================================
Running german_credit 100 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.48672476231296663
0.4795378809274016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.84      0.87        75
           1       0.60      0.72      0.65        25

    accuracy                           0.81       100
   macro avg       0.75      0.78      0.76       100
weighted avg       0.82      0.81      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [408, 36, 459]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.47469196540571695
0.4708297386642019
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.82      0.86        78
           1       0.53      0.73      0.62        22

    accuracy                           0.80       100
   macro avg       0.72      0.77      0.74       100
weighted avg       0.83      0.80      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), SVC(probability=True), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [327, 20, 20, 461, 66, 24]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4884257001455196
0.49478629410605013
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.75      0.81        83
           1       0.30      0.53      0.38        17

    accuracy                           0.71       100
   macro avg       0.59      0.64      0.60       100
weighted avg       0.79      0.71      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [426, 20, 463]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.4796614732686855
0.4765905981679584
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [424, 24, 454]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.48276300434148933
0.47441835275671274
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [126, 290, 20, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.46793719405749856
0.4650650102952572
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.70      0.78        88
           1       0.13      0.33      0.19        12

    accuracy                           0.66       100
   macro avg       0.51      0.52      0.49       100
weighted avg       0.80      0.66      0.71       100

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [20, 418, 469]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4765426630678307
0.47731018491516
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.77      0.79        74
           1       0.43      0.50      0.46        26

    accuracy                           0.70       100
   macro avg       0.62      0.64      0.63       100
weighted avg       0.72      0.70      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [409, 21, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.478089728773841
0.49142745648719743
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        78
           1       0.50      0.68      0.58        22

    accuracy                           0.78       100
   macro avg       0.70      0.74      0.71       100
weighted avg       0.81      0.78      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [412, 20, 478]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4917777795431861
0.4986150697447421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [20, 21, 407, 471]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.4903896802145927
0.4899742123972434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.79      0.84        78
           1       0.47      0.64      0.54        22

    accuracy                           0.76       100
   macro avg       0.68      0.72      0.69       100
weighted avg       0.79      0.76      0.77       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [40, 441, 27, 397]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746
F1: 0.5048716689142221
======================================================
Running german_credit 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        82
           1       0.27      0.44      0.33        18

    accuracy                           0.68       100
   macro avg       0.56      0.59      0.56       100
weighted avg       0.75      0.68      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.71      0.77        83
           1       0.20      0.35      0.26        17

    accuracy                           0.65       100
   macro avg       0.52      0.53      0.51       100
weighted avg       0.73      0.65      0.68       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        74
           1       0.57      0.65      0.61        26

    accuracy                           0.78       100
   macro avg       0.72      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7390000000000001
F1: 0.48148797416624767
======================================================
Running german_credit 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        82
           1       0.27      0.44      0.33        18

    accuracy                           0.68       100
   macro avg       0.56      0.59      0.56       100
weighted avg       0.75      0.68      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        77
           1       0.47      0.61      0.53        23

    accuracy                           0.75       100
   macro avg       0.67      0.70      0.68       100
weighted avg       0.78      0.75      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        82
           1       0.23      0.39      0.29        18

    accuracy                           0.66       100
   macro avg       0.54      0.55      0.53       100
weighted avg       0.73      0.66      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        74
           1       0.57      0.65      0.61        26

    accuracy                           0.78       100
   macro avg       0.72      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.741
F1: 0.48438148604711395
======================================================
Running german_credit 75 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        81
           1       0.40      0.63      0.49        19

    accuracy                           0.75       100
   macro avg       0.65      0.70      0.66       100
weighted avg       0.81      0.75      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        85
           1       0.43      0.87      0.58        15

    accuracy                           0.81       100
   macro avg       0.70      0.83      0.73       100
weighted avg       0.89      0.81      0.83       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.73      0.80        83
           1       0.27      0.47      0.34        17

    accuracy                           0.69       100
   macro avg       0.57      0.60      0.57       100
weighted avg       0.77      0.69      0.72       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.76      0.77        72
           1       0.43      0.46      0.45        28

    accuracy                           0.68       100
   macro avg       0.61      0.61      0.61       100
weighted avg       0.69      0.68      0.68       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.73      0.78        81
           1       0.27      0.42      0.33        19

    accuracy                           0.67       100
   macro avg       0.55      0.57      0.55       100
weighted avg       0.73      0.67      0.70       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.74      0.80        82
           1       0.30      0.50      0.38        18

    accuracy                           0.70       100
   macro avg       0.59      0.62      0.59       100
weighted avg       0.77      0.70      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.77      0.78        71
           1       0.47      0.48      0.47        29

    accuracy                           0.69       100
   macro avg       0.63      0.63      0.63       100
weighted avg       0.69      0.69      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7299999999999999
F1: 0.4727519236446745
======================================================
Running german_credit 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.85        87
           1       0.33      0.77      0.47        13

    accuracy                           0.77       100
   macro avg       0.65      0.77      0.66       100
weighted avg       0.88      0.77      0.80       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.74      0.81        84
           1       0.27      0.50      0.35        16

    accuracy                           0.70       100
   macro avg       0.58      0.62      0.58       100
weighted avg       0.79      0.70      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        88
           1       0.33      0.83      0.48        12

    accuracy                           0.78       100
   macro avg       0.65      0.80      0.67       100
weighted avg       0.89      0.78      0.81       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.81      0.81        70
           1       0.57      0.57      0.57        30

    accuracy                           0.74       100
   macro avg       0.69      0.69      0.69       100
weighted avg       0.74      0.74      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.72      0.77        80
           1       0.27      0.40      0.32        20

    accuracy                           0.66       100
   macro avg       0.55      0.56      0.55       100
weighted avg       0.72      0.66      0.68       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.76      0.81        79
           1       0.37      0.52      0.43        21

    accuracy                           0.71       100
   macro avg       0.61      0.64      0.62       100
weighted avg       0.75      0.71      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        75
           1       0.53      0.64      0.58        25

    accuracy                           0.77       100
   macro avg       0.70      0.73      0.71       100
weighted avg       0.79      0.77      0.78       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.83        73
           1       0.53      0.59      0.56        27

    accuracy                           0.75       100
   macro avg       0.69      0.70      0.69       100
weighted avg       0.76      0.75      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.739
F1: 0.4851403849503252
======================================================
Running german_credit 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        85
           1       0.37      0.73      0.49        15

    accuracy                           0.77       100
   macro avg       0.65      0.75      0.67       100
weighted avg       0.86      0.77      0.80       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.74      0.81        84
           1       0.27      0.50      0.35        16

    accuracy                           0.70       100
   macro avg       0.58      0.62      0.58       100
weighted avg       0.79      0.70      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        88
           1       0.33      0.83      0.48        12

    accuracy                           0.78       100
   macro avg       0.65      0.80      0.67       100
weighted avg       0.89      0.78      0.81       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.79      0.81        73
           1       0.50      0.56      0.53        27

    accuracy                           0.73       100
   macro avg       0.66      0.68      0.67       100
weighted avg       0.74      0.73      0.73       100

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        80
           1       0.30      0.45      0.36        20

    accuracy                           0.68       100
   macro avg       0.57      0.59      0.57       100
weighted avg       0.73      0.68      0.70       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        75
           1       0.53      0.64      0.58        25

    accuracy                           0.77       100
   macro avg       0.70      0.73      0.71       100
weighted avg       0.79      0.77      0.78       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.83        73
           1       0.53      0.59      0.56        27

    accuracy                           0.75       100
   macro avg       0.69      0.70      0.69       100
weighted avg       0.76      0.75      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.739
F1: 0.48434530331097836
======================================================
Running german_credit 75 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.76      0.83        86
           1       0.30      0.64      0.41        14

    accuracy                           0.74       100
   macro avg       0.61      0.70      0.62       100
weighted avg       0.84      0.74      0.77       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        88
           1       0.33      0.83      0.48        12

    accuracy                           0.78       100
   macro avg       0.65      0.80      0.67       100
weighted avg       0.89      0.78      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.74      0.83        91
           1       0.20      0.67      0.31         9

    accuracy                           0.73       100
   macro avg       0.58      0.70      0.57       100
weighted avg       0.89      0.73      0.79       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        93
           1       0.23      1.00      0.38         7

    accuracy                           0.77       100
   macro avg       0.62      0.88      0.62       100
weighted avg       0.95      0.77      0.83       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.75      0.81        81
           1       0.33      0.53      0.41        19

    accuracy                           0.71       100
   macro avg       0.60      0.64      0.61       100
weighted avg       0.77      0.71      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.72      0.83        94
           1       0.13      0.67      0.22         6

    accuracy                           0.72       100
   macro avg       0.55      0.70      0.53       100
weighted avg       0.92      0.72      0.79       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.72      0.82        93
           1       0.13      0.57      0.22         7

    accuracy                           0.71       100
   macro avg       0.55      0.65      0.52       100
weighted avg       0.90      0.71      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        85
           1       0.40      0.80      0.53        15

    accuracy                           0.79       100
   macro avg       0.68      0.79      0.70       100
weighted avg       0.87      0.79      0.81       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        88
           1       0.23      0.58      0.33        12

    accuracy                           0.72       100
   macro avg       0.58      0.66      0.58       100
weighted avg       0.85      0.72      0.76       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.74      0.80        82
           1       0.30      0.50      0.38        18

    accuracy                           0.70       100
   macro avg       0.59      0.62      0.59       100
weighted avg       0.77      0.70      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7369999999999999
F1: 0.36596204417632994
======================================================
Running german_credit 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.75      0.84        89
           1       0.27      0.73      0.39        11

    accuracy                           0.75       100
   macro avg       0.61      0.74      0.62       100
weighted avg       0.88      0.75      0.79       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        80
           1       0.40      0.60      0.48        20

    accuracy                           0.74       100
   macro avg       0.64      0.69      0.65       100
weighted avg       0.79      0.74      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.71      0.79        87
           1       0.17      0.38      0.23        13

    accuracy                           0.67       100
   macro avg       0.53      0.55      0.51       100
weighted avg       0.79      0.67      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.71      0.82        94
           1       0.10      0.50      0.17         6

    accuracy                           0.70       100
   macro avg       0.53      0.61      0.49       100
weighted avg       0.91      0.70      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7060000000000001
F1: 0.12694687086405748
======================================================
Running german_credit 75 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        88
           1       0.30      0.75      0.43        12

    accuracy                           0.76       100
   macro avg       0.63      0.76      0.64       100
weighted avg       0.88      0.76      0.80       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.71      0.79        87
           1       0.17      0.38      0.23        13

    accuracy                           0.67       100
   macro avg       0.53      0.55      0.51       100
weighted avg       0.79      0.67      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.71      0.82        94
           1       0.10      0.50      0.17         6

    accuracy                           0.70       100
   macro avg       0.53      0.61      0.49       100
weighted avg       0.91      0.70      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7060000000000001
F1: 0.12983844700670966
======================================================
Running german_credit 75 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.43      0.68      0.53        44
           1       0.53      0.29      0.37        56

    accuracy                           0.46       100
   macro avg       0.48      0.48      0.45       100
weighted avg       0.49      0.46      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.71      0.48        35
           1       0.67      0.31      0.42        65

    accuracy                           0.45       100
   macro avg       0.51      0.51      0.45       100
weighted avg       0.56      0.45      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.62      0.45        40
           1       0.50      0.25      0.33        60

    accuracy                           0.40       100
   macro avg       0.43      0.44      0.39       100
weighted avg       0.44      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.62      0.45        40
           1       0.50      0.25      0.33        60

    accuracy                           0.40       100
   macro avg       0.43      0.44      0.39       100
weighted avg       0.44      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.70      0.66        63
           1       0.37      0.30      0.33        37

    accuracy                           0.55       100
   macro avg       0.50      0.50      0.50       100
weighted avg       0.53      0.55      0.54       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.51      0.84      0.64        43
           1       0.77      0.40      0.53        57

    accuracy                           0.59       100
   macro avg       0.64      0.62      0.58       100
weighted avg       0.66      0.59      0.58       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.73      0.68        60
           1       0.47      0.35      0.40        40

    accuracy                           0.58       100
   macro avg       0.55      0.54      0.54       100
weighted avg       0.56      0.58      0.57       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.67      0.48        39
           1       0.57      0.28      0.37        61

    accuracy                           0.43       100
   macro avg       0.47      0.47      0.43       100
weighted avg       0.49      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.23      0.80      0.36        20
           1       0.87      0.33      0.47        80

    accuracy                           0.42       100
   macro avg       0.55      0.56      0.41       100
weighted avg       0.74      0.42      0.45       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.68      0.48        38
           1       0.60      0.29      0.39        62

    accuracy                           0.44       100
   macro avg       0.49      0.49      0.44       100
weighted avg       0.51      0.44      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4720000000000001
F1: 0.3954564156820293
======================================================
Running german_credit 75 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.48672476231296663
0.4795378809274016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        75
           1       0.57      0.68      0.62        25

    accuracy                           0.79       100
   macro avg       0.73      0.75      0.74       100
weighted avg       0.81      0.79      0.80       100

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [408, 36, 459]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.47469196540571695
0.4708297386642019
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        77
           1       0.43      0.57      0.49        23

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.65       100
weighted avg       0.76      0.73      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), SVC(probability=True), LogisticRegression(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [327, 20, 20, 461, 66, 24]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4884257001455196
0.49478629410605013
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        88
           1       0.23      0.58      0.33        12

    accuracy                           0.72       100
   macro avg       0.58      0.66      0.58       100
weighted avg       0.85      0.72      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [426, 20, 463]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.4796614732686855
0.4765905981679584
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.76      0.83        84
           1       0.33      0.62      0.43        16

    accuracy                           0.74       100
   macro avg       0.62      0.69      0.63       100
weighted avg       0.82      0.74      0.77       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [424, 24, 454]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.48276300434148933
0.47441835275671274
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.75      0.77        73
           1       0.40      0.44      0.42        27

    accuracy                           0.67       100
   macro avg       0.59      0.60      0.60       100
weighted avg       0.68      0.67      0.68       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [126, 290, 20, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.46793719405749856
0.4650650102952572
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [20, 418, 469]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.4765426630678307
0.47731018491516
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        80
           1       0.37      0.55      0.44        20

    accuracy                           0.72       100
   macro avg       0.62      0.66      0.63       100
weighted avg       0.77      0.72      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [409, 21, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.478089728773841
0.49142745648719743
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.82      0.86        78
           1       0.53      0.73      0.62        22

    accuracy                           0.80       100
   macro avg       0.72      0.77      0.74       100
weighted avg       0.83      0.80      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [412, 20, 478]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4917777795431861
0.4986150697447421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.81      0.81        69
           1       0.57      0.55      0.56        31

    accuracy                           0.73       100
   macro avg       0.68      0.68      0.68       100
weighted avg       0.73      0.73      0.73       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [20, 21, 407, 471]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.4903896802145927
0.4899742123972434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [40, 441, 27, 397]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7410000000000001
F1: 0.4857949139418943
======================================================
Running german_credit 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.78      0.80        73
           1       0.47      0.52      0.49        27

    accuracy                           0.71       100
   macro avg       0.64      0.65      0.64       100
weighted avg       0.72      0.71      0.71       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.79      0.85        81
           1       0.43      0.68      0.53        19

    accuracy                           0.77       100
   macro avg       0.67      0.74      0.69       100
weighted avg       0.82      0.77      0.79       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.79      0.80        72
           1       0.50      0.54      0.52        28

    accuracy                           0.72       100
   macro avg       0.66      0.66      0.66       100
weighted avg       0.73      0.72      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        88
           1       0.23      0.58      0.33        12

    accuracy                           0.72       100
   macro avg       0.58      0.66      0.58       100
weighted avg       0.85      0.72      0.76       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.76      0.81        79
           1       0.37      0.52      0.43        21

    accuracy                           0.71       100
   macro avg       0.61      0.64      0.62       100
weighted avg       0.75      0.71      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        76
           1       0.53      0.67      0.59        24

    accuracy                           0.78       100
   macro avg       0.71      0.74      0.72       100
weighted avg       0.80      0.78      0.79       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7350000000000001
F1: 0.48482008976205926
======================================================
Running german_credit 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        72
           1       0.47      0.50      0.48        28

    accuracy                           0.70       100
   macro avg       0.63      0.64      0.64       100
weighted avg       0.71      0.70      0.70       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.79      0.85        81
           1       0.43      0.68      0.53        19

    accuracy                           0.77       100
   macro avg       0.67      0.74      0.69       100
weighted avg       0.82      0.77      0.79       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.79      0.80        72
           1       0.50      0.54      0.52        28

    accuracy                           0.72       100
   macro avg       0.66      0.66      0.66       100
weighted avg       0.73      0.72      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.74      0.78        78
           1       0.33      0.45      0.38        22

    accuracy                           0.68       100
   macro avg       0.58      0.60      0.58       100
weighted avg       0.72      0.68      0.70       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.75      0.81        83
           1       0.30      0.53      0.38        17

    accuracy                           0.71       100
   macro avg       0.59      0.64      0.60       100
weighted avg       0.79      0.71      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        76
           1       0.53      0.67      0.59        24

    accuracy                           0.78       100
   macro avg       0.71      0.74      0.72       100
weighted avg       0.80      0.78      0.79       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.73
F1: 0.48426196738015087
======================================================
Running german_credit 50 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.82      0.86        77
           1       0.53      0.70      0.60        23

    accuracy                           0.79       100
   macro avg       0.72      0.76      0.73       100
weighted avg       0.82      0.79      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.73      0.78        81
           1       0.27      0.42      0.33        19

    accuracy                           0.67       100
   macro avg       0.55      0.57      0.55       100
weighted avg       0.73      0.67      0.70       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        77
           1       0.47      0.61      0.53        23

    accuracy                           0.75       100
   macro avg       0.67      0.70      0.68       100
weighted avg       0.78      0.75      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.81      0.82        72
           1       0.53      0.57      0.55        28

    accuracy                           0.74       100
   macro avg       0.68      0.69      0.68       100
weighted avg       0.75      0.74      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        84
           1       0.30      0.56      0.39        16

    accuracy                           0.72       100
   macro avg       0.60      0.66      0.60       100
weighted avg       0.80      0.72      0.75       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        80
           1       0.30      0.45      0.36        20

    accuracy                           0.68       100
   macro avg       0.57      0.59      0.57       100
weighted avg       0.73      0.68      0.70       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        81
           1       0.40      0.63      0.49        19

    accuracy                           0.75       100
   macro avg       0.65      0.70      0.66       100
weighted avg       0.81      0.75      0.77       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.77      0.80        77
           1       0.40      0.52      0.45        23

    accuracy                           0.71       100
   macro avg       0.62      0.64      0.63       100
weighted avg       0.74      0.71      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7350000000000001
F1: 0.4745999807181507
======================================================
Running german_credit 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        88
           1       0.17      0.42      0.24        12

    accuracy                           0.68       100
   macro avg       0.53      0.57      0.52       100
weighted avg       0.81      0.68      0.73       100

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.71      0.76        80
           1       0.23      0.35      0.28        20

    accuracy                           0.64       100
   macro avg       0.52      0.53      0.52       100
weighted avg       0.70      0.64      0.66       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        80
           1       0.37      0.55      0.44        20

    accuracy                           0.72       100
   macro avg       0.62      0.66      0.63       100
weighted avg       0.77      0.72      0.74       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7240000000000001
F1: 0.4427835549005762
======================================================
Running german_credit 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        80
           1       0.37      0.55      0.44        20

    accuracy                           0.72       100
   macro avg       0.62      0.66      0.63       100
weighted avg       0.77      0.72      0.74       100

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.70      0.76        83
           1       0.17      0.29      0.21        17

    accuracy                           0.63       100
   macro avg       0.50      0.50      0.49       100
weighted avg       0.72      0.63      0.67       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        80
           1       0.37      0.55      0.44        20

    accuracy                           0.72       100
   macro avg       0.62      0.66      0.63       100
weighted avg       0.77      0.72      0.74       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7220000000000001
F1: 0.43579396721628294
======================================================
Running german_credit 50 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.76      0.83        86
           1       0.30      0.64      0.41        14

    accuracy                           0.74       100
   macro avg       0.61      0.70      0.62       100
weighted avg       0.84      0.74      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.72      0.81        92
           1       0.13      0.50      0.21         8

    accuracy                           0.70       100
   macro avg       0.54      0.61      0.51       100
weighted avg       0.88      0.70      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        90
           1       0.27      0.80      0.40        10

    accuracy                           0.76       100
   macro avg       0.62      0.78      0.62       100
weighted avg       0.90      0.76      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        80
           1       0.37      0.55      0.44        20

    accuracy                           0.72       100
   macro avg       0.62      0.66      0.63       100
weighted avg       0.77      0.72      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.72      0.81        89
           1       0.17      0.45      0.24        11

    accuracy                           0.69       100
   macro avg       0.54      0.59      0.52       100
weighted avg       0.83      0.69      0.74       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        88
           1       0.30      0.75      0.43        12

    accuracy                           0.76       100
   macro avg       0.63      0.76      0.64       100
weighted avg       0.88      0.76      0.80       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.74      0.80        82
           1       0.30      0.50      0.38        18

    accuracy                           0.70       100
   macro avg       0.59      0.62      0.59       100
weighted avg       0.77      0.70      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.73
F1: 0.3622307016902652
======================================================
Running german_credit 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.70      0.80        91
           1       0.10      0.33      0.15         9

    accuracy                           0.67       100
   macro avg       0.51      0.52      0.47       100
weighted avg       0.84      0.67      0.74       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.75      0.81        83
           1       0.30      0.53      0.38        17

    accuracy                           0.71       100
   macro avg       0.59      0.64      0.60       100
weighted avg       0.79      0.71      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.71      0.82        96
           1       0.07      0.50      0.12         4

    accuracy                           0.70       100
   macro avg       0.52      0.60      0.47       100
weighted avg       0.94      0.70      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6970000000000001
F1: 0.08596001412021438
======================================================
Running german_credit 50 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.39102851546635775
0.39102851546635775
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.71      0.81        93
           1       0.10      0.43      0.16         7

    accuracy                           0.69       100
   macro avg       0.52      0.57      0.49       100
weighted avg       0.88      0.69      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39738877033519515
0.39738877033519515
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.2808775660724787
0.2807947630292322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [889, 20]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.75      0.81        83
           1       0.30      0.53      0.38        17

    accuracy                           0.71       100
   macro avg       0.59      0.64      0.60       100
weighted avg       0.79      0.71      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.72      0.81        92
           1       0.13      0.50      0.21         8

    accuracy                           0.70       100
   macro avg       0.54      0.61      0.51       100
weighted avg       0.88      0.70      0.77       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.71      0.82        96
           1       0.07      0.50      0.12         4

    accuracy                           0.70       100
   macro avg       0.52      0.60      0.47       100
weighted avg       0.94      0.70      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.3967416750997974
0.3967416750997974
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.396966214693609
0.396966214693609
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.39706850107612046
0.39706850107612046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82       100
           1       0.00      0.00      0.00         0

    accuracy                           0.70       100
   macro avg       0.50      0.35      0.41       100
weighted avg       1.00      0.70      0.82       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [890, 10]
Selected clustering_algorithm: spectral
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7
F1: 0.08733142601794205
======================================================
Running german_credit 50 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.70      0.45        33
           1       0.67      0.30      0.41        67

    accuracy                           0.43       100
   macro avg       0.50      0.50      0.43       100
weighted avg       0.56      0.43      0.42       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.30      0.75      0.43        28
           1       0.77      0.32      0.45        72

    accuracy                           0.44       100
   macro avg       0.53      0.53      0.44       100
weighted avg       0.64      0.44      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.75      0.68        59
           1       0.50      0.37      0.42        41

    accuracy                           0.59       100
   macro avg       0.56      0.56      0.55       100
weighted avg       0.58      0.59      0.58       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.62      0.46        42
           1       0.47      0.24      0.32        58

    accuracy                           0.40       100
   macro avg       0.42      0.43      0.39       100
weighted avg       0.43      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.68      0.68        69
           1       0.27      0.26      0.26        31

    accuracy                           0.55       100
   macro avg       0.47      0.47      0.47       100
weighted avg       0.55      0.55      0.55       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.84      0.51        31
           1       0.83      0.36      0.51        69

    accuracy                           0.51       100
   macro avg       0.60      0.60      0.51       100
weighted avg       0.69      0.51      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.73      0.70        64
           1       0.43      0.36      0.39        36

    accuracy                           0.60       100
   macro avg       0.55      0.55      0.55       100
weighted avg       0.59      0.60      0.59       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.30      0.64      0.41        33
           1       0.60      0.27      0.37        67

    accuracy                           0.39       100
   macro avg       0.45      0.45      0.39       100
weighted avg       0.50      0.39      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.24      0.77      0.37        22
           1       0.83      0.32      0.46        78

    accuracy                           0.42       100
   macro avg       0.54      0.55      0.42       100
weighted avg       0.70      0.42      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.40      0.74      0.52        38
           1       0.67      0.32      0.43        62

    accuracy                           0.48       100
   macro avg       0.53      0.53      0.48       100
weighted avg       0.57      0.48      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48100000000000004
F1: 0.4034233128861189
======================================================
Running german_credit 50 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        60
           1       0.38      0.62      0.47        21
           2       0.60      0.46      0.52        67

    accuracy                           0.56       148
   macro avg       0.54      0.58      0.54       148
weighted avg       0.58      0.56      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.73      0.74        64
           1       0.32      0.61      0.42        18
           2       0.73      0.56      0.63        66

    accuracy                           0.64       148
   macro avg       0.60      0.64      0.60       148
weighted avg       0.69      0.64      0.65       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.62      0.60        58
           1       0.35      0.46      0.40        26
           2       0.61      0.48      0.54        64

    accuracy                           0.53       148
   macro avg       0.51      0.52      0.51       148
weighted avg       0.55      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.58      0.58        64
           1       0.27      0.56      0.37        16
           2       0.53      0.40      0.46        67

    accuracy                           0.50       147
   macro avg       0.46      0.51      0.47       147
weighted avg       0.53      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.59      0.68        85
           1       0.27      0.75      0.40        12
           2       0.49      0.50      0.50        50

    accuracy                           0.57       147
   macro avg       0.52      0.61      0.52       147
weighted avg       0.65      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.27      0.35      0.31        26
           2       0.51      0.54      0.53        48

    accuracy                           0.56       147
   macro avg       0.51      0.52      0.51       147
weighted avg       0.59      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        71
           1       0.21      0.50      0.30        14
           2       0.65      0.53      0.58        62

    accuracy                           0.59       147
   macro avg       0.53      0.56      0.52       147
weighted avg       0.65      0.59      0.61       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.77      0.72        56
           1       0.52      0.47      0.49        36
           2       0.55      0.51      0.53        55

    accuracy                           0.60       147
   macro avg       0.58      0.58      0.58       147
weighted avg       0.59      0.60      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.58      0.55        57
           1       0.58      0.47      0.52        40
           2       0.43      0.44      0.44        50

    accuracy                           0.50       147
   macro avg       0.51      0.50      0.50       147
weighted avg       0.51      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.65      0.67        68
           1       0.24      0.40      0.30        20
           2       0.59      0.51      0.55        59

    accuracy                           0.56       147
   macro avg       0.51      0.52      0.51       147
weighted avg       0.59      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.561403750689465
F1: 0.5531981365369327
======================================================
Running contraceptive 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.64      0.63        61
           1       0.35      0.50      0.41        24
           2       0.58      0.48      0.52        63

    accuracy                           0.55       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.68      0.69        65
           1       0.44      0.58      0.50        26
           2       0.59      0.53      0.56        57

    accuracy                           0.60       148
   macro avg       0.58      0.59      0.58       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.61      0.62        66
           1       0.24      0.36      0.29        22
           2       0.55      0.47      0.50        60

    accuracy                           0.51       148
   macro avg       0.47      0.48      0.47       148
weighted avg       0.54      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.62        65
           1       0.33      0.52      0.41        21
           2       0.51      0.43      0.46        61

    accuracy                           0.52       147
   macro avg       0.49      0.52      0.50       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.61      0.69        80
           1       0.39      0.50      0.44        26
           2       0.47      0.59      0.52        41

    accuracy                           0.59       147
   macro avg       0.55      0.57      0.55       147
weighted avg       0.62      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.67      0.68        64
           1       0.30      0.38      0.34        26
           2       0.53      0.47      0.50        57

    accuracy                           0.54       147
   macro avg       0.50      0.51      0.51       147
weighted avg       0.56      0.54      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.62      0.66        71
           1       0.27      0.47      0.35        19
           2       0.61      0.54      0.57        57

    accuracy                           0.57       147
   macro avg       0.53      0.55      0.53       147
weighted avg       0.61      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.70      0.68        60
           1       0.45      0.42      0.43        36
           2       0.43      0.43      0.43        51

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.53      0.54      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.59      0.57        59
           1       0.55      0.49      0.51        37
           2       0.45      0.45      0.45        51

    accuracy                           0.52       147
   macro avg       0.52      0.51      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.68      0.68        63
           1       0.30      0.43      0.36        23
           2       0.57      0.48      0.52        61

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5498896856039713
F1: 0.544872789587093
======================================================
Running contraceptive 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.64      0.63        61
           1       0.35      0.50      0.41        24
           2       0.58      0.48      0.52        63

    accuracy                           0.55       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.68      0.69        65
           1       0.44      0.58      0.50        26
           2       0.59      0.53      0.56        57

    accuracy                           0.60       148
   macro avg       0.58      0.59      0.58       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.61      0.62        66
           1       0.24      0.36      0.29        22
           2       0.55      0.47      0.50        60

    accuracy                           0.51       148
   macro avg       0.47      0.48      0.47       148
weighted avg       0.54      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.66      0.66        62
           1       0.48      0.53      0.51        30
           2       0.53      0.49      0.51        55

    accuracy                           0.57       147
   macro avg       0.56      0.56      0.56       147
weighted avg       0.57      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.58      0.67        86
           1       0.30      0.67      0.42        15
           2       0.47      0.52      0.49        46

    accuracy                           0.57       147
   macro avg       0.52      0.59      0.53       147
weighted avg       0.64      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.63      0.64        65
           1       0.52      0.49      0.50        35
           2       0.47      0.51      0.49        47

    accuracy                           0.56       147
   macro avg       0.55      0.54      0.54       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.62      0.66        71
           1       0.27      0.50      0.35        18
           2       0.61      0.53      0.57        58

    accuracy                           0.57       147
   macro avg       0.53      0.55      0.53       147
weighted avg       0.61      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.70      0.68        60
           1       0.45      0.42      0.43        36
           2       0.43      0.43      0.43        51

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.53      0.54      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.59      0.57        59
           1       0.55      0.49      0.51        37
           2       0.45      0.45      0.45        51

    accuracy                           0.52       147
   macro avg       0.52      0.51      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.68      0.68        63
           1       0.30      0.43      0.36        23
           2       0.57      0.48      0.52        61

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5546515903658761
F1: 0.5496092570178641
======================================================
Running contraceptive 100 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.69      0.63      0.66        68
           1       0.32      0.50      0.39        22
           2       0.52      0.47      0.49        58

    accuracy                           0.55       148
   macro avg       0.51      0.53      0.52       148
weighted avg       0.57      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.81      0.63      0.71        81
           1       0.35      0.60      0.44        20
           2       0.57      0.62      0.59        47

    accuracy                           0.62       148
   macro avg       0.58      0.62      0.58       148
weighted avg       0.67      0.62      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.73      0.55      0.63        83
           1       0.32      0.37      0.34        30
           2       0.35      0.51      0.42        35

    accuracy                           0.51       148
   macro avg       0.47      0.48      0.46       148
weighted avg       0.56      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.63      0.56      0.60        71
           1       0.39      0.50      0.44        26
           2       0.37      0.38      0.38        50

    accuracy                           0.49       147
   macro avg       0.47      0.48      0.47       147
weighted avg       0.50      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.48      0.61       110
           1       0.33      0.52      0.41        21
           2       0.10      0.31      0.15        16

    accuracy                           0.47       147
   macro avg       0.42      0.44      0.39       147
weighted avg       0.69      0.47      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        79
           1       0.27      0.32      0.30        28
           2       0.27      0.35      0.31        40

    accuracy                           0.44       147
   macro avg       0.40      0.40      0.40       147
weighted avg       0.48      0.44      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.81      0.55      0.66        92
           1       0.30      0.43      0.36        23
           2       0.33      0.53      0.41        32

    accuracy                           0.53       147
   macro avg       0.48      0.51      0.47       147
weighted avg       0.63      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.71      0.61      0.66        74
           1       0.45      0.50      0.48        30
           2       0.31      0.37      0.34        43

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.52      0.54      0.53        61
           1       0.36      0.29      0.32        41
           2       0.35      0.40      0.38        45

    accuracy                           0.43       147
   macro avg       0.41      0.41      0.41       147
weighted avg       0.43      0.43      0.43       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.57      0.61        74
           1       0.36      0.39      0.38        31
           2       0.39      0.48      0.43        42

    accuracy                           0.50       147
   macro avg       0.47      0.48      0.47       147
weighted avg       0.52      0.50      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5056628056628056
F1: 0.4894623381993263
======================================================
Running contraceptive 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.66      0.65      0.66        63
           1       0.38      0.52      0.44        25
           2       0.58      0.50      0.54        60

    accuracy                           0.57       148
   macro avg       0.54      0.56      0.54       148
weighted avg       0.58      0.57      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.69      0.66        58
           1       0.44      0.50      0.47        30
           2       0.61      0.52      0.56        60

    accuracy                           0.58       148
   macro avg       0.56      0.57      0.56       148
weighted avg       0.58      0.58      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.65        61
           1       0.32      0.44      0.37        25
           2       0.59      0.48      0.53        62

    accuracy                           0.55       148
   macro avg       0.52      0.53      0.52       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.63      0.64        65
           1       0.45      0.56      0.50        27
           2       0.51      0.47      0.49        55

    accuracy                           0.56       147
   macro avg       0.54      0.55      0.54       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.64      0.71        78
           1       0.30      0.53      0.38        19
           2       0.51      0.52      0.51        50

    accuracy                           0.59       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.63      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.68      0.65        57
           1       0.24      0.27      0.25        30
           2       0.57      0.48      0.52        60

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.66      0.69        70
           1       0.36      0.46      0.41        26
           2       0.51      0.51      0.51        51

    accuracy                           0.57       147
   macro avg       0.53      0.54      0.54       147
weighted avg       0.59      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.74      0.71        58
           1       0.36      0.55      0.44        22
           2       0.63      0.48      0.54        67

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.56       147
weighted avg       0.61      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.60      0.59        60
           1       0.45      0.42      0.43        36
           2       0.47      0.47      0.47        51

    accuracy                           0.51       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.65      0.65        63
           1       0.27      0.33      0.30        27
           2       0.53      0.47      0.50        57

    accuracy                           0.52       147
   macro avg       0.48      0.49      0.48       147
weighted avg       0.53      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5553088803088804
F1: 0.551875896614043
======================================================
Running contraceptive 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.70      0.67        57
           1       0.29      0.45      0.36        22
           2       0.63      0.48      0.55        69

    accuracy                           0.56       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.59      0.56      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.74      0.74        62
           1       0.35      0.57      0.44        21
           2       0.71      0.55      0.62        65

    accuracy                           0.64       148
   macro avg       0.60      0.62      0.60       148
weighted avg       0.67      0.64      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.64      0.65        64
           1       0.26      0.36      0.31        25
           2       0.55      0.47      0.51        59

    accuracy                           0.53       148
   macro avg       0.49      0.49      0.49       148
weighted avg       0.55      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.59      0.60        64
           1       0.39      0.52      0.45        25
           2       0.53      0.47      0.50        58

    accuracy                           0.53       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.54      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.64      0.72        81
           1       0.42      0.52      0.47        27
           2       0.45      0.59      0.51        39

    accuracy                           0.61       147
   macro avg       0.57      0.58      0.57       147
weighted avg       0.65      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.62        65
           1       0.30      0.34      0.32        29
           2       0.53      0.51      0.52        53

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.54      0.46        24
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.57      0.59      0.58       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        61
           1       0.42      0.56      0.48        25
           2       0.57      0.48      0.52        61

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.57       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.57      0.57        63
           1       0.42      0.42      0.42        33
           2       0.49      0.49      0.49        51

    accuracy                           0.51       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        62
           1       0.33      0.37      0.35        30
           2       0.51      0.47      0.49        55

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5620932156646442
F1: 0.5573316584290684
======================================================
Running contraceptive 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.68      0.64        56
           1       0.32      0.46      0.38        24
           2       0.62      0.47      0.53        68

    accuracy                           0.55       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.57      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.69      0.70        65
           1       0.41      0.52      0.46        27
           2       0.59      0.54      0.56        56

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.64      0.65        64
           1       0.26      0.36      0.31        25
           2       0.55      0.47      0.51        59

    accuracy                           0.53       148
   macro avg       0.49      0.49      0.49       148
weighted avg       0.55      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.62      0.64        66
           1       0.48      0.57      0.52        28
           2       0.53      0.51      0.52        53

    accuracy                           0.57       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.58      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.59      0.69        88
           1       0.27      0.50      0.35        18
           2       0.39      0.49      0.43        41

    accuracy                           0.55       147
   macro avg       0.50      0.53      0.49       147
weighted avg       0.64      0.55      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.60      0.58        58
           1       0.30      0.34      0.32        29
           2       0.59      0.50      0.54        60

    accuracy                           0.51       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.52      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.54      0.46        24
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.57      0.59      0.58       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        61
           1       0.42      0.56      0.48        25
           2       0.57      0.48      0.52        61

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.57       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.58      0.57        60
           1       0.48      0.44      0.46        36
           2       0.49      0.49      0.49        51

    accuracy                           0.52       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        62
           1       0.33      0.37      0.35        30
           2       0.51      0.47      0.49        55

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5553226696083838
F1: 0.550323022779863
======================================================
Running contraceptive 100 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.52      0.36        33
           1       0.62      0.41      0.49        51
           2       0.52      0.42      0.47        64

    accuracy                           0.44       148
   macro avg       0.47      0.45      0.44       148
weighted avg       0.50      0.44      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.61      0.65        70
           1       0.44      0.50      0.47        30
           2       0.57      0.60      0.59        48

    accuracy                           0.59       148
   macro avg       0.56      0.57      0.57       148
weighted avg       0.60      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.64      0.44        33
           1       0.59      0.33      0.42        61
           2       0.51      0.48      0.50        54

    accuracy                           0.45       148
   macro avg       0.48      0.48      0.45       148
weighted avg       0.50      0.45      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.25      0.62      0.36        26
           1       0.73      0.41      0.52        59
           2       0.63      0.52      0.57        62

    accuracy                           0.49       147
   macro avg       0.54      0.51      0.48       147
weighted avg       0.60      0.49      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.60      0.47        40
           1       0.48      0.36      0.42        44
           2       0.55      0.44      0.49        63

    accuracy                           0.46       147
   macro avg       0.47      0.47      0.46       147
weighted avg       0.48      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.50      0.35        34
           1       0.52      0.30      0.38        57
           2       0.47      0.43      0.45        56

    accuracy                           0.39       147
   macro avg       0.42      0.41      0.39       147
weighted avg       0.44      0.39      0.40       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.65      0.48        37
           1       0.64      0.41      0.50        51
           2       0.53      0.46      0.49        59

    accuracy                           0.49       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.53      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.79      0.54        33
           1       0.55      0.39      0.46        46
           2       0.55      0.41      0.47        68

    accuracy                           0.49       147
   macro avg       0.50      0.53      0.49       147
weighted avg       0.52      0.49      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.30      0.50      0.38        38
           1       0.67      0.23      0.34        96
           2       0.06      0.23      0.09        13

    accuracy                           0.30       147
   macro avg       0.34      0.32      0.27       147
weighted avg       0.52      0.30      0.33       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.14      0.47      0.22        19
           1       0.70      0.28      0.40        81
           2       0.35      0.38      0.37        47

    accuracy                           0.34       147
   macro avg       0.40      0.38      0.33       147
weighted avg       0.52      0.34      0.37       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.44457161242875526
F1: 0.4355690045184327
======================================================
Running contraceptive 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.56      0.65        86
           1       0.44      0.47      0.45        32
           2       0.33      0.57      0.41        30

    accuracy                           0.54       148
   macro avg       0.51      0.53      0.51       148
weighted avg       0.61      0.54      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.69      0.76        77
           1       0.53      0.56      0.55        32
           2       0.51      0.67      0.58        39

    accuracy                           0.66       148
   macro avg       0.63      0.64      0.63       148
weighted avg       0.69      0.66      0.66       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.55      0.65        91
           1       0.29      0.31      0.30        32
           2       0.22      0.44      0.29        25

    accuracy                           0.48       148
   macro avg       0.43      0.43      0.41       148
weighted avg       0.59      0.48      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.58      0.47      0.52        40
           2       0.22      0.46      0.29        24

    accuracy                           0.54       147
   macro avg       0.52      0.51      0.50       147
weighted avg       0.63      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.53      0.66       101
           1       0.24      0.38      0.30        21
           2       0.29      0.60      0.39        25

    accuracy                           0.52       147
   macro avg       0.46      0.51      0.45       147
weighted avg       0.67      0.52      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.55      0.62        82
           1       0.21      0.29      0.25        24
           2       0.37      0.46      0.41        41

    accuracy                           0.48       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.54      0.48      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.58      0.67        84
           1       0.42      0.47      0.44        30
           2       0.35      0.55      0.43        33

    accuracy                           0.55       147
   macro avg       0.52      0.53      0.51       147
weighted avg       0.61      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.59      0.68        86
           1       0.52      0.57      0.54        30
           2       0.29      0.48      0.37        31

    accuracy                           0.56       147
   macro avg       0.54      0.55      0.53       147
weighted avg       0.64      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.51      0.56        79
           1       0.36      0.38      0.37        32
           2       0.29      0.42      0.34        36

    accuracy                           0.46       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.49      0.46      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.56      0.63        80
           1       0.33      0.35      0.34        31
           2       0.35      0.50      0.41        36

    accuracy                           0.50       147
   macro avg       0.47      0.47      0.46       147
weighted avg       0.55      0.50      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5294723294723295
F1: 0.508083250072243
======================================================
Running contraceptive 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.58      0.65        79
           1       0.59      0.53      0.56        38
           2       0.33      0.55      0.41        31

    accuracy                           0.56       148
   macro avg       0.55      0.55      0.54       148
weighted avg       0.62      0.56      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.75        84
           1       0.47      0.53      0.50        30
           2       0.43      0.65      0.52        34

    accuracy                           0.63       148
   macro avg       0.59      0.61      0.59       148
weighted avg       0.69      0.63      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.53      0.63        93
           1       0.26      0.36      0.31        25
           2       0.29      0.50      0.37        30

    accuracy                           0.49       148
   macro avg       0.45      0.46      0.43       148
weighted avg       0.59      0.49      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.56      0.64        86
           1       0.58      0.46      0.51        41
           2       0.24      0.60      0.34        20

    accuracy                           0.54       147
   macro avg       0.52      0.54      0.50       147
weighted avg       0.64      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.53      0.67       110
           1       0.27      0.50      0.35        18
           2       0.22      0.58      0.31        19

    accuracy                           0.53       147
   macro avg       0.47      0.54      0.45       147
weighted avg       0.75      0.53      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.56      0.65        88
           1       0.30      0.33      0.32        30
           2       0.27      0.48      0.35        29

    accuracy                           0.50       147
   macro avg       0.45      0.46      0.44       147
weighted avg       0.58      0.50      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.68        94
           1       0.42      0.48      0.45        29
           2       0.29      0.62      0.40        24

    accuracy                           0.56       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.67      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.48      0.59      0.53        27
           2       0.35      0.49      0.41        37

    accuracy                           0.56       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.62      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.51      0.55        72
           1       0.52      0.42      0.47        40
           2       0.29      0.43      0.35        35

    accuracy                           0.47       147
   macro avg       0.47      0.46      0.45       147
weighted avg       0.50      0.47      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.54      0.63        89
           1       0.39      0.41      0.40        32
           2       0.29      0.58      0.39        26

    accuracy                           0.52       147
   macro avg       0.48      0.51      0.47       147
weighted avg       0.60      0.52      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5355901820187534
F1: 0.5111937500622579
======================================================
Running contraceptive 100 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.60      0.68        84
           1       0.53      0.56      0.55        32
           2       0.31      0.50      0.38        32

    accuracy                           0.57       148
   macro avg       0.55      0.55      0.54       148
weighted avg       0.64      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.75        84
           1       0.47      0.53      0.50        30
           2       0.43      0.65      0.52        34

    accuracy                           0.63       148
   macro avg       0.59      0.61      0.59       148
weighted avg       0.69      0.63      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.54      0.61        79
           1       0.24      0.35      0.28        23
           2       0.39      0.43      0.41        46

    accuracy                           0.48       148
   macro avg       0.44      0.44      0.43       148
weighted avg       0.52      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.57      0.65        84
           1       0.58      0.49      0.53        39
           2       0.31      0.67      0.43        24

    accuracy                           0.56       147
   macro avg       0.55      0.58      0.54       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.53      0.67       110
           1       0.27      0.50      0.35        18
           2       0.22      0.58      0.31        19

    accuracy                           0.53       147
   macro avg       0.47      0.54      0.45       147
weighted avg       0.75      0.53      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.56      0.65        88
           1       0.42      0.50      0.46        28
           2       0.29      0.48      0.37        31

    accuracy                           0.53       147
   macro avg       0.50      0.51      0.49       147
weighted avg       0.61      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.68        94
           1       0.42      0.48      0.45        29
           2       0.29      0.62      0.40        24

    accuracy                           0.56       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.67      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.48      0.59      0.53        27
           2       0.35      0.49      0.41        37

    accuracy                           0.56       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.62      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.51      0.55        72
           1       0.52      0.42      0.47        40
           2       0.29      0.43      0.35        35

    accuracy                           0.47       147
   macro avg       0.47      0.46      0.45       147
weighted avg       0.50      0.47      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.55      0.64        89
           1       0.36      0.39      0.38        31
           2       0.27      0.52      0.36        27

    accuracy                           0.51       147
   macro avg       0.47      0.49      0.46       147
weighted avg       0.60      0.51      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5403566832138261
F1: 0.5176782652817408
======================================================
Running contraceptive 100 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.60      0.64        70
           1       0.44      0.60      0.51        25
           2       0.48      0.47      0.48        53

    accuracy                           0.55       148
   macro avg       0.53      0.56      0.54       148
weighted avg       0.57      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.73      0.75        67
           1       0.29      0.59      0.39        17
           2       0.69      0.55      0.61        64

    accuracy                           0.64       148
   macro avg       0.59      0.62      0.58       148
weighted avg       0.68      0.64      0.65       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.59      0.62        69
           1       0.24      0.31      0.27        26
           2       0.51      0.49      0.50        53

    accuracy                           0.51       148
   macro avg       0.47      0.46      0.46       148
weighted avg       0.53      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.65      0.67        68
           1       0.45      0.54      0.49        28
           2       0.49      0.49      0.49        51

    accuracy                           0.57       147
   macro avg       0.55      0.56      0.55       147
weighted avg       0.58      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.59      0.66        80
           1       0.33      0.58      0.42        19
           2       0.45      0.48      0.46        48

    accuracy                           0.55       147
   macro avg       0.51      0.55      0.52       147
weighted avg       0.60      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.64      0.65        66
           1       0.33      0.35      0.34        31
           2       0.47      0.48      0.48        50

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.69      0.69        64
           1       0.36      0.43      0.39        28
           2       0.57      0.53      0.55        55

    accuracy                           0.58       147
   macro avg       0.54      0.55      0.54       147
weighted avg       0.59      0.58      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.67      0.63        57
           1       0.33      0.44      0.38        25
           2       0.49      0.38      0.43        65

    accuracy                           0.50       147
   macro avg       0.48      0.50      0.48       147
weighted avg       0.51      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.62      0.58        55
           1       0.36      0.52      0.43        23
           2       0.61      0.45      0.52        69

    accuracy                           0.52       147
   macro avg       0.50      0.53      0.51       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.64      0.66        67
           1       0.36      0.41      0.39        29
           2       0.51      0.51      0.51        51

    accuracy                           0.55       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5498667034381319
F1: 0.5447789189012157
======================================================
Running contraceptive 100 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
CBEG               precision    recall  f1-score   support

           0       0.73      0.48      0.58        93
           1       0.65      0.46      0.54        48
           2       0.12      0.86      0.20         7

    accuracy                           0.49       148
   macro avg       0.50      0.60      0.44       148
weighted avg       0.67      0.49      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
CBEG               precision    recall  f1-score   support

           0       0.84      0.54      0.66        98
           1       0.38      0.43      0.41        30
           2       0.24      0.60      0.34        20

    accuracy                           0.53       148
   macro avg       0.49      0.52      0.47       148
weighted avg       0.67      0.53      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
CBEG               precision    recall  f1-score   support

           0       0.81      0.45      0.58       113
           1       0.29      0.30      0.30        33
           2       0.02      0.50      0.04         2

    accuracy                           0.42       148
   macro avg       0.37      0.42      0.31       148
weighted avg       0.68      0.42      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
CBEG               precision    recall  f1-score   support

           0       0.87      0.50      0.64       110
           1       0.52      0.50      0.51        34
           2       0.06      1.00      0.11         3

    accuracy                           0.51       147
   macro avg       0.48      0.67      0.42       147
weighted avg       0.77      0.51      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
CBEG               precision    recall  f1-score   support

           0       0.90      0.47      0.62       122
           1       0.24      0.32      0.28        25
           2       0.00      0.00      0.00         0

    accuracy                           0.44       147
   macro avg       0.38      0.26      0.30       147
weighted avg       0.79      0.44      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
CBEG               precision    recall  f1-score   support

           0       0.76      0.43      0.55       111
           1       0.24      0.23      0.24        35
           2       0.00      0.00      0.00         1

    accuracy                           0.38       147
   macro avg       0.33      0.22      0.26       147
weighted avg       0.63      0.38      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
CBEG               precision    recall  f1-score   support

           0       0.51      0.54      0.52        59
           1       0.45      0.39      0.42        38
           2       0.47      0.48      0.48        50

    accuracy                           0.48       147
   macro avg       0.48      0.47      0.47       147
weighted avg       0.48      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
CBEG               precision    recall  f1-score   support

           0       0.87      0.50      0.63       111
           1       0.33      0.42      0.37        26
           2       0.10      0.50      0.16        10

    accuracy                           0.48       147
   macro avg       0.43      0.47      0.39       147
weighted avg       0.72      0.48      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
CBEG               precision    recall  f1-score   support

           0       0.75      0.47      0.58        99
           1       0.30      0.26      0.28        39
           2       0.16      0.89      0.27         9

    accuracy                           0.44       147
   macro avg       0.40      0.54      0.37       147
weighted avg       0.59      0.44      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
CBEG               precision    recall  f1-score   support

           0       0.87      0.49      0.62       113
           1       0.33      0.37      0.35        30
           2       0.06      0.75      0.11         4

    accuracy                           0.47       147
   macro avg       0.42      0.53      0.36       147
weighted avg       0.74      0.47      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4650073542930685
F1: 0.3980318311892381
======================================================
Running contraceptive 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.82      0.41      0.55        68
           2       0.21      0.65      0.32        17

    accuracy                           0.50       148
   macro avg       0.53      0.54      0.48       148
weighted avg       0.64      0.50      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.56      0.43      0.49        44
           2       0.29      0.58      0.39        26

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.51       148
weighted avg       0.61      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
CBEG               precision    recall  f1-score   support

           0       0.54      0.50      0.52        68
           1       0.65      0.31      0.42        70
           2       0.12      0.60      0.20        10

    accuracy                           0.42       148
   macro avg       0.43      0.47      0.38       148
weighted avg       0.56      0.42      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.59        69
           1       0.70      0.43      0.53        54
           2       0.25      0.54      0.35        24

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.59      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
CBEG               precision    recall  f1-score   support

           0       0.75      0.57      0.65        82
           1       0.64      0.44      0.52        48
           2       0.20      0.59      0.29        17

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.49       147
weighted avg       0.65      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
CBEG               precision    recall  f1-score   support

           0       0.56      0.49      0.52        72
           1       0.55      0.30      0.38        61
           2       0.16      0.57      0.25        14

    accuracy                           0.41       147
   macro avg       0.42      0.45      0.38       147
weighted avg       0.51      0.41      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.76      0.45      0.57        55
           2       0.27      0.58      0.37        24

    accuracy                           0.56       147
   macro avg       0.57      0.56      0.53       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.67      0.43      0.52        51
           2       0.25      0.57      0.35        23

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.53       147
weighted avg       0.65      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
CBEG               precision    recall  f1-score   support

           0       0.43      0.51      0.47        53
           1       0.61      0.30      0.40        67
           2       0.25      0.48      0.33        27

    accuracy                           0.41       147
   macro avg       0.43      0.43      0.40       147
weighted avg       0.48      0.41      0.41       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.55      0.27      0.36        66
           2       0.24      0.52      0.32        23

    accuracy                           0.44       147
   macro avg       0.44      0.46      0.42       147
weighted avg       0.49      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488798492369921
F1: 0.46911264360560995
======================================================
Running contraceptive 100 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.82      0.41      0.55        68
           2       0.21      0.65      0.32        17

    accuracy                           0.50       148
   macro avg       0.53      0.54      0.48       148
weighted avg       0.64      0.50      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.56      0.43      0.49        44
           2       0.29      0.58      0.39        26

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.51       148
weighted avg       0.61      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
CBEG               precision    recall  f1-score   support

           0       0.54      0.50      0.52        68
           1       0.65      0.31      0.42        70
           2       0.12      0.60      0.20        10

    accuracy                           0.42       148
   macro avg       0.43      0.47      0.38       148
weighted avg       0.56      0.42      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.59        69
           1       0.70      0.43      0.53        54
           2       0.25      0.54      0.35        24

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.59      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
CBEG               precision    recall  f1-score   support

           0       0.75      0.57      0.65        82
           1       0.64      0.44      0.52        48
           2       0.20      0.59      0.29        17

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.49       147
weighted avg       0.65      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
CBEG               precision    recall  f1-score   support

           0       0.56      0.49      0.52        72
           1       0.55      0.30      0.38        61
           2       0.16      0.57      0.25        14

    accuracy                           0.41       147
   macro avg       0.42      0.45      0.38       147
weighted avg       0.51      0.41      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.76      0.45      0.57        55
           2       0.27      0.58      0.37        24

    accuracy                           0.56       147
   macro avg       0.57      0.56      0.53       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.67      0.43      0.52        51
           2       0.25      0.57      0.35        23

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.53       147
weighted avg       0.65      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
CBEG               precision    recall  f1-score   support

           0       0.43      0.51      0.47        53
           1       0.61      0.30      0.40        67
           2       0.25      0.48      0.33        27

    accuracy                           0.41       147
   macro avg       0.43      0.43      0.40       147
weighted avg       0.48      0.41      0.41       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.55      0.27      0.36        66
           2       0.24      0.52      0.32        23

    accuracy                           0.44       147
   macro avg       0.44      0.46      0.42       147
weighted avg       0.49      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488798492369921
F1: 0.46911264360560995
======================================================
Running contraceptive 100 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.50      0.58      0.54        53
           1       0.79      0.47      0.59        58
           2       0.38      0.54      0.45        37

    accuracy                           0.53       148
   macro avg       0.56      0.53      0.53       148
weighted avg       0.59      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.81      0.57      0.67        89
           1       0.41      0.52      0.46        27
           2       0.35      0.56      0.43        32

    accuracy                           0.56       148
   macro avg       0.52      0.55      0.52       148
weighted avg       0.64      0.56      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.44      0.58      0.50        48
           1       0.53      0.31      0.39        58
           2       0.45      0.55      0.49        42

    accuracy                           0.47       148
   macro avg       0.47      0.48      0.46       148
weighted avg       0.48      0.47      0.46       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.65      0.48        37
           1       0.73      0.44      0.55        55
           2       0.55      0.51      0.53        55

    accuracy                           0.52       147
   macro avg       0.55      0.53      0.52       147
weighted avg       0.57      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.61      0.54        51
           1       0.58      0.45      0.51        42
           2       0.51      0.48      0.50        54

    accuracy                           0.52       147
   macro avg       0.53      0.51      0.52       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.51      0.44        47
           1       0.48      0.29      0.36        55
           2       0.43      0.49      0.46        45

    accuracy                           0.42       147
   macro avg       0.43      0.43      0.42       147
weighted avg       0.44      0.42      0.42       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.60      0.47        40
           1       0.58      0.40      0.47        47
           2       0.51      0.43      0.47        60

    accuracy                           0.47       147
   macro avg       0.49      0.48      0.47       147
weighted avg       0.50      0.47      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.70      0.58        44
           1       0.55      0.41      0.47        44
           2       0.47      0.41      0.44        59

    accuracy                           0.50       147
   macro avg       0.50      0.51      0.49       147
weighted avg       0.50      0.50      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.63      0.48      0.54        84
           1       0.55      0.30      0.38        61
           2       0.02      0.50      0.04         2

    accuracy                           0.40       147
   macro avg       0.40      0.42      0.32       147
weighted avg       0.59      0.40      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.54      0.55      0.54        62
           1       0.61      0.31      0.41        64
           2       0.25      0.62      0.36        21

    accuracy                           0.46       147
   macro avg       0.47      0.49      0.44       147
weighted avg       0.53      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4832965618679904
F1: 0.47488802214421666
======================================================
Running contraceptive 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.68      0.69        65
           1       0.38      0.68      0.49        19
           2       0.58      0.47      0.52        64

    accuracy                           0.59       148
   macro avg       0.56      0.61      0.57       148
weighted avg       0.61      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.73      0.74        64
           1       0.32      0.61      0.42        18
           2       0.73      0.56      0.63        66

    accuracy                           0.64       148
   macro avg       0.60      0.64      0.60       148
weighted avg       0.69      0.64      0.65       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.58      0.57        60
           1       0.29      0.38      0.33        26
           2       0.59      0.48      0.53        62

    accuracy                           0.51       148
   macro avg       0.48      0.48      0.48       148
weighted avg       0.52      0.51      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.65      0.67        68
           1       0.45      0.56      0.50        27
           2       0.47      0.46      0.47        52

    accuracy                           0.56       147
   macro avg       0.54      0.55      0.55       147
weighted avg       0.57      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.63      0.70        78
           1       0.33      0.46      0.39        24
           2       0.47      0.53      0.50        45

    accuracy                           0.57       147
   macro avg       0.53      0.54      0.53       147
weighted avg       0.61      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.63        64
           1       0.30      0.29      0.29        35
           2       0.47      0.50      0.48        48

    accuracy                           0.50       147
   macro avg       0.47      0.47      0.47       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.70      0.69        61
           1       0.18      0.50      0.27        12
           2       0.71      0.49      0.58        74

    accuracy                           0.58       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.65      0.58      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.70      0.69        61
           1       0.39      0.45      0.42        29
           2       0.51      0.46      0.48        57

    accuracy                           0.56       147
   macro avg       0.53      0.54      0.53       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.48      0.50      0.49        32
           2       0.49      0.44      0.46        57

    accuracy                           0.51       147
   macro avg       0.50      0.51      0.51       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.62      0.66        73
           1       0.33      0.48      0.39        23
           2       0.51      0.51      0.51        51

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5580023901452473
F1: 0.5516749760713643
======================================================
Running contraceptive 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        60
           1       0.35      0.55      0.43        22
           2       0.60      0.47      0.53        66

    accuracy                           0.55       148
   macro avg       0.53      0.56      0.53       148
weighted avg       0.57      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.68      0.70        68
           1       0.44      0.58      0.50        26
           2       0.59      0.56      0.57        54

    accuracy                           0.61       148
   macro avg       0.59      0.60      0.59       148
weighted avg       0.63      0.61      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.60      0.60        63
           1       0.41      0.45      0.43        31
           2       0.53      0.50      0.51        54

    accuracy                           0.53       148
   macro avg       0.51      0.52      0.52       148
weighted avg       0.54      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.60      0.61        65
           1       0.48      0.53      0.51        30
           2       0.45      0.44      0.45        52

    accuracy                           0.53       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.53      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.64      0.70        77
           1       0.42      0.52      0.47        27
           2       0.47      0.56      0.51        43

    accuracy                           0.59       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.62      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.64      0.65        64
           1       0.30      0.31      0.31        32
           2       0.51      0.51      0.51        51

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.64      0.66        67
           1       0.24      0.44      0.31        18
           2       0.61      0.50      0.55        62

    accuracy                           0.56       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.60      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.45      0.54      0.49        28
           2       0.59      0.50      0.54        60

    accuracy                           0.59       147
   macro avg       0.56      0.58      0.57       147
weighted avg       0.59      0.59      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.62      0.57        53
           1       0.45      0.60      0.52        25
           2       0.65      0.48      0.55        69

    accuracy                           0.55       147
   macro avg       0.54      0.57      0.55       147
weighted avg       0.57      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.68      0.67        62
           1       0.45      0.44      0.45        34
           2       0.57      0.57      0.57        51

    accuracy                           0.59       147
   macro avg       0.56      0.56      0.56       147
weighted avg       0.58      0.59      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5627872770729914
F1: 0.559613819464871
======================================================
Running contraceptive 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        60
           1       0.35      0.55      0.43        22
           2       0.60      0.47      0.53        66

    accuracy                           0.55       148
   macro avg       0.53      0.56      0.53       148
weighted avg       0.57      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.66      0.68        67
           1       0.47      0.59      0.52        27
           2       0.57      0.54      0.55        54

    accuracy                           0.60       148
   macro avg       0.58      0.60      0.58       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.58      0.58        64
           1       0.47      0.46      0.46        35
           2       0.53      0.55      0.54        49

    accuracy                           0.54       148
   macro avg       0.53      0.53      0.53       148
weighted avg       0.54      0.54      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.61      0.62        66
           1       0.48      0.53      0.51        30
           2       0.45      0.45      0.45        51

    accuracy                           0.54       147
   macro avg       0.52      0.53      0.53       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.63      0.70        78
           1       0.39      0.50      0.44        26
           2       0.47      0.56      0.51        43

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.55       147
weighted avg       0.62      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.64      0.67        69
           1       0.33      0.42      0.37        26
           2       0.53      0.52      0.52        52

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.57      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.64      0.66        67
           1       0.24      0.47      0.32        17
           2       0.63      0.51      0.56        63

    accuracy                           0.56       147
   macro avg       0.52      0.54      0.51       147
weighted avg       0.61      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.45      0.54      0.49        28
           2       0.59      0.50      0.54        60

    accuracy                           0.59       147
   macro avg       0.56      0.58      0.57       147
weighted avg       0.59      0.59      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.63      0.60        57
           1       0.55      0.53      0.54        34
           2       0.51      0.46      0.49        56

    accuracy                           0.54       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.68      0.67        62
           1       0.45      0.44      0.45        34
           2       0.57      0.57      0.57        51

    accuracy                           0.59       147
   macro avg       0.56      0.56      0.56       147
weighted avg       0.58      0.59      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5655129619415333
F1: 0.5620393199629892
======================================================
Running contraceptive 75 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.64      0.69        74
           1       0.29      0.53      0.38        19
           2       0.54      0.51      0.52        55

    accuracy                           0.57       148
   macro avg       0.53      0.56      0.53       148
weighted avg       0.62      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.70      0.67        57
           1       0.47      0.52      0.49        31
           2       0.63      0.53      0.58        60

    accuracy                           0.59       148
   macro avg       0.58      0.58      0.58       148
weighted avg       0.60      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.60      0.64        72
           1       0.44      0.45      0.45        33
           2       0.45      0.53      0.49        43

    accuracy                           0.55       148
   macro avg       0.52      0.53      0.52       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.63      0.64        65
           1       0.42      0.52      0.47        27
           2       0.51      0.47      0.49        55

    accuracy                           0.55       147
   macro avg       0.53      0.54      0.53       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.73        88
           1       0.45      0.54      0.49        28
           2       0.39      0.65      0.49        31

    accuracy                           0.61       147
   macro avg       0.57      0.60      0.57       147
weighted avg       0.69      0.61      0.63       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.64      0.61        58
           1       0.24      0.26      0.25        31
           2       0.53      0.47      0.50        58

    accuracy                           0.49       147
   macro avg       0.45      0.45      0.45       147
weighted avg       0.49      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.61      0.65        70
           1       0.33      0.50      0.40        22
           2       0.49      0.45      0.47        55

    accuracy                           0.54       147
   macro avg       0.50      0.52      0.51       147
weighted avg       0.56      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        67
           1       0.45      0.48      0.47        31
           2       0.43      0.45      0.44        49

    accuracy                           0.56       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.57      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.60      0.58        58
           1       0.48      0.43      0.46        37
           2       0.49      0.48      0.49        52

    accuracy                           0.52       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.51      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.66      0.69        68
           1       0.36      0.40      0.38        30
           2       0.51      0.53      0.52        49

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.57      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5552950910093767
F1: 0.5500905000322461
======================================================
Running contraceptive 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.67      0.64        57
           1       0.41      0.50      0.45        28
           2       0.58      0.48      0.52        63

    accuracy                           0.55       148
   macro avg       0.53      0.55      0.54       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.65      0.70        72
           1       0.35      0.55      0.43        22
           2       0.57      0.54      0.55        54

    accuracy                           0.59       148
   macro avg       0.56      0.58      0.56       148
weighted avg       0.62      0.59      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.62        65
           1       0.41      0.44      0.42        32
           2       0.47      0.47      0.47        51

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.51       148
weighted avg       0.53      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.62      0.62        63
           1       0.42      0.50      0.46        28
           2       0.51      0.46      0.49        56

    accuracy                           0.54       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.60      0.68        83
           1       0.33      0.48      0.39        23
           2       0.47      0.59      0.52        41

    accuracy                           0.58       147
   macro avg       0.53      0.56      0.53       147
weighted avg       0.63      0.58      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.64      0.62        59
           1       0.36      0.32      0.34        37
           2       0.53      0.53      0.53        51

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.68      0.73        72
           1       0.33      0.50      0.40        22
           2       0.57      0.55      0.56        53

    accuracy                           0.61       147
   macro avg       0.56      0.58      0.56       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.45      0.60      0.52        25
           2       0.61      0.49      0.54        63

    accuracy                           0.59       147
   macro avg       0.57      0.60      0.58       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.52      0.46      0.49        37
           2       0.45      0.44      0.45        52

    accuracy                           0.50       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.67      0.68        64
           1       0.30      0.42      0.35        24
           2       0.59      0.51      0.55        59

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.558043758043758
F1: 0.5543102916851063
======================================================
Running contraceptive 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.66      0.68      0.67        60
           1       0.44      0.56      0.49        27
           2       0.56      0.48      0.51        61

    accuracy                           0.57       148
   macro avg       0.55      0.57      0.56       148
weighted avg       0.58      0.57      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.70      0.72        67
           1       0.44      0.52      0.48        29
           2       0.57      0.56      0.56        52

    accuracy                           0.61       148
   macro avg       0.59      0.59      0.59       148
weighted avg       0.62      0.61      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.62        65
           1       0.41      0.44      0.42        32
           2       0.47      0.47      0.47        51

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.51       148
weighted avg       0.53      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.59      0.62        69
           1       0.42      0.50      0.46        28
           2       0.47      0.48      0.48        50

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.55      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.66        89
           1       0.21      0.50      0.30        14
           2       0.43      0.50      0.46        44

    accuracy                           0.54       147
   macro avg       0.48      0.52      0.47       147
weighted avg       0.63      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.65      0.63        60
           1       0.36      0.33      0.35        36
           2       0.53      0.53      0.53        51

    accuracy                           0.53       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.53      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.64      0.70        75
           1       0.42      0.47      0.44        30
           2       0.47      0.57      0.52        42

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.55       147
weighted avg       0.61      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.45      0.60      0.52        25
           2       0.61      0.49      0.54        63

    accuracy                           0.59       147
   macro avg       0.57      0.60      0.58       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.52      0.46      0.49        37
           2       0.45      0.44      0.45        52

    accuracy                           0.50       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.36      0.35      0.36        34
           2       0.51      0.48      0.50        54

    accuracy                           0.54       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.53      0.54      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5539345467916897
F1: 0.5503952892006827
======================================================
Running contraceptive 75 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.68        98
           1       0.41      0.52      0.46        27
           2       0.25      0.57      0.35        23

    accuracy                           0.55       148
   macro avg       0.51      0.54      0.49       148
weighted avg       0.69      0.55      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.67      0.73        76
           1       0.44      0.56      0.49        27
           2       0.55      0.62      0.58        45

    accuracy                           0.64       148
   macro avg       0.60      0.62      0.60       148
weighted avg       0.66      0.64      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.49      0.63       115
           1       0.29      0.30      0.30        33
           2       0.00      0.00      0.00         0

    accuracy                           0.45       148
   macro avg       0.39      0.26      0.31       148
weighted avg       0.76      0.45      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.58      0.47      0.52        40
           2       0.22      0.46      0.29        24

    accuracy                           0.54       147
   macro avg       0.52      0.51      0.50       147
weighted avg       0.63      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.50      0.66       117
           1       0.39      0.43      0.41        30
           2       0.00      0.00      0.00         0

    accuracy                           0.49       147
   macro avg       0.44      0.31      0.36       147
weighted avg       0.83      0.49      0.61       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.57      0.64        80
           1       0.30      0.33      0.32        30
           2       0.31      0.43      0.36        37

    accuracy                           0.49       147
   macro avg       0.45      0.45      0.44       147
weighted avg       0.54      0.49      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       101
           1       0.42      0.47      0.44        30
           2       0.14      0.44      0.21        16

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.44       147
weighted avg       0.70      0.52      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.59      0.70        94
           1       0.48      0.50      0.49        32
           2       0.16      0.38      0.22        21

    accuracy                           0.54       147
   macro avg       0.50      0.49      0.47       147
weighted avg       0.69      0.54      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.52      0.62        93
           1       0.48      0.41      0.44        39
           2       0.18      0.60      0.27        15

    accuracy                           0.50       147
   macro avg       0.47      0.51      0.44       147
weighted avg       0.63      0.50      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.56      0.62        78
           1       0.30      0.32      0.31        31
           2       0.37      0.50      0.43        38

    accuracy                           0.50       147
   macro avg       0.46      0.46      0.45       147
weighted avg       0.53      0.50      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5193004228718514
F1: 0.47173508988985474
======================================================
Running contraceptive 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.51      0.65       108
           1       0.59      0.50      0.54        40
           2       0.00      0.00      0.00         0

    accuracy                           0.51       148
   macro avg       0.49      0.34      0.40       148
weighted avg       0.81      0.51      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.60      0.73        96
           1       0.50      0.47      0.49        36
           2       0.20      0.62      0.30        16

    accuracy                           0.57       148
   macro avg       0.54      0.57      0.50       148
weighted avg       0.74      0.57      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.49      0.63       114
           1       0.29      0.34      0.32        29
           2       0.04      0.40      0.07         5

    accuracy                           0.46       148
   macro avg       0.41      0.41      0.34       148
weighted avg       0.74      0.46      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.57      0.65        84
           1       0.58      0.49      0.53        39
           2       0.31      0.67      0.43        24

    accuracy                           0.56       147
   macro avg       0.55      0.58      0.54       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.53      0.66       106
           1       0.24      0.47      0.32        17
           2       0.29      0.62      0.40        24

    accuracy                           0.54       147
   macro avg       0.48      0.54      0.46       147
weighted avg       0.72      0.54      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.44      0.61       142
           1       0.06      0.50      0.11         4
           2       0.00      0.00      0.00         1

    accuracy                           0.44       147
   macro avg       0.35      0.31      0.24       147
weighted avg       0.97      0.44      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.61      0.69        84
           1       0.42      0.48      0.45        29
           2       0.37      0.56      0.45        34

    accuracy                           0.57       147
   macro avg       0.54      0.55      0.53       147
weighted avg       0.63      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.61      0.67        77
           1       0.39      0.62      0.48        21
           2       0.51      0.53      0.52        49

    accuracy                           0.59       147
   macro avg       0.55      0.59      0.56       147
weighted avg       0.62      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.53      0.60        83
           1       0.52      0.36      0.42        47
           2       0.12      0.35      0.18        17

    accuracy                           0.46       147
   macro avg       0.44      0.41      0.40       147
weighted avg       0.57      0.46      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.58      0.66        83
           1       0.33      0.42      0.37        26
           2       0.43      0.58      0.49        38

    accuracy                           0.55       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.60      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.524802353373782
F1: 0.4697945419602291
======================================================
Running contraceptive 75 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.51      0.65       108
           1       0.59      0.50      0.54        40
           2       0.00      0.00      0.00         0

    accuracy                           0.51       148
   macro avg       0.49      0.34      0.40       148
weighted avg       0.81      0.51      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.60      0.73        96
           1       0.50      0.47      0.49        36
           2       0.20      0.62      0.30        16

    accuracy                           0.57       148
   macro avg       0.54      0.57      0.50       148
weighted avg       0.74      0.57      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.49      0.63       114
           1       0.29      0.34      0.32        29
           2       0.04      0.40      0.07         5

    accuracy                           0.46       148
   macro avg       0.41      0.41      0.34       148
weighted avg       0.74      0.46      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.57      0.65        84
           1       0.58      0.49      0.53        39
           2       0.31      0.67      0.43        24

    accuracy                           0.56       147
   macro avg       0.55      0.58      0.54       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.53      0.66       106
           1       0.24      0.47      0.32        17
           2       0.29      0.62      0.40        24

    accuracy                           0.54       147
   macro avg       0.48      0.54      0.46       147
weighted avg       0.72      0.54      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.48      0.59        99
           1       0.39      0.36      0.38        36
           2       0.08      0.33      0.13        12

    accuracy                           0.44       147
   macro avg       0.41      0.39      0.37       147
weighted avg       0.62      0.44      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.61      0.69        84
           1       0.42      0.48      0.45        29
           2       0.37      0.56      0.45        34

    accuracy                           0.57       147
   macro avg       0.54      0.55      0.53       147
weighted avg       0.63      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.61      0.67        77
           1       0.39      0.62      0.48        21
           2       0.51      0.53      0.52        49

    accuracy                           0.59       147
   macro avg       0.55      0.59      0.56       147
weighted avg       0.62      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.53      0.60        83
           1       0.52      0.36      0.42        47
           2       0.12      0.35      0.18        17

    accuracy                           0.46       147
   macro avg       0.44      0.41      0.40       147
weighted avg       0.57      0.46      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.62      0.68        76
           1       0.39      0.41      0.40        32
           2       0.39      0.51      0.44        39

    accuracy                           0.54       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.58      0.54      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5241220812649384
F1: 0.47896634156464557
======================================================
Running contraceptive 75 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.53      0.52        60
           1       0.76      0.43      0.55        61
           2       0.25      0.48      0.33        27

    accuracy                           0.48       148
   macro avg       0.51      0.48      0.47       148
weighted avg       0.57      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.67        95
           1       0.35      0.55      0.43        22
           2       0.33      0.55      0.41        31

    accuracy                           0.55       148
   macro avg       0.51      0.55      0.50       148
weighted avg       0.66      0.55      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.55      0.58        69
           1       0.62      0.33      0.43        64
           2       0.14      0.47      0.21        15

    accuracy                           0.45       148
   macro avg       0.45      0.45      0.41       148
weighted avg       0.56      0.45      0.48       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.38      0.69      0.49        35
           1       0.55      0.39      0.46        46
           2       0.57      0.44      0.50        66

    accuracy                           0.48       147
   macro avg       0.50      0.51      0.48       147
weighted avg       0.52      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.49      0.61      0.54        51
           1       0.61      0.44      0.51        45
           2       0.47      0.47      0.47        51

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.51       147
weighted avg       0.52      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.41      0.60      0.49        43
           1       0.48      0.35      0.41        46
           2       0.51      0.45      0.48        58

    accuracy                           0.46       147
   macro avg       0.47      0.47      0.46       147
weighted avg       0.47      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.62      0.64        68
           1       0.55      0.40      0.46        45
           2       0.33      0.50      0.40        34

    accuracy                           0.52       147
   macro avg       0.52      0.51      0.50       147
weighted avg       0.55      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.63      0.63        63
           1       0.48      0.43      0.46        37
           2       0.33      0.36      0.35        47

    accuracy                           0.50       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.46      0.56        97
           1       0.39      0.50      0.44        26
           2       0.20      0.42      0.27        24

    accuracy                           0.46       147
   macro avg       0.43      0.46      0.42       147
weighted avg       0.57      0.46      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.51      0.59        84
           1       0.39      0.29      0.33        45
           2       0.18      0.50      0.26        18

    accuracy                           0.44       147
   macro avg       0.42      0.43      0.39       147
weighted avg       0.53      0.44      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.486068211068211
F1: 0.4727927716422469
======================================================
Running contraceptive 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.64        59
           1       0.38      0.52      0.44        25
           2       0.60      0.48      0.53        64

    accuracy                           0.56       148
   macro avg       0.54      0.56      0.54       148
weighted avg       0.57      0.56      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.73      0.74        66
           1       0.41      0.64      0.50        22
           2       0.61      0.52      0.56        60

    accuracy                           0.63       148
   macro avg       0.59      0.63      0.60       148
weighted avg       0.65      0.63      0.63       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.29      0.37      0.33        27
           2       0.45      0.40      0.42        58

    accuracy                           0.46       148
   macro avg       0.43      0.44      0.44       148
weighted avg       0.47      0.46      0.46       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.54      0.56        69
           1       0.39      0.45      0.42        29
           2       0.35      0.37      0.36        49

    accuracy                           0.46       147
   macro avg       0.44      0.45      0.45       147
weighted avg       0.47      0.46      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.55      0.63        83
           1       0.30      0.56      0.39        18
           2       0.43      0.48      0.45        46

    accuracy                           0.53       147
   macro avg       0.49      0.53      0.49       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.62      0.67        72
           1       0.27      0.45      0.34        20
           2       0.53      0.49      0.51        55

    accuracy                           0.55       147
   macro avg       0.51      0.52      0.51       147
weighted avg       0.59      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.59      0.66        79
           1       0.15      0.42      0.22        12
           2       0.49      0.45      0.47        56

    accuracy                           0.52       147
   macro avg       0.46      0.49      0.45       147
weighted avg       0.60      0.52      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.69      0.64        55
           1       0.36      0.35      0.36        34
           2       0.53      0.47      0.50        58

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.52      0.57        77
           1       0.30      0.53      0.38        19
           2       0.39      0.39      0.39        51

    accuracy                           0.48       147
   macro avg       0.44      0.48      0.45       147
weighted avg       0.51      0.48      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.61      0.66        74
           1       0.24      0.42      0.31        19
           2       0.53      0.50      0.51        54

    accuracy                           0.54       147
   macro avg       0.50      0.51      0.49       147
weighted avg       0.59      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5260893546607832
F1: 0.5174264560348025
======================================================
Running contraceptive 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.66      0.71      0.68        58
           1       0.29      0.71      0.42        14
           2       0.69      0.47      0.56        76

    accuracy                           0.59       148
   macro avg       0.55      0.63      0.55       148
weighted avg       0.64      0.59      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.71      0.73        66
           1       0.44      0.60      0.51        25
           2       0.65      0.58      0.61        57

    accuracy                           0.64       148
   macro avg       0.61      0.63      0.62       148
weighted avg       0.66      0.64      0.65       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.52      0.54        67
           1       0.29      0.36      0.32        28
           2       0.51      0.49      0.50        53

    accuracy                           0.48       148
   macro avg       0.45      0.46      0.45       148
weighted avg       0.49      0.48      0.48       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.60      0.59        62
           1       0.55      0.56      0.55        32
           2       0.45      0.43      0.44        53

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.53      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.57      0.66        88
           1       0.18      0.67      0.29         9
           2       0.45      0.46      0.46        50

    accuracy                           0.54       147
   macro avg       0.48      0.56      0.47       147
weighted avg       0.64      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.59      0.63        73
           1       0.21      0.35      0.26        20
           2       0.45      0.43      0.44        54

    accuracy                           0.50       147
   macro avg       0.45      0.45      0.44       147
weighted avg       0.53      0.50      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.67      0.70        69
           1       0.33      0.58      0.42        19
           2       0.65      0.56      0.60        59

    accuracy                           0.61       147
   macro avg       0.57      0.60      0.57       147
weighted avg       0.65      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.67      0.63        55
           1       0.45      0.60      0.52        25
           2       0.63      0.48      0.54        67

    accuracy                           0.57       147
   macro avg       0.56      0.58      0.56       147
weighted avg       0.58      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.62      0.57        53
           1       0.33      0.61      0.43        18
           2       0.69      0.46      0.55        76

    accuracy                           0.54       147
   macro avg       0.51      0.56      0.52       147
weighted avg       0.58      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.63        64
           1       0.24      0.32      0.28        25
           2       0.57      0.50      0.53        58

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.551898326898327
F1: 0.5435887788922853
======================================================
Running contraceptive 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.66      0.71      0.68        58
           1       0.35      0.63      0.45        19
           2       0.65      0.48      0.55        71

    accuracy                           0.59       148
   macro avg       0.56      0.61      0.56       148
weighted avg       0.62      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.71      0.73        66
           1       0.44      0.60      0.51        25
           2       0.65      0.58      0.61        57

    accuracy                           0.64       148
   macro avg       0.61      0.63      0.62       148
weighted avg       0.66      0.64      0.65       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.50      0.60        94
           1       0.26      0.38      0.31        24
           2       0.27      0.47      0.35        30

    accuracy                           0.47       148
   macro avg       0.43      0.45      0.42       148
weighted avg       0.57      0.47      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.60      0.64        72
           1       0.58      0.58      0.58        33
           2       0.39      0.48      0.43        42

    accuracy                           0.56       147
   macro avg       0.55      0.55      0.55       147
weighted avg       0.58      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       102
           1       0.33      0.55      0.42        20
           2       0.27      0.56      0.37        25

    accuracy                           0.54       147
   macro avg       0.49      0.55      0.48       147
weighted avg       0.70      0.54      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.62      0.66        71
           1       0.27      0.45      0.34        20
           2       0.53      0.48      0.50        56

    accuracy                           0.54       147
   macro avg       0.50      0.52      0.50       147
weighted avg       0.58      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.68      0.70        66
           1       0.33      0.55      0.42        20
           2       0.67      0.56      0.61        61

    accuracy                           0.61       147
   macro avg       0.57      0.60      0.57       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.65        61
           1       0.48      0.57      0.52        28
           2       0.59      0.52      0.55        58

    accuracy                           0.59       147
   macro avg       0.57      0.58      0.57       147
weighted avg       0.59      0.59      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.63      0.60        57
           1       0.55      0.49      0.51        37
           2       0.51      0.49      0.50        53

    accuracy                           0.54       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.09      0.27      0.14        11
           2       0.59      0.44      0.50        68

    accuracy                           0.52       147
   macro avg       0.45      0.45      0.43       147
weighted avg       0.59      0.52      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5607464607464607
F1: 0.547940247063282
======================================================
Running contraceptive 50 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.66      0.65        61
           1       0.35      0.60      0.44        20
           2       0.67      0.52      0.59        67

    accuracy                           0.59       148
   macro avg       0.56      0.59      0.56       148
weighted avg       0.62      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.71      0.67        56
           1       0.44      0.45      0.45        33
           2       0.57      0.49      0.53        59

    accuracy                           0.57       148
   macro avg       0.55      0.55      0.55       148
weighted avg       0.57      0.57      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.58      0.62        73
           1       0.35      0.41      0.38        29
           2       0.39      0.43      0.41        46

    accuracy                           0.50       148
   macro avg       0.47      0.47      0.47       148
weighted avg       0.52      0.50      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.55      0.58        71
           1       0.52      0.36      0.42        47
           2       0.25      0.45      0.33        29

    accuracy                           0.47       147
   macro avg       0.46      0.45      0.44       147
weighted avg       0.51      0.47      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.62      0.73        90
           1       0.45      0.54      0.49        28
           2       0.33      0.59      0.42        29

    accuracy                           0.60       147
   macro avg       0.56      0.58      0.55       147
weighted avg       0.70      0.60      0.63       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.62      0.64        66
           1       0.27      0.36      0.31        25
           2       0.51      0.46      0.49        56

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.58      0.58        64
           1       0.27      0.47      0.35        19
           2       0.47      0.38      0.42        64

    accuracy                           0.48       147
   macro avg       0.44      0.48      0.45       147
weighted avg       0.50      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.39      0.34      0.37        38
           2       0.43      0.44      0.44        50

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.51      0.52      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.54      0.54        63
           1       0.30      0.33      0.32        30
           2       0.29      0.28      0.29        54

    accuracy                           0.40       147
   macro avg       0.38      0.38      0.38       147
weighted avg       0.40      0.40      0.40       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.52      0.60        86
           1       0.12      0.33      0.18        12
           2       0.37      0.39      0.38        49

    accuracy                           0.46       147
   macro avg       0.40      0.41      0.39       147
weighted avg       0.55      0.46      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5097582276153705
F1: 0.5010359473137009
======================================================
Running contraceptive 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.71      0.65        52
           1       0.35      0.55      0.43        22
           2       0.67      0.47      0.56        74

    accuracy                           0.57       148
   macro avg       0.54      0.58      0.54       148
weighted avg       0.60      0.57      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.72      0.73        65
           1       0.47      0.53      0.50        30
           2       0.57      0.55      0.56        53

    accuracy                           0.62       148
   macro avg       0.60      0.60      0.60       148
weighted avg       0.63      0.62      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.51      0.60        93
           1       0.32      0.33      0.33        33
           2       0.25      0.59      0.36        22

    accuracy                           0.48       148
   macro avg       0.44      0.48      0.43       148
weighted avg       0.58      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.62      0.60        60
           1       0.58      0.58      0.58        33
           2       0.49      0.46      0.48        54

    accuracy                           0.55       147
   macro avg       0.55      0.55      0.55       147
weighted avg       0.55      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.57      0.64        81
           1       0.00      0.00      0.00         0
           2       0.57      0.44      0.50        66

    accuracy                           0.51       147
   macro avg       0.43      0.34      0.38       147
weighted avg       0.66      0.51      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.60      0.66        77
           1       0.24      0.47      0.32        17
           2       0.55      0.53      0.54        53

    accuracy                           0.56       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.61      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.64      0.69        74
           1       0.33      0.50      0.40        22
           2       0.51      0.51      0.51        51

    accuracy                           0.57       147
   macro avg       0.53      0.55      0.53       147
weighted avg       0.60      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.55      0.63        84
           1       0.12      0.80      0.21         5
           2       0.51      0.45      0.48        58

    accuracy                           0.52       147
   macro avg       0.45      0.60      0.44       147
weighted avg       0.62      0.52      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.64      0.59        55
           1       0.55      0.50      0.52        36
           2       0.57      0.52      0.54        56

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.55       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.63      0.65        67
           1       0.03      0.12      0.05         8
           2       0.65      0.46      0.54        72

    accuracy                           0.52       147
   macro avg       0.45      0.40      0.41       147
weighted avg       0.62      0.52      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5451231844088986
F1: 0.5253447236053942
======================================================
Running contraceptive 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.69      0.65        55
           1       0.41      0.50      0.45        28
           2       0.60      0.48      0.53        65

    accuracy                           0.56       148
   macro avg       0.54      0.56      0.54       148
weighted avg       0.57      0.56      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.67      0.71        70
           1       0.44      0.58      0.50        26
           2       0.55      0.54      0.54        52

    accuracy                           0.61       148
   macro avg       0.58      0.60      0.58       148
weighted avg       0.62      0.61      0.61       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.51      0.60        88
           1       0.35      0.34      0.35        35
           2       0.27      0.56      0.37        25

    accuracy                           0.48       148
   macro avg       0.45      0.47      0.44       148
weighted avg       0.55      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.53      0.56        70
           1       0.58      0.56      0.57        34
           2       0.35      0.42      0.38        43

    accuracy                           0.50       147
   macro avg       0.51      0.50      0.50       147
weighted avg       0.52      0.50      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.57      0.64        81
           1       0.00      0.00      0.00         0
           2       0.57      0.44      0.50        66

    accuracy                           0.51       147
   macro avg       0.43      0.34      0.38       147
weighted avg       0.66      0.51      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.27      0.41      0.33        22
           2       0.55      0.49      0.52        57

    accuracy                           0.54       147
   macro avg       0.50      0.51      0.50       147
weighted avg       0.57      0.54      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.62      0.69        81
           1       0.27      0.60      0.38        15
           2       0.53      0.53      0.53        51

    accuracy                           0.59       147
   macro avg       0.53      0.58      0.53       147
weighted avg       0.65      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.56      0.63        82
           1       0.12      0.80      0.21         5
           2       0.53      0.45      0.49        60

    accuracy                           0.52       147
   macro avg       0.46      0.60      0.44       147
weighted avg       0.63      0.52      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.52      0.46      0.49        37
           2       0.45      0.44      0.45        52

    accuracy                           0.50       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.65        61
           1       0.15      0.20      0.17        25
           2       0.53      0.44      0.48        61

    accuracy                           0.49       147
   macro avg       0.44      0.43      0.43       147
weighted avg       0.51      0.49      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.530851259422688
F1: 0.5145605865722971
======================================================
Running contraceptive 50 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1741779534090911
0.1741779534090911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.66        87
           1       0.56      0.51      0.54        37
           2       0.31      0.67      0.42        24

    accuracy                           0.57       148
   macro avg       0.55      0.58      0.54       148
weighted avg       0.65      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [398, 927]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17339066704454154
0.17339066704454154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.68      0.73        74
           1       0.56      0.42      0.48        45
           2       0.29      0.52      0.38        29

    accuracy                           0.57       148
   macro avg       0.55      0.54      0.53       148
weighted avg       0.62      0.57      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [399, 926]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1731918521451877
0.1731918521451877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.48      0.63       121
           1       0.32      0.41      0.36        27
           2       0.00      0.00      0.00         0

    accuracy                           0.47       148
   macro avg       0.41      0.30      0.33       148
weighted avg       0.81      0.47      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [390, 935]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17075315807477984
0.17075315807477984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.52      0.63        98
           1       0.64      0.43      0.51        49
           2       0.00      0.00      0.00         0

    accuracy                           0.49       147
   macro avg       0.48      0.32      0.38       147
weighted avg       0.75      0.49      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [946, 380]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17153648040139421
0.17153648040139421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.50      0.64       114
           1       0.12      0.33      0.18        12
           2       0.20      0.48      0.28        21

    accuracy                           0.48       147
   macro avg       0.41      0.44      0.37       147
weighted avg       0.74      0.48      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [943, 383]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17385681576711626
0.17385681576711626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.55      0.64        85
           1       0.24      0.38      0.30        21
           2       0.35      0.44      0.39        41

    accuracy                           0.50       147
   macro avg       0.45      0.46      0.44       147
weighted avg       0.56      0.50      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1725827161028955
0.1725827161028955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.54      0.67       104
           1       0.36      0.41      0.39        29
           2       0.12      0.43      0.18        14

    accuracy                           0.50       147
   macro avg       0.46      0.46      0.41       147
weighted avg       0.71      0.50      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [922, 404]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17469242541140878
0.17469242541140878
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.51      0.66       111
           1       0.36      0.48      0.41        25
           2       0.08      0.36      0.13        11

    accuracy                           0.50       147
   macro avg       0.45      0.45      0.40       147
weighted avg       0.75      0.50      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [933, 393]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17493570608136272
0.17493570608136272
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.48      0.58        96
           1       0.42      0.50      0.46        28
           2       0.10      0.22      0.14        23

    accuracy                           0.44       147
   macro avg       0.42      0.40      0.39       147
weighted avg       0.57      0.44      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [930, 396]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.17107593551696046
0.17107593551696046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.51      0.61        97
           1       0.33      0.33      0.33        33
           2       0.22      0.65      0.32        17

    accuracy                           0.48       147
   macro avg       0.44      0.50      0.42       147
weighted avg       0.61      0.48      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [949, 377]
Selected clustering_algorithm: spectral
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.49959091744806033
F1: 0.44256619423274274
======================================================
Running contraceptive 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.51      0.65       107
           1       0.62      0.51      0.56        41
           2       0.00      0.00      0.00         0

    accuracy                           0.51       148
   macro avg       0.50      0.34      0.40       148
weighted avg       0.81      0.51      0.63       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.62      0.75        95
           1       0.50      0.46      0.48        37
           2       0.20      0.62      0.30        16

    accuracy                           0.58       148
   macro avg       0.54      0.57      0.51       148
weighted avg       0.75      0.58      0.63       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.48      0.61       110
           1       0.35      0.32      0.33        38
           2       0.00      0.00      0.00         0

    accuracy                           0.44       148
   macro avg       0.40      0.27      0.32       148
weighted avg       0.72      0.44      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.65        90
           1       0.67      0.50      0.57        44
           2       0.10      0.38      0.16        13

    accuracy                           0.52       147
   macro avg       0.52      0.48      0.46       147
weighted avg       0.69      0.52      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.50      0.64       115
           1       0.45      0.50      0.48        30
           2       0.04      1.00      0.08         2

    accuracy                           0.50       147
   macro avg       0.47      0.67      0.40       147
weighted avg       0.80      0.50      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.45      0.62       137
           1       0.09      0.38      0.15         8
           2       0.00      0.00      0.00         2

    accuracy                           0.44       147
   macro avg       0.36      0.28      0.26       147
weighted avg       0.92      0.44      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.67       100
           1       0.45      0.45      0.45        33
           2       0.14      0.50      0.22        14

    accuracy                           0.52       147
   macro avg       0.49      0.50      0.45       147
weighted avg       0.71      0.52      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.48      0.63       116
           1       0.21      0.88      0.34         8
           2       0.22      0.48      0.30        23

    accuracy                           0.50       147
   macro avg       0.44      0.61      0.42       147
weighted avg       0.75      0.50      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.56      0.62        81
           1       0.55      0.38      0.44        48
           2       0.14      0.39      0.20        18

    accuracy                           0.48       147
   macro avg       0.47      0.44      0.42       147
weighted avg       0.59      0.48      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.53      0.62        88
           1       0.27      0.41      0.33        22
           2       0.39      0.54      0.45        37

    accuracy                           0.52       147
   macro avg       0.47      0.49      0.47       147
weighted avg       0.59      0.52      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.502357970215113
F1: 0.42881548926728164
======================================================
Running contraceptive 50 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.53      0.66       104
           1       0.68      0.52      0.59        44
           2       0.00      0.00      0.00         0

    accuracy                           0.53       148
   macro avg       0.52      0.35      0.42       148
weighted avg       0.82      0.53      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.62      0.75        95
           1       0.50      0.46      0.48        37
           2       0.20      0.62      0.30        16

    accuracy                           0.58       148
   macro avg       0.54      0.57      0.51       148
weighted avg       0.75      0.58      0.63       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.48      0.61       110
           1       0.35      0.32      0.33        38
           2       0.00      0.00      0.00         0

    accuracy                           0.44       148
   macro avg       0.40      0.27      0.32       148
weighted avg       0.72      0.44      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.65        90
           1       0.67      0.50      0.57        44
           2       0.10      0.38      0.16        13

    accuracy                           0.52       147
   macro avg       0.52      0.48      0.46       147
weighted avg       0.69      0.52      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.50      0.64       115
           1       0.45      0.50      0.48        30
           2       0.04      1.00      0.08         2

    accuracy                           0.50       147
   macro avg       0.47      0.67      0.40       147
weighted avg       0.80      0.50      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.45      0.62       137
           1       0.09      0.50      0.15         6
           2       0.04      0.50      0.07         4

    accuracy                           0.46       147
   macro avg       0.37      0.48      0.28       147
weighted avg       0.92      0.46      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.50      0.65       118
           1       0.33      0.69      0.45        16
           2       0.14      0.54      0.22        13

    accuracy                           0.52       147
   macro avg       0.47      0.58      0.44       147
weighted avg       0.80      0.52      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.48      0.63       116
           1       0.21      0.88      0.34         8
           2       0.22      0.48      0.30        23

    accuracy                           0.50       147
   macro avg       0.44      0.61      0.42       147
weighted avg       0.75      0.50      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.53      0.60        83
           1       0.52      0.36      0.42        47
           2       0.12      0.35      0.18        17

    accuracy                           0.46       147
   macro avg       0.44      0.41      0.40       147
weighted avg       0.57      0.46      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.54      0.63        87
           1       0.21      0.54      0.30        13
           2       0.45      0.49      0.47        47

    accuracy                           0.52       147
   macro avg       0.47      0.52      0.47       147
weighted avg       0.60      0.52      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5037093215664645
F1: 0.429563805064781
======================================================
Running contraceptive 50 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.57      0.62        74
           1       0.59      0.51      0.55        39
           2       0.33      0.49      0.39        35

    accuracy                           0.53       148
   macro avg       0.53      0.52      0.52       148
weighted avg       0.57      0.53      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.56      0.66        91
           1       0.35      0.50      0.41        24
           2       0.41      0.64      0.50        33

    accuracy                           0.57       148
   macro avg       0.52      0.57      0.53       148
weighted avg       0.65      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.58      0.65        79
           1       0.62      0.36      0.45        59
           2       0.10      0.50      0.16        10

    accuracy                           0.49       148
   macro avg       0.48      0.48      0.42       148
weighted avg       0.64      0.49      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.54      0.64        91
           1       0.55      0.46      0.50        39
           2       0.14      0.41      0.21        17

    accuracy                           0.50       147
   macro avg       0.49      0.47      0.45       147
weighted avg       0.64      0.50      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.49      0.42        47
           1       0.24      0.80      0.37        10
           2       0.67      0.38      0.48        90

    accuracy                           0.44       147
   macro avg       0.42      0.56      0.42       147
weighted avg       0.54      0.44      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.61      0.57        56
           1       0.42      0.34      0.38        41
           2       0.47      0.48      0.48        50

    accuracy                           0.49       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.48      0.49      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.62      0.69        79
           1       0.48      0.41      0.44        39
           2       0.29      0.52      0.38        29

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.50       147
weighted avg       0.60      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.62      0.67        74
           1       0.55      0.45      0.49        40
           2       0.27      0.42      0.33        33

    accuracy                           0.53       147
   macro avg       0.52      0.50      0.50       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.47      0.57        97
           1       0.48      0.55      0.52        29
           2       0.14      0.33      0.19        21

    accuracy                           0.47       147
   macro avg       0.45      0.45      0.43       147
weighted avg       0.60      0.47      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.49      0.56        86
           1       0.27      0.36      0.31        25
           2       0.39      0.56      0.46        36

    accuracy                           0.48       147
   macro avg       0.44      0.47      0.44       147
weighted avg       0.53      0.48      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5050422871851443
F1: 0.48288040459337517
======================================================
Running wine 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
0.6428531638549563
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.25      0.29         8
           1       0.57      0.40      0.47        10
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.30      0.22      0.25        18
weighted avg       0.47      0.33      0.39        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535064
0.6457279700242041
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       1.00      0.50      0.67        14
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.42      0.42        18
weighted avg       0.89      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5514269239609062
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6695550800443301
0.6689792381846519
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.40      0.50        10
           1       0.71      0.62      0.67         8
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.34      0.39        18
weighted avg       0.69      0.50      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6490015686411413
0.6521218750177725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.54      0.70        13
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.51      0.54        18
weighted avg       0.95      0.67      0.76        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 35, 39, 17, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6486856869794573
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.64      0.78        11
           2       0.20      1.00      0.33         1

    accuracy                           0.78        18
   macro avg       0.73      0.88      0.70        18
weighted avg       0.96      0.78      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5630779846357151
0.5582614896019559
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      1.00      0.80         4
           1       1.00      0.78      0.88         9
           2       1.00      1.00      1.00         5

    accuracy                           0.89        18
   macro avg       0.89      0.93      0.89        18
weighted avg       0.93      0.89      0.89        18

Selected Base Classifiers: [GaussianNB(), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 45, 47, 35]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.36578947, 0.14663951, 0.44385027, 0.61340206, 0.41304348,
        0.35172414, 0.36919831, 0.39622642, 0.41811847, 0.0665529 ,
        0.47154472, 0.61904762, 0.04778887],
       [0.62368421, 0.61507128, 0.59893048, 0.63917526, 0.34782609,
        0.28275862, 0.08649789, 0.56603774, 0.34843206, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.68684211, 0.45010183, 0.64171123, 0.2371134 , 0.5       ,
        0.59310345, 0.56751055, 0.0754717 , 0.43554007, 0.32593857,
        0.3902439 , 0.76556777, 0.40442225],
       [0.65263158, 0.18533605, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.30188679, 0.39372822, 0.24914676,
        0.50406504, 0.58608059, 0.58273894]]),
       n_clusters=4))
Best evaluation: 0.5566672902403165
0.5555848400654919
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.17      1.00      0.29         1
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.39      0.47      0.29        18
weighted avg       0.95      0.44      0.57        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 53, 32, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6328446143719906
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       0.71      0.71      0.71         7
           2       0.50      0.40      0.44         5

    accuracy                           0.71        17
   macro avg       0.68      0.70      0.69        17
weighted avg       0.69      0.71      0.69        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
0.5530435807303951
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.50      1.00      0.67         4
           2       0.75      0.50      0.60         6

    accuracy                           0.71        17
   macro avg       0.75      0.74      0.70        17
weighted avg       0.79      0.71      0.71        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5967320261437908
F1: 0.5311215775872639
======================================================
Running wine 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
0.4102364489714664
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.33      0.40         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.36      0.26      0.30        18
weighted avg       0.54      0.39      0.45        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
0.41319458515307916
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39082880414288523
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.4233517317642528
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.40      0.50        10
           1       0.71      0.62      0.67         8
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.34      0.39        18
weighted avg       0.69      0.50      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42568841936132373
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.70      0.82        10
           2       0.40      1.00      0.57         2

    accuracy                           0.83        18
   macro avg       0.80      0.90      0.80        18
weighted avg       0.93      0.83      0.85        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43574614363484715
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.53      0.58        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3960631352009547
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.17      1.00      0.29         1
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.39      0.47      0.29        18
weighted avg       0.95      0.44      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3929666007558449
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.42115559564755967
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.33      0.14      0.19        17
weighted avg       1.00      0.41      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.40789474, 0.11201629, 0.39572193, 0.48453608, 0.35869565,
        0.17241379, 0.05063291, 0.75471698, 0.31230284, 0.53924915,
        0.08130081, 0.1025641 , 0.25820257],
       [0.73684211, 0.18533605, 0.6631016 , 0.34020619, 0.26086957,
        0.50689655, 0.55907173, 0.16981132, 0.59305994, 0.36860068,
        0.61788618, 0.76923077, 0.70399429],
       [0.21315789, 0.0305499 , 0.65240642, 0.3814433 ,...
        0.42068966, 0.39451477, 0.16981132, 0.61198738, 0.15102389,
        0.25203252, 0.66300366, 0.17261056],
       [0.20789474, 0.14867617, 0.3368984 , 0.5257732 , 0.17391304,
        0.34482759, 0.26582278, 0.32075472, 0.3533123 , 0.05716724,
        0.38211382, 0.75457875, 0.15477889],
       [0.64736842, 0.58044807, 0.44385027, 0.45876289, 0.19565217,
        0.22068966, 0.02953586, 0.8490566 , 0.14826498, 0.37713311,
        0.26829268, 0.2014652 , 0.21540656]]),
       n_clusters=5))
Best evaluation: 0.42236119052313603
0.4211214058152277
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.50      1.00      0.67         4
           2       0.75      0.50      0.60         6

    accuracy                           0.71        17
   macro avg       0.75      0.74      0.70        17
weighted avg       0.79      0.71      0.71        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 50, 32, 39, 33]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5339869281045753
F1: 0.43534502253852103
======================================================
Running wine 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
0.4113916784109647
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.33      0.40         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.36      0.26      0.30        18
weighted avg       0.54      0.39      0.45        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.47849462, 0.31027668, 0.55614973, 0.69072165, 0.30434783,
        0.05862069, 0.15822785, 0.26415094, 0.13249211, 0.37713311,
        0.14634146, 0.02583026, 0.20114123],
       [0.89784946, 0.23913043, 0.60962567, 0.31958763, 0.4673913 ,
        0.98965517, 0.66455696, 0.20754717, 0.55835962, 0.55631399,
        0.30894309, 0.79704797, 0.85734665],
       [0.16397849, 0.26086957, 0.58823529, 0.567010...
        0.33448276, 0.28481013, 0.66037736, 0.29652997, 0.12969283,
        0.42276423, 0.53874539, 0.28673324],
       [0.48924731, 0.16996047, 0.62032086, 0.37113402, 0.27173913,
        0.51724138, 0.42827004, 0.24528302, 0.33123028, 0.22610922,
        0.49593496, 0.86346863, 0.5256776 ],
       [0.39784946, 0.09881423, 0.47593583, 0.3556701 , 0.16304348,
        0.35172414, 0.05063291, 0.88679245, 0.26498423, 0.35580205,
        0.2195122 , 0.08118081, 0.26533524]]),
       n_clusters=5))
Best evaluation: 0.4222070163772233
0.419012995902208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       0.86      1.00      0.92         6
           2       1.00      0.83      0.91         6

    accuracy                           0.94        18
   macro avg       0.95      0.94      0.94        18
weighted avg       0.95      0.94      0.94        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [30, 49, 37, 32, 23]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3900631120692844
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      1.00      0.80         4
           1       0.71      1.00      0.83         5
           2       1.00      0.56      0.71         9

    accuracy                           0.78        18
   macro avg       0.79      0.85      0.78        18
weighted avg       0.85      0.78      0.77        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.42192732390019183
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.44      0.53         9
           1       0.71      0.56      0.62         9
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.33      0.39        18
weighted avg       0.69      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4259600121871181
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.70      0.82        10
           2       0.40      1.00      0.57         2

    accuracy                           0.83        18
   macro avg       0.80      0.90      0.80        18
weighted avg       0.93      0.83      0.85        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4346947026438792
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39709836860188236
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.17      1.00      0.29         1
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.39      0.47      0.29        18
weighted avg       0.95      0.44      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.88157895, 0.19959267, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.88850174, 0.53071672,
        0.58536585, 0.63369963, 0.90513552],
       [0.30789474, 0.43584521, 0.51336898, 0.43298969, 0.2826087 ,
        0.09310345, 0.03164557, 0.50943396, 0.11149826, 0.36006826,
        0.14634146, 0.20512821, 0.16547789],
       [0.64473684, 0.18737271, 0.56149733, 0.51030928, 0.32...
        0.59310345, 0.55696203, 0.24528302, 0.50522648, 0.32593857,
        0.45528455, 0.80586081, 0.45791726],
       [0.66578947, 0.16700611, 0.50802139, 0.28865979, 0.51086957,
        0.74827586, 0.62236287, 0.39622642, 0.67247387, 0.41382253,
        0.38211382, 0.77289377, 0.36875892],
       [0.36578947, 0.33808554, 0.48663102, 0.58762887, 0.2173913 ,
        0.24137931, 0.3164557 , 1.        , 0.35191638, 0.12116041,
        0.30894309, 0.74358974, 0.02639087]]),
       n_clusters=5))
Best evaluation: 0.40789992721993173
0.4062180448873674
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 53, 29, 36, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.42058226032189894
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.33      0.14      0.19        17
weighted avg       1.00      0.41      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.69473684, 0.10386965, 0.29946524, 0.3814433 , 0.26086957,
        0.3862069 , 0.30590717, 0.35849057, 0.10094637, 0.21501706,
        0.6097561 , 0.43589744, 0.2510699 ],
       [0.7       , 0.51323829, 0.63101604, 0.48453608, 0.40217391,
        0.29310345, 0.0464135 , 0.69811321, 0.12302839, 0.39249147,
        0.3902439 , 0.2014652 , 0.28673324],
       [0.44473684, 0.21792261, 0.44919786, 0.42268041, 0.17391304,
        0.42068966, 0.46202532, 0.24528302, 0.42902208, 0.22354949,
        0.55284553, 0.68498168, 0.31098431],
       [0.76578947, 0.20162933, 0.48663102, 0.35051546, 0.41304348,
        0.65517241, 0.67510549, 0.35849057, 0.52681388, 0.65017065,
        0.5203252 , 0.67032967, 0.70042796],
       [0.56052632, 0.57637475, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.23208191,
        0.09756098, 0.15018315, 0.39372325]]),
       n_clusters=5))
Best evaluation: 0.41611592781800977
0.4185170220981837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.50      1.00      0.67         4
           2       0.75      0.50      0.60         6

    accuracy                           0.71        17
   macro avg       0.75      0.74      0.70        17
weighted avg       0.79      0.71      0.71        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 39, 43, 50, 15]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5950980392156863
F1: 0.5244683198065551
======================================================
Running wine 100 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.14      0.08      0.11        12
           2       0.00      0.00      0.00         1

    accuracy                           0.06        18
   macro avg       0.05      0.03      0.04        18
weighted avg       0.10      0.06      0.07        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [47, 59, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.71      1.00      0.83         5
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.49      0.49        18
weighted avg       0.92      0.61      0.69        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.71      1.00      0.83         5
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.49      0.49        18
weighted avg       0.92      0.61      0.69        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 49, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.86      0.86      0.86         7
           2       1.00      0.50      0.67        10

    accuracy                           0.61        18
   macro avg       0.62      0.45      0.51        18
weighted avg       0.89      0.61      0.70        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 54, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.22      0.27         9
           1       0.71      0.56      0.62         9
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.35      0.26      0.30        18
weighted avg       0.52      0.39      0.45        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.33      0.44        12
           1       0.57      0.67      0.62         6
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.41      0.33      0.35        18
weighted avg       0.63      0.44      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [50, 50, 60]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       1.00      1.00      1.00         7
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.52      0.57        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [53, 60, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.57      1.00      0.73         4
           2       1.00      0.31      0.47        13

    accuracy                           0.47        17
   macro avg       0.52      0.44      0.40        17
weighted avg       0.90      0.47      0.53        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 57, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.50      1.00      0.67         4
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.50      0.46      0.41        17
weighted avg       0.88      0.53      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [53, 47, 61]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5
F1: 0.4342391159280159
======================================================
Running wine 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.5598430492823778
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       1.00      0.78      0.88         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.44      0.51        18
weighted avg       0.92      0.67      0.77        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 46, 48, 50]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.84946237, 0.16798419, 0.59893048, 0.30412371, 0.41304348,
        0.8       , 0.75738397, 0.35849057, 0.45741325, 0.6331058 ,
        0.6097561 , 0.56457565, 1.        ],
       [0.20967742, 0.27272727, 0.73796791, 0.56185567, 0.69565217,
        0.2137931 , 0.1371308 , 0.01886792, 0.36277603, 0.10409556,
        0.38211382, 0.35793358, 0.24750357],
       [0.48924731, 0.16996047, 0.62032086, 0.37113402, 0.27173913,
        0.51...028, 0.22610922,
        0.49593496, 0.86346863, 0.5256776 ],
       [0.59139785, 0.50592885, 0.49197861, 0.40721649, 0.30434783,
        0.28275862, 0.10337553, 0.90566038, 0.46056782, 0.7883959 ,
        0.06504065, 0.08118081, 0.2831669 ],
       [0.30376344, 0.17193676, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.36277603, 0.09982935,
        0.69105691, 0.35793358, 0.15477889]]),
       n_clusters=5))
Best evaluation: 0.5732046319591022
0.5756391020818856
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 45, 46, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5518440073083504
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
0.5526334434637257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6431564297731764
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6524334272420256
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.563077984635715
0.5577370948387693
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       1.00      0.88      0.93         8
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.46      0.52        18
weighted avg       0.91      0.67      0.76        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [49, 35, 47, 45]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.5561538861641053
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6339136674291943
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.53157895, 0.63543788, 0.51336898, 0.61340206, 0.16304348,
        0.23103448, 0.26371308, 0.90566038, 0.38170347, 0.3003413 ,
        0.29268293, 0.27106227, 0.16904422],
       [0.76578947, 0.20162933, 0.48663102, 0.35051546, 0.41304348,
        0.65517241, 0.67510549, 0.35849057, 0.52681388, 0.65017065,
        0.5203252 , 0.67032967, 0.70042796],
       [0.3       , 0.14460285, 0.62566845, 0.43298969, 0.369...
        0.3137931 , 0.29746835, 0.60377358, 0.1955836 , 0.14249147,
        0.78861789, 0.35164835, 0.05492154],
       [0.73947368, 0.68839104, 0.54545455, 0.45876289, 0.20652174,
        0.28275862, 0.10337553, 0.66037736, 0.36277603, 0.65955631,
        0.07317073, 0.13553114, 0.14407989],
       [0.5       , 0.62321792, 0.68983957, 0.41237113, 0.34782609,
        0.49310345, 0.43670886, 0.22641509, 0.49526814, 0.27474403,
        0.44715447, 0.82417582, 0.35092725]]),
       n_clusters=5))
Best evaluation: 0.6430060586900402
0.6415900724689413
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [26, 48, 35, 28, 30]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.453921568627451
F1: 0.33899316460590967
======================================================
Running wine 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3886695625322416
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        10
           1       1.00      0.88      0.93         8
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.49      0.56        18
weighted avg       1.00      0.72      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [39, 48, 50, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.75268817, 0.16403162, 0.67379679, 0.48453608, 0.48913043,
        0.67931034, 0.64556962, 0.50943396, 0.41324921, 0.45392491,
        0.52845528, 0.47232472, 0.60770328],
       [0.31989247, 0.10869565, 0.31016043, 0.43298969, 0.23913043,
        0.47586207, 0.35864979, 0.49056604, 0.52681388, 0.12116041,
        0.30894309, 0.63837638, 0.02425107],
       [0.35752688, 0.61067194, 0.54545455, 0.53608247, 0.19565217,
        0.45517241, 0.12236287, 0.69811321, 0.19873817, 0.54351536,
        0.06504065, 0.10701107, 0.17261056],
       [0.63709677, 0.62648221, 0.59893048, 0.63917526, 0.34782609,
        0.28275862, 0.08649789, 0.56603774, 0.31545741, 0.51365188,
        0.17886179, 0.099631  , 0.33666191]]),
       n_clusters=4))
Best evaluation: 0.3977950548941245
0.38797021240285845
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [63, 46, 26, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3905804757908644
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42484559092258894
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43372998863379597
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39674683157511936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3950540739185926
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.42031146603728986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3942006868916702
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.43888888888888883
F1: 0.32043590919311793
======================================================
Running wine 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.31052632, 0.08893281, 0.03267974, 0.29032258, 0.88043478,
        0.3       , 0.19831224, 0.01886792, 0.65822785, 0.13395904,
        0.6504065 , 0.65934066, 0.31383738],
       [0.64473684, 0.21146245, 0.46405229, 0.48924731, 0.32608696,
        0.59310345, 0.55696203, 0.24528302, 0.4556962 , 0.32593857,
        0.45528455, 0.80586081, 0.45791726],
       [0.50789474, 0.53557312, 0.4248366 , 0.38172043, 0.3913...
        0.14137931, 0.07594937, 0.50943396, 0.16455696, 0.34129693,
        0.16260163, 0.17582418, 0.2831669 ],
       [0.36578947, 0.35770751, 0.37254902, 0.56989247, 0.2173913 ,
        0.24137931, 0.3164557 , 1.        , 0.3164557 , 0.12116041,
        0.30894309, 0.74358974, 0.02639087],
       [0.67105263, 0.36363636, 0.64705882, 0.70430108, 0.38043478,
        0.19655172, 0.10548523, 0.49056604, 0.35443038, 0.62969283,
        0.21138211, 0.19413919, 0.33666191]]),
       n_clusters=5))
Best evaluation: 0.40997651346346836
0.404712978280749
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [63, 34, 49, 19]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.38709677, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.49446494, 0.4700428 ],
       [0.60483871, 0.17786561, 0.79144385, 0.25257732, 0.43478261,
        0.55862069, 0.49367089, 0.39622642, 0.29968454, 0.28327645,
        0.49593496, 0.5498155 , 0.42938659],
       [0.72043011, 0.97035573, 0.5828877 , 0.51030928, 0.27173913,
        0.24137931, 0.05696203, 0.73584906, 0.20504732, 0.54778157,
        0.1300813 , 0.16605166, 0.32952924],
       [0.53763441, 0.03162055, 0.18716578, 0.27835052, 0.17391304,
        0.33448276, 0.35654008, 0.20754717, 0.33123028, 0.28327645,
        0.57723577, 0.43911439, 0.08131241],
       [0.16666667, 0.18379447, 0.67379679, 0.79381443, 0.19565217,
        0.32413793, 0.26793249, 0.50943396, 0.29337539, 0.11262799,
        0.71544715, 0.70848708, 0.20256776]]),
       n_clusters=5))
Best evaluation: 0.4075133600277703
0.4012886080736019
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [52, 53, 27, 40]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39089986500885143
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.52631579, 0.03162055, 0.18716578, 0.27835052, 0.17391304,
        0.3057554 , 0.33839479, 0.20754717, 0.33123028, 0.28327645,
        0.57723577, 0.45660377, 0.08114558],
       [0.35263158, 0.09288538, 0.64171123, 0.38659794, 0.30434783,
        0.47482014, 0.47288503, 0.45283019, 0.52681388, 0.28327645,
        0.57723577, 0.38867925, 0.30867144],
       [0.72368421, 0.39920949, 0.5026738 , 0.5876288...
        0.08992806, 0.04555315, 0.52830189, 0.1955836 , 0.70819113,
        0.17886179, 0.15471698, 0.25855211],
       [0.74736842, 0.22924901, 0.77005348, 0.45360825, 0.40217391,
        0.66546763, 0.54229935, 0.45283019, 0.42586751, 0.27474403,
        0.62601626, 0.80377358, 0.49721559],
       [0.70789474, 0.13636364, 0.60962567, 0.31443299, 0.41304348,
        0.82733813, 0.69414317, 0.11320755, 0.51419558, 0.47098976,
        0.33333333, 0.60377358, 0.79156722]]),
       n_clusters=5))
Best evaluation: 0.41784159318279074
0.4161617607671109
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 31, 53, 31, 32]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4252851415714793
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43608156596331543
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.65526316, 0.48023715, 0.72727273, 0.66494845, 0.29347826,
        0.19655172, 0.03797468, 0.74      , 0.04416404, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.47894737, 0.16996047, 0.62032086, 0.37113402, 0.27173913,
        0.51724138, 0.42827004, 0.26      , 0.33123028, 0.22610922,
        0.49593496, 0.86446886, 0.5256776 ],
       [0.33157895, 0.41304348, 0.45989305, 0.3814433 , 0.19565217,
        0.50689655, 0.40295359, 0.24      , 0.49842271, 0.07423208,
        0.54471545, 0.74358974, 0.0085592 ],
       [0.71052632, 0.15019763, 0.71657754, 0.61340206, 0.33695652,
        0.69655172, 0.61392405, 0.32      , 0.6214511 , 0.37713311,
        0.57723577, 0.52747253, 0.71825963]]),
       n_clusters=4))
Best evaluation: 0.4037893673503898
0.3967547343475365
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [53, 34, 38, 48]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39241745061477934
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.42027785465890005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.395257865014568
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3944444444444445
F1: 0.2718400022467152
======================================================
Running wine 100 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.43      0.43      0.43         7
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.32      0.38        18
weighted avg       0.78      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [59, 45, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        10
           1       0.43      0.38      0.40         8
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.33      0.38        18
weighted avg       0.75      0.50      0.59        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 46, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        10
           1       0.43      0.38      0.40         8
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.33      0.38        18
weighted avg       0.75      0.50      0.59        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.54      0.70        13
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.51      0.54        18
weighted avg       0.95      0.67      0.76        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [46, 56, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.86      0.50      0.63        12
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.56      0.44      0.49        18
weighted avg       0.85      0.61      0.70        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [59, 54, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.14      0.20        18
weighted avg       0.78      0.33      0.47        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 49, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.86      0.50      0.63        12
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.56      0.44      0.49        18
weighted avg       0.85      0.61      0.70        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 50, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 55, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.33      0.31         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.43      0.29      0.34        17
weighted avg       0.75      0.47      0.57        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 46, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [47, 54, 60]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4820261437908496
F1: 0.37848648356843584
======================================================
Running wine 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.560402486839183
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 50, 48, 39]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.28225806, 0.0770751 , 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31230284, 0.07849829,
        0.67479675, 0.52767528, 0.2510699 ],
       [0.77150538, 0.18577075, 0.40641711, 0.27835052, 0.33695652,
        0.73103448, 0.64345992, 0.1509434 , 0.54574132, 0.4112628 ,
        0.3495935 , 0.75276753, 0.5042796 ],
       [0.48924731, 0.5       , 0.65240642, 0.58762887, 0.39130435,
        0.23103448, 0.05485232, 0.88679245, 0.17350158, 0.3668942 ,
        0.31707317, 0.30258303, 0.20827389],
       [0.84139785, 0.34980237, 0.59893048, 0.48453608, 0.22826087,
        0.24137931, 0.07594937, 0.58490566, 0.26182965, 0.71843003,
        0.11382114, 0.15498155, 0.2724679 ]]),
       n_clusters=4))
Best evaluation: 0.5553910230560434
0.5559759213072557
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 63, 26, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5508355310376882
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
0.5526334434637257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6441087270091594
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6447340166663464
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5630779846357151
0.5576535734217162
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 35, 45, 47]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.5561125907247475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6330589081934215
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71578947, 0.20162933, 0.56149733, 0.27835052, 0.20652174,
        0.55862069, 0.51054852, 0.30188679, 0.44164038, 0.36860068,
        0.54471545, 0.5970696 , 0.74322397],
       [0.45789474, 0.33604888, 0.49197861, 0.45876289, 0.17391304,
        0.14137931, 0.03586498, 0.66037736, 0.07255521, 0.7354948 ,
        0.07317073, 0.13186813, 0.13694722],
       [0.62631579, 0.63136456, 0.40641711, 0.4226804...
        0.50689655, 0.49367089, 0.26415094, 0.33753943, 0.2559727 ,
        0.3495935 , 0.63369963, 0.53994294],
       [0.19210526, 0.39511202, 0.8342246 , 0.48453608, 0.35869565,
        0.26551724, 0.35654008, 0.88679245, 0.20189274, 0.21501706,
        0.6097561 , 0.45054945, 0.23466476],
       [0.27631579, 0.07942974, 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31230284, 0.07849829,
        0.67479675, 0.53113553, 0.2510699 ]]),
       n_clusters=5))
Best evaluation: 0.6380856122559666
0.6390291187857134
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 40, 20, 26, 38]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3892065748844555
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 50, 39, 48]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.90053763, 0.22332016, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.8044164 , 0.53071672,
        0.58536585, 0.63099631, 0.90513552],
       [0.21774194, 0.42490119, 0.46524064, 0.3814433 , 0.45652174,
        0.25517241, 0.20675105, 0.56603774, 0.170347  , 0.1168942 ,
        0.3902439 , 0.45387454, 0.15834522],
       [0.49731183, 0.44466403, 0.55614973, 0.48453608, 0.36956522,
        0.11034483, 0.18565401, 0.20754717, 0.13249211, 0.35153584,
        0.21138211, 0.04797048, 0.17974322],
       [0.59408602, 0.64031621, 0.4973262 , 0.3556701 , 0.35869565,
        0.57241379, 0.48312236, 0.35849057, 0.39432177, 0.26279863,
        0.27642276, 0.63099631, 0.28673324]]),
       n_clusters=4))
Best evaluation: 0.4069054786662437
0.3984704785504667
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 40, 53, 32]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3902678513918447
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4265389001391979
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.435224348124427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.70526316, 0.22134387, 0.53475936, 0.30927835, 0.33695652,
        0.56206897, 0.53586498, 0.28      , 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294],
       [0.41315789, 0.33992095, 0.44919786, 0.40721649, 0.26086957,
        0.22068966, 0.06751055, 1.        , 0.16719243, 0.49658703,
        0.20325203, 0.11355311, 0.29743224],
       [0.53157895, 0.25889328, 0.99465241, 0.74226804, 0.58695652,
        0.56896552, 0.49367089, 0.68      , 0.47634069, 0.19624573,
        0.52845528, 0.70695971, 0.39372325],
       [0.27631579, 0.0770751 , 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.54      , 0.31230284, 0.07849829,
        0.67479675, 0.53113553, 0.2510699 ]]),
       n_clusters=4))
Best evaluation: 0.4053322633080698
0.39765144745386566
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 53, 33, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.392189227985087
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4198158532290209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.39587389779947724
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 100 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3889645456301074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 39, 46, 50]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.54301075, 0.19565217, 0.36363636, 0.09278351, 0.23913043,
        0.6       , 0.61814346, 0.0754717 , 0.78864353, 0.50511945,
        0.5203252 , 0.59778598, 0.62196862],
       [0.72580645, 0.71541502, 0.48128342, 0.61340206, 0.19565217,
        0.10344828, 0.02742616, 0.73584906, 0.23343849, 0.4556314 ,
        0.24390244, 0.1697417 , 0.17261056],
       [0.37365591, 0.35770751, 0.48663102, 0.58762887, 0.2173913 ,
        0.24137931, 0.3164557 , 1.        , 0.31861199, 0.12116041,
        0.30894309, 0.74169742, 0.02639087],
       [0.59408602, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.60516605, 0.32596291]]),
       n_clusters=4))
Best evaluation: 0.4100045856134372
0.4008379773818476
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [49, 53, 38, 33]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3908650095471125
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.62631579, 0.61264822, 0.40641711, 0.42268041, 0.2173913 ,
        0.48561151, 0.47939262, 0.26415094, 0.33753943, 0.2559727 ,
        0.3495935 , 0.65283019, 0.59268099],
       [0.43684211, 0.15612648, 0.48128342, 0.52061856, 0.10869565,
        0.10071942, 0.21475054, 0.8490566 , 0.38170347, 0.15102389,
        0.3902439 , 0.29811321, 0.16308671],
       [0.30789474, 0.45256917, 0.51336898, 0.43298969, 0.2826087 ,
        0.05395683, 0.00433839, 0.50943396, 0.10094637, 0.36006826,
        0.14634146, 0.21132075, 0.17501989],
       [0.88157895, 0.22332016, 0.54545455, 0.07216495, 0.34782609,
        0.79136691, 0.68763557, 0.30188679, 0.8044164 , 0.53071672,
        0.58536585, 0.65283019, 1.        ]]),
       n_clusters=4))
Best evaluation: 0.4098795020997202
0.39934333617153933
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 40, 53, 50]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42545887611913086
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4343677230613246
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39586115036366815
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39280291276084295
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4202022278348623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.64736842, 0.58044807, 0.44385027, 0.45876289, 0.19565217,
        0.22068966, 0.02953586, 0.8490566 , 0.14826498, 0.37713311,
        0.26829268, 0.2014652 , 0.21540656],
       [0.35263158, 0.06720978, 0.39572193, 0.40721649, 0.19565217,
        0.87586207, 0.71940928, 0.20754717, 0.48580442, 0.27474403,
        0.45528455, 0.54945055, 0.2724679 ],
       [0.70526316, 0.22810591, 0.53475936, 0.30927835...
        0.56206897, 0.53586498, 0.26415094, 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294],
       [0.32105263, 0.20162933, 0.40641711, 0.43298969, 0.10869565,
        0.23103448, 0.35654008, 0.45283019, 0.38485804, 0.18088737,
        0.42276423, 0.6959707 , 0.16547789],
       [0.37894737, 0.15885947, 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.4981685 , 0.4700428 ]]),
       n_clusters=5))
Best evaluation: 0.4116975055971082
0.40063303217873875
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 27, 50, 41]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 100 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 46, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [56, 47, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [58, 46, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.42      0.56        12
           1       0.00      0.00      0.00         6
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.28      0.14      0.19        18
weighted avg       0.56      0.28      0.37        18

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [54, 49, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [59, 55, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.79      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [48, 53, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [50, 55, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.56      0.62         9
           2       0.00      0.00      0.00         0

    accuracy                           0.65        17
   macro avg       0.57      0.44      0.49        17
weighted avg       0.85      0.65      0.73        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [57, 46, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [51, 56, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.40522875816993464
F1: 0.2843920460992072
======================================================
Running wine 100 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.5601513401322534
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 50, 39, 48]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.4116108901186653
0.41431802671649165
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [53, 63, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5537276672761662
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.65      , 0.47035573, 0.67379679, 0.69072165, 0.57608696,
        0.10791367, 0.23861171, 0.16981132, 0.26498423, 0.62457338,
        0.08943089, 0.01132075, 0.16706444],
       [0.11315789, 0.59288538, 0.2459893 , 0.45876289, 0.40217391,
        0.74820144, 0.45770065, 0.20754717, 1.        , 0.13822526,
        0.2195122 , 0.58113208, 0.21638823],
       [0.75      , 0.22727273, 0.65775401, 0.22680412, 0.33695652,
        0.77338...006, 0.35409556,
        0.32520325, 0.86415094, 0.64041368],
       [0.30789474, 0.45256917, 0.51336898, 0.43298969, 0.2826087 ,
        0.05395683, 0.00433839, 0.50943396, 0.10094637, 0.36006826,
        0.14634146, 0.21132075, 0.17501989],
       [0.86052632, 0.23320158, 0.72727273, 0.48453608, 0.54347826,
        0.61151079, 0.5791757 , 0.37735849, 0.49211356, 0.41979522,
        0.4796748 , 0.52075472, 0.7875895 ]]),
       n_clusters=5))
Best evaluation: 0.6629836180568838
0.6610899754383484
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [41, 41, 26, 31, 37]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6430962929250892
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6466277501555339
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5630779846357151
0.5585978845836068
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 45, 47, 35]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.5541963358506174
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6338654781073473
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
0.5513067600984851
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19673280115735362
======================================================
Running wine 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3889446210526183
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [39, 46, 50, 48]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.21236559, 0.19367589, 0.27807487, 0.45876289, 0.17391304,
        0.52413793, 0.2742616 , 0.45283019, 0.31861199, 0.0665529 ,
        0.37398374, 0.42435424, 0.09771755],
       [0.90053763, 0.22332016, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.8044164 , 0.53071672,
        0.58536585, 0.63099631, 0.90513552],
       [0.54301075, 0.1798419 , 0.63636364, 0.3814433 , 0.30434783,
        0.50689655, 0.44092827, 0.30188679, 0.32492114, 0.25341297,
        0.5203252 , 0.4501845 , 0.58987161],
       [0.62634409, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.43542435, 0.35805991],
       [0.55107527, 0.62450593, 0.53475936, 0.56185567, 0.4673913 ,
        0.14827586, 0.22151899, 0.39622642, 0.23028391, 0.69283276,
        0.07317073, 0.01476015, 0.19400856]]),
       n_clusters=5))
Best evaluation: 0.39512557129371884
0.3950707746340816
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 26, 37, 25, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39023462401284004
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.425211635716649
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4350212578022864
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3960317012213377
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3934911853468327
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.41956367616441903
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.395257865014568
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 100 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.388502642861159
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 39, 48, 50]
Selected clustering_algorithm: spectral
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.7311828 , 0.19565217, 0.56149733, 0.27835052, 0.20652174,
        0.55862069, 0.51054852, 0.30188679, 0.44164038, 0.36860068,
        0.54471545, 0.59409594, 0.74322397],
       [0.32795699, 0.62055336, 0.44919786, 0.40721649, 0.45652174,
        0.13793103, 0.092827  , 0.30188679, 0.23028391, 0.59129693,
        0.13821138, 0.26199262, 0.41155492],
       [0.11290323, 0.32806324, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.44794953, 0.16808874,
        0.2601626 , 0.77490775, 0.24750357]]),
       n_clusters=3))
Best evaluation: 0.36050305881183853
0.34742004027061674
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [63, 53, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39107451658574227
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.36578947, 0.17193676, 0.44385027, 0.61340206, 0.41304348,
        0.32374101, 0.35140998, 0.39622642, 0.3785489 , 0.0665529 ,
        0.47154472, 0.63773585, 0.04375497],
       [0.83421053, 0.20158103, 0.5828877 , 0.2371134 , 0.45652174,
        0.78057554, 0.63340564, 0.39622642, 0.49211356, 0.46672355,
        0.46341463, 0.59622642, 0.92283214],
       [0.43684211, 0.15612648, 0.48128342, 0.52061856,...
        0.10071942, 0.21475054, 0.8490566 , 0.38170347, 0.15102389,
        0.3902439 , 0.29811321, 0.16308671],
       [0.53157895, 0.20355731, 0.39572193, 0.32989691, 0.40217391,
        0.68345324, 0.54880694, 0.28301887, 0.51104101, 0.32081911,
        0.32520325, 0.78490566, 0.47334924],
       [0.68157895, 0.83201581, 0.52941176, 0.48453608, 0.23913043,
        0.32374101, 0.07158351, 0.64150943, 0.19242902, 0.2662116 ,
        0.3495935 , 0.29433962, 0.20684169]]),
       n_clusters=5))
Best evaluation: 0.41829125899836905
0.41680170104355474
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 37, 29, 26, 41]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4254435808285484
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43160687227371114
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39672071873333087
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.35263158, 0.06517312, 0.64171123, 0.38659794, 0.30434783,
        0.49655172, 0.48734177, 0.45283019, 0.58188153, 0.28327645,
        0.57723577, 0.37728938, 0.2853067 ],
       [0.5       , 0.3910387 , 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.1184669 , 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ],
       [1.        , 0.15274949, 0.43315508, 0.17525773, 0.29347826,
        0.627...0.54703833, 0.33447099,
        0.48780488, 0.57875458, 0.54707561],
       [0.81578947, 0.65376782, 0.73796791, 0.71649485, 0.2826087 ,
        0.36896552, 0.08860759, 0.81132075, 0.32752613, 0.67576792,
        0.10569106, 0.12087912, 0.20114123],
       [0.25526316, 0.51731161, 0.34224599, 0.43298969, 0.18478261,
        0.35172414, 0.2742616 , 0.45283019, 0.5087108 , 0.        ,
        0.36585366, 0.65201465, 0.20399429]]),
       n_clusters=5))
Best evaluation: 0.42535339606573863
0.41908555823233484
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 31, 50, 22, 32]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4200295585659127
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3958349979575793
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19673280115735362
======================================================
Running wine 100 2 majority_voting default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 majority_voting default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [50, 56, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.43      0.21      0.29        14
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.14      0.07      0.10        18
weighted avg       0.33      0.17      0.22        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 54, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.17      0.14      0.15         7
           1       0.14      0.09      0.11        11
           2       0.00      0.00      0.00         0

    accuracy                           0.11        18
   macro avg       0.10      0.08      0.09        18
weighted avg       0.15      0.11      0.13        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.50      0.38      0.43         8
           1       0.29      0.20      0.24        10
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.26      0.19      0.22        18
weighted avg       0.38      0.28      0.32        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.33      0.33         6
           1       0.43      0.25      0.32        12
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.25      0.19      0.22        18
weighted avg       0.40      0.28      0.32        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [50, 56, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       1.00      1.00      1.00         7
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.52      0.57        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 60, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.52      0.49      0.45        17
weighted avg       0.90      0.59      0.65        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 46, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.50      1.00      0.67         4
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.50      0.46      0.41        17
weighted avg       0.88      0.53      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [53, 61, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.40620915032679744
F1: 0.3370868698629277
======================================================
Running wine 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
0.6458002153781164
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.67      0.44         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.44      0.38      0.36        18
weighted avg       0.89      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535064
0.6435672766611836
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       0.86      0.46      0.60        13
           2       0.00      0.00      0.00         1

    accuracy                           0.50        18
   macro avg       0.45      0.40      0.40        18
weighted avg       0.73      0.50      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71052632, 0.15019763, 0.71657754, 0.66480447, 0.33695652,
        0.69655172, 0.61392405, 0.28846154, 0.6214511 , 0.37713311,
        0.57723577, 0.52747253, 0.71825963],
       [0.72368421, 0.39920949, 0.5026738 , 0.63687151, 0.2173913 ,
        0.12758621, 0.07172996, 0.51923077, 0.1955836 , 0.70819113,
        0.17886179, 0.15018315, 0.2403709 ],
       [0.39210526, 0.33399209, 0.43315508, 0.58100559, 0...
        0.54137931, 0.407173  , 0.23076923, 0.2555205 , 0.06143345,
        0.34146341, 0.55311355, 0.03352354],
       [0.71315789, 0.18379447, 0.47593583, 0.32402235, 0.52173913,
        0.55862069, 0.54008439, 0.13461538, 0.38170347, 0.38993174,
        0.35772358, 0.70695971, 0.55777461],
       [0.2       , 0.27470356, 0.75935829, 1.        , 0.23913043,
        0.39655172, 0.40084388, 0.84615385, 0.42586751, 0.14675768,
        0.39837398, 0.42857143, 0.13409415]]),
       n_clusters=5))
Best evaluation: 0.6507927380558256
0.6506717288580501
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         1

    accuracy                           0.44        18
   macro avg       0.43      0.47      0.34        18
weighted avg       0.87      0.44      0.53        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 53, 37, 30, 23]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6695550800443301
0.6697320105463848
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.50      0.57         8
           1       0.71      0.50      0.59        10
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.33      0.39        18
weighted avg       0.69      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6490015686411413
0.6502236582897378
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.53      0.58        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 35, 39, 17, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.53157895, 0.1798419 , 0.63636364, 0.3814433 , 0.34567901,
        0.50689655, 0.44092827, 0.30188679, 0.32492114, 0.31197479,
        0.5203252 , 0.45421245, 0.58987161],
       [0.65526316, 0.48023715, 0.72727273, 0.66494845, 0.33333333,
        0.19655172, 0.03797468, 0.69811321, 0.04416404, 0.32247899,
        0.33333333, 0.28937729, 0.17261056],
       [0.88157895, 0.22332016, 0.54545455, 0.07216495...
        0.8       , 0.69620253, 0.30188679, 0.8044164 , 0.65336134,
        0.58536585, 0.63369963, 0.90513552],
       [0.35263158, 0.08498024, 0.29946524, 0.46391753, 0.09876543,
        0.38965517, 0.35021097, 0.26415094, 0.19873817, 0.35714286,
        0.5203252 , 0.80952381, 0.16547789],
       [0.56052632, 0.55928854, 0.42245989, 0.53608247, 0.39506173,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.28571429,
        0.09756098, 0.15018315, 0.39372325]]),
       n_clusters=5))
Best evaluation: 0.6478736729771221
0.648972979346925
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.78      0.88         9
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.93      0.88        18
weighted avg       0.93      0.89      0.90        18

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 26, 29, 44, 32]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.563077984635715
0.556166962727705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [47, 35, 49, 45]
Selected clustering_algorithm: spectral
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.5553108481672002
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.53      0.58        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6329152402958172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       0.86      0.75      0.80         8
           2       0.50      0.50      0.50         4

    accuracy                           0.76        17
   macro avg       0.73      0.75      0.74        17
weighted avg       0.77      0.76      0.76        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.36578947, 0.36863544, 0.48663102, 0.58762887, 0.2173913 ,
        0.24137931, 0.3164557 , 1.        , 0.31861199, 0.12116041,
        0.30894309, 0.74358974, 0.02639087],
       [0.81315789, 0.15071283, 0.51336898, 0.31958763, 0.27173913,
        0.42068966, 0.44092827, 0.24528302, 0.3659306 , 0.31740614,
        0.56097561, 0.56776557, 0.7146933 ],
       [0.21315789, 0.0305499 , 0.65240642, 0.3814433 , 0.26086957,
        0.42068966, 0.39451477, 0.16981132, 0.61198738, 0.15102389,
        0.25203252, 0.66300366, 0.17261056],
       [0.60263158, 0.50916497, 0.54545455, 0.56185567, 0.23913043,
        0.32758621, 0.08860759, 0.60377358, 0.26498423, 0.60921502,
        0.05691057, 0.12820513, 0.26533524]]),
       n_clusters=4))
Best evaluation: 0.5525323349726282
0.5518318395198227
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.47      0.64        17
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.33      0.16      0.21        17
weighted avg       1.00      0.47      0.64        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 64, 34, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6457516339869281
F1: 0.5746078765193832
======================================================
Running wine 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
0.4108285830093646
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.50      0.40         4
           1       0.86      0.43      0.57        14
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.40      0.31      0.32        18
weighted avg       0.74      0.44      0.53        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
0.4120643441068181
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       0.86      0.43      0.57        14
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.45      0.39      0.39        18
weighted avg       0.78      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.83684211, 0.65217391, 0.57754011, 0.46368715, 0.44565217,
        0.64482759, 0.48734177, 0.30769231, 0.26498423, 0.33788396,
        0.31707317, 0.75457875, 0.57203994],
       [0.16052632, 0.26086957, 0.58823529, 0.61452514, 0.15217391,
        0.33448276, 0.28481013, 0.65384615, 0.29652997, 0.12969283,
        0.42276423, 0.54212454, 0.28673324],
       [0.58947368, 0.69960474, 0.48128342, 0.52513966, 0.54347826,
        0.21034483, 0.07383966, 0.55769231, 0.29652997, 0.76109215,
        0.08943089, 0.10622711, 0.39728959],
       [0.11315789, 0.59288538, 0.2459893 , 0.4972067 , 0.40217391,
        0.75862069, 0.47257384, 0.19230769, 1.        , 0.13822526,
        0.2195122 , 0.56410256, 0.20256776]]),
       n_clusters=4))
Best evaluation: 0.40610528081950426
0.3947793911337205
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [51, 38, 53, 33]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.4212209397023742
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.36      0.47        11
           1       0.71      0.71      0.71         7
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.36      0.39        18
weighted avg       0.69      0.50      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4276114400665755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.44      0.61        16
           2       0.40      1.00      0.57         2

    accuracy                           0.50        18
   macro avg       0.47      0.48      0.39        18
weighted avg       0.93      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4345407872822764
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.64      0.78        11
           2       0.20      1.00      0.33         1

    accuracy                           0.78        18
   macro avg       0.73      0.88      0.70        18
weighted avg       0.96      0.78      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.58947368, 0.69960474, 0.48128342, 0.48453608, 0.54347826,
        0.21034483, 0.07383966, 0.6       , 0.29652997, 0.76109215,
        0.08943089, 0.10622711, 0.39728959],
       [0.74473684, 0.15217391, 0.70053476, 0.74226804, 0.17391304,
        0.67931034, 0.53164557, 0.16      , 0.46056782, 0.17918089,
        0.71544715, 0.69230769, 0.09415121],
       [0.70526316, 0.22134387, 0.53475936, 0.30927835, 0.33695652,
        0.56206897, 0.53586498, 0.28      , 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294],
       [0.65526316, 0.48023715, 0.72727273, 0.66494845, 0.29347826,
        0.19655172, 0.03797468, 0.74      , 0.04416404, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.69736842, 0.21541502, 0.53475936, 0.34020619, 0.36956522,
        0.49655172, 0.49578059, 0.58      , 0.49211356, 0.21843003,
        0.6097561 , 0.58608059, 0.50784593]]),
       n_clusters=5))
Best evaluation: 0.41836080514277374
0.41404219304372347
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [35, 34, 45, 28, 22]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.58157895, 0.34623218, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.49056604, 0.4912892 , 0.25938567,
        0.45528455, 0.60805861, 0.32596291],
       [0.73947368, 0.65784114, 0.54545455, 0.45876289, 0.20652174,
        0.28275862, 0.10337553, 0.66037736, 0.40069686, 0.65955631,
        0.07317073, 0.13553114, 0.14407989],
       [0.27631579, 0.24236253, 0.18181818, 0.355670...
        0.43103448, 0.38607595, 0.24528302, 0.34494774, 0.17235495,
        0.64227642, 0.61904762, 0.30813124],
       [0.5       , 0.3910387 , 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.1184669 , 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ],
       [0.66578947, 0.16700611, 0.50802139, 0.28865979, 0.51086957,
        0.74827586, 0.62236287, 0.39622642, 0.67247387, 0.41382253,
        0.38211382, 0.77289377, 0.36875892]]),
       n_clusters=5))
Best evaluation: 0.4300375302015303
0.4259128375283452
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.54      0.70        13
           2       1.00      1.00      1.00         5

    accuracy                           0.67        18
   macro avg       0.67      0.51      0.57        18
weighted avg       1.00      0.67      0.78        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 24, 39, 33, 50]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.86842105, 0.56324111, 0.49462366, 0.27835052, 0.34782609,
        0.79094077, 0.78830084, 0.26415094, 0.5615142 , 0.28063943,
        0.57731959, 0.79487179, 0.56134094],
       [0.37426901, 0.15612648, 0.48387097, 0.52061856, 0.10869565,
        0.13937282, 0.31197772, 0.8490566 , 0.38170347, 0.11634103,
        0.49484536, 0.28937729, 0.15477889],
       [0.58187135, 0.76284585, 0.80645161, 0.7422680...
        0.34843206, 0.17270195, 0.26415094, 0.22082019, 0.60035524,
        0.19587629, 0.23809524, 0.2510699 ],
       [0.28070175, 0.0770751 , 0.43010753, 0.43298969, 0.18478261,
        0.87804878, 0.76880223, 0.11320755, 0.46056782, 0.24067496,
        0.7628866 , 0.58608059, 0.10128388],
       [0.32163743, 0.19565217, 0.33333333, 0.51030928, 0.16304348,
        0.42508711, 0.44011142, 0.35849057, 0.33753943, 0.10657194,
        0.57731959, 0.84249084, 0.2810271 ]]),
       n_clusters=5))
Best evaluation: 0.4258675268354902
0.41932683403207316
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.33      0.14      0.19        17
weighted avg       1.00      0.41      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 25, 40, 32, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3941902515670499
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.47      0.64        17
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.33      0.16      0.21        17
weighted avg       1.00      0.47      0.64        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5715686274509804
F1: 0.47952116135577344
======================================================
Running wine 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
0.40992385469265114
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.40      0.36         5
           1       0.86      0.46      0.60        13
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.40      0.29      0.32        18
weighted avg       0.71      0.44      0.53        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
0.41279773713900936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       1.00      0.50      0.67        14
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.42      0.42        18
weighted avg       0.89      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3902136171916951
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.42257327792979227
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.40      0.50        10
           1       0.86      0.75      0.80         8
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.51      0.38      0.43        18
weighted avg       0.75      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4253906865477118
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.44      0.61        16
           2       0.40      1.00      0.57         2

    accuracy                           0.50        18
   macro avg       0.47      0.48      0.39        18
weighted avg       0.93      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4351222561165283
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3958178067203031
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3938898459245299
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.80      0.73         5
           1       0.86      0.75      0.80         8
           2       1.00      1.00      1.00         5

    accuracy                           0.83        18
   macro avg       0.84      0.85      0.84        18
weighted avg       0.84      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4207150872181008
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.33      0.14      0.19        17
weighted avg       1.00      0.41      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.395118420954357
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.47      0.64        17
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.33      0.16      0.21        17
weighted avg       1.00      0.47      0.64        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5271241830065361
F1: 0.42168850236625166
======================================================
Running wine 75 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.20526316, 0.27272727, 0.67973856, 0.54301075, 0.69565217,
        0.2137931 , 0.1371308 , 0.01886792, 0.36075949, 0.10409556,
        0.38211382, 0.36263736, 0.24750357],
       [0.53157895, 0.1798419 , 0.55555556, 0.35483871, 0.30434783,
        0.50689655, 0.44092827, 0.30188679, 0.32278481, 0.25341297,
        0.5203252 , 0.45421245, 0.58987161],
       [0.56315789, 0.87944664, 0.40522876, 0.56989247,...
        0.26206897, 0.06118143, 0.90566038, 0.35759494, 0.56484642,
        0.09756098, 0.07692308, 0.31883024],
       [0.16578947, 0.22529644, 0.14379085, 0.24731183, 0.29347826,
        0.21724138, 0.25949367, 0.39622642, 0.23101266, 0.21501706,
        0.6097561 , 0.31868132, 0.10699001],
       [0.27631579, 0.11660079, 0.39215686, 0.65591398, 0.        ,
        0.42068966, 0.26371308, 0.54716981, 0.30379747, 0.03924915,
        0.4796748 , 0.71062271, 0.24750357]]),
       n_clusters=5))
Best evaluation: 0.5779521824157292
0.5795872731886831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.17      0.08      0.11        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.11        18
   macro avg       0.10      0.08      0.09        18
weighted avg       0.16      0.11      0.13        18

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [63, 53, 17, 41]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.26075269, 0.15217391, 0.56684492, 0.58762887, 0.17391304,
        0.16206897, 0.19198312, 0.69811321, 0.38485804, 0.19795222,
        0.46341463, 0.50184502, 0.12268188],
       [0.90053763, 0.22332016, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.8044164 , 0.53071672,
        0.58536585, 0.63099631, 0.90513552],
       [0.55107527, 0.62450593, 0.53475936, 0.56185567, 0.46...
        0.14827586, 0.22151899, 0.39622642, 0.23028391, 0.69283276,
        0.07317073, 0.01476015, 0.19400856],
       [0.60752688, 0.243083  , 0.70588235, 0.31958763, 0.34782609,
        0.69655172, 0.60970464, 0.33962264, 0.39432177, 0.40273038,
        0.4796748 , 0.57195572, 0.70756063],
       [0.15591398, 0.12055336, 0.71657754, 0.48453608, 0.26086957,
        0.60689655, 0.5443038 , 0.30188679, 0.65615142, 0.1168942 ,
        0.3902439 , 0.72693727, 0.28673324]]),
       n_clusters=5))
Best evaluation: 0.46107041698576207
0.46174608621489643
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [32, 10, 53, 51, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.62368421, 0.62648221, 0.59893048, 0.69273743, 0.34782609,
        0.28275862, 0.08649789, 0.55769231, 0.31545741, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.35263158, 0.06521739, 0.39572193, 0.44134078, 0.19565217,
        0.87586207, 0.71940928, 0.19230769, 0.48580442, 0.27474403,
        0.45528455, 0.54945055, 0.2724679 ],
       [0.80789474, 0.25296443, 0.55614973, 0.458100...
        0.61034483, 0.5443038 , 0.34615385, 0.6214511 , 0.41979522,
        0.4796748 , 0.54212454, 0.55777461],
       [0.3       , 0.14031621, 0.62566845, 0.46927374, 0.36956522,
        0.3137931 , 0.29746835, 0.59615385, 0.1955836 , 0.14249147,
        0.78861789, 0.35164835, 0.05492154],
       [0.70526316, 0.22134387, 0.53475936, 0.33519553, 0.33695652,
        0.56206897, 0.53586498, 0.25      , 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294]]),
       n_clusters=5))
Best evaluation: 0.6489447800516186
0.6495847277291706
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [53, 29, 36, 32, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.45789474, 0.53162055, 0.3315508 , 0.27835052, 0.10869565,
        0.19064748, 0.1691974 , 0.56603774, 0.13249211, 0.18088737,
        0.17886179, 0.32075472, 0.06523469],
       [0.73421053, 0.19960474, 0.56684492, 0.17525773, 0.44565217,
        1.        , 0.70932755, 0.35849057, 0.46056782, 0.49232082,
        0.43089431, 0.7509434 , 0.71599045],
       [0.32105263, 0.19565217, 0.40641711, 0.43298969, 0.10869...
        0.19784173, 0.33839479, 0.45283019, 0.38485804, 0.18088737,
        0.42276423, 0.71698113, 0.17501989],
       [0.71315789, 0.18379447, 0.47593583, 0.29896907, 0.52173913,
        0.53956835, 0.52711497, 0.1509434 , 0.38170347, 0.38993174,
        0.35772358, 0.72830189, 0.61256961],
       [0.62368421, 0.76284585, 0.80213904, 0.74226804, 0.45652174,
        0.31654676, 0.10629067, 0.26415094, 0.22082019, 0.61604096,
        0.15447154, 0.24528302, 0.27048528]]),
       n_clusters=5))
Best evaluation: 0.652734677445415
0.6530669036908399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 19, 49, 44, 26]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6436690710603525
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6447819295413787
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.37894737, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.38      , 0.90536278, 0.11262799,
        0.55284553, 0.4981685 , 0.4700428 ],
       [0.64736842, 0.56324111, 0.44385027, 0.45876289, 0.19565217,
        0.22068966, 0.02953586, 0.9       , 0.14826498, 0.37713311,
        0.26829268, 0.2014652 , 0.21540656],
       [0.11052632, 0.32806324, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0....7764, 0.38      , 0.44794953, 0.16808874,
        0.2601626 , 0.77655678, 0.24750357],
       [0.88157895, 0.22332016, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.32      , 0.8044164 , 0.53071672,
        0.58536585, 0.63369963, 0.90513552],
       [0.64473684, 0.21146245, 0.56149733, 0.51030928, 0.32608696,
        0.59310345, 0.55696203, 0.26      , 0.45741325, 0.32593857,
        0.45528455, 0.80586081, 0.45791726]]),
       n_clusters=5))
Best evaluation: 0.578882559034812
0.5786465663621453
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [53, 49, 21, 42]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.555830071365788
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.6330111689055429
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
0.5527567275118364
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3611111111111111
F1: 0.23848865891253435
======================================================
Running wine 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3890093668241135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        10
           1       1.00      0.88      0.93         8
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.49      0.56        18
weighted avg       1.00      0.72      0.83        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [48, 50, 39, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.1155914 , 0.59288538, 0.2459893 , 0.45876289, 0.40217391,
        0.75862069, 0.47257384, 0.20754717, 1.        , 0.13822526,
        0.2195122 , 0.56088561, 0.20256776],
       [0.37365591, 0.17193676, 0.44385027, 0.61340206, 0.41304348,
        0.35172414, 0.36919831, 0.39622642, 0.3785489 , 0.0665529 ,
        0.47154472, 0.61623616, 0.04778887],
       [0.87903226, 0.23320158, 0.72727273, 0.48453608, 0.54347826,
        0.62758621, 0.5907173 , 0.37735849, 0.49211356, 0.41979522,
        0.4796748 , 0.50184502, 0.7146933 ],
       [0.62634409, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.43542435, 0.35805991]]),
       n_clusters=4))
Best evaluation: 0.3615935578331708
0.3531714012887799
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.71      0.38      0.50        13
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.24      0.13      0.17        18
weighted avg       0.52      0.28      0.36        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [54, 63, 53]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.56315789, 0.87944664, 0.51336898, 0.63687151, 0.25      ,
        0.26206897, 0.06118143, 0.90384615, 0.35962145, 0.56484642,
        0.09756098, 0.07692308, 0.31883024],
       [0.65      , 0.21146245, 0.6684492 , 0.52513966, 0.2826087 ,
        0.53448276, 0.47890295, 0.26923077, 0.39432177, 0.19112628,
        0.5203252 , 0.93406593, 0.40442225],
       [0.15526316, 0.24703557, 0.49197861, 0.41340782, 0.30434783,
        0.70344828, 0.40506329, 0.05769231, 0.29652997, 0.16808874,
        0.55284553, 0.61904762, 0.04778887],
       [0.30789474, 0.45256917, 0.51336898, 0.46927374, 0.2826087 ,
        0.09310345, 0.03164557, 0.5       , 0.10094637, 0.36006826,
        0.14634146, 0.20512821, 0.16547789]]),
       n_clusters=4))
Best evaluation: 0.4052049766476238
0.39696293502553226
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.12      0.17        18
weighted avg       0.94      0.33      0.49        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [28, 63, 48, 30]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4252851415714793
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43608021370036304
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39583828549907796
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39556018312744434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4219582175245774
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3958349979575793
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4222222222222222
F1: 0.3059644684429048
======================================================
Running wine 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.21315789, 0.02964427, 0.5751634 , 0.35483871, 0.26086957,
        0.42068966, 0.39451477, 0.16981132, 0.61075949, 0.15102389,
        0.25203252, 0.66300366, 0.17261056],
       [0.62368421, 0.62648221, 0.50980392, 0.62365591, 0.34782609,
        0.28275862, 0.08649789, 0.56603774, 0.31329114, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.80789474, 0.28063241, 0.39215686, 0.354838...
        0.67931034, 0.62869198, 0.16981132, 0.62025316, 0.38139932,
        0.62601626, 0.6959707 , 0.87874465],
       [0.65      , 0.21146245, 0.59477124, 0.46236559, 0.2826087 ,
        0.53448276, 0.47890295, 0.28301887, 0.39240506, 0.19112628,
        0.5203252 , 0.93406593, 0.40442225],
       [0.25526316, 0.53162055, 0.19607843, 0.40860215, 0.18478261,
        0.35172414, 0.2742616 , 0.45283019, 0.45886076, 0.        ,
        0.36585366, 0.65201465, 0.20399429]]),
       n_clusters=5))
Best evaluation: 0.4210544068278147
0.4200389201607174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 53, 30, 33, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.55107527, 0.62450593, 0.53475936, 0.56185567, 0.4673913 ,
        0.14827586, 0.22151899, 0.39622642, 0.23028391, 0.69283276,
        0.07317073, 0.01476015, 0.19400856],
       [0.59408602, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.60516605, 0.32596291],
       [0.28225806, 0.11660079, 0.5026738 , 0.67010309, 0.        ,
        0.42068966, 0.26371308, 0.54716981, 0.30599369, 0.03924915,
        0.4796748 , 0.70848708, 0.24750357],
       [0.68548387, 0.18181818, 0.53475936, 0.43814433, 0.39130435,
        0.64827586, 0.60126582, 0.16981132, 0.48580442, 0.47952218,
        0.49593496, 0.58671587, 0.88231098]]),
       n_clusters=4))
Best evaluation: 0.4069054786662437
0.39838021171262755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [53, 32, 40, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3908577918624466
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.72105263, 0.22924901, 0.70588235, 0.33505155, 0.48913043,
        0.68345324, 0.5032538 , 0.49056604, 0.40063091, 0.42832765,
        0.52845528, 0.62641509, 0.86316627],
       [0.57894737, 0.50592885, 0.49197861, 0.40721649, 0.30434783,
        0.25179856, 0.07809111, 0.90566038, 0.46056782, 0.7883959 ,
        0.06504065, 0.09056604, 0.30628481],
       [0.16052632, 0.26086957, 0.58823529, 0.5670103...
        0.3057554 , 0.26464208, 0.66037736, 0.29652997, 0.12969283,
        0.42276423, 0.55849057, 0.31026253],
       [0.53157895, 0.20355731, 0.39572193, 0.32989691, 0.40217391,
        0.68345324, 0.54880694, 0.28301887, 0.51104101, 0.32081911,
        0.32520325, 0.78490566, 0.47334924],
       [0.43947368, 0.55533597, 0.53475936, 0.56185567, 0.39130435,
        0.21582734, 0.15835141, 0.0754717 , 0.13564669, 0.31740614,
        0.24390244, 0.00754717, 0.24661893]]),
       n_clusters=5))
Best evaluation: 0.4414619225039621
0.44228450511522016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.33      0.48        15
           1       0.14      0.33      0.20         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.22      0.23        18
weighted avg       0.72      0.33      0.43        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [50, 31, 39, 33, 22]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42750702318601785
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43375134604034343
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39529496605659814
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39170271066215867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4200770428241267
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3959501012459093
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.38888888888888884
F1: 0.26837726932746053
======================================================
Running wine 75 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.5596113081085772
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), GaussianNB()]
Number of samples by cluster: [50, 39, 46, 48]
Selected clustering_algorithm: spectral
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.22580645, 0.7055336 , 0.55080214, 0.53608247, 0.13043478,
        0.64827586, 0.56751055, 0.1509434 , 0.78864353, 0.12969283,
        0.2195122 , 0.86715867, 0.07275321],
       [0.5483871 , 0.15019763, 0.39572193, 0.25257732, 0.30434783,
        0.48965517, 0.48523207, 0.28301887, 0.30283912, 0.20648464,
        0.56910569, 0.51660517, 0.52924394],
       [0.57258065, 0.55928854, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.23208191,
        0.09756098, 0.14391144, 0.39372325]]),
       n_clusters=3))
Best evaluation: 0.4116108901186654
0.41568441324374755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [57, 63, 53]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5526130025960122
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
0.5526334434637257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.644401540321932
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6448875683036746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.30789474, 0.45256917, 0.51336898, 0.43298969, 0.2826087 ,
        0.09310345, 0.03164557, 0.54      , 0.10094637, 0.36006826,
        0.14634146, 0.20512821, 0.16547789],
       [0.65263158, 0.20948617, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.32      , 0.35646688, 0.24914676,
        0.50406504, 0.58608059, 0.58273894],
       [0.27631579, 0.21541502, 0.51336898, 0.40721649, 0.11956522,
        0.2137931 , 0.24472574, 0.78      , 0.38801262, 0.09556314,
        0.48780488, 0.36630037, 0.14407989],
       [0.82368421, 0.34980237, 0.59893048, 0.48453608, 0.22826087,
        0.24137931, 0.07594937, 0.62      , 0.26182965, 0.71843003,
        0.11382114, 0.16117216, 0.2724679 ],
       [1.        , 0.17786561, 0.43315508, 0.17525773, 0.29347826,
        0.62758621, 0.55696203, 0.32      , 0.49526814, 0.33447099,
        0.48780488, 0.57875458, 0.54707561]]),
       n_clusters=5))
Best evaluation: 0.6454048349061772
0.6446171015524811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [31, 32, 38, 22, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
0.5542064331703253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.86549708, 0.23913043, 0.61290323, 0.31958763, 0.4673913 ,
        1.        , 0.87743733, 0.20754717, 0.55835962, 0.53818828,
        0.39175258, 0.7985348 , 0.85734665],
       [0.64619883, 0.83201581, 0.53225806, 0.48453608, 0.23913043,
        0.3554007 , 0.1281337 , 0.64150943, 0.19242902, 0.23623446,
        0.44329897, 0.28571429, 0.19400856],
       [0.07017544, 0.18379447, 0.67741935, 0.79381443, 0.19565217,
        0.32752613, 0.35376045, 0.50943396, 0.29337539, 0.07637655,
        0.90721649, 0.71062271, 0.20256776],
       [0.65204678, 0.46640316, 0.64516129, 0.2371134 , 0.5       ,
        0.59930314, 0.74930362, 0.0754717 , 0.39432177, 0.29840142,
        0.49484536, 0.76556777, 0.40442225],
       [0.42690058, 0.76482213, 0.60215054, 0.56185567, 0.17391304,
        0.25087108, 0.08635097, 0.64150943, 0.14195584, 0.52486679,
        0.06185567, 0.21611722, 0.24750357]]),
       n_clusters=5))
Best evaluation: 0.6456081032208187
0.6479833939763222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [18, 23, 50, 45, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.80789474, 0.26069246, 0.55614973, 0.42268041, 0.35869565,
        0.61034483, 0.5443038 , 0.35849057, 0.6214511 , 0.41979522,
        0.4796748 , 0.54212454, 0.55777461],
       [0.29736842, 0.17718941, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.36277603, 0.09982935,
        0.69105691, 0.36263736, 0.15477889],
       [0.41315789, 0.3503055 , 0.44919786, 0.40721649, 0...
        0.22068966, 0.06751055, 0.94339623, 0.16719243, 0.49658703,
        0.20325203, 0.11355311, 0.29743224],
       [0.64473684, 0.18940937, 0.68449198, 0.61340206, 0.20652174,
        0.55862069, 0.16033755, 0.73584906, 0.59305994, 0.89334471,
        0.07317073, 0.18681319, 0.24393723],
       [0.20789474, 0.19959267, 0.27807487, 0.45876289, 0.17391304,
        0.52413793, 0.2742616 , 0.45283019, 0.31861199, 0.0665529 ,
        0.37398374, 0.42857143, 0.09771755]]),
       n_clusters=5))
Best evaluation: 0.6456700621567271
0.645475039959784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [64, 21, 43, 11, 37]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3369281045751634
F1: 0.1755634994445736
======================================================
Running wine 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3888518415862353
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), GaussianNB()]
Number of samples by cluster: [39, 50, 46, 48]
Selected clustering_algorithm: spectral
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.32795699, 0.19565217, 0.40641711, 0.43298969, 0.10869565,
        0.23103448, 0.35654008, 0.45283019, 0.38485804, 0.18088737,
        0.42276423, 0.69372694, 0.16547789],
       [0.55107527, 0.62450593, 0.53475936, 0.56185567, 0.4673913 ,
        0.14827586, 0.22151899, 0.39622642, 0.23028391, 0.69283276,
        0.07317073, 0.01476015, 0.19400856],
       [0.57258065, 0.3201581 , 0.70053476, 0.41237113, 0.33695652,
        0.62758621, 0.61181435, 0.32075472, 0.75709779, 0.37542662,
        0.44715447, 0.69372694, 0.64693295],
       [0.35752688, 0.61067194, 0.54545455, 0.53608247, 0.19565217,
        0.45517241, 0.12236287, 0.69811321, 0.19873817, 0.54351536,
        0.06504065, 0.10701107, 0.17261056]]),
       n_clusters=4))
Best evaluation: 0.3988666422288223
0.39099093772962945
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 13, 63, 40]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3905047152084286
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4264279192796088
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4364546573085931
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39528669555107965
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3945679501016245
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4215304493025634
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3938947979575317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 75 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71052632, 0.71541502, 0.36601307, 0.59677419, 0.19565217,
        0.10344828, 0.02742616, 0.73584906, 0.23101266, 0.4556314 ,
        0.24390244, 0.17582418, 0.17261056],
       [0.38947368, 0.19565217, 0.18300654, 0.48924731, 0.16304348,
        0.42068966, 0.33333333, 0.35849057, 0.33544304, 0.14163823,
        0.45528455, 0.84249084, 0.2810271 ],
       [0.71052632, 0.15019763, 0.65359477, 0.5967741...
        0.69655172, 0.61392405, 0.30188679, 0.62025316, 0.37713311,
        0.57723577, 0.52747253, 0.71825963],
       [0.62105263, 0.20355731, 0.60130719, 0.25268817, 0.25      ,
        0.64482759, 0.54852321, 0.39622642, 0.32594937, 0.3003413 ,
        0.35772358, 0.71428571, 0.65406562],
       [0.44473684, 0.19960474, 0.37908497, 0.59677419, 0.15217391,
        0.13793103, 0.29957806, 0.66037736, 0.38291139, 0.17235495,
        0.32520325, 0.42124542, 0.14978602]]),
       n_clusters=5))
Best evaluation: 0.41873579099259417
0.4189004283581677
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [53, 36, 28, 35, 23]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25      , 0.06916996, 0.5026738 , 0.53608247, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.39116719, 0.16467577,
        0.41463415, 0.67896679, 0.43366619],
       [0.84139785, 0.34980237, 0.59893048, 0.48453608, 0.22826087,
        0.24137931, 0.07594937, 0.58490566, 0.26182965, 0.71843003,
        0.11382114, 0.15498155, 0.2724679 ],
       [0.51075269, 0.60474308, 0.68983957, 0.41237113, 0.34782609,
        0.49310345, 0.43670886, 0.22641509, 0.49526814, 0.27474403,
        0.44715447, 0.82287823, 0.35092725],
       [0.28225806, 0.0770751 , 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31230284, 0.07849829,
        0.67479675, 0.52767528, 0.2510699 ]]),
       n_clusters=4))
Best evaluation: 0.41000458561343733
0.4003554241203152
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 53, 49, 38]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3896056662814666
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4253382539823696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43413552550870327
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3966855029928913
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39304455358169893
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.419760524808919
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3948736357625324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 75 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 majority_voting default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 majority_voting default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.43      0.75      0.55         4
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.39      0.38        18
weighted avg       0.87      0.50      0.59        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 59, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [56, 46, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [48, 56, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.29      0.31         7
           1       0.29      0.18      0.22        11
           2       0.00      0.00      0.00         0

    accuracy                           0.22        18
   macro avg       0.21      0.16      0.18        18
weighted avg       0.30      0.22      0.26        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [59, 54, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 49, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.33      0.33         6
           1       0.43      0.25      0.32        12
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.25      0.19      0.22        18
weighted avg       0.40      0.28      0.32        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [56, 50, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 55, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.48      0.48      0.40        17
weighted avg       0.90      0.53      0.60        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 58, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 54, 51]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.38235294117647056
F1: 0.2757114888322319
======================================================
Running wine 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
0.6499398502266481
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.56      0.42      0.47        18
weighted avg       0.89      0.61      0.71        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535064
0.644003811217299
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.60      0.55         5
           1       0.71      0.38      0.50        13
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.40      0.33      0.35        18
weighted avg       0.65      0.44      0.51        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5539478575099425
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.57      1.00      0.73         4
           2       1.00      0.42      0.59        12

    accuracy                           0.61        18
   macro avg       0.63      0.81      0.61        18
weighted avg       0.83      0.61      0.61        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6695550800443301
0.669273429542995
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.86      0.75      0.80         8
           2       1.00      0.50      0.67        10

    accuracy                           0.61        18
   macro avg       0.62      0.42      0.49        18
weighted avg       0.94      0.61      0.73        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6490015686411413
0.6486199855551146
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.53      0.58        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 35, 39, 17, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6437564925605669
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.67      0.75         9
           2       0.40      1.00      0.57         2

    accuracy                           0.78        18
   macro avg       0.75      0.84      0.75        18
weighted avg       0.86      0.78      0.80        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
0.5539116435995868
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.59473684, 0.21995927, 0.70588235, 0.31958763, 0.34782609,
        0.69655172, 0.60970464, 0.33962264, 0.43554007, 0.40273038,
        0.4796748 , 0.57509158, 0.70756063],
       [0.42368421, 0.09572301, 0.35294118, 0.31958763, 0.32608696,
        0.35862069, 0.2257384 , 0.75471698, 0.07317073, 0.38139932,
        0.40650407, 0.11721612, 0.12268188],
       [0.27631579, 0.04887984, 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.34494774, 0.07849829,
        0.67479675, 0.53113553, 0.2510699 ],
       [0.5       , 0.59266802, 0.68983957, 0.41237113, 0.34782609,
        0.49310345, 0.43670886, 0.22641509, 0.54703833, 0.27474403,
        0.44715447, 0.82417582, 0.35092725]]),
       n_clusters=4))
Best evaluation: 0.5554111834342043
0.5573335871943166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [50, 53, 37, 34]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
0.633343827938679
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.41      0.58        17
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.33      0.14      0.19        17
weighted avg       1.00      0.41      0.58        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.47894737, 0.17515275, 0.62032086, 0.37113402, 0.27173913,
        0.51724138, 0.42827004, 0.24528302, 0.33123028, 0.22610922,
        0.49593496, 0.86446886, 0.5256776 ],
       [0.60263158, 0.50916497, 0.54545455, 0.56185567, 0.23913043,
        0.32758621, 0.08860759, 0.60377358, 0.26498423, 0.60921502,
        0.05691057, 0.12820513, 0.26533524],
       [0.27631579, 0.12016293, 0.5026738 , 0.6701030...
        0.42068966, 0.26371308, 0.54716981, 0.30599369, 0.03924915,
        0.4796748 , 0.71062271, 0.24750357],
       [0.66578947, 0.19755601, 0.50802139, 0.28865979, 0.51086957,
        0.74827586, 0.62236287, 0.39622642, 0.60883281, 0.41382253,
        0.38211382, 0.77289377, 0.36875892],
       [0.11052632, 0.33808554, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.44794953, 0.16808874,
        0.2601626 , 0.77655678, 0.24750357]]),
       n_clusters=5))
Best evaluation: 0.6500730427094765
0.6509063849614305
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 54, 38, 35, 19]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5428104575163399
F1: 0.4486914822114715
======================================================
Running wine 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.56315789, 0.87944664, 0.40522876, 0.56989247, 0.25      ,
        0.26206897, 0.06118143, 0.90566038, 0.35759494, 0.56484642,
        0.09756098, 0.07692308, 0.31883024],
       [0.15263158, 0.12055336, 0.65359477, 0.46236559, 0.26086957,
        0.60689655, 0.5443038 , 0.30188679, 0.65506329, 0.1168942 ,
        0.3902439 , 0.72893773, 0.28673324],
       [0.47631579, 0.43873518, 0.59477124, 0.67741935, 0.336...
        0.46206897, 0.05485232, 0.75471698, 0.12341772, 0.3105802 ,
        0.33333333, 0.32234432, 0.22253923],
       [0.71842105, 0.15612648, 0.65359477, 0.43548387, 0.67391304,
        0.67931034, 0.50632911, 0.69811321, 0.2943038 , 0.35153584,
        0.62601626, 0.63369963, 0.68259629],
       [0.35263158, 0.17588933, 0.39215686, 0.70430108, 0.19565217,
        0.42758621, 0.44514768, 0.50943396, 0.46835443, 0.07167235,
        0.33333333, 0.55311355, 0.04564907]]),
       n_clusters=5))
Best evaluation: 0.4285186504561331
0.4181224214978871
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.50      0.50         6
           1       0.86      0.67      0.75         9
           2       0.40      0.67      0.50         3

    accuracy                           0.61        18
   macro avg       0.59      0.61      0.58        18
weighted avg       0.66      0.61      0.62        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 27, 26, 50, 42]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
0.41279862873011763
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.60      0.55         5
           1       0.71      0.38      0.50        13
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.40      0.33      0.35        18
weighted avg       0.65      0.44      0.51        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.3899822907338281
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.60      0.55         5
           1       0.57      1.00      0.73         4
           2       1.00      0.56      0.71         9

    accuracy                           0.67        18
   macro avg       0.69      0.72      0.66        18
weighted avg       0.77      0.67      0.67        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.42133180571575163
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.36      0.47        11
           1       0.71      0.71      0.71         7
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.46      0.36      0.39        18
weighted avg       0.69      0.50      0.57        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4253906865477118
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.44      0.61        16
           2       0.40      1.00      0.57         2

    accuracy                           0.50        18
   macro avg       0.47      0.48      0.39        18
weighted avg       0.93      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.43573752614823624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.88      0.93         8
           2       0.80      1.00      0.89         4

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.96      0.94      0.95        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.39674683157511936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       1.00      0.44      0.61        16
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.44      0.48      0.37        18
weighted avg       0.93      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39259648057124474
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.60      0.55         5
           1       0.57      0.57      0.57         7
           2       1.00      0.83      0.91         6

    accuracy                           0.67        18
   macro avg       0.69      0.67      0.68        18
weighted avg       0.69      0.67      0.68        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4198158532290209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.57      0.62         7
           1       0.86      0.67      0.75         9
           2       0.00      0.00      0.00         1

    accuracy                           0.59        17
   macro avg       0.51      0.41      0.46        17
weighted avg       0.73      0.59      0.65        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3956099223537958
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.47      0.64        17
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.33      0.16      0.21        17
weighted avg       1.00      0.47      0.64        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5892156862745097
F1: 0.5296981414752088
======================================================
Running wine 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
0.4111011739464538
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       1.00      0.50      0.67        14
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.42      0.42        18
weighted avg       0.89      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 37, 37, 53, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
0.4131766673879597
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       0.71      0.62      0.67         8
           2       0.40      0.50      0.44         4

    accuracy                           0.72        18
   macro avg       0.70      0.71      0.70        18
weighted avg       0.74      0.72      0.73        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 35, 37, 21, 53]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.54736842, 0.05335968, 0.18181818, 0.24581006, 0.08695652,
        0.68965517, 0.59915612, 0.23076923, 0.58990536, 0.34300341,
        0.5203252 , 0.6996337 , 0.15977175],
       [0.62368421, 0.62648221, 0.59893048, 0.69273743, 0.34782609,
        0.28275862, 0.08649789, 0.55769231, 0.31545741, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.58157895, 0.36561265, 0.80748663, 0.5810055...
        0.62758621, 0.49578059, 0.48076923, 0.44479495, 0.25938567,
        0.45528455, 0.60805861, 0.32596291],
       [0.47894737, 0.16996047, 0.62032086, 0.40223464, 0.27173913,
        0.51724138, 0.42827004, 0.23076923, 0.33123028, 0.22610922,
        0.49593496, 0.86446886, 0.5256776 ],
       [0.1       , 0.        , 0.60962567, 0.58100559, 0.19565217,
        0.51724138, 0.35232068, 0.53846154, 0.32492114, 0.15358362,
        0.50406504, 0.38095238, 0.11126961]]),
       n_clusters=5))
Best evaluation: 0.5111397444769818
0.4953438866261354
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67         6
           1       0.71      0.62      0.67         8
           2       0.80      1.00      0.89         4

    accuracy                           0.72        18
   macro avg       0.73      0.76      0.74        18
weighted avg       0.72      0.72      0.72        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 63, 49, 42]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
0.42218397838243904
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.17      0.50      0.25         2
           1       0.71      0.71      0.71         7
           2       1.00      0.56      0.71         9

    accuracy                           0.61        18
   macro avg       0.63      0.59      0.56        18
weighted avg       0.80      0.61      0.66        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 38, 30, 42]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42479706211688323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.70      0.82        10
           2       0.40      1.00      0.57         2

    accuracy                           0.83        18
   macro avg       0.80      0.90      0.80        18
weighted avg       0.93      0.83      0.85        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4334024009819689
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       1.00      0.47      0.64        15
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.50      0.49      0.43        18
weighted avg       0.92      0.56      0.64        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.60474308, 0.68983957, 0.41237113, 0.34782609,
        0.49310345, 0.43670886, 0.24      , 0.49526814, 0.27474403,
        0.44715447, 0.82417582, 0.35092725],
       [0.56052632, 0.55928854, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.6       , 0.2807571 , 0.23208191,
        0.09756098, 0.15018315, 0.39372325],
       [0.27631579, 0.11660079, 0.5026738 , 0.67010309, 0.        ,
        0.42068966, 0.26371308, 0.58      , 0.30599369, 0.03924915,
        0.4796748 , 0.71062271, 0.24750357],
       [0.66578947, 0.19565217, 0.58823529, 0.51030928, 0.5       ,
        0.68275862, 0.51476793, 0.14      , 0.64353312, 0.42406143,
        0.40650407, 0.64468864, 0.60057061]]),
       n_clusters=4))
Best evaluation: 0.4037893673503898
0.397344897716565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       1.00      0.44      0.61        16
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.44      0.48      0.37        18
weighted avg       0.93      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 53, 38, 48]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39115766532806334
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.39      0.56        18
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.33      0.13      0.19        18
weighted avg       1.00      0.39      0.56        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4200295585659127
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      1.00      0.80         4
           1       0.86      0.75      0.80         8
           2       0.50      0.40      0.44         5

    accuracy                           0.71        17
   macro avg       0.67      0.72      0.68        17
weighted avg       0.71      0.71      0.70        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.39608182502500217
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.47      0.64        17
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.33      0.16      0.21        17
weighted avg       1.00      0.47      0.64        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6065359477124184
F1: 0.5383925173055608
======================================================
Running wine 50 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.5598920729597676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       1.00      0.78      0.88         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.44      0.51        18
weighted avg       0.92      0.67      0.77        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 39, 48, 50]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25      , 0.06916996, 0.5026738 , 0.53608247, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.39116719, 0.16467577,
        0.41463415, 0.67896679, 0.43366619],
       [0.88978495, 0.18577075, 0.71657754, 0.74226804, 0.30434783,
        0.62758621, 0.20464135, 0.75471698, 0.72239748, 1.        ,
        0.07317073, 0.24723247, 0.2724679 ],
       [0.75268817, 0.16403162, 0.67379679, 0.48453608, 0.48913043,
        0.6793103...24921, 0.45392491,
        0.52845528, 0.47232472, 0.60770328],
       [0.4811828 , 0.51976285, 0.5026738 , 0.45876289, 0.19565217,
        0.17241379, 0.06751055, 0.50943396, 0.17665615, 0.7662116 ,
        0.19512195, 0.1697417 , 0.29029957],
       [0.15860215, 0.24703557, 0.49197861, 0.3814433 , 0.30434783,
        0.70344828, 0.40506329, 0.0754717 , 0.29652997, 0.16808874,
        0.55284553, 0.61623616, 0.04778887]]),
       n_clusters=5))
Best evaluation: 0.5695035054683778
0.5754022840912858
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         8
           1       0.57      0.40      0.47        10
           2       0.00      0.00      0.00         0

    accuracy                           0.22        18
   macro avg       0.19      0.13      0.16        18
weighted avg       0.32      0.22      0.26        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 49, 51, 42]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5536640667360069
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
0.5526334434637257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6444616771700193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.648676728741556
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5630779846357151
0.557233837545686
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       1.00      0.88      0.93         8
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.46      0.52        18
weighted avg       0.91      0.67      0.76        18

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 35, 49, 47]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.15526316, 0.22403259, 0.49197861, 0.3814433 , 0.30434783,
        0.70344828, 0.40506329, 0.0754717 , 0.32752613, 0.16808874,
        0.55284553, 0.61904762, 0.04778887],
       [0.64473684, 0.15885947, 0.68449198, 0.61340206, 0.20652174,
        0.55862069, 0.16033755, 0.73584906, 0.65505226, 0.89334471,
        0.07317073, 0.18681319, 0.24393723],
       [0.83157895, 0.14256619, 0.59893048, 0.30412371, 0.41304348,
        0.8       , 0.75738397, 0.35849057, 0.50522648, 0.6331058 ,
        0.6097561 , 0.56776557, 1.        ],
       [0.64736842, 0.54989817, 0.44385027, 0.45876289, 0.19565217,
        0.22068966, 0.02953586, 0.8490566 , 0.16376307, 0.37713311,
        0.26829268, 0.2014652 , 0.21540656]]),
       n_clusters=4))
Best evaluation: 0.5667080001470532
0.5652430582058264
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [53, 17, 63, 36]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.6871345 , 0.15612648, 0.72043011, 0.45876289, 0.67391304,
        0.68641115, 0.66852368, 0.69811321, 0.29652997, 0.3250444 ,
        0.79381443, 0.63369963, 0.68259629],
       [0.35964912, 0.12252964, 0.35483871, 0.31958763, 0.32608696,
        0.36236934, 0.29805014, 0.75471698, 0.06624606, 0.35612789,
        0.51546392, 0.11721612, 0.12268188],
       [0.34795322, 0.11857708, 0.29032258, 0.4072164...
        0.16376307, 0.28412256, 0.30188679, 0.29652997, 0.06305506,
        0.57731959, 0.54945055, 0.20256776],
       [0.6754386 , 0.13636364, 0.61290323, 0.31443299, 0.41304348,
        0.84320557, 0.9275766 , 0.11320755, 0.51419558, 0.44937833,
        0.42268041, 0.58608059, 0.71825963],
       [0.24561404, 0.62055336, 0.4516129 , 0.40721649, 0.45652174,
        0.13937282, 0.12256267, 0.30188679, 0.23028391, 0.57460036,
        0.17525773, 0.26739927, 0.41155492]]),
       n_clusters=5))
Best evaluation: 0.6402639705637527
0.6395534758599484
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 27, 44, 36, 40]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.65      , 0.48472505, 0.67379679, 0.69072165, 0.57608696,
        0.14482759, 0.25949367, 0.16981132, 0.26498423, 0.62457338,
        0.08943089, 0.01098901, 0.15834522],
       [0.44473684, 0.21792261, 0.44919786, 0.42268041, 0.17391304,
        0.42068966, 0.46202532, 0.24528302, 0.42902208, 0.22354949,
        0.55284553, 0.68498168, 0.31098431],
       [0.48421053, 0.78818737, 0.59893048, 0.56185567, 0....
        0.24827586, 0.06540084, 0.64150943, 0.14195584, 0.54351536,
        0.04878049, 0.21611722, 0.24750357],
       [0.87894737, 0.24643585, 0.60962567, 0.31958763, 0.4673913 ,
        0.98965517, 0.66455696, 0.20754717, 0.55835962, 0.55631399,
        0.30894309, 0.7985348 , 0.85734665],
       [0.56052632, 0.3299389 , 0.70053476, 0.41237113, 0.33695652,
        0.62758621, 0.61181435, 0.32075472, 0.75709779, 0.37542662,
        0.44715447, 0.6959707 , 0.64693295]]),
       n_clusters=5))
Best evaluation: 0.6500937125876338
0.6504574513832979
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [19, 51, 35, 19, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4091503267973856
F1: 0.2835698811071786
======================================================
Running wine 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.38860660614494047
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       1.00      0.78      0.88         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.44      0.51        18
weighted avg       0.92      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 39, 46, 50]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.66666667, 0.20948617, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.30188679, 0.35646688, 0.24914676,
        0.50406504, 0.58302583, 0.58273894],
       [0.57526882, 0.87944664, 0.51336898, 0.58762887, 0.25      ,
        0.26206897, 0.06118143, 0.90566038, 0.35962145, 0.56484642,
        0.09756098, 0.0701107 , 0.31883024],
       [0.40053763, 0.33399209, 0.43315508, 0.53608247, 0.19565217,
        0.54137931, 0.407173  , 0.24528302, 0.2555205 , 0.06143345,
        0.34146341, 0.5498155 , 0.03352354],
       [0.57258065, 0.55928854, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.23208191,
        0.09756098, 0.14391144, 0.39372325]]),
       n_clusters=4))
Best evaluation: 0.4062438542151504
0.3980783629919422
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.14      0.25      0.18         4
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.23      0.26        18
weighted avg       0.81      0.39      0.51        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [63, 26, 55, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39094152177165004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4253906865477118
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4360596829716093
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3974497536210275
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.39255380546678587
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.41956367616441903
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.3949638774863585
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      0.56      0.59         9
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.54      0.39      0.45        17
weighted avg       0.80      0.59      0.67        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.43888888888888883
F1: 0.325793653300862
======================================================
Running wine 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.38921456977019425
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       1.00      0.78      0.88         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.44      0.51        18
weighted avg       0.92      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [48, 39, 50, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.38709677, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.49446494, 0.4700428 ],
       [0.37365591, 0.17193676, 0.44385027, 0.61340206, 0.41304348,
        0.35172414, 0.36919831, 0.39622642, 0.3785489 , 0.0665529 ,
        0.47154472, 0.61623616, 0.04778887],
       [0.5188172 , 0.53557312, 0.52941176, 0.40721649, 0.39130435,
        0.14137931, 0.07594937, 0.50943396, 0.16719243, 0.34129693,
        0.16260163, 0.1697417 , 0.2831669 ]]),
       n_clusters=3))
Best evaluation: 0.3605030588118386
0.3481521443374156
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [63, 58, 53]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.35263158, 0.06521739, 0.39572193, 0.44134078, 0.19565217,
        0.87586207, 0.71940928, 0.19230769, 0.48580442, 0.27474403,
        0.45528455, 0.54945055, 0.2724679 ],
       [0.16052632, 0.26086957, 0.58823529, 0.61452514, 0.15217391,
        0.33448276, 0.28481013, 0.65384615, 0.29652997, 0.12969283,
        0.42276423, 0.54212454, 0.28673324],
       [0.56052632, 0.55928854, 0.42245989, 0.581005...
        0.17931034, 0.0443038 , 0.55769231, 0.2807571 , 0.23208191,
        0.09756098, 0.15018315, 0.39372325],
       [0.81315789, 0.14624506, 0.51336898, 0.34636872, 0.27173913,
        0.42068966, 0.44092827, 0.23076923, 0.3659306 , 0.31740614,
        0.56097561, 0.56776557, 0.7146933 ],
       [0.5       , 0.60474308, 0.68983957, 0.44692737, 0.34782609,
        0.49310345, 0.43670886, 0.21153846, 0.49526814, 0.27474403,
        0.44715447, 0.82417582, 0.35092725]]),
       n_clusters=5))
Best evaluation: 0.4354226869745491
0.4362925774156545
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 32, 53, 44, 20]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.15217391, 0.44919786, 0.56185567, 0.08333333,
        0.51034483, 0.38607595, 0.73584906, 0.50473186, 0.05290102,
        1.        , 0.58608059, 0.09201141],
       [0.53157895, 0.1798419 , 0.63636364, 0.3814433 , 0.23809524,
        0.50689655, 0.44092827, 0.30188679, 0.32492114, 0.25341297,
        0.4957265 , 0.45421245, 0.58987161],
       [0.53157895, 0.61660079, 0.51336898, 0.61340206, 0.08333333,
        0.23....90566038, 0.38170347, 0.3003413 ,
        0.25641026, 0.27106227, 0.16904422],
       [0.58947368, 0.69960474, 0.48128342, 0.48453608, 0.5       ,
        0.21034483, 0.07383966, 0.56603774, 0.29652997, 0.76109215,
        0.04273504, 0.10622711, 0.39728959],
       [0.37894737, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.52991453, 0.4981685 , 0.4700428 ]]),
       n_clusters=5))
Best evaluation: 0.5131862320840805
0.5131862320840805
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 53, 33, 29]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4383052609124235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3974652314666639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.59736842, 0.16904277, 0.4171123 , 0.32989691, 0.26086957,
        0.48965517, 0.39029536, 0.26415094, 0.32752613, 0.2278157 ,
        0.43902439, 0.54945055, 0.71825963],
       [0.50789474, 0.52138493, 0.52941176, 0.40721649, 0.39130435,
        0.14137931, 0.07594937, 0.50943396, 0.18466899, 0.34129693,
        0.16260163, 0.17582418, 0.2831669 ],
       [0.53157895, 0.23625255, 0.99465241, 0.74226804, 0.58695652,
        0.56896552, 0.49367089, 0.64150943, 0.5261324 , 0.19624573,
        0.52845528, 0.70695971, 0.39372325],
       [0.20789474, 0.11812627, 0.3368984 , 0.5257732 , 0.17391304,
        0.34482759, 0.26582278, 0.32075472, 0.3902439 , 0.05716724,
        0.38211382, 0.75457875, 0.15477889]]),
       n_clusters=4))
Best evaluation: 0.42084291499444987
0.4095646228649549
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 53, 21, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4207423599078353
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.74473684, 0.15682281, 0.70053476, 0.74226804, 0.17391304,
        0.67931034, 0.53164557, 0.1509434 , 0.46056782, 0.17918089,
        0.71544715, 0.69230769, 0.09415121],
       [0.46315789, 0.39307536, 0.59893048, 0.58762887, 0.45652174,
        0.17241379, 0.21518987, 0.20754717, 0.2681388 , 0.81228669,
        0.        , 0.07326007, 0.14407989],
       [0.25526316, 0.15682281, 0.56684492, 0.58762887, 0.1739...
        0.16206897, 0.19198312, 0.69811321, 0.38485804, 0.19795222,
        0.46341463, 0.50549451, 0.12268188],
       [0.88157895, 0.58044807, 0.49197861, 0.27835052, 0.34782609,
        0.78275862, 0.59704641, 0.26415094, 0.5615142 , 0.30887372,
        0.45528455, 0.79487179, 0.56134094],
       [0.31315789, 0.11201629, 0.31016043, 0.43298969, 0.23913043,
        0.47586207, 0.35864979, 0.49056604, 0.52681388, 0.12116041,
        0.30894309, 0.64102564, 0.02425107]]),
       n_clusters=5))
Best evaluation: 0.5092990937802836
0.49705205368394234
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [40, 41, 51, 42]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3983660130718954
F1: 0.27060129961961743
======================================================
Running wine 50 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5651142224224377
0.5599195989584529
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [48, 39, 50, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.65860215, 0.21146245, 0.56149733, 0.51030928, 0.32608696,
        0.59310345, 0.55696203, 0.24528302, 0.45741325, 0.32593857,
        0.45528455, 0.80442804, 0.45791726],
       [0.47311828, 0.38142292, 0.59893048, 0.58762887, 0.45652174,
        0.17241379, 0.21518987, 0.20754717, 0.2681388 , 0.81228669,
        0.        , 0.06642066, 0.14407989],
       [0.41666667, 0.10869565, 0.39572193, 0.48453608, 0.358...
        0.17241379, 0.05063291, 0.75471698, 0.31230284, 0.53924915,
        0.08130081, 0.09594096, 0.25820257],
       [0.73655914, 0.22924901, 0.70588235, 0.33505155, 0.48913043,
        0.69655172, 0.51687764, 0.49056604, 0.40063091, 0.42832765,
        0.52845528, 0.60516605, 0.78245364],
       [0.44086022, 0.04743083, 0.47058824, 0.3814433 , 0.31521739,
        0.42068966, 0.33755274, 0.32075472, 0.33123028, 0.11433447,
        0.6097561 , 0.6900369 , 0.12268188]]),
       n_clusters=5))
Best evaluation: 0.4792649717068219
0.48037406973291663
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.79      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 20, 43, 32, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
0.5498463455162501
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
0.5526334434637257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
0.6433161208994926
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
0.6486866553901738
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.563077984635715
0.5573297738802067
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [49, 35, 47, 45]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.68157895, 0.82688391, 0.52941176, 0.48453608, 0.23913043,
        0.35172414, 0.09704641, 0.64150943, 0.21254355, 0.2662116 ,
        0.3495935 , 0.28571429, 0.19400856],
       [0.88157895, 0.19959267, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.88850174, 0.53071672,
        0.58536585, 0.63369963, 0.90513552],
       [0.44473684, 0.18737271, 0.44919786, 0.42268041, 0.173...
        0.42068966, 0.46202532, 0.24528302, 0.4738676 , 0.22354949,
        0.55284553, 0.68498168, 0.31098431],
       [0.72368421, 0.3808554 , 0.5026738 , 0.58762887, 0.2173913 ,
        0.12758621, 0.07172996, 0.52830189, 0.21602787, 0.70819113,
        0.17886179, 0.15018315, 0.2403709 ],
       [0.83947368, 0.63136456, 0.61497326, 0.13402062, 0.63043478,
        0.69655172, 0.56962025, 0.13207547, 0.58188153, 0.32593857,
        0.33333333, 0.82783883, 0.34379458]]),
       n_clusters=5))
Best evaluation: 0.6470163721974236
0.6490872818196065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 27, 44, 32, 36]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.24561404, 0.19565217, 0.40860215, 0.43298969, 0.10869565,
        0.23344948, 0.47075209, 0.45283019, 0.38485804, 0.14742451,
        0.53608247, 0.6959707 , 0.16547789],
       [0.79239766, 0.14624506, 0.51612903, 0.31958763, 0.27173913,
        0.42508711, 0.5821727 , 0.24528302, 0.3659306 , 0.28952043,
        0.71134021, 0.56776557, 0.7146933 ],
       [0.45321637, 0.53557312, 0.53225806, 0.40721649,...
        0.14285714, 0.10027855, 0.50943396, 0.16719243, 0.31438721,
        0.20618557, 0.17582418, 0.2831669 ],
       [0.48538012, 0.15019763, 0.39784946, 0.25257732, 0.30434783,
        0.49477352, 0.64066852, 0.28301887, 0.30283912, 0.1740675 ,
        0.72164948, 0.52014652, 0.52924394],
       [0.32163743, 0.09881423, 0.47849462, 0.3556701 , 0.16304348,
        0.3554007 , 0.06685237, 0.88679245, 0.26498423, 0.3294849 ,
        0.27835052, 0.08791209, 0.26533524]]),
       n_clusters=5))
Best evaluation: 0.6454321025820757
0.643361735690483
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [44, 37, 31, 30, 23]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
0.5536691473821621
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19456108398563643
======================================================
Running wine 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3886837571986188
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [48, 50, 39, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.38709677, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.49446494, 0.4700428 ],
       [0.38172043, 0.45256917, 0.68449198, 0.84536082, 0.29347826,
        0.31724138, 0.05063291, 0.94339623, 0.23028391, 0.53071672,
        0.15447154, 0.16236162, 0.42938659],
       [0.30376344, 0.17193676, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.36277603, 0.09982935,
        0.69105691, 0.35793358, 0.15477889],
       [0.84946237, 0.16798419, 0.59893048, 0.30412371, 0.41304348,
        0.8       , 0.75738397, 0.35849057, 0.45741325, 0.6331058 ,
        0.6097561 , 0.56457565, 1.        ]]),
       n_clusters=4))
Best evaluation: 0.36670364148204593
0.3555300521916076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [53, 54, 63]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.38995439308823815
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.31315789, 0.10869565, 0.31016043, 0.43298969, 0.23913043,
        0.45323741, 0.34056399, 0.49056604, 0.52681388, 0.12116041,
        0.30894309, 0.66037736, 0.01750199],
       [0.81578947, 0.66403162, 0.73796791, 0.71649485, 0.2826087 ,
        0.34172662, 0.06290672, 0.81132075, 0.29652997, 0.67576792,
        0.10569106, 0.1245283 , 0.21479714],
       [0.71578947, 0.19565217, 0.56149733, 0.2783505...
        0.53956835, 0.4967462 , 0.30188679, 0.44164038, 0.36860068,
        0.54471545, 0.61509434, 0.8194113 ],
       [0.43684211, 0.15612648, 0.48128342, 0.52061856, 0.10869565,
        0.10071942, 0.21475054, 0.8490566 , 0.38170347, 0.15102389,
        0.3902439 , 0.29811321, 0.16308671],
       [0.58157895, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.61151079, 0.48156182, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.62641509, 0.3540175 ]]),
       n_clusters=5))
Best evaluation: 0.44070633356847116
0.4344167990114528
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [36, 35, 50, 28, 20]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.42514966364079987
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4364259478527677
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.36578947, 0.17193676, 0.44385027, 0.61340206, 0.41304348,
        0.35172414, 0.36919831, 0.42      , 0.3785489 , 0.0665529 ,
        0.47154472, 0.61904762, 0.04778887],
       [0.62368421, 0.62648221, 0.59893048, 0.63917526, 0.34782609,
        0.28275862, 0.08649789, 0.6       , 0.31545741, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.79736842, 0.27865613, 0.6684492 , 0.36082474, 0.55434783,
        0...36      , 0.26498423, 0.32167235,
        0.47154472, 0.84615385, 0.7253923 ],
       [0.58157895, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.52      , 0.44479495, 0.25938567,
        0.45528455, 0.60805861, 0.32596291],
       [0.15526316, 0.24703557, 0.49197861, 0.3814433 , 0.30434783,
        0.70344828, 0.40506329, 0.08      , 0.29652997, 0.16808874,
        0.55284553, 0.61904762, 0.04778887]]),
       n_clusters=5))
Best evaluation: 0.4420947480717849
0.43655026449513884
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 53, 48, 20, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3911906002424408
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4197826558220106
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.39490413731870877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 50 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4066317234711158
0.3894173079219488
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [39, 48, 50, 46]
Selected clustering_algorithm: spectral
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.15591398, 0.12055336, 0.71657754, 0.48453608, 0.26086957,
        0.60689655, 0.5443038 , 0.30188679, 0.65615142, 0.1168942 ,
        0.3902439 , 0.72693727, 0.28673324],
       [0.47311828, 0.38142292, 0.59893048, 0.58762887, 0.45652174,
        0.17241379, 0.21518987, 0.20754717, 0.2681388 , 0.81228669,
        0.        , 0.06642066, 0.14407989],
       [0.85215054, 0.20158103, 0.5828877 , 0.2371134 , 0.45652174,
        0.78965517, 0.64345992, 0.39622642, 0.49211356, 0.46672355,
        0.46341463, 0.57564576, 0.83594864],
       [0.57258065, 0.55928854, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.23208191,
        0.09756098, 0.14391144, 0.39372325],
       [0.59408602, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.60516605, 0.32596291]]),
       n_clusters=5))
Best evaluation: 0.42238806883736624
0.41789985063285623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [40, 26, 49, 27, 30]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
0.39026551968333867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [49, 26, 46, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
0.38805144729038865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 39, 62]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
0.4264279192796088
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 25]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
0.4381326453842789
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 30, 20, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
0.3946115791365125
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [34, 48, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
0.3934794001056199
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 49, 53, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
0.4207423599078353
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 35, 49, 33, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
0.39491251396313964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 50, 54, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 50 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 majority_voting default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 majority_voting default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.55      0.67        11
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.47      0.53        18
weighted avg       0.91      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 57, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.29      0.67      0.40         3
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.36      0.32        18
weighted avg       0.88      0.44      0.54        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 54, 60]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.43      0.21      0.29        14
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.14      0.07      0.10        18
weighted avg       0.33      0.17      0.22        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 57, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.42      0.56        12
           1       0.00      0.00      0.00         6
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.28      0.14      0.19        18
weighted avg       0.56      0.28      0.37        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.86      0.67      0.75         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.44      0.52        18
weighted avg       0.93      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [58, 46, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 59, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.71      1.00      0.83         5
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.49      0.49        18
weighted avg       0.92      0.61      0.69        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 46, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.52      0.49      0.45        17
weighted avg       0.90      0.59      0.65        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 58, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.31      0.48        16
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.16        17
weighted avg       0.94      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [5, 94, 62]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4493464052287582
F1: 0.3485969166903119
======================================================
Running pima 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.83      0.79        46
           1       0.70      0.61      0.66        31

    accuracy                           0.74        77
   macro avg       0.73      0.72      0.72        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.10861477262886214
0.10861477262886214
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.83      0.85        53
           1       0.67      0.75      0.71        24

    accuracy                           0.81        77
   macro avg       0.77      0.79      0.78        77
weighted avg       0.81      0.81      0.81        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [164, 299, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11131440617742068
0.11131440617742068
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [165, 295, 231]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.10501357209235528
0.10501357209235528
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), GaussianNB(), GradientBoostingClassifier()]
Number of samples by cluster: [78, 157, 286, 170]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.107779613927052
0.107779613927052
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [233, 290, 168]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11580005633285678
0.11580005633285678
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [174, 291, 226]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11247258578925376
0.11209267863977682
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), SVC(probability=True), GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [21, 146, 159, 274, 95]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11483040763106755
0.11483040763106755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.41      0.65      0.50        17

    accuracy                           0.71        77
   macro avg       0.64      0.69      0.65        77
weighted avg       0.78      0.71      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [282, 181, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.10994500657712872
0.10994500657712872
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.58      0.68      0.62        22

    accuracy                           0.76        76
   macro avg       0.72      0.74      0.73        76
weighted avg       0.78      0.76      0.77        76

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [84, 162, 166, 280]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11416544194522346
0.1110079011389777
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.87        54
           1       0.65      0.77      0.71        22

    accuracy                           0.82        76
   macro avg       0.78      0.80      0.79        76
weighted avg       0.83      0.82      0.82        76

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), SVC(probability=True), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [89, 162, 156, 250, 37]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7721804511278195
F1: 0.6397972083152058
======================================================
Running pima 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.73      0.81        63
           1       0.37      0.71      0.49        14

    accuracy                           0.73        77
   macro avg       0.65      0.72      0.65        77
weighted avg       0.82      0.73      0.75        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.58      0.75      0.65        20

    accuracy                           0.79        76
   macro avg       0.74      0.78      0.75        76
weighted avg       0.81      0.79      0.80        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7682330827067669
F1: 0.6234117923772775
======================================================
Running pima 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.69      0.78        65
           1       0.26      0.58      0.36        12

    accuracy                           0.68        77
   macro avg       0.58      0.64      0.57        77
weighted avg       0.80      0.68      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.87        54
           1       0.65      0.77      0.71        22

    accuracy                           0.82        76
   macro avg       0.78      0.80      0.79        76
weighted avg       0.83      0.82      0.82        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7656698564593302
F1: 0.614695407136502
======================================================
Running pima 100 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.88        54
           1       0.70      0.83      0.76        23

    accuracy                           0.84        77
   macro avg       0.81      0.84      0.82        77
weighted avg       0.86      0.84      0.85        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.59      0.70      0.64        23

    accuracy                           0.77        77
   macro avg       0.73      0.75      0.73        77
weighted avg       0.78      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.59      0.84      0.70        19

    accuracy                           0.82        77
   macro avg       0.77      0.83      0.78        77
weighted avg       0.85      0.82      0.83        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.52      0.70      0.60        20

    accuracy                           0.75        77
   macro avg       0.70      0.74      0.71        77
weighted avg       0.79      0.75      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.50      0.65      0.57        20

    accuracy                           0.74        76
   macro avg       0.68      0.71      0.69        76
weighted avg       0.77      0.74      0.75        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.87      0.88        52
           1       0.73      0.79      0.76        24

    accuracy                           0.84        76
   macro avg       0.82      0.83      0.82        76
weighted avg       0.85      0.84      0.84        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7578947368421052
F1: 0.6083704193158402
======================================================
Running pima 100 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.78      0.75        46
           1       0.63      0.55      0.59        31

    accuracy                           0.69        77
   macro avg       0.67      0.67      0.67        77
weighted avg       0.68      0.69      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.87      0.91        55
           1       0.74      0.91      0.82        22

    accuracy                           0.88        77
   macro avg       0.85      0.89      0.87        77
weighted avg       0.90      0.88      0.89        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.80      0.81        51
           1       0.63      0.65      0.64        26

    accuracy                           0.75        77
   macro avg       0.72      0.73      0.73        77
weighted avg       0.76      0.75      0.75        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.50      0.76      0.60        17

    accuracy                           0.78        76
   macro avg       0.71      0.77      0.72        76
weighted avg       0.83      0.78      0.79        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.762987012987013
F1: 0.6132684209138306
======================================================
Running pima 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        50
           1       0.67      0.67      0.67        27

    accuracy                           0.77        77
   macro avg       0.74      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.87      0.91        55
           1       0.74      0.91      0.82        22

    accuracy                           0.88        77
   macro avg       0.85      0.89      0.87        77
weighted avg       0.90      0.88      0.89        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.79      0.80        52
           1       0.59      0.64      0.62        25

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.75      0.74      0.74        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        55
           1       0.56      0.68      0.61        22

    accuracy                           0.75        77
   macro avg       0.71      0.73      0.72        77
weighted avg       0.77      0.75      0.76        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.70      0.76        60
           1       0.33      0.53      0.41        17

    accuracy                           0.66        77
   macro avg       0.59      0.61      0.59        77
weighted avg       0.73      0.66      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.38      0.62      0.48        16

    accuracy                           0.71        76
   macro avg       0.63      0.68      0.64        76
weighted avg       0.78      0.71      0.73        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.50      0.76      0.60        17

    accuracy                           0.78        76
   macro avg       0.71      0.77      0.72        76
weighted avg       0.83      0.78      0.79        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7655673274094326
F1: 0.6149761607901143
======================================================
Running pima 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.81      0.78        47
           1       0.67      0.60      0.63        30

    accuracy                           0.73        77
   macro avg       0.71      0.70      0.71        77
weighted avg       0.72      0.73      0.72        77

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.87      0.91        55
           1       0.74      0.91      0.82        22

    accuracy                           0.88        77
   macro avg       0.85      0.89      0.87        77
weighted avg       0.90      0.88      0.89        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.79      0.80        52
           1       0.59      0.64      0.62        25

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.75      0.74      0.74        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.70      0.76        60
           1       0.33      0.53      0.41        17

    accuracy                           0.66        77
   macro avg       0.59      0.61      0.59        77
weighted avg       0.73      0.66      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.38      0.62      0.48        16

    accuracy                           0.71        76
   macro avg       0.63      0.68      0.64        76
weighted avg       0.78      0.71      0.73        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.50      0.76      0.60        17

    accuracy                           0.78        76
   macro avg       0.71      0.77      0.72        76
weighted avg       0.83      0.78      0.79        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7603725222146274
F1: 0.6079792689746544
======================================================
Running pima 100 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.83      0.82        48
           1       0.70      0.66      0.68        29

    accuracy                           0.77        77
   macro avg       0.75      0.74      0.75        77
weighted avg       0.76      0.77      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.78      0.74      0.76        53
           1       0.48      0.54      0.51        24

    accuracy                           0.68        77
   macro avg       0.63      0.64      0.63        77
weighted avg       0.69      0.68      0.68        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.87        54
           1       0.67      0.78      0.72        23

    accuracy                           0.82        77
   macro avg       0.78      0.81      0.79        77
weighted avg       0.83      0.82      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        56
           1       0.41      0.52      0.46        21

    accuracy                           0.66        77
   macro avg       0.60      0.62      0.61        77
weighted avg       0.69      0.66      0.67        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.54      0.64      0.58        22

    accuracy                           0.74        76
   macro avg       0.69      0.71      0.70        76
weighted avg       0.75      0.74      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474538619275461
F1: 0.6081141761052247
======================================================
Running pima 100 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        50
           1       0.67      0.67      0.67        27

    accuracy                           0.77        77
   macro avg       0.74      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        67
           1       0.22      0.60      0.32        10

    accuracy                           0.68        77
   macro avg       0.57      0.64      0.56        77
weighted avg       0.83      0.68      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7669343814080657
F1: 0.6016833511448706
======================================================
Running pima 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        60
           1       0.44      0.71      0.55        17

    accuracy                           0.74        77
   macro avg       0.67      0.73      0.68        77
weighted avg       0.80      0.74      0.76        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        62
           1       0.38      0.71      0.50        14

    accuracy                           0.74        76
   macro avg       0.65      0.73      0.66        76
weighted avg       0.82      0.74      0.76        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7656185919343814
F1: 0.5862823404019204
======================================================
Running pima 100 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.48      0.65      0.55        20

    accuracy                           0.73        77
   macro avg       0.67      0.70      0.68        77
weighted avg       0.76      0.73      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        62
           1       0.38      0.71      0.50        14

    accuracy                           0.74        76
   macro avg       0.65      0.73      0.66        76
weighted avg       0.82      0.74      0.76        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.58      0.75      0.65        20

    accuracy                           0.79        76
   macro avg       0.74      0.78      0.75        76
weighted avg       0.81      0.79      0.80        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7604237867395762
F1: 0.5817346833103226
======================================================
Running pima 100 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.52      0.67      0.58        21

    accuracy                           0.74        77
   macro avg       0.69      0.72      0.70        77
weighted avg       0.77      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.44      0.75      0.56        16

    accuracy                           0.75        77
   macro avg       0.68      0.75      0.69        77
weighted avg       0.82      0.75      0.77        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        67
           1       0.22      0.60      0.32        10

    accuracy                           0.68        77
   macro avg       0.57      0.64      0.56        77
weighted avg       0.83      0.68      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.58      0.75      0.65        20

    accuracy                           0.79        76
   macro avg       0.74      0.78      0.75        76
weighted avg       0.81      0.79      0.80        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7630382775119618
F1: 0.5779629241607342
======================================================
Running pima 100 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
CBEG               precision    recall  f1-score   support

           0       0.70      0.78      0.74        45
           1       0.63      0.53      0.58        32

    accuracy                           0.68        77
   macro avg       0.66      0.65      0.66        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
CBEG               precision    recall  f1-score   support

           0       0.90      0.82      0.86        55
           1       0.63      0.77      0.69        22

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.78        77
weighted avg       0.82      0.81      0.81        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
CBEG               precision    recall  f1-score   support

           0       0.70      0.74      0.72        47
           1       0.56      0.50      0.53        30

    accuracy                           0.65        77
   macro avg       0.63      0.62      0.62        77
weighted avg       0.64      0.65      0.65        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
CBEG               precision    recall  f1-score   support

           0       0.74      0.74      0.74        50
           1       0.52      0.52      0.52        27

    accuracy                           0.66        77
   macro avg       0.63      0.63      0.63        77
weighted avg       0.66      0.66      0.66        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7435235816814764
F1: 0.6182114522381795
======================================================
Running pima 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
CBEG               precision    recall  f1-score   support

           0       0.82      0.75      0.78        55
           1       0.48      0.59      0.53        22

    accuracy                           0.70        77
   macro avg       0.65      0.67      0.66        77
weighted avg       0.72      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
CBEG               precision    recall  f1-score   support

           0       0.90      0.82      0.86        55
           1       0.63      0.77      0.69        22

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.78        77
weighted avg       0.82      0.81      0.81        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7487183868762816
F1: 0.5956603005062648
======================================================
Running pima 100 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
CBEG               precision    recall  f1-score   support

           0       0.82      0.75      0.78        55
           1       0.48      0.59      0.53        22

    accuracy                           0.70        77
   macro avg       0.65      0.67      0.66        77
weighted avg       0.72      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
CBEG               precision    recall  f1-score   support

           0       0.90      0.82      0.86        55
           1       0.63      0.77      0.69        22

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.78        77
weighted avg       0.82      0.81      0.81        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7487183868762816
F1: 0.5956603005062648
======================================================
Running pima 100 2 majority_voting default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746120984278879
F1: 0.5951138569127087
======================================================
Running pima 100 3 majority_voting default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.10861477262886214
0.10861477262886214
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [164, 299, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11131440617742068
0.11131440617742068
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [165, 295, 231]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.10501357209235528
0.10501357209235528
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [KNeighborsClassifier(), GaussianNB(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [78, 157, 286, 170]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.107779613927052
0.107779613927052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.80      0.87        60
           1       0.56      0.88      0.68        17

    accuracy                           0.82        77
   macro avg       0.76      0.84      0.78        77
weighted avg       0.87      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [233, 290, 168]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11580005633285678
0.11580005633285678
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [174, 291, 226]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11247258578925376
0.11209267863977682
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), LogisticRegression(), AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [21, 146, 159, 274, 95]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11483040763106755
0.11483040763106755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.71      0.76        58
           1       0.37      0.53      0.43        19

    accuracy                           0.66        77
   macro avg       0.60      0.62      0.60        77
weighted avg       0.71      0.66      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [282, 181, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.10994500657712872
0.10994500657712872
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.58      0.68      0.62        22

    accuracy                           0.76        76
   macro avg       0.72      0.74      0.73        76
weighted avg       0.78      0.76      0.77        76

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [84, 162, 166, 280]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11416544194522346
0.1110079011389777
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.62      0.70      0.65        23

    accuracy                           0.78        76
   macro avg       0.74      0.75      0.74        76
weighted avg       0.79      0.78      0.78        76

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), SVC(probability=True), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [89, 162, 156, 250, 37]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7539473684210527
F1: 0.6085411159969458
======================================================
Running pima 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        51
           1       0.67      0.69      0.68        26

    accuracy                           0.78        77
   macro avg       0.75      0.76      0.76        77
weighted avg       0.78      0.78      0.78        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.83      0.85        53
           1       0.67      0.75      0.71        24

    accuracy                           0.81        77
   macro avg       0.77      0.79      0.78        77
weighted avg       0.81      0.81      0.81        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.73      0.75        52
           1       0.48      0.52      0.50        25

    accuracy                           0.66        77
   macro avg       0.62      0.63      0.62        77
weighted avg       0.67      0.66      0.67        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.69      0.72        55
           1       0.37      0.45      0.41        22

    accuracy                           0.62        77
   macro avg       0.57      0.57      0.57        77
weighted avg       0.65      0.62      0.63        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.71      0.80        65
           1       0.30      0.67      0.41        12

    accuracy                           0.70        77
   macro avg       0.61      0.69      0.61        77
weighted avg       0.82      0.70      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.82      0.86        55
           1       0.62      0.76      0.68        21

    accuracy                           0.80        76
   macro avg       0.76      0.79      0.77        76
weighted avg       0.82      0.80      0.81        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.751367053998633
F1: 0.5931564766367045
======================================================
Running pima 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.85      0.82        47
           1       0.74      0.67      0.70        30

    accuracy                           0.78        77
   macro avg       0.77      0.76      0.76        77
weighted avg       0.78      0.78      0.78        77

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.69      0.72        55
           1       0.37      0.45      0.41        22

    accuracy                           0.62        77
   macro avg       0.57      0.57      0.57        77
weighted avg       0.65      0.62      0.63        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.71      0.80        65
           1       0.30      0.67      0.41        12

    accuracy                           0.70        77
   macro avg       0.61      0.69      0.61        77
weighted avg       0.82      0.70      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.83      0.85        53
           1       0.65      0.74      0.69        23

    accuracy                           0.80        76
   macro avg       0.77      0.78      0.77        76
weighted avg       0.81      0.80      0.81        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.760457963089542
F1: 0.6088089661316544
======================================================
Running pima 75 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.84      0.90        57
           1       0.67      0.90      0.77        20

    accuracy                           0.86        77
   macro avg       0.81      0.87      0.83        77
weighted avg       0.88      0.86      0.86        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        63
           1       0.44      0.86      0.59        14

    accuracy                           0.78        77
   macro avg       0.70      0.81      0.72        77
weighted avg       0.87      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.50      0.65      0.57        20

    accuracy                           0.74        76
   macro avg       0.68      0.71      0.69        76
weighted avg       0.77      0.74      0.75        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.50      0.72      0.59        18

    accuracy                           0.76        76
   macro avg       0.70      0.75      0.71        76
weighted avg       0.81      0.76      0.78        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7487012987012986
F1: 0.5827782109491789
======================================================
Running pima 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.83      0.85        53
           1       0.67      0.75      0.71        24

    accuracy                           0.81        77
   macro avg       0.77      0.79      0.78        77
weighted avg       0.81      0.81      0.81        77

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        63
           1       0.44      0.86      0.59        14

    accuracy                           0.78        77
   macro avg       0.70      0.81      0.72        77
weighted avg       0.87      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.73      0.73        51
           1       0.48      0.50      0.49        26

    accuracy                           0.65        77
   macro avg       0.61      0.61      0.61        77
weighted avg       0.65      0.65      0.65        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        61
           1       0.33      0.56      0.42        16

    accuracy                           0.68        77
   macro avg       0.60      0.63      0.60        77
weighted avg       0.75      0.68      0.70        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7357484620642516
F1: 0.5783250929329462
======================================================
Running pima 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.79      0.80        52
           1       0.59      0.64      0.62        25

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.75      0.74      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.87      0.89        53
           1       0.74      0.83      0.78        24

    accuracy                           0.86        77
   macro avg       0.83      0.85      0.84        77
weighted avg       0.86      0.86      0.86        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.77      0.78        52
           1       0.56      0.60      0.58        25

    accuracy                           0.71        77
   macro avg       0.68      0.68      0.68        77
weighted avg       0.72      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.59      0.70      0.64        23

    accuracy                           0.77        77
   macro avg       0.73      0.75      0.73        77
weighted avg       0.78      0.77      0.77        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        63
           1       0.44      0.86      0.59        14

    accuracy                           0.78        77
   macro avg       0.70      0.81      0.72        77
weighted avg       0.87      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.70      0.78        63
           1       0.30      0.57      0.39        14

    accuracy                           0.68        77
   macro avg       0.59      0.63      0.58        77
weighted avg       0.77      0.68      0.71        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.50      0.72      0.59        18

    accuracy                           0.76        76
   macro avg       0.70      0.75      0.71        76
weighted avg       0.81      0.76      0.78        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7552289815447711
F1: 0.5971960140580937
======================================================
Running pima 75 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.75      0.78        55
           1       0.48      0.59      0.53        22

    accuracy                           0.70        77
   macro avg       0.65      0.67      0.66        77
weighted avg       0.72      0.70      0.71        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.72      0.82        67
           1       0.30      0.80      0.43        10

    accuracy                           0.73        77
   macro avg       0.63      0.76      0.63        77
weighted avg       0.87      0.73      0.77        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.73      0.76        55
           1       0.44      0.55      0.49        22

    accuracy                           0.68        77
   macro avg       0.62      0.64      0.63        77
weighted avg       0.70      0.68      0.68        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        62
           1       0.44      0.80      0.57        15

    accuracy                           0.77        77
   macro avg       0.69      0.78      0.71        77
weighted avg       0.84      0.77      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.54      0.61      0.57        23

    accuracy                           0.72        76
   macro avg       0.68      0.69      0.68        76
weighted avg       0.73      0.72      0.73        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7396274777853726
F1: 0.5432491758488436
======================================================
Running pima 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.72      0.82        67
           1       0.30      0.80      0.43        10

    accuracy                           0.73        77
   macro avg       0.63      0.76      0.63        77
weighted avg       0.87      0.73      0.77        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.46      0.75      0.57        16

    accuracy                           0.76        76
   macro avg       0.69      0.76      0.70        76
weighted avg       0.82      0.76      0.78        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7526657552973343
F1: 0.5554055828458082
======================================================
Running pima 75 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.73      0.83        66
           1       0.33      0.82      0.47        11

    accuracy                           0.74        77
   macro avg       0.65      0.77      0.65        77
weighted avg       0.87      0.74      0.78        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.72      0.79        61
           1       0.37      0.62      0.47        16

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.63        77
weighted avg       0.77      0.70      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.83        63
           1       0.41      0.79      0.54        14

    accuracy                           0.75        77
   macro avg       0.67      0.77      0.68        77
weighted avg       0.84      0.75      0.78        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.46      0.75      0.57        16

    accuracy                           0.76        76
   macro avg       0.69      0.76      0.70        76
weighted avg       0.82      0.76      0.78        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7409774436090226
F1: 0.5366097183459205
======================================================
Running pima 75 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 majority_voting default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.73      0.76        55
           1       0.44      0.55      0.49        22

    accuracy                           0.68        77
   macro avg       0.62      0.64      0.63        77
weighted avg       0.70      0.68      0.68        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.52      0.70      0.60        20

    accuracy                           0.75        77
   macro avg       0.70      0.74      0.71        77
weighted avg       0.79      0.75      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.72      0.78        60
           1       0.37      0.59      0.45        17

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.62        77
weighted avg       0.75      0.69      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.73      0.81        63
           1       0.37      0.71      0.49        14

    accuracy                           0.73        77
   macro avg       0.65      0.72      0.65        77
weighted avg       0.82      0.73      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.58      0.83      0.68        18

    accuracy                           0.82        76
   macro avg       0.76      0.82      0.78        76
weighted avg       0.85      0.82      0.83        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474538619275461
F1: 0.569617011370971
======================================================
Running pima 75 3 majority_voting default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.76      0.76        50
           1       0.56      0.56      0.56        27

    accuracy                           0.69        77
   macro avg       0.66      0.66      0.66        77
weighted avg       0.69      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.10861477262886214
0.10861477262886214
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [164, 299, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11131440617742068
0.11131440617742068
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [165, 295, 231]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.10501357209235528
0.10501357209235528
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 157, 286, 170]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.107779613927052
0.107779613927052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [233, 290, 168]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11580005633285678
0.11580005633285678
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.48      0.65      0.55        20

    accuracy                           0.73        77
   macro avg       0.67      0.70      0.68        77
weighted avg       0.76      0.73      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [174, 291, 226]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11247258578925376
0.11209267863977682
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), SVC(probability=True), LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [21, 146, 159, 274, 95]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.11483040763106755
0.11483040763106755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [282, 181, 228]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.10994500657712872
0.10994500657712872
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.46      0.63      0.53        19

    accuracy                           0.72        76
   macro avg       0.66      0.69      0.67        76
weighted avg       0.76      0.72      0.74        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [84, 162, 166, 280]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.11416544194522346
0.1110079011389777
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.62      0.73      0.67        22

    accuracy                           0.79        76
   macro avg       0.75      0.77      0.76        76
weighted avg       0.80      0.79      0.79        76

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), SVC(probability=True), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [89, 162, 156, 250, 37]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7409261790840739
F1: 0.5768183967332904
======================================================
Running pima 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.83      0.82        48
           1       0.70      0.66      0.68        29

    accuracy                           0.77        77
   macro avg       0.75      0.74      0.75        77
weighted avg       0.76      0.77      0.76        77

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.72      0.77        57
           1       0.41      0.55      0.47        20

    accuracy                           0.68        77
   macro avg       0.61      0.63      0.62        77
weighted avg       0.71      0.68      0.69        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.80        58
           1       0.44      0.63      0.52        19

    accuracy                           0.71        77
   macro avg       0.65      0.69      0.66        77
weighted avg       0.76      0.71      0.73        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.33      0.69      0.45        13

    accuracy                           0.71        77
   macro avg       0.63      0.71      0.63        77
weighted avg       0.82      0.71      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.46      0.67      0.55        18

    accuracy                           0.74        76
   macro avg       0.67      0.71      0.68        76
weighted avg       0.78      0.74      0.75        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.54      0.82      0.65        17

    accuracy                           0.80        76
   macro avg       0.74      0.81      0.76        76
weighted avg       0.85      0.80      0.82        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7630382775119617
F1: 0.6007227701734833
======================================================
Running pima 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.82      0.87        56
           1       0.63      0.81      0.71        21

    accuracy                           0.82        77
   macro avg       0.77      0.82      0.79        77
weighted avg       0.84      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.72      0.77        57
           1       0.41      0.55      0.47        20

    accuracy                           0.68        77
   macro avg       0.61      0.63      0.62        77
weighted avg       0.71      0.68      0.69        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.80        58
           1       0.44      0.63      0.52        19

    accuracy                           0.71        77
   macro avg       0.65      0.69      0.66        77
weighted avg       0.76      0.71      0.73        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.59      0.84      0.70        19

    accuracy                           0.82        77
   macro avg       0.77      0.83      0.78        77
weighted avg       0.85      0.82      0.83        77

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.33      0.69      0.45        13

    accuracy                           0.71        77
   macro avg       0.63      0.71      0.63        77
weighted avg       0.82      0.71      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.54      0.74      0.62        19

    accuracy                           0.78        76
   macro avg       0.72      0.76      0.73        76
weighted avg       0.81      0.78      0.79        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7578263841421736
F1: 0.5968167301400419
======================================================
Running pima 50 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.75      0.76        52
           1       0.52      0.56      0.54        25

    accuracy                           0.69        77
   macro avg       0.65      0.66      0.65        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.72      0.75        54
           1       0.44      0.52      0.48        23

    accuracy                           0.66        77
   macro avg       0.61      0.62      0.61        77
weighted avg       0.68      0.66      0.67        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.86        62
           1       0.48      0.87      0.62        15

    accuracy                           0.79        77
   macro avg       0.72      0.82      0.74        77
weighted avg       0.87      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.72      0.79        61
           1       0.37      0.62      0.47        16

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.63        77
weighted avg       0.77      0.70      0.72        77

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), GradientBoostingClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        51
           1       0.65      0.68      0.67        25

    accuracy                           0.78        76
   macro avg       0.75      0.75      0.75        76
weighted avg       0.78      0.78      0.78        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.79      0.82        53
           1       0.58      0.65      0.61        23

    accuracy                           0.75        76
   macro avg       0.71      0.72      0.71        76
weighted avg       0.76      0.75      0.75        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7383458646616541
F1: 0.5782412035385798
======================================================
Running pima 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.85      0.84        48
           1       0.74      0.69      0.71        29

    accuracy                           0.79        77
   macro avg       0.78      0.77      0.78        77
weighted avg       0.79      0.79      0.79        77

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.87      0.89        53
           1       0.74      0.83      0.78        24

    accuracy                           0.86        77
   macro avg       0.83      0.85      0.84        77
weighted avg       0.86      0.86      0.86        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.86        62
           1       0.48      0.87      0.62        15

    accuracy                           0.79        77
   macro avg       0.72      0.82      0.74        77
weighted avg       0.87      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.75      0.75        51
           1       0.52      0.54      0.53        26

    accuracy                           0.68        77
   macro avg       0.64      0.64      0.64        77
weighted avg       0.68      0.68      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.72      0.79        61
           1       0.37      0.62      0.47        16

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.63        77
weighted avg       0.77      0.70      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.58      0.68      0.62        22

    accuracy                           0.76        76
   macro avg       0.72      0.74      0.73        76
weighted avg       0.78      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7552118933697882
F1: 0.6080428798285006
======================================================
Running pima 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.85      0.82        47
           1       0.74      0.67      0.70        30

    accuracy                           0.78        77
   macro avg       0.77      0.76      0.76        77
weighted avg       0.78      0.78      0.78        77

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.87      0.89        53
           1       0.74      0.83      0.78        24

    accuracy                           0.86        77
   macro avg       0.83      0.85      0.84        77
weighted avg       0.86      0.86      0.86        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.76      0.77        51
           1       0.56      0.58      0.57        26

    accuracy                           0.70        77
   macro avg       0.67      0.67      0.67        77
weighted avg       0.70      0.70      0.70        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.59      0.84      0.70        19

    accuracy                           0.82        77
   macro avg       0.77      0.83      0.78        77
weighted avg       0.85      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.52      0.70      0.60        20

    accuracy                           0.75        77
   macro avg       0.70      0.74      0.71        77
weighted avg       0.79      0.75      0.76        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.72      0.79        61
           1       0.37      0.62      0.47        16

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.63        77
weighted avg       0.77      0.70      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7629870129870129
F1: 0.6220122034642733
======================================================
Running pima 50 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.44      0.75      0.56        16

    accuracy                           0.75        77
   macro avg       0.68      0.75      0.69        77
weighted avg       0.82      0.75      0.77        77

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        61
           1       0.33      0.56      0.42        16

    accuracy                           0.68        77
   macro avg       0.60      0.63      0.60        77
weighted avg       0.75      0.68      0.70        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10343121222385751
0.10343121222385751
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        62
           1       0.44      0.80      0.57        15

    accuracy                           0.77        77
   macro avg       0.69      0.78      0.71        77
weighted avg       0.84      0.77      0.79        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10387519469417186
0.10387519469417186
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.73      0.83        66
           1       0.33      0.82      0.47        11

    accuracy                           0.74        77
   macro avg       0.65      0.77      0.65        77
weighted avg       0.87      0.74      0.78        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.71      0.76        58
           1       0.37      0.53      0.43        19

    accuracy                           0.66        77
   macro avg       0.60      0.62      0.60        77
weighted avg       0.71      0.66      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10815480175182482
0.10815480175182482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        61
           1       0.52      0.88      0.65        16

    accuracy                           0.81        77
   macro avg       0.74      0.83      0.76        77
weighted avg       0.87      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.71      0.81        66
           1       0.30      0.73      0.42        11

    accuracy                           0.71        77
   macro avg       0.62      0.72      0.62        77
weighted avg       0.85      0.71      0.75        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.10936376968721243
0.10936376968721243
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.86        62
           1       0.46      0.86      0.60        14

    accuracy                           0.79        76
   macro avg       0.71      0.82      0.73        76
weighted avg       0.87      0.79      0.81        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474709501025292
F1: 0.5404217317814253
======================================================
Running pima 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.41      0.65      0.50        17

    accuracy                           0.71        77
   macro avg       0.64      0.69      0.65        77
weighted avg       0.78      0.71      0.73        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.73      0.83        66
           1       0.33      0.82      0.47        11

    accuracy                           0.74        77
   macro avg       0.65      0.77      0.65        77
weighted avg       0.87      0.74      0.78        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.41      0.65      0.50        17

    accuracy                           0.71        77
   macro avg       0.64      0.69      0.65        77
weighted avg       0.78      0.71      0.73        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        61
           1       0.52      0.88      0.65        16

    accuracy                           0.81        77
   macro avg       0.74      0.83      0.76        77
weighted avg       0.87      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.33      0.69      0.45        13

    accuracy                           0.71        77
   macro avg       0.63      0.71      0.63        77
weighted avg       0.82      0.71      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.74      0.81        61
           1       0.38      0.67      0.49        15

    accuracy                           0.72        76
   macro avg       0.64      0.70      0.65        76
weighted avg       0.80      0.72      0.75        76

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.86        62
           1       0.46      0.86      0.60        14

    accuracy                           0.79        76
   macro avg       0.71      0.82      0.73        76
weighted avg       0.87      0.79      0.81        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7578092959671908
F1: 0.5599402949556529
======================================================
Running pima 50 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1786383525120412
0.1786383525120412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [237, 454]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527279639358957
0.18527279639358957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [217, 474]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18527574297132138
0.18527574297132138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.77      0.78        52
           1       0.56      0.60      0.58        25

    accuracy                           0.71        77
   macro avg       0.68      0.68      0.68        77
weighted avg       0.72      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [215, 476]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18490690727010434
0.18490690727010434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18609954123791017
0.18609954123791017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.73      0.83        66
           1       0.33      0.82      0.47        11

    accuracy                           0.74        77
   macro avg       0.65      0.77      0.65        77
weighted avg       0.87      0.74      0.78        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.1850012498677171
0.1850012498677171
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.73      0.80        60
           1       0.41      0.65      0.50        17

    accuracy                           0.71        77
   macro avg       0.64      0.69      0.65        77
weighted avg       0.78      0.71      0.73        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [474, 217]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.18514055652773204
0.18514055652773204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.80      0.87        60
           1       0.56      0.88      0.68        17

    accuracy                           0.82        77
   macro avg       0.76      0.84      0.78        77
weighted avg       0.87      0.82      0.83        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [477, 214]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19137757728283397
0.19137757728283397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [222, 469]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.183062295616352
0.183062295616352
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.74      0.81        61
           1       0.38      0.67      0.49        15

    accuracy                           0.72        76
   macro avg       0.64      0.70      0.65        76
weighted avg       0.80      0.72      0.75        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [227, 465]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.19199382381925473
0.19199382381925473
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.86        62
           1       0.46      0.86      0.60        14

    accuracy                           0.79        76
   macro avg       0.71      0.82      0.73        76
weighted avg       0.87      0.79      0.81        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [468, 224]
Selected clustering_algorithm: spectral
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7526144907723855
F1: 0.556985439287718
======================================================
Running pima 50 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 majority_voting default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.48      0.76      0.59        17

    accuracy                           0.77        77
   macro avg       0.70      0.77      0.71        77
weighted avg       0.82      0.77      0.78        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.70      0.76        60
           1       0.33      0.53      0.41        17

    accuracy                           0.66        77
   macro avg       0.59      0.61      0.59        77
weighted avg       0.73      0.66      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.33      0.69      0.45        13

    accuracy                           0.71        77
   macro avg       0.63      0.71      0.63        77
weighted avg       0.82      0.71      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.46      0.63      0.53        19

    accuracy                           0.72        76
   macro avg       0.66      0.69      0.67        76
weighted avg       0.76      0.72      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        61
           1       0.50      0.87      0.63        15

    accuracy                           0.80        76
   macro avg       0.73      0.83      0.75        76
weighted avg       0.87      0.80      0.82        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474367737525631
F1: 0.5598650074445408
======================================================
Running pima 50 3 majority_voting default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.72090684774605
0.72090684774605
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       1.00      1.00      1.00        22

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [71, 404, 37]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.95937151e-02, 1.68421568e-01, 2.33682787e-01, 1.60406886e-01,
        9.04059041e-02, 2.60720412e-01, 5.81559414e-02, 3.20759138e-02,
        6.80914513e-02, 2.44312026e-01, 2.42628475e-01, 1.08636611e-02,
        1.34127475e-01, 9.94204401e-03, 5.42026679e-03, 1.41754768e-01,
        3.01243729e-02, 3.09348255e-02, 1.51320293e-01, 1.52007607e-01,
        6.74794675e-02, 1.09714202e-01,...
        1.45576541e-01, 4.45828819e-01, 2.46840775e-01, 5.23990585e-02,
        1.49796676e-01, 4.37732649e-02, 2.20732987e-02, 1.68236054e-01,
        7.53146874e-02, 6.92890059e-02, 2.45965770e-01, 1.04176571e-01,
        8.60087775e-02, 1.45164827e-01, 2.44402985e-01, 1.34156881e-01,
        6.65442636e-02, 4.47269365e-01, 1.27009537e-01, 1.44089457e-01,
        3.30171821e-01, 2.16482650e-01, 1.50239674e-01]]),
       n_clusters=9))
Best evaluation: 0.671275074705778
0.669365405884394
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.92      0.93        36
           1       0.86      0.90      0.88        21

    accuracy                           0.91        57
   macro avg       0.90      0.91      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [148, 34, 87, 49, 32, 16, 49, 105]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.6642598764398561
0.6642598764398561
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [346, 10, 59, 12, 85]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5795805224505389
0.5789344060913936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [51, 82, 190, 48, 91, 58]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.8304093755369217
0.8304093755369217
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [388, 72, 15, 27, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.6944210860627545
0.6840230647863592
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [29, 11, 20, 76, 384]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.6097226372839476
0.6108391345648606
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [356, 68, 59, 21, 11, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.42672936e-04, 5.42808462e-01, 4.12580318e-01, 5.28021560e-01,
        3.95121951e-01, 3.15095649e-01, 2.38359610e-01, 2.70149953e-01,
        3.40308151e-01, 2.80298986e-01, 1.53959562e-01, 1.75411914e-01,
        1.86041372e-01, 1.41780144e-01, 1.14957471e-01, 1.45766054e-01,
        8.98849401e-02, 7.20959596e-02, 1.73290396e-01, 9.90319131e-02,
        4.52648453e-02, 5.19032373e-01,...
        9.06063618e-01, 7.41591030e-01, 4.30286436e-01, 3.99601666e-01,
        2.61845827e-01, 4.37874005e-01, 3.04816230e-01, 1.63238943e-01,
        6.34091387e-01, 2.62626263e-01, 4.69785944e-01, 3.26982608e-01,
        1.43104902e-01, 7.28210601e-01, 4.26172708e-01, 7.78873450e-01,
        5.34506488e-01, 6.53305157e-01, 6.52375547e-01, 7.67412141e-01,
        1.00000000e+00, 4.90833826e-01, 2.81057327e-01]]),
       n_clusters=9))
Best evaluation: 0.6924090959695957
0.6924090959695957
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        21

    accuracy                           0.96        56
   macro avg       0.96      0.96      0.96        56
weighted avg       0.96      0.96      0.96        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [64, 88, 161, 39, 25, 13, 34, 98]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9718671679197994
F1: 0.9619988925802879
======================================================
Running wdbc 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.45890634230970645
0.45890634230970645
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 384, 76, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4783899700142416
0.4783899700142416
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.94        37
           1       0.86      0.95      0.90        20

    accuracy                           0.93        57
   macro avg       0.92      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 82, 396, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4621289782488964
0.4590732567274111
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [76, 41, 376, 27]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4781278872633752
0.4746407886371724
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [85, 399, 24, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.46741481893719294
0.46578944353266705
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [83, 20, 377, 40]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.45899956193113134
0.45899956193113134
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [80, 395, 10, 27]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44940549382391404
0.44940549382391404
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        35
           1       0.95      0.91      0.93        22

    accuracy                           0.95        57
   macro avg       0.95      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 346, 13, 107]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4571764637034856
0.4563601780103806
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 377, 90, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.5080589456589574
0.5091071297637271
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [120, 11, 351, 20, 20]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.46321399571964106
0.46321399571964106
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        34
           1       0.95      0.91      0.93        22

    accuracy                           0.95        56
   macro avg       0.95      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [384, 39, 77, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9648182957393484
F1: 0.9526976924254292
======================================================
Running wdbc 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5278914080881929
0.5278914080881929
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [20, 86, 406]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.49634195628047983
0.4904949970985556
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        33
           1       0.91      0.83      0.87        24

    accuracy                           0.89        57
   macro avg       0.90      0.89      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 383, 28, 86]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.46387082177129824
0.4604233822334994
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [34, 377, 81, 28]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4953502462462631
0.4953047720942931
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [92, 352, 12, 47, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0096613 , 0.29764778, 0.24721001, 0.28166678, 0.17090138,
        0.28726189, 0.09373658, 0.08327085, 0.12206759, 0.22020202,
        0.14279697, 0.06561651, 0.11687192, 0.06064176, 0.03339198,
        0.14681987, 0.08935616, 0.05704545, 0.17156658, 0.09762481,
        0.05291341, 0.25649235, 0.30863539, 0.24119727, 0.12868659,
        0.38327786, 0.10071698, 0.14265176, 0.33257732, 0.18549182,
        0...
       [0.00099484, 0.12754981, 0.11599594, 0.14048787, 0.05471898,
        0.6578496 , 0.61658794, 0.27835052, 0.34980119, 0.50353535,
        0.96440607, 0.05898968, 0.22726569, 0.04853225, 0.02029892,
        0.68181664, 0.47411234, 0.13103535, 0.27467323, 0.25944166,
        0.36408317, 0.09498399, 0.16044776, 0.09492505, 0.03512092,
        0.87910073, 0.3289092 , 0.23266773, 0.36941581, 0.25290755,
        0.53364817]]),
       n_clusters=9))
Best evaluation: 0.4448346209317895
0.4447770404827378
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [143, 96, 43, 111, 34, 74, 12]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44976966657198403
0.44976966657198403
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [345, 104, 15, 48]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44934020276650355
0.44934020276650355
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        35
           1       0.95      0.91      0.93        22

    accuracy                           0.95        57
   macro avg       0.95      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [346, 110, 20, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4582799262299875
0.45806892692445245
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [381, 35, 90, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4732535444190059
0.469310692828769
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [15, 73, 408, 20]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4860977521981986
0.4825345290933437
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.90      1.00      0.95        19

    accuracy                           0.96        56
   macro avg       0.95      0.97      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [375, 102, 18, 26]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9683583959899748
F1: 0.9582368519842932
======================================================
Running wdbc 100 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        39
           1       0.82      1.00      0.90        18

    accuracy                           0.93        57
   macro avg       0.91      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.87      0.90        38
           1       0.77      0.89      0.83        19

    accuracy                           0.88        57
   macro avg       0.86      0.88      0.87        57
weighted avg       0.89      0.88      0.88        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.89      0.90        37
           1       0.81      0.85      0.83        20

    accuracy                           0.88        57
   macro avg       0.86      0.87      0.87        57
weighted avg       0.88      0.88      0.88        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.78      0.90      0.84        31
           1       0.86      0.69      0.77        26

    accuracy                           0.81        57
   macro avg       0.82      0.80      0.80        57
weighted avg       0.81      0.81      0.80        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 167]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        34
           1       0.95      0.91      0.93        22

    accuracy                           0.95        56
   macro avg       0.95      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8999060150375939
F1: 0.867119255329149
======================================================
Running wdbc 100 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7188851546497473
0.7188851546497473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        54
           1       0.14      1.00      0.24         3

    accuracy                           0.67        57
   macro avg       0.57      0.82      0.51        57
weighted avg       0.95      0.67      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [411, 23, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
0.617397593888967
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82        50
           1       0.32      1.00      0.48         7

    accuracy                           0.74        57
   macro avg       0.66      0.85      0.65        57
weighted avg       0.92      0.74      0.78        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [54, 25, 120, 83, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.6648286163640877
0.6648286163640877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 345, 10, 85, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.92900529e-04, 2.22395759e-01, 2.18464660e-01, 2.19058807e-01,
        1.17497349e-01, 5.43197617e-01, 2.24679468e-01, 1.00257732e-01,
        1.55666004e-01, 4.00505051e-01, 2.95914069e-01, 9.40793047e-02,
        1.75086781e-01, 8.46722895e-02, 3.87898349e-02, 2.47645919e-01,
        1.08471957e-01, 4.67424242e-02, 2.21064596e-01, 1.91900715e-01,
        7.77474136e-02, 1.91746709e-01,...
        8.85188867e-02, 3.53030303e-01, 2.50000000e-01, 3.97609995e-02,
        2.04050499e-01, 3.66583424e-02, 1.95331324e-02, 1.32406432e-01,
        1.44466588e-01, 3.86111111e-02, 1.89372987e-01, 1.57708111e-01,
        4.03405411e-02, 2.07043757e-01, 3.72334755e-01, 1.86314059e-01,
        9.69573339e-02, 3.98220471e-01, 1.51943806e-01, 1.00239617e-01,
        2.85635739e-01, 2.32406860e-01, 1.13734750e-01]]),
       n_clusters=10))
Best evaluation: 0.6253198489528956
0.6248719363844155
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [92, 67, 66, 43, 33, 21, 73, 19, 111]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.51615341e-02, 4.49092421e-01, 4.90871369e-01, 4.36098106e-01,
        2.82629905e-01, 4.34865036e-01, 3.34396663e-01, 2.44376757e-01,
        2.78976143e-01, 5.55555556e-01, 1.88500421e-01, 1.31053194e-01,
        1.99964639e-01, 1.16637791e-01, 6.88795998e-02, 1.46366286e-01,
        1.29690269e-01, 5.60353535e-02, 1.74862663e-01, 1.05082456e-01,
        5.10689164e-02, 4.10530060e-01,...
        4.11083499e-01, 4.51010101e-01, 1.33319292e-01, 1.78862123e-01,
        6.70526874e-02, 1.28430112e-01, 9.49723383e-02, 9.98750983e-02,
        1.21428786e-01, 9.36868687e-02, 2.27315780e-01, 1.65447177e-01,
        8.43732294e-02, 5.91604411e-01, 4.90138593e-01, 5.10433787e-01,
        3.53372002e-01, 3.54817407e-01, 2.84570830e-01, 4.59664537e-01,
        6.72164948e-01, 4.71318746e-01, 2.48196248e-01]]),
       n_clusters=7))
Best evaluation: 0.7435523363431354
0.7433386374823697
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [97, 161, 109, 22, 35, 20, 70]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
0.6487881933326375
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.62959076e-04, 5.90136779e-01, 3.25329726e-01, 5.71556907e-01,
        4.35364042e-01, 5.52514391e-01, 3.04950617e-01, 3.23102156e-01,
        4.26988072e-01, 3.61616162e-01, 1.37110362e-01, 1.75411914e-01,
        6.05551627e-02, 1.43240824e-01, 1.23743731e-01, 9.98062345e-02,
        1.18274401e-01, 6.94191919e-02, 2.40007577e-01, 8.11617043e-02,
        5.71839200e-02, 7.05158730e-01,...
        7.46520875e-02, 1.77272727e-01, 2.62636900e-01, 7.83269962e-02,
        1.54437765e-01, 8.09499128e-02, 3.10872440e-02, 1.67896114e-01,
        1.82263346e-01, 5.60858586e-02, 1.47887858e-01, 1.55597456e-01,
        8.69297846e-02, 1.88492063e-01, 2.55597015e-01, 1.80446084e-01,
        9.38154491e-02, 2.85478439e-01, 1.47092781e-01, 9.79233227e-02,
        1.89312715e-01, 1.26749458e-01, 1.39971140e-01]]),
       n_clusters=10))
Best evaluation: 0.7239089389435668
0.7205407992645633
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [67, 80, 17, 89, 14, 63, 13, 67, 112]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
0.6499323509896758
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.14      1.00      0.25         3

    accuracy                           0.68        56
   macro avg       0.57      0.83      0.52        56
weighted avg       0.95      0.68      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6661027568922305
F1: 0.17891921871232214
======================================================
Running wdbc 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.45644091085325245
0.45644091085325245
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        45
           1       0.55      1.00      0.71        12

    accuracy                           0.82        57
   macro avg       0.77      0.89      0.79        57
weighted avg       0.90      0.82      0.84        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [387, 83, 31, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4881706328387445
0.49149269765618464
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.18      1.00      0.31         4

    accuracy                           0.68        57
   macro avg       0.59      0.83      0.55        57
weighted avg       0.94      0.68      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [82, 401, 21, 16]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4508980049642317
0.4508980049642317
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.73      0.85        49
           1       0.38      1.00      0.55         8

    accuracy                           0.77        57
   macro avg       0.69      0.87      0.70        57
weighted avg       0.91      0.77      0.81        57

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 343, 110, 16]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.48348757206855575
0.48360300075928675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [84, 12, 24, 398]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.99973334e-01, 4.77968669e-01, 5.89786946e-01, 4.65828208e-01,
        3.33997879e-01, 4.18434594e-01, 2.81025704e-01, 2.35941893e-01,
        3.19632207e-01, 3.70202020e-01, 2.70640270e-01, 2.96070976e-01,
        1.74644586e-01, 2.49446355e-01, 2.02462467e-01, 2.38875480e-01,
        2.02729084e-01, 6.87121212e-02, 2.76188672e-01, 1.76844712e-01,
        1.19449149e-01, 5.34685165e-01,...
        4.02037773e-01, 5.18686869e-01, 5.51179444e-01, 8.07532138e-02,
        1.16761370e-01, 6.87932903e-02, 3.80800825e-02, 1.97062923e-01,
        3.17220482e-01, 9.27272727e-02, 2.15381701e-01, 1.93729949e-01,
        1.42482085e-01, 2.68231946e-01, 3.12633262e-01, 2.63907565e-01,
        1.36747936e-01, 7.33070706e-01, 4.82783712e-01, 4.27715655e-01,
        5.98281787e-01, 4.77035285e-01, 4.54939000e-01]]),
       n_clusters=5))
Best evaluation: 0.44517734775180484
0.44335247961153434
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [324, 95, 16, 79]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.48753119790216093
0.48662094369942244
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [101, 355, 20, 34, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44729681156435663
0.44729681156435663
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [336, 22, 118, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4532163088307741
0.45245234940005374
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        51
           1       0.29      1.00      0.44         6

    accuracy                           0.74        57
   macro avg       0.64      0.85      0.64        57
weighted avg       0.92      0.74      0.79        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [402, 10, 24, 79]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4646993307532019
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [380, 12, 78, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.66      0.78        50
           1       0.19      0.67      0.30         6

    accuracy                           0.66        56
   macro avg       0.57      0.66      0.54        56
weighted avg       0.86      0.66      0.73        56

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6994047619047619
F1: 0.3122473105738826
======================================================
Running wdbc 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4581568678800493
0.4581568678800493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.80      0.89        44
           1       0.59      1.00      0.74        13

    accuracy                           0.84        57
   macro avg       0.80      0.90      0.81        57
weighted avg       0.91      0.84      0.85        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [32, 80, 13, 387]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5212801591484709
0.5177838530329901
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 380, 79, 21, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4708789961028431
0.46826268929787895
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.81      0.89        43
           1       0.62      0.93      0.74        14

    accuracy                           0.84        57
   macro avg       0.80      0.87      0.81        57
weighted avg       0.89      0.84      0.85        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [35, 366, 14, 105]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4715449025517084
0.4714828619497815
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        55
           1       0.10      1.00      0.17         2

    accuracy                           0.67        57
   macro avg       0.55      0.83      0.48        57
weighted avg       0.97      0.67      0.77        57

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [395, 78, 20, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.46312687372744643
0.46312687372744643
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92        42
           1       0.71      1.00      0.83        15

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [343, 11, 146, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4507685510847271
0.4507685510847271
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [347, 15, 36, 114]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4578277102079642
0.45709589060106864
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.90      0.93        39
           1       0.81      0.94      0.87        18

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [471, 15, 34]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.46262809459245524
0.46262809459245524
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        51
           1       0.29      1.00      0.44         6

    accuracy                           0.74        57
   macro avg       0.64      0.85      0.64        57
weighted avg       0.92      0.74      0.79        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [362, 61, 79, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5300374856403203
0.5331596897067438
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [370, 32, 13, 22, 73, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.475892235459762
0.47210313033933243
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        55
           1       0.05      1.00      0.09         1

    accuracy                           0.64        56
   macro avg       0.52      0.82      0.43        56
weighted avg       0.98      0.64      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [15, 75, 26, 401]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7467418546365916
F1: 0.4150109069674287
======================================================
Running wdbc 100 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.94        25

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.95        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.91      0.91      0.91        22

    accuracy                           0.93        57
   macro avg       0.93      0.93      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      1.00      0.94        32
           1       1.00      0.84      0.91        25

    accuracy                           0.93        57
   macro avg       0.94      0.92      0.93        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.75      1.00      0.86        27
           1       1.00      0.70      0.82        30

    accuracy                           0.84        57
   macro avg       0.88      0.85      0.84        57
weighted avg       0.88      0.84      0.84        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [346, 166]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        33
           1       1.00      0.91      0.95        23

    accuracy                           0.96        56
   macro avg       0.97      0.96      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9227443609022556
F1: 0.9041312517872576
======================================================
Running wdbc 100 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7177977497953458
0.7177977497953458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [79, 411, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
0.6166798137386608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 25, 120, 83, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.6646111172270486
0.6646111172270486
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [381, 84, 10, 11, 26]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.49716628e-04, 1.46670453e-01, 1.82617518e-01, 1.38000138e-01,
        7.38069989e-02, 3.61469712e-01, 8.45653641e-02, 3.74179944e-03,
        1.19483101e-02, 3.24747475e-01, 2.21566976e-01, 1.13344197e-01,
        2.00291848e-01, 9.06092447e-02, 3.66605777e-02, 4.30941292e-01,
        9.91174198e-02, 4.03282828e-03, 4.55389278e-02, 2.46214893e-01,
        8.66488638e-02, 1.40163643e-01,...
        4.75198807e-01, 3.56060606e-01, 5.89721988e-03, 2.71084555e-01,
        2.47164430e-01, 2.95528436e-01, 1.95925274e-01, 2.17935208e-01,
        3.44267296e-01, 1.38611111e-01, 5.23773442e-01, 3.35988068e-01,
        4.83760915e-02, 5.44646033e-01, 4.21641791e-01, 5.37327556e-01,
        3.61482501e-01, 3.16715343e-01, 2.56822967e-01, 3.08386581e-01,
        6.59793814e-01, 2.64931993e-01, 2.36783419e-02]]),
       n_clusters=10))
Best evaluation: 0.6012572166837615
0.6018208722477478
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [84, 38, 92, 69, 97, 57, 63, 16, 11]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7188981484818738
0.7188981484818738
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [427, 72, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7194992087783817
0.7194992087783817
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [424, 78, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.7492736740778897
0.7485045153029208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [370, 22, 11, 73, 10, 31]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.36824564e-02, 4.75128970e-01, 4.82583700e-01, 4.76884804e-01,
        3.20593849e-01, 5.66854991e-01, 3.99423348e-01, 5.66307404e-01,
        5.97912525e-01, 5.77148959e-01, 2.91912384e-01, 1.77222524e-01,
        2.29358204e-01, 1.52758799e-01, 1.13892842e-01, 2.22830336e-01,
        2.14558236e-01, 1.27323232e-01, 2.10645956e-01, 1.84865200e-01,
        1.02234567e-01, 4.60690146e-01,...
        1.37009544e-01, 1.92387749e-01, 1.00055211e-01, 4.01593252e-02,
        6.26739563e-02, 2.01281367e-01, 2.06402696e-01, 4.07025167e-02,
        1.72118105e-01, 3.86373274e-02, 2.09899925e-02, 1.15001530e-01,
        7.35872863e-02, 2.37626263e-02, 8.62095094e-02, 1.15354309e-01,
        5.19671655e-02, 2.21985059e-01, 5.32249467e-01, 2.10817272e-01,
        1.07574715e-01, 3.59440005e-01, 1.48548088e-01, 9.82428115e-02,
        2.17697595e-01, 3.02582298e-01, 1.77030041e-01]])))
Best evaluation: 0.6670863171544487
0.6670863171544487
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [43, 87, 122, 60, 11, 78, 32, 80]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4581487704876342
0.4581487704876342
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [378, 11, 87, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4805686536411209
0.48293095436976574
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [87, 13, 21, 396]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4579454990712258
0.45527058793793074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 372, 14, 50]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4942201275739394
0.4942201275739394
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 85, 343, 14, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4669982208758827
0.4636844081864073
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [42, 382, 10, 86]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4597421620329403
0.45486689022775073
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [409, 20, 79, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44934020276650355
0.44934020276650355
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [110, 36, 346, 20]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.481210887455799
0.4753497123260845
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [120, 361, 27, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4658419790571478
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [380, 12, 44, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.46714284432098213
0.4664197936985389
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [114, 366, 23, 20]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 100 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.45753102120947275
0.45753102120947275
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [388, 13, 31, 80]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5034377414012733
0.5048960727372985
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [75, 14, 10, 396, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4635918262345526
0.4635918262345526
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [368, 13, 43, 88]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4798307525340203
0.47600066570971156
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [397, 14, 24, 84]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4669982208758827
0.46256895766916717
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [382, 42, 86, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44916633428545216
0.44916633428545216
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [113, 40, 16, 343]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4575942930815218
0.4575942930815218
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [42, 379, 77, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4110954880557498
0.4150361028694489
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [73, 37, 410]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5297500986931618
0.5323299533438737
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [78, 363, 32, 10, 16, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.48144094544437027
0.4776187442454775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [401, 14, 26, 79]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6625
F1: 0.0975609756097561
======================================================
Running wdbc 100 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.85      0.92        41
           1       0.73      1.00      0.84        16

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.80      0.89        44
           1       0.59      1.00      0.74        13

    accuracy                           0.84        57
   macro avg       0.80      0.90      0.81        57
weighted avg       0.91      0.84      0.85        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.83      0.90        42
           1       0.67      0.93      0.78        15

    accuracy                           0.86        57
   macro avg       0.82      0.88      0.84        57
weighted avg       0.89      0.86      0.87        57

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        40
           1       0.81      1.00      0.89        17

    accuracy                           0.93        57
   macro avg       0.90      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [170, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.90      0.93        39
           1       0.81      0.94      0.87        18

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.83      0.90        42
           1       0.67      0.93      0.78        15

    accuracy                           0.86        57
   macro avg       0.82      0.88      0.84        57
weighted avg       0.89      0.86      0.87        57

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92        42
           1       0.71      1.00      0.83        15

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.84      0.91        43
           1       0.67      1.00      0.80        14

    accuracy                           0.88        57
   macro avg       0.83      0.92      0.86        57
weighted avg       0.92      0.88      0.88        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [166, 346]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        38
           1       0.86      1.00      0.92        18

    accuracy                           0.95        56
   macro avg       0.93      0.96      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [173, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8963972431077692
F1: 0.8386536854957907
======================================================
Running wdbc 100 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7183525193995655
0.7183525193995655
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [74, 405, 33]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.61272497e-04, 1.87521426e-01, 1.76530267e-01, 1.84592403e-01,
        1.01218570e-01, 4.39378893e-01, 1.80050304e-01, 1.01405811e-01,
        1.45576541e-01, 4.45828819e-01, 2.46840775e-01, 5.23990585e-02,
        1.49796676e-01, 4.37732649e-02, 2.20732987e-02, 1.68236054e-01,
        7.53146874e-02, 6.92890059e-02, 2.45965770e-01, 1.04176571e-01,
        8.60087775e-02, 1.45164827e-01,...
        6.28727634e-01, 4.41495125e-01, 2.15669756e-01, 3.13090712e-01,
        3.38534300e-01, 3.00193187e-01, 1.80796342e-01, 2.28643301e-01,
        3.34124433e-01, 1.94338381e-01, 6.20048900e-01, 3.97069629e-01,
        1.54389671e-01, 5.66917623e-01, 5.80756930e-01, 5.36373341e-01,
        3.59120683e-01, 3.73968170e-01, 3.04945135e-01, 2.95766773e-01,
        7.39518900e-01, 3.36159306e-01, 1.38617112e-01]]),
       n_clusters=10))
Best evaluation: 0.7080284590350439
0.7059573699098102
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [105, 72, 13, 53, 34, 55, 104, 61, 22]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.6828423183319954
0.6842967982413994
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 373, 22, 11, 76]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.6656830783884968
0.6656830783884968
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [343, 12, 11, 85, 61]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.6808635865759631
0.6820056730143088
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [10, 124, 20, 356, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.99004038e-03, 1.35720926e-01, 7.67219917e-01, 1.25008735e-01,
        6.25238600e-02, 2.45644127e-01, 8.24489295e-02, 3.61059044e-02,
        5.18389662e-02, 2.83333333e-01, 2.01347936e-01, 2.61859739e-02,
        2.93228430e-01, 2.71614598e-02, 8.36387136e-03, 2.25516954e-01,
        7.84690720e-02, 3.66161616e-02, 1.15627960e-01, 1.10570158e-01,
        4.74413720e-02, 9.74742085e-02,...
        9.35884692e-02, 4.11111111e-01, 1.90185341e-01, 4.98643427e-02,
        2.07478784e-01, 9.16559548e-02, 2.50430521e-02, 8.86339455e-02,
        2.61949109e-01, 8.71717172e-02, 2.01742754e-01, 2.59441662e-01,
        9.70869091e-02, 2.20562078e-01, 3.35554371e-01, 2.28597042e-01,
        1.07328942e-01, 1.46074094e-01, 1.98416625e-01, 1.28115016e-01,
        2.27079038e-01, 3.23674354e-01, 1.14325069e-01]]),
       n_clusters=10))
Best evaluation: 0.7315810920958734
0.727960938984206
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 43, 73, 63, 70, 10, 47, 15, 71, 90]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
0.6487881933326375
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.6742846534344222
0.6742846534344222
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [105, 13, 350, 11, 33]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.63207070e-04, 3.30304321e-01, 2.48224552e-01, 3.29210144e-01,
        1.94655355e-01, 4.66745961e-01, 3.32863015e-01, 2.29358013e-01,
        2.60735586e-01, 3.95621997e-01, 2.38837405e-01, 1.13525258e-01,
        9.93635078e-02, 8.50963577e-02, 5.40495108e-02, 1.57663936e-01,
        1.84291165e-01, 7.87626263e-02, 2.54214813e-01, 1.79236787e-01,
        6.21933861e-02, 3.00960512e-01,...
        4.73594910e-01, 3.54841907e-01, 2.55567143e-01, 3.46532334e-01,
        4.72067594e-01, 2.21569674e-01, 8.40353833e-02, 2.34184320e-01,
        1.45155587e-01, 2.40682279e-01, 1.97232713e-01, 1.62525071e-01,
        1.25259110e-01, 8.56313131e-02, 2.88122751e-01, 7.98953115e-02,
        3.80788525e-02, 6.89790110e-01, 5.02665245e-01, 6.79266896e-01,
        5.43845851e-01, 5.28495014e-01, 2.79137682e-01, 4.29073482e-01,
        8.20618557e-01, 2.37137788e-01, 1.38462548e-01]])))
Best evaluation: 0.6667751516917009
0.6667751516917009
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [79, 17, 84, 48, 120, 24, 77, 64]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4588119928605212
0.4588119928605212
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [37, 11, 82, 382]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.49094276618693977
0.48938198336730954
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [383, 89, 26, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4960328121159351
0.49674736607508085
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [379, 20, 34, 11, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.49307371824930185
0.4935666655109041
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [349, 14, 10, 93, 47]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
0.4376641701748208
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4486805487685464
0.4486805487685464
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 103, 340, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.456680388801199
0.456680388801199
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [77, 380, 14, 41]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4082643475522183
0.4089879068471568
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 419, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5205930248927712
0.5164724769617219
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [358, 74, 11, 16, 28, 31]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.98904511e-03, 5.96762743e-01, 5.17078120e-01, 5.79849354e-01,
        4.44326617e-01, 4.03310536e-01, 2.43328630e-01, 3.87769447e-01,
        4.50447316e-01, 2.64815804e-01, 8.31929233e-02, 1.28879232e-01,
        2.24275106e-01, 1.01729256e-01, 9.22267173e-02, 3.46296359e-01,
        1.27962868e-01, 1.23914141e-01, 2.83955295e-01, 1.19997749e-01,
        3.15147244e-02, 4.80611882e-01,...
        8.83200795e-02, 1.86332088e-01, 1.81760741e-01, 2.53847547e-02,
        8.95951202e-02, 2.57268058e-02, 1.13709801e-02, 1.69833770e-01,
        1.10839066e-01, 5.25252525e-02, 1.42015533e-01, 1.87960826e-01,
        6.47153932e-02, 1.72180719e-01, 3.19829424e-01, 1.60715175e-01,
        7.61649626e-02, 4.16231922e-01, 1.48936170e-01, 1.48562300e-01,
        2.84810997e-01, 3.24265720e-01, 1.54729109e-01]]),
       n_clusters=10))
Best evaluation: 0.459674187998661
0.459674187998661
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [73, 116, 87, 51, 14, 86, 72, 14]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6625
F1: 0.09767441860465116
======================================================
Running wdbc 100 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.45861259774453167
0.45861259774453167
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [372, 13, 79, 48]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5205128515258387
0.5180421187993227
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [23, 82, 382, 11, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.410914300340986
0.4081290624253897
CBEG               precision    recall  f1-score   support

           0       0.92      1.00      0.96        33
           1       1.00      0.88      0.93        24

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [19, 360, 141]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.47708916752380776
0.4779030370231966
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [82, 393, 20, 24]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4671378459040163
0.4675461481736993
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [88, 10, 382, 40]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4821601366581172
0.4810653562256212
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [12, 110, 341, 16, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4497708946581949
0.4502064912796001
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [359, 32, 116, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4864768468887998
0.48220409457206215
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 26, 369, 80]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5312489327348547
0.5260749701992526
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [22, 364, 11, 12, 77, 31]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4573323296326556
0.4577020198117517
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [353, 14, 129, 25]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6589912280701754
F1: 0.09333333333333334
======================================================
Running wdbc 100 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.92        37
           1       0.82      0.90      0.86        20

    accuracy                           0.89        57
   macro avg       0.88      0.90      0.89        57
weighted avg       0.90      0.89      0.90        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        36
           1       0.81      0.81      0.81        21

    accuracy                           0.86        57
   macro avg       0.85      0.85      0.85        57
weighted avg       0.86      0.86      0.86        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.75      0.90      0.82        30
           1       0.86      0.67      0.75        27

    accuracy                           0.79        57
   macro avg       0.80      0.78      0.78        57
weighted avg       0.80      0.79      0.79        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [346, 166]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.90      0.90      0.90        21

    accuracy                           0.93        56
   macro avg       0.92      0.92      0.92        56
weighted avg       0.93      0.93      0.93        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [171, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8928571428571429
F1: 0.8599611093513533
======================================================
Running wdbc 100 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7189917858832101
0.7189917858832101
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.94        25

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.95        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [78, 412, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.637420642823826
0.6345137013873992
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.91      0.91      0.91        22

    accuracy                           0.93        57
   macro avg       0.93      0.93      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [83, 404, 21, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.6613386735437928
0.6613386735437928
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [77, 291, 13, 10, 121]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 2.92914951e-01, 2.87791681e-01, 2.79800981e-01,
        1.67041357e-01, 1.98880563e-01, 1.24409545e-01, 1.13847235e-01,
        1.42644135e-01, 1.98989899e-01, 1.16470093e-01, 3.28806808e-02,
        7.13922483e-02, 2.25698535e-02, 1.88420577e-02, 1.44678247e-01,
        1.28909586e-01, 3.94949495e-02, 1.60314453e-01, 4.28885012e-02,
        2.43733483e-02, 2.47954465e-01,...
        1.08300199e-01, 4.84343434e-01, 2.72535805e-01, 5.90983161e-02,
        1.85920538e-01, 5.52702257e-02, 2.37729689e-02, 2.78138491e-01,
        2.87529996e-01, 4.11616162e-02, 1.75715098e-01, 2.06816007e-01,
        4.51549441e-02, 1.82141587e-01, 4.04850746e-01, 1.72717765e-01,
        8.29974440e-02, 4.85159275e-01, 1.85706940e-01, 9.29712460e-02,
        2.83951890e-01, 2.97654248e-01, 1.21146530e-01]]),
       n_clusters=10))
Best evaluation: 0.7084914499206818
0.7075731290094187
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [69, 70, 13, 99, 42, 79, 48, 33, 66]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7882497788009645
0.7882497788009645
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 412, 73, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7263144981621784
0.7263144981621784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [385, 11, 116]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7022829404650397
0.7076103451543998
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [355, 23, 11, 115, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7195669683874103
0.7195669683874103
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.90      1.00      0.95        19

    accuracy                           0.96        56
   macro avg       0.95      0.97      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [72, 426, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9666040100250626
F1: 0.9551242538813891
======================================================
Running wdbc 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5298578767058297
0.5298578767058297
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [23, 87, 402]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.47490686539857846
0.4747909148171038
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        38
           1       0.86      1.00      0.93        19

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [85, 13, 396, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4494832193431553
0.4494832193431553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [348, 20, 108, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4568030861683004
0.45443691987111756
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [123, 353, 28, 16]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4745665491062506
0.47376754518719777
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [361, 12, 136, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44916633428545216
0.44916633428545216
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [343, 16, 113, 40]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4506492657414941
0.4492815630052534
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 345, 144, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.45667231862875013
0.4568196334129073
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [38, 12, 92, 377]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4971858664216958
0.4971858664216958
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [349, 16, 24, 11, 112]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        34
           1       0.95      0.91      0.93        22

    accuracy                           0.95        56
   macro avg       0.95      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9665726817042606
F1: 0.9540852082939434
======================================================
Running wdbc 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.467312647200799
0.46643179743802504
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [40, 72, 387, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.47825210667044915
0.4789656890384975
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.94      0.96        36
           1       0.91      0.95      0.93        21

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [13, 397, 21, 85]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.46485285335220844
0.4625925937269406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [389, 43, 12, 73]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.47913614048003966
0.4776711119012569
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [80, 13, 23, 404]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.46704794955284595
0.46780160439487606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [382, 40, 13, 85]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4640998224509134
0.4624362490183248
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [380, 22, 37, 81]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44934020276650355
0.44934020276650355
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [36, 110, 346, 20]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4829573358545075
0.4820736419054166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [359, 119, 27, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.46589313990516046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [78, 12, 380, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4885531918479664
0.49185762513868864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.90      1.00      0.95        19

    accuracy                           0.96        56
   macro avg       0.95      0.97      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [32, 74, 388, 26]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9666040100250625
F1: 0.9537126747960553
======================================================
Running wdbc 75 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7191299550165979
0.7191299550165979
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        54
           1       0.14      1.00      0.24         3

    accuracy                           0.67        57
   macro avg       0.57      0.82      0.51        57
weighted avg       0.95      0.67      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [412, 22, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
0.6172504602536574
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.70      0.82        50
           1       0.32      1.00      0.48         7

    accuracy                           0.74        57
   macro avg       0.66      0.85      0.65        57
weighted avg       0.92      0.74      0.78        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 25, 120, 83, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7239289484322852
0.7239289484322852
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        52
           1       0.19      0.80      0.31         5

    accuracy                           0.68        57
   macro avg       0.58      0.74      0.55        57
weighted avg       0.90      0.68      0.75        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [411, 13, 88]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.6778573356976499
0.6778573356976499
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [114, 32, 339, 13, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.28877438e-04, 3.05693596e-01, 4.01420358e-01, 2.92930689e-01,
        1.77942736e-01, 2.61713460e-01, 1.25544445e-01, 7.28678538e-02,
        1.00944334e-01, 3.65656566e-01, 1.24473463e-01, 4.59894985e-02,
        1.02677486e-01, 3.84017340e-02, 2.56407383e-02, 5.32685182e-02,
        8.91528043e-02, 3.51010101e-02, 1.30346657e-01, 8.32723589e-02,
        1.10038550e-02, 2.84596229e-01,...
        2.18240557e-01, 2.38888889e-01, 2.50210615e-01, 9.00597501e-02,
        2.46722236e-01, 1.15676389e-01, 3.86404133e-02, 2.76710745e-01,
        4.07715459e-01, 1.58358586e-01, 3.72419019e-01, 2.60426634e-01,
        1.12106319e-01, 1.93525436e-01, 2.77452026e-01, 1.92290453e-01,
        8.90188753e-02, 2.61020173e-01, 1.67758147e-01, 1.90734824e-01,
        3.18384880e-01, 1.09599842e-01, 1.10455201e-01]]),
       n_clusters=10))
Best evaluation: 0.6339041503408149
0.6343217376362756
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [80, 102, 46, 12, 102, 14, 51, 24, 49, 55]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7910828589910222
0.7910828589910222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [370, 12, 118, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00099556, 0.35964788, 0.13358133, 0.34897381, 0.218579  ,
        0.4124763 , 0.21409729, 0.19264292, 0.21615308, 0.34292929,
        0.13050847, 0.11044722, 0.05823462, 0.08500212, 0.05585713,
        0.1101404 , 0.11917565, 0.07664141, 0.16381891, 0.1056453 ,
        0.0478905 , 0.31412309, 0.15633423, 0.28930724, 0.16633897,
        0.33764776, 0.16057863, 0.19904153, 0.3156701 , 0.20914646,
        0.10127...
        0.30407976],
       [0.09932432, 0.52103744, 0.37030774, 0.51143667, 0.35978791,
        0.46014264, 0.34053126, 0.28139644, 0.43856859, 0.47070707,
        0.22139831, 0.12391816, 0.11339728, 0.10856147, 0.07959669,
        0.18757861, 0.19127587, 0.06335859, 0.28035613, 0.08805651,
        0.08433868, 0.46780505, 0.40101827, 0.43672494, 0.28603028,
        0.50868388, 0.33589467, 0.26365815, 0.67835052, 0.29469742,
        0.19670733]])))
Best evaluation: 0.772237573176857
0.772237573176857
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [123, 31, 72, 96, 24, 15, 71, 80]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00092694, 0.55132756, 0.52079811, 0.55980927, 0.40097644,
        0.58401216, 0.51935464, 0.54334583, 0.61829026, 0.56717172,
        0.25294861, 0.26043817, 0.24438649, 0.22697074, 0.18927984,
        0.15416256, 0.23648872, 0.13121212, 0.21935973, 0.17149772,
        0.12662549, 0.60396825, 0.58608742, 0.61540612, 0.45731181,
        0.51462722, 0.38653938, 0.48985623, 0.63505155, 0.37039227,...
       [0.0010035 , 0.12788111, 0.32566791, 0.11927303, 0.06036935,
        0.3506028 , 0.09484081, 0.05475633, 0.04778827, 0.26262626,
        0.26095198, 0.06670288, 0.22162306, 0.06111294, 0.02204712,
        0.19468335, 0.06742873, 0.05901515, 0.18213677, 0.19907694,
        0.11259898, 0.11904762, 0.36167377, 0.10447761, 0.05513121,
        0.32179885, 0.06613888, 0.07468051, 0.13216495, 0.19455943,
        0.15846779]]),
       n_clusters=9))
Best evaluation: 0.6199001934010573
0.619797297957181
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [28, 105, 74, 91, 26, 23, 50, 65, 66]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7188766866201067
0.7188766866201067
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.64      0.77        53
           1       0.10      0.67      0.17         3

    accuracy                           0.64        56
   macro avg       0.53      0.65      0.47        56
weighted avg       0.92      0.64      0.74        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [77, 425, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6520050125313283
F1: 0.13789357768668115
======================================================
Running wdbc 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5298578767058297
0.5298578767058297
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        54
           1       0.14      1.00      0.24         3

    accuracy                           0.67        57
   macro avg       0.57      0.82      0.51        57
weighted avg       0.95      0.67      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [23, 87, 402]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.48110330998976664
0.46991679110593065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.18      1.00      0.31         4

    accuracy                           0.68        57
   macro avg       0.59      0.83      0.55        57
weighted avg       0.94      0.68      0.76        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 400, 79, 18]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4517768490825589
0.44652825366021465
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.83      0.88        41
           1       0.67      0.88      0.76        16

    accuracy                           0.84        57
   macro avg       0.81      0.85      0.82        57
weighted avg       0.87      0.84      0.85        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [142, 17, 344, 16]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.494308929469902
0.494308929469902
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [87, 10, 12, 334, 69]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.45855754479193056
0.45855754479193056
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.82      0.90        44
           1       0.62      1.00      0.76        13

    accuracy                           0.86        57
   macro avg       0.81      0.91      0.83        57
weighted avg       0.91      0.86      0.87        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [355, 11, 68, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4507685510847271
0.4507685510847271
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        53
           1       0.14      0.75      0.24         4

    accuracy                           0.67        57
   macro avg       0.56      0.71      0.51        57
weighted avg       0.91      0.67      0.75        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [347, 114, 36, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.47908252102031096
0.47516628766662583
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        55
           1       0.10      1.00      0.17         2

    accuracy                           0.67        57
   macro avg       0.55      0.83      0.48        57
weighted avg       0.97      0.67      0.77        57

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 393, 17, 84]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.47498928038110133
0.4745156377687826
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [124, 13, 27, 353]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4637062457226504
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [78, 380, 12, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.24      1.00      0.38         5

    accuracy                           0.71        56
   macro avg       0.62      0.84      0.60        56
weighted avg       0.93      0.71      0.78        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.718796992481203
F1: 0.3727823235035511
======================================================
Running wdbc 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4585042093718084
0.4585042093718084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        45
           1       0.50      0.92      0.65        12

    accuracy                           0.79        57
   macro avg       0.74      0.84      0.75        57
weighted avg       0.87      0.79      0.81        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [82, 13, 368, 49]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4905198507655377
0.49147408986215424
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.18      1.00      0.31         4

    accuracy                           0.68        57
   macro avg       0.59      0.83      0.55        57
weighted avg       0.94      0.68      0.76        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [402, 21, 15, 81]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4919393035301385
0.4919393035301385
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.72      0.84        50
           1       0.33      1.00      0.50         7

    accuracy                           0.75        57
   macro avg       0.67      0.86      0.67        57
weighted avg       0.92      0.75      0.80        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [47, 85, 358, 10, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5215979489147036
0.5212140595377199
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        55
           1       0.10      1.00      0.17         2

    accuracy                           0.67        57
   macro avg       0.55      0.83      0.48        57
weighted avg       0.97      0.67      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [379, 13, 25, 73, 30]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.46713784590401625
0.46842534422255955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.78      0.86        45
           1       0.52      0.92      0.67        12

    accuracy                           0.81        57
   macro avg       0.75      0.85      0.77        57
weighted avg       0.88      0.81      0.82        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [382, 10, 40, 88]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.461709188872129
0.4589326321190629
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        46
           1       0.48      0.91      0.62        11

    accuracy                           0.79        57
   macro avg       0.72      0.83      0.74        57
weighted avg       0.88      0.79      0.81        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [412, 84, 13, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44934020276650355
0.44934020276650355
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [346, 110, 20, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4643144384428262
0.46392534186659395
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.72      0.84        50
           1       0.33      1.00      0.50         7

    accuracy                           0.75        57
   macro avg       0.67      0.86      0.67        57
weighted avg       0.92      0.75      0.80        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [375, 80, 10, 48]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5136520124382928
0.5109621001589251
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 358, 16, 74, 28, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.24      1.00      0.38         5

    accuracy                           0.71        56
   macro avg       0.62      0.84      0.60        56
weighted avg       0.93      0.71      0.78        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7293233082706767
F1: 0.4124946225982032
======================================================
Running wdbc 75 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.7890230548152088
0.7890230548152088
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [372, 10, 87, 43]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
0.6179682404039636
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [54, 25, 120, 83, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.53044998e-05, 3.44502816e-01, 3.20761246e-01, 3.73436528e-01,
        2.06320255e-01, 2.32373386e-01, 6.90768691e-01, 7.03608247e-01,
        3.87574553e-01, 3.25252525e-01, 5.84035383e-01, 9.10012674e-02,
        3.19531648e-01, 1.24487584e-01, 4.19276874e-02, 9.24357938e-02,
        5.39686376e-01, 3.62373737e-01, 4.34173139e-01, 3.31815297e-01,
        4.17520003e-01, 2.62184276e-01,...
        1.16500994e-01, 3.60101010e-01, 9.11962932e-02, 1.17037842e-01,
        1.97069970e-01, 9.76299298e-02, 6.18754646e-02, 5.91645294e-02,
        1.78701997e-01, 8.51262626e-02, 1.90755825e-01, 3.37787898e-01,
        7.57362188e-02, 2.51867663e-01, 3.73819163e-01, 2.37013796e-01,
        1.27998427e-01, 6.92368782e-02, 9.94648823e-02, 1.08546326e-01,
        2.09828179e-01, 2.16439976e-01, 5.35878263e-02]]),
       n_clusters=10))
Best evaluation: 0.7253780323091995
0.7252837877783838
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [15, 95, 19, 51, 10, 55, 47, 69, 92, 69]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.92634145e-04, 2.22395759e-01, 2.18464660e-01, 2.19058807e-01,
        1.17497349e-01, 5.43197617e-01, 2.24679468e-01, 1.04162610e-01,
        1.63721903e-01, 4.00505051e-01, 2.95914069e-01, 9.40793047e-02,
        1.75433168e-01, 8.40508096e-02, 3.87898349e-02, 2.47645919e-01,
        8.01213687e-02, 4.67424242e-02, 2.21064596e-01, 1.91900715e-01,
        8.00892721e-02, 1.91746709e-01,...
        3.53319394e-01, 6.13636364e-01, 4.71988206e-01, 1.31667572e-01,
        2.58088755e-01, 1.03854097e-01, 6.02318275e-02, 2.70829792e-01,
        2.72689038e-01, 8.77777778e-02, 3.06118583e-01, 2.31581021e-01,
        2.10749969e-01, 2.87442191e-01, 5.57569296e-01, 2.76856417e-01,
        1.48151789e-01, 7.14719672e-01, 3.58306410e-01, 2.70047923e-01,
        5.23940751e-01, 4.11196531e-01, 4.14928506e-01]]),
       n_clusters=6))
Best evaluation: 0.7060961181909174
0.7060961181909174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [133, 14, 185, 36, 76, 68]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.31298125e-04, 3.15159260e-01, 2.24213730e-01, 3.00048373e-01,
        1.81675504e-01, 2.18651259e-01, 1.26403288e-01, 4.35098407e-02,
        8.56361829e-02, 1.47979798e-01, 2.01558551e-01, 2.74126381e-02,
        1.24101793e-01, 3.26061349e-02, 1.44714773e-02, 9.39592752e-02,
        9.67787855e-02, 2.72474747e-02, 1.50710362e-01, 7.55332921e-02,
        5.48183862e-02, 2.39772323e-01,...
        4.29025845e-01, 3.58080808e-01, 5.93934288e-02, 2.10103205e-01,
        1.69117159e-01, 1.67082882e-01, 1.62847078e-01, 1.02491756e-01,
        1.05116525e-01, 4.33080808e-02, 1.96628149e-01, 4.14813981e-02,
        3.52836861e-02, 7.55602988e-01, 6.28198294e-01, 6.85243289e-01,
        5.97178529e-01, 4.68179040e-01, 2.25776407e-01, 2.51996805e-01,
        6.90378007e-01, 2.47782377e-01, 1.32624951e-01]]),
       n_clusters=10))
Best evaluation: 0.5844107798627856
0.5820132638596704
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [116, 32, 46, 90, 77, 67, 36, 64]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.6836682006245279
0.6917797645240412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [341, 12, 55, 12, 99]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00262571e-01, 2.49372900e-01, 4.30503889e-01, 2.37647709e-01,
        1.37009544e-01, 2.64421775e-01, 1.00055211e-01, 4.01593252e-02,
        6.26739563e-02, 2.44444444e-01, 2.06402696e-01, 4.07025167e-02,
        1.72118105e-01, 3.86373274e-02, 2.09899925e-02, 1.15001530e-01,
        7.35872863e-02, 2.37626263e-02, 8.62095094e-02, 1.15354309e-01,
        5.19671655e-02, 2.21985059e-01,...
        1.31461233e-01, 7.47474747e-01, 2.29780960e-01, 1.11787072e-01,
        2.12561881e-01, 9.97031522e-02, 5.22564522e-02, 1.80303906e-01,
        6.88557094e-02, 4.92171717e-02, 2.18412578e-01, 3.04328249e-01,
        2.20485607e-02, 2.21629313e-01, 3.22228145e-01, 2.01255043e-01,
        1.06050924e-01, 3.86515222e-01, 8.07307584e-02, 6.47923323e-02,
        2.16357388e-01, 3.21506012e-01, 6.10651974e-02]]),
       n_clusters=6))
Best evaluation: 0.6560243067934389
0.6560243067934389
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [121, 37, 81, 197, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.8313001760940605
0.8313001760940605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [376, 13, 83, 10, 30]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
0.6499323509896758
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5250472566407711
0.5250472566407711
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [29, 85, 398]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5076730875389999
0.502368243937889
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 123, 19, 344, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4682516006541036
0.4689400357561675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [11, 367, 14, 128]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.494117406079844
0.494117406079844
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [86, 334, 69, 11, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4605739760692546
0.45631666171688
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [342, 12, 19, 142]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.46079625939421875
0.45978509233875603
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [29, 79, 12, 400]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.47641749162243335
0.4738773462672673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 120, 361, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4578026439814722
0.45683188806996583
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [93, 381, 35, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4639237762038193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [380, 78, 44, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.45231735591397454
0.45138615901249657
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [104, 381, 10, 26]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 75 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.42267325632555464
0.42212839490273957
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [90, 63, 13, 70, 101, 57, 32, 17, 75]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5204534524876616
0.5200516058927407
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [81, 383, 23, 11, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4621916910075081
0.4622166877066778
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [370, 12, 88, 43]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4818201163018334
0.48451118748020094
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [459, 14, 18, 25]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.46507774600907004
0.46507774600907004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [96, 416]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4507685510847271
0.4507685510847271
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 347, 36, 114]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4497708946581949
0.44856002667623596
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [359, 116, 13, 32]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.47943161885869867
0.4791974116886558
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [79, 27, 400, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4669613634502018
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [44, 380, 12, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.45770057714036294
0.4593185508986758
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [133, 25, 352, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 75 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        38
           1       0.68      0.79      0.73        19

    accuracy                           0.81        57
   macro avg       0.78      0.80      0.79        57
weighted avg       0.82      0.81      0.81        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        36
           1       0.81      0.81      0.81        21

    accuracy                           0.86        57
   macro avg       0.85      0.85      0.85        57
weighted avg       0.86      0.86      0.86        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [170, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.90      0.82        30
           1       0.86      0.67      0.75        27

    accuracy                           0.79        57
   macro avg       0.80      0.78      0.78        57
weighted avg       0.80      0.79      0.79        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [346, 166]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.90      0.90      0.90        21

    accuracy                           0.93        56
   macro avg       0.92      0.92      0.92        56
weighted avg       0.93      0.93      0.93        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8875939849624059
F1: 0.8514344686636235
======================================================
Running wdbc 75 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7190730642231182
0.7190730642231182
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.94        25

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.95        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [406, 31, 75]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76839067e-03, 1.47852490e-01, 3.61176868e-01, 1.53506900e-01,
        7.48734232e-02, 5.01670127e-01, 3.35930311e-01, 1.97938144e-01,
        1.42495030e-01, 3.29360780e-01, 3.93007582e-01, 7.54300199e-02,
        2.49469590e-01, 6.94058333e-02, 2.60329699e-02, 2.44382500e-01,
        3.42461021e-01, 2.41573404e-01, 4.26650367e-01, 2.55593494e-01,
        3.05719957e-01, 1.10079673e-01,...
        8.83200795e-02, 2.47020585e-01, 1.81760741e-01, 2.53847547e-02,
        8.95951202e-02, 2.57268058e-02, 1.13709801e-02, 1.69833770e-01,
        1.10839066e-01, 6.84660961e-02, 1.83300733e-01, 1.68575586e-01,
        8.52803526e-02, 1.49550471e-01, 3.19829424e-01, 1.43307407e-01,
        6.73630409e-02, 4.16231922e-01, 1.48936170e-01, 1.48562300e-01,
        2.84810997e-01, 3.24132492e-01, 1.53785541e-01]]),
       n_clusters=10))
Best evaluation: 0.6803275342744949
0.6793792327961536
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.94      0.96        36
           1       0.91      0.95      0.93        21

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 24, 44, 140, 69, 101, 87, 31]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.6629672430518155
0.6629672430518155
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [333, 12, 71, 11, 85]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.86203590e-04, 1.65601780e-01, 1.78221170e-01, 1.63775828e-01,
        8.06362672e-02, 4.11031868e-01, 2.51272928e-01, 1.48430178e-01,
        1.10238569e-01, 4.36868687e-01, 4.04170177e-01, 7.82545718e-02,
        1.69117159e-01, 8.51434764e-02, 2.60890029e-02, 1.92099806e-01,
        3.70297312e-01, 1.32904040e-01, 2.39439288e-01, 1.93167108e-01,
        1.33753814e-01, 1.49413020e-01,...
        2.17445328e-01, 5.30808081e-01, 6.42375737e-01, 7.81821474e-02,
        1.83930664e-01, 5.31498846e-02, 2.02989178e-02, 2.66376585e-01,
        8.52157644e-01, 7.67171717e-01, 6.29285850e-01, 4.79653290e-01,
        2.97547425e-01, 8.46673782e-02, 2.83315565e-01, 7.51531451e-02,
        3.42852930e-02, 5.23195001e-01, 3.97017590e-01, 1.00000000e+00,
        6.01374570e-01, 5.24935935e-01, 4.09681228e-01]]),
       n_clusters=10))
Best evaluation: 0.6258887526957037
0.6257091462364519
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 74, 127, 12, 51, 79, 69, 14, 11]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7188981484818738
0.7188981484818738
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [72, 427, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.85251318e-05, 2.94334801e-01, 2.06628340e-01, 2.78349803e-01,
        1.67041357e-01, 2.93220186e-01, 1.01619533e-01, 3.42314902e-03,
        1.62077535e-02, 2.88888889e-01, 1.84322034e-01, 2.85352164e-02,
        4.71402051e-02, 2.10620553e-02, 1.54624915e-02, 6.52343883e-02,
        4.21260552e-02, 2.84848485e-03, 4.51979542e-02, 7.82067879e-02,
        5.83931014e-02, 2.30522946e-01,...
        1.41633086e-01, 4.58337095e-01, 3.55561009e-01, 2.54217432e-01,
        2.26739563e-01, 4.45959596e-01, 4.05296610e-01, 1.06391454e-01,
        3.20190948e-01, 8.88187344e-02, 5.08662136e-02, 2.51045314e-01,
        2.71862889e-01, 9.50252525e-02, 2.50236787e-01, 1.53346091e-01,
        1.65042909e-01, 2.74635361e-01, 8.18209045e-01, 2.55441008e-01,
        1.43457530e-01, 7.08776332e-01, 4.30101580e-01, 3.53434505e-01,
        5.01374570e-01, 3.25251331e-01, 4.29358520e-01]])))
Best evaluation: 0.7718003401513439
0.7718003401513439
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        36
           1       0.90      0.90      0.90        21

    accuracy                           0.93        57
   macro avg       0.92      0.92      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [121, 78, 26, 15, 111, 65, 27, 69]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.6914300228269313
0.6914300228269313
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [74, 11, 375, 26, 35]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7196029701229832
0.7196029701229832
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.90      1.00      0.95        19

    accuracy                           0.96        56
   macro avg       0.95      0.97      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [427, 15, 71]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9648496240601503
F1: 0.9530661474954325
======================================================
Running wdbc 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4900245746185824
0.49020874131875414
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        33
           1       1.00      0.92      0.96        24

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [388, 80, 21, 31]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.49456482573365224
0.4952658644833037
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.94        37
           1       0.86      0.95      0.90        20

    accuracy                           0.93        57
   macro avg       0.92      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [100, 381, 18, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5134985371334404
0.5086361652898181
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        36
           1       0.90      0.90      0.90        21

    accuracy                           0.93        57
   macro avg       0.92      0.92      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [16, 125, 26, 13, 340]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4922386577651643
0.4922386577651643
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [329, 11, 13, 85, 74]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.4602286345176105
0.4616555700232134
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [143, 19, 12, 341]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.452386025719047
0.4512861860425934
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.88      0.92        40
           1       0.76      0.94      0.84        17

    accuracy                           0.89        57
   macro avg       0.87      0.91      0.88        57
weighted avg       0.91      0.89      0.90        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [124, 356, 27, 13]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.45847594882249043
0.45847594882249043
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [78, 381, 39, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4110954880557498
0.41241577862365597
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [73, 37, 410]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.46511453775610384
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [380, 12, 78, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.50484751e-04, 3.42609683e-01, 4.53500169e-01, 3.49526639e-01,
        1.97836691e-01, 4.45931212e-01, 6.80694436e-01, 4.64151828e-01,
        3.28926441e-01, 6.49759744e-01, 5.36225779e-01, 6.31902951e-02,
        3.86713225e-01, 6.38458276e-02, 4.65410779e-02, 2.12700139e-01,
        1.00000000e+00, 2.94444444e-01, 3.15590074e-01, 6.08543930e-01,
        3.73989470e-01, 2.77837069e-01,...
        6.51093439e-01, 5.54191137e-01, 1.89974726e-01, 3.23193916e-01,
        1.01794554e-01, 2.64571455e-01, 2.44860833e-01, 1.21358398e-01,
        2.76594466e-01, 2.40353535e-01, 3.53097177e-01, 2.26937581e-01,
        1.41895720e-01, 6.27890430e-01, 3.99253731e-01, 5.72189850e-01,
        4.48486040e-01, 3.29723304e-01, 2.81272133e-01, 5.58386581e-01,
        7.23367698e-01, 3.07707471e-01, 1.53810836e-01]]),
       n_clusters=4))
Best evaluation: 0.44272324705313193
0.44272324705313193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        21

    accuracy                           0.96        56
   macro avg       0.96      0.96      0.96        56
weighted avg       0.96      0.96      0.96        56

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [75, 318, 30, 90]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9613408521303258
F1: 0.9465293668954997
======================================================
Running wdbc 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.45843836191154
0.45843836191154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [384, 79, 13, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5169755206913282
0.5126517751353554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [22, 10, 127, 17, 344]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.47483524753243256
0.47178487546343784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [118, 25, 14, 363]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.4825419381854994
0.48145366198655476
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [400, 24, 11, 83]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.45384171317887534
0.45384171317887534
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [349, 11, 79, 73]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
0.44506692740831116
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.45628162635152875
0.4582678224554586
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [355, 17, 68, 73]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4679229509278423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [380, 12, 78, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.97      0.94        33
           1       0.95      0.87      0.91        23

    accuracy                           0.93        56
   macro avg       0.93      0.92      0.93        56
weighted avg       0.93      0.93      0.93        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.956015037593985
F1: 0.9404712631541899
======================================================
Running wdbc 50 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.7192479044820989
0.7192479044820989
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.63      0.76        54
           1       0.09      0.67      0.16         3

    accuracy                           0.63        57
   macro avg       0.53      0.65      0.46        57
weighted avg       0.93      0.63      0.73        57

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [408, 75, 29]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.74931926e-04, 1.74298448e-01, 1.71457558e-01, 1.66880068e-01,
        9.42246632e-02, 2.74713370e-01, 7.72958714e-02, 2.28139644e-03,
        1.46172962e-02, 3.86240520e-01, 2.28517270e-01, 3.72623574e-02,
        1.40536598e-01, 3.63756302e-02, 1.54427174e-02, 1.32712377e-01,
        3.65908613e-02, 3.20506912e-03, 7.19070905e-02, 1.07490167e-01,
        5.16817511e-02, 1.49185001e-01,...
        3.83996024e-01, 4.70205850e-01, 2.10614996e-02, 1.74180699e-01,
        7.20694837e-02, 1.46586251e-01, 1.27097972e-01, 9.59649182e-02,
        8.64301379e-02, 8.70638578e-02, 3.04889976e-01, 1.78516373e-01,
        3.16045381e-02, 5.25619472e-01, 2.93443497e-01, 4.86553810e-01,
        3.55647082e-01, 2.26045037e-01, 1.22643615e-01, 2.08146965e-01,
        4.89690722e-01, 2.93572555e-01, 2.70536476e-02]]),
       n_clusters=10))
Best evaluation: 0.7117451238135492
0.7117451238135492
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.76      0.86        46
           1       0.50      1.00      0.67        11

    accuracy                           0.81        57
   macro avg       0.75      0.88      0.77        57
weighted avg       0.90      0.81      0.83        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [119, 31, 48, 88, 13, 77, 14, 44, 78]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.6828423183319954
0.6828423183319954
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.65      0.78        54
           1       0.10      0.67      0.17         3

    accuracy                           0.65        57
   macro avg       0.53      0.66      0.47        57
weighted avg       0.93      0.65      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [76, 22, 373, 37, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.28579215e-04, 3.07586729e-01, 3.75718634e-01, 3.08271716e-01,
        1.76330859e-01, 4.42087208e-01, 3.25501503e-01, 2.58763389e-01,
        2.84317825e-01, 3.33333333e-01, 2.99705139e-01, 3.67553866e-02,
        5.10961810e-02, 3.64757693e-02, 2.18865218e-02, 1.24213890e-01,
        1.51245231e-01, 7.69949495e-02, 2.39060428e-01, 8.28502280e-02,
        7.91910230e-02, 2.70366418e-01,...
        6.03763722e-01, 2.49494949e-01, 1.40058972e-01, 2.00181061e-01,
        2.21181047e-01, 1.77786370e-01, 1.40247069e-01, 1.27613285e-01,
        1.38928110e-01, 8.04292929e-02, 2.77704111e-01, 3.38830416e-02,
        4.52648453e-02, 6.31447883e-01, 5.34381663e-01, 5.86632800e-01,
        4.51435313e-01, 4.33401572e-01, 2.74383677e-01, 3.51357827e-01,
        7.85394420e-01, 1.38576779e-01, 1.26000262e-01]]),
       n_clusters=10))
Best evaluation: 0.6942932972940574
0.69042067207617
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [70, 128, 34, 87, 68, 13, 90, 25]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.5917878130426393
0.5917878130426393
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        53
           1       0.14      0.75      0.24         4

    accuracy                           0.67        57
   macro avg       0.56      0.71      0.51        57
weighted avg       0.91      0.67      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [80, 383, 20, 38]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.6863329594846757
0.6878905292109562
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 125, 20, 349, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.64      0.77        55
           1       0.05      0.50      0.09         2

    accuracy                           0.63        57
   macro avg       0.51      0.57      0.43        57
weighted avg       0.94      0.63      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00966125, 0.15140328, 0.26445722, 0.14739824, 0.07194062,
        0.48271193, 0.20133734, 0.04142455, 0.09517893, 0.42929293,
        0.40269587, 0.0489589 , 0.18935644, 0.04165292, 0.01540536,
        0.21028657, 0.08823264, 0.02155051, 0.14442129, 0.26014521,
        0.0990216 , 0.11526147, 0.28837953, 0.10722646, 0.04679512,
        0.45849567, 0.11323263, 0.05249201, 0.19158076, 0.29371181,
        0....
       [0.00955143, 0.49642671, 0.50625634, 0.49968903, 0.35677625,
        0.47187867, 0.43224342, 0.50585754, 0.51838966, 0.24141414,
        0.28833193, 0.35361217, 0.23201025, 0.31004099, 0.21572363,
        0.15164701, 0.25601586, 0.11727273, 0.29721538, 0.05020544,
        0.14597239, 0.54108858, 0.5413113 , 0.52238657, 0.36246559,
        0.43868454, 0.34511162, 0.39057508, 0.59140893, 0.1172876 ,
        0.24898334]]),
       n_clusters=6))
Best evaluation: 0.7058072990620615
0.7058072990620615
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [128, 73, 53, 21, 191, 46]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.7492151509231877
0.746133766166786
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [364, 10, 22, 39, 11, 71]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.98785452e-03, 2.37067538e-01, 5.13358133e-01, 2.33708797e-01,
        1.26320255e-01, 4.01328179e-01, 2.23299184e-01, 1.27483599e-01,
        2.12425447e-01, 3.48638548e-01, 3.90480202e-01, 5.46080029e-02,
        1.86483380e-01, 5.22075107e-02, 2.35114812e-02, 2.24598022e-01,
        1.35172890e-01, 5.89393939e-02, 3.15400644e-01, 1.83739517e-01,
        9.60159197e-02, 1.79651370e-01,...
        9.77306469e-02, 4.04301715e-01, 2.19587755e-01, 1.26452671e-01,
        1.66053678e-01, 3.25146823e-01, 4.02485257e-01, 1.75991309e-02,
        1.02170262e-01, 2.81769778e-02, 7.46734205e-03, 1.93867492e-01,
        1.24057440e-01, 6.96464646e-02, 1.91324114e-01, 2.19479935e-01,
        6.98630516e-02, 1.41942369e-01, 2.10021322e-01, 1.46172618e-01,
        6.26228864e-02, 4.66420128e-01, 1.87938411e-01, 1.83626198e-01,
        3.69415808e-01, 3.42203824e-01, 2.34553325e-01]])))
Best evaluation: 0.6669415913787106
0.6669415913787106
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.14      1.00      0.25         3

    accuracy                           0.68        56
   macro avg       0.57      0.83      0.52        56
weighted avg       0.95      0.68      0.77        56

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [78, 10, 66, 116, 74, 32, 51, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6661027568922306
F1: 0.1890289855072464
======================================================
Running wdbc 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5273782997746802
0.5273782997746802
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        54
           1       0.14      1.00      0.24         3

    accuracy                           0.67        57
   macro avg       0.57      0.82      0.51        57
weighted avg       0.95      0.67      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [19, 86, 407]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4826911252081452
0.4733009905108571
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.27      1.00      0.43         6

    accuracy                           0.72        57
   macro avg       0.64      0.84      0.62        57
weighted avg       0.92      0.72      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [104, 21, 381, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.4686580827448033
0.4688256450879932
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.64      0.76        53
           1       0.10      0.50      0.16         4

    accuracy                           0.63        57
   macro avg       0.52      0.57      0.46        57
weighted avg       0.88      0.63      0.72        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [121, 14, 358, 27]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4782958169333663
0.4765761731638909
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [409, 25, 67, 18]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.45585163498462544
0.45488207618303095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [353, 12, 130, 25]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.5707367567770945
0.5707367567770945
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.64      0.76        53
           1       0.10      0.50      0.16         4

    accuracy                           0.63        57
   macro avg       0.52      0.57      0.46        57
weighted avg       0.88      0.63      0.72        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [403, 10, 12, 13, 74]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4607509293869479
0.4602159000148612
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        52
           1       0.19      0.80      0.31         5

    accuracy                           0.68        57
   macro avg       0.58      0.74      0.55        57
weighted avg       0.90      0.68      0.75        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [399, 83, 11, 25]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.40859658996330495
0.4092985269662184
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.73      0.85        49
           1       0.38      1.00      0.55         8

    accuracy                           0.77        57
   macro avg       0.69      0.87      0.70        57
weighted avg       0.91      0.77      0.81        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [424, 74, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.46673016217854124
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [78, 380, 12, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.48140800388622673
0.4821138943311153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        55
           1       0.05      1.00      0.09         1

    accuracy                           0.64        56
   macro avg       0.52      0.82      0.43        56
weighted avg       0.98      0.64      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [40, 379, 26, 75]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6870927318295739
F1: 0.2963512349719246
======================================================
Running wdbc 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.42267325632555464
0.42231389350159604
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        55
           1       0.05      0.50      0.08         2

    accuracy                           0.61        57
   macro avg       0.51      0.56      0.42        57
weighted avg       0.94      0.61      0.73        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [90, 63, 13, 70, 101, 57, 32, 17, 75]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5101815549536637
0.5093919696763536
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.63      0.76        54
           1       0.09      0.67      0.16         3

    accuracy                           0.63        57
   macro avg       0.53      0.65      0.46        57
weighted avg       0.93      0.63      0.73        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [20, 81, 10, 11, 398]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.49417593294217194
0.4917217746140267
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.62      0.74        53
           1       0.05      0.25      0.08         4

    accuracy                           0.60        57
   macro avg       0.48      0.44      0.41        57
weighted avg       0.86      0.60      0.70        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 78, 377, 20, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.49531517757525056
0.49531517757525056
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [346, 10, 85, 59, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.46078602841186056
0.46078602841186056
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 338, 131, 15]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4566835316579478
0.4559689252337248
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [115, 14, 366, 25]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44934020276650355
0.44934020276650355
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        53
           1       0.14      0.75      0.24         4

    accuracy                           0.67        57
   macro avg       0.56      0.71      0.51        57
weighted avg       0.91      0.67      0.75        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [346, 110, 20, 36]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.46403982828896023
0.46403982828896023
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        51
           1       0.29      1.00      0.44         6

    accuracy                           0.74        57
   macro avg       0.64      0.85      0.64        57
weighted avg       0.92      0.74      0.79        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [79, 61, 10, 362]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4637062457226504
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [380, 12, 44, 78]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.48331147061767427
0.48137377248368846
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.65      0.77        51
           1       0.14      0.60      0.23         5

    accuracy                           0.64        56
   macro avg       0.54      0.62      0.50        56
weighted avg       0.87      0.64      0.72        56

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [404, 20, 81, 16]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6695488721804511
F1: 0.24833022533022536
======================================================
Running wdbc 50 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7106645055587959
0.712469358455254
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [90, 63, 13, 70, 101, 57, 32, 17, 75]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.6188333630167995
0.6052990201686977
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [474, 14, 21, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.7948452049732933
0.7948452049732933
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [124, 366, 12, 10]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.98939672e-03, 2.20029344e-01, 6.62157592e-01, 2.14774376e-01,
        1.15206787e-01, 3.69594656e-01, 2.03545795e-01, 1.74294060e-01,
        1.05436487e-01, 3.73232323e-01, 2.46419545e-01, 7.31486511e-02,
        4.56550566e-01, 6.50019332e-02, 3.04969387e-02, 2.76982697e-01,
        1.64688918e-01, 1.07954545e-01, 1.74559576e-01, 2.37350144e-01,
        4.26046460e-02, 1.84631804e-01,...
        6.28855201e-01, 6.00000000e-01, 2.91912384e-01, 1.77222524e-01,
        2.29358204e-01, 1.52183548e-01, 1.13892842e-01, 2.22830336e-01,
        2.14558236e-01, 1.27323232e-01, 2.10645956e-01, 1.84865200e-01,
        1.02234567e-01, 4.60690146e-01, 5.34914712e-01, 4.26764281e-01,
        2.84801416e-01, 6.09060292e-01, 3.18819066e-01, 4.46325879e-01,
        6.36238374e-01, 3.87344766e-01, 1.95329923e-01]]),
       n_clusters=10))
Best evaluation: 0.7289311654007308
0.7295190115976756
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [71, 20, 109, 51, 14, 12, 95, 58, 65, 27]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00735222e-03, 6.22320034e-01, 6.26986811e-01, 6.04035658e-01,
        4.74019088e-01, 4.07781890e-01, 2.57714251e-01, 3.37394564e-01,
        4.86630219e-01, 3.49494949e-01, 1.13100253e-01, 2.36827811e-01,
        4.64502863e-01, 2.09489705e-01, 1.72279314e-01, 1.37879457e-01,
        2.23471753e-01, 9.97474747e-02, 3.17863232e-01, 1.56160297e-01,
        5.29826785e-02, 5.60654571e-01,...
        8.75745527e-02, 3.06565657e-01, 9.54085931e-02, 5.45355785e-02,
        1.92332353e-01, 4.24068228e-02, 2.68734661e-02, 1.47567733e-01,
        6.83491276e-02, 1.43459596e-02, 1.20022732e-01, 6.00551584e-02,
        1.89008614e-02, 2.28032729e-01, 5.29317697e-01, 2.02450321e-01,
        1.08951042e-01, 3.43883719e-01, 7.95665124e-02, 3.56389776e-02,
        2.03470790e-01, 1.46067416e-01, 5.16200971e-02]]),
       n_clusters=9))
Best evaluation: 0.6993461363334185
0.6943434677333138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [20, 119, 20, 39, 24, 95, 78, 124]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[2.66648573e-07, 2.89104164e-01, 1.41493776e-01, 2.66228775e-01,
        1.57963945e-01, 1.52748939e-01, 5.49352800e-02, 5.29522024e-02,
        5.82007952e-02, 1.39898990e-01, 1.23209773e-01, 1.59500123e-02,
        2.40452617e-02, 2.00078243e-02, 1.09787485e-02, 1.39612342e-01,
        8.41019016e-02, 4.17171717e-02, 1.11858306e-01, 1.16902122e-01,
        4.09808880e-02, 2.02419068e-01,...
        2.43936382e-01, 6.41414141e-01, 7.89174389e-01, 1.44248952e-01,
        3.42733380e-01, 1.68333985e-01, 3.24954520e-02, 3.76185410e-01,
        4.78024454e-01, 2.59343434e-01, 4.78689146e-01, 3.80311814e-01,
        2.41221342e-01, 7.57737460e-02, 3.03304904e-01, 9.06917675e-02,
        2.75019662e-02, 3.36327016e-01, 3.37155941e-01, 3.68130990e-01,
        3.93470790e-01, 3.09481569e-01, 3.30972058e-01]]),
       n_clusters=10))
Best evaluation: 0.7268482460287025
0.726517096192057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [107, 21, 44, 70, 52, 72, 63, 28, 46, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 25, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.687830020051935
0.6871747989609427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [22, 120, 13, 11, 348]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
0.6499323509896758
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.48006657704926103
0.48570345858516883
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 28, 372, 92]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4920350353333456
0.4863227582518992
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [87, 381, 30, 21]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.465578524659308
0.4637923517161914
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [41, 390, 72, 14]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4749392228695494
0.47540591870598226
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [76, 401, 25, 18]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.467047949552846
0.4695220068024053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [85, 40, 13, 382]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4497696665719841
0.4497696665719841
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [345, 15, 48, 104]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.4582217396703531
0.4582217396703531
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [352, 11, 102, 47]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4610947518530165
0.4655385995111606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [12, 37, 81, 388]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.4661518005335329
0.4649698980349394
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [78, 380, 12, 44]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4814536379472573
0.47741013458026726
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 402, 74, 18]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 50 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.5170293451525734
0.5170293451525734
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [79, 30, 403]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.49663584161522695
0.49605098042277906
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [121, 19, 12, 341, 22]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering())
Best evaluation: 0.46262597584216036
0.46097944829602877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [61, 370, 75, 12]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.49399999917287585
0.49399999917287585
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [87, 334, 11, 12, 68]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=7))
Best evaluation: 0.46713784590401625
0.46842534422255955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [40, 382, 10, 88]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=5))
Best evaluation: 0.44982296896797214
0.44982296896797214
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [113, 346, 15, 38]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=10))
Best evaluation: 0.4550760750234518
0.45548311139392283
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [80, 395, 14, 24]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=6))
Best evaluation: 0.4610947518530165
0.46202155252584165
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 37, 388, 81]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=9))
Best evaluation: 0.46945244634854966
0.46945244634854966
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [104, 311, 74, 12, 11]
Selected clustering_algorithm: spectral
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 50 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       1.00      1.00      1.00        22

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.92        37
           1       0.82      0.90      0.86        20

    accuracy                           0.89        57
   macro avg       0.88      0.90      0.89        57
weighted avg       0.90      0.89      0.90        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.97      0.91        32
           1       0.95      0.80      0.87        25

    accuracy                           0.89        57
   macro avg       0.91      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.97      0.94        34
           1       0.95      0.87      0.91        23

    accuracy                           0.93        57
   macro avg       0.93      0.92      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      1.00      0.96        33
           1       1.00      0.88      0.93        24

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [170, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.93      0.83        29
           1       0.90      0.68      0.78        28

    accuracy                           0.81        57
   macro avg       0.83      0.80      0.80        57
weighted avg       0.83      0.81      0.80        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 167]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        32
           1       0.95      0.83      0.89        24

    accuracy                           0.91        56
   macro avg       0.92      0.90      0.91        56
weighted avg       0.91      0.91      0.91        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9156328320802005
F1: 0.8933269656178799
======================================================
Running wdbc 50 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.80      0.44      0.57         9
           2       1.00      0.83      0.91         6

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.50      0.67        10
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8466666666666667
F1: 0.8134319384319383
======================================================
Running iris 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.80      0.44      0.57         9
           2       1.00      0.83      0.91         6

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.50      0.67        10
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8133333333333332
F1: 0.7689874939874939
======================================================
Running iris 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.80      0.44      0.57         9
           2       1.00      0.83      0.91         6

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.50      0.67        10
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8133333333333332
F1: 0.7689874939874939
======================================================
Running iris 100 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.20      1.00      0.33         1
           2       0.80      1.00      0.89         4

    accuracy                           0.67        15
   macro avg       0.67      0.83      0.63        15
weighted avg       0.89      0.67      0.70        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.40      1.00      0.57         2
           2       0.80      1.00      0.89         4

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.72        15
weighted avg       0.87      0.73      0.74        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.60      1.00      0.75         3
           2       1.00      1.00      1.00         5

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.60      1.00      0.75         3
           2       1.00      1.00      1.00         5

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.60      0.27      0.38        11
           2       0.40      0.50      0.44         4

    accuracy                           0.33        15
   macro avg       0.33      0.26      0.27        15
weighted avg       0.55      0.33      0.39        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.20      1.00      0.33         1
           2       1.00      0.71      0.83         7

    accuracy                           0.73        15
   macro avg       0.73      0.81      0.67        15
weighted avg       0.95      0.73      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.45      0.62        11
           2       0.80      1.00      0.89         4

    accuracy                           0.60        15
   macro avg       0.60      0.48      0.50        15
weighted avg       0.95      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.50      0.44         4
           2       0.60      1.00      0.75         3

    accuracy                           0.67        15
   macro avg       0.67      0.71      0.65        15
weighted avg       0.76      0.67      0.68        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         0
           2       0.60      1.00      0.75         3

    accuracy                           0.53        15
   macro avg       0.53      0.47      0.45        15
weighted avg       0.92      0.53      0.62        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6733333333333333
F1: 0.6304340539634657
======================================================
Running iris 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.20537065703474372
======================================================
Running iris 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.21092621259029926
======================================================
Running iris 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.21092621259029926
======================================================
Running iris 100 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2486965811965812
======================================================
Running iris 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3466666666666667
F1: 0.1979632496273363
======================================================
Running iris 100 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 2 majority_voting default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 majority_voting default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.40      0.33      0.36         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.76      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2399612370200606
======================================================
Running iris 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       1.00      1.00      1.00         5
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         0
           2       0.80      1.00      0.89         4

    accuracy                           0.60        15
   macro avg       0.60      0.48      0.50        15
weighted avg       0.95      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.57      0.67         7
           1       0.00      0.00      0.00         1
           2       1.00      0.71      0.83         7

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.50        15
weighted avg       0.84      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8600000000000001
F1: 0.8276394901394901
======================================================
Running iris 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       1.00      1.00      1.00         5
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.57      0.67         7
           1       0.00      0.00      0.00         1
           2       1.00      0.71      0.83         7

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.50        15
weighted avg       0.84      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.86
F1: 0.8265271765271767
======================================================
Running iris 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       1.00      1.00      1.00         5
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.57      0.67         7
           1       0.00      0.00      0.00         1
           2       1.00      0.71      0.83         7

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.50        15
weighted avg       0.84      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.86
F1: 0.8265271765271767
======================================================
Running iris 75 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.20274624469670907
======================================================
Running iris 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.21036578374039677
======================================================
Running iris 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.21036578374039677
======================================================
Running iris 75 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 majority_voting default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 majority_voting default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.40      0.33      0.36         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.76      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2399612370200606
======================================================
Running iris 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.80      1.00      0.89         4
           2       0.80      1.00      0.89         4

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.87        15
weighted avg       0.89      0.87      0.86        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         0
           2       0.80      1.00      0.89         4

    accuracy                           0.60        15
   macro avg       0.60      0.48      0.50        15
weighted avg       0.95      0.60      0.70        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8866666666666667
F1: 0.8646765271765272
======================================================
Running iris 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.80      1.00      0.89         4
           2       0.80      1.00      0.89         4

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.87        15
weighted avg       0.89      0.87      0.86        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.50      0.67        10
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8533333333333333
F1: 0.819119769119769
======================================================
Running iris 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.80      1.00      0.89         4
           2       0.80      1.00      0.89         4

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.87        15
weighted avg       0.89      0.87      0.86        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.50      0.67        10
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      0.75      0.67         4
           2       0.80      0.67      0.73         6

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.83      0.91         6
           2       0.80      0.44      0.57         9

    accuracy                           0.60        15
   macro avg       0.60      0.43      0.49        15
weighted avg       0.88      0.60      0.71        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8533333333333333
F1: 0.819119769119769
======================================================
Running iris 50 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.34
F1: 0.18226120857699807
======================================================
Running iris 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.34
F1: 0.18988074762068569
======================================================
Running iris 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.20      1.00      0.33         1
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.45      0.29        15
weighted avg       0.95      0.40      0.51        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.34
F1: 0.18988074762068569
======================================================
Running iris 50 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563662862857993
0.7563662862857993
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7569326733399896
0.7569326733399896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7572483112395307
0.7572483112395307
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7576352351923421
0.7576352351923421
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 24, 61, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7564247419812524
0.7564247419812524
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7563582847994406
0.7563582847994406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7568235304422279
0.7568235304422279
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566195698687147
0.7566195698687147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.7566261850752172
0.7566261850752172
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.575077850467203
0.575077850467203
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [25, 24, 20, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5770558017004209
0.5770558017004209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [27, 24, 21, 63]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5868226352013222
0.5868226352013222
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 29, 61, 26]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.579410413856064
0.579410413856064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 21, 24, 28]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5852084700987831
0.5852084700987831
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 28, 24, 62]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5771173454327458
0.5771173454327458
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [25, 20, 24, 66]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5741419810210675
0.5741419810210675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 23, 67, 21]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=4))
Best evaluation: 0.5760430639893153
0.5760430639893153
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 65, 25, 20]
Selected clustering_algorithm: spectral
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 majority_voting default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 majority_voting default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24200812803753985
======================================================
Running heart 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3149326974900053
0.3149326974900053
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.92      0.79      0.85        14

    accuracy                           0.85        27
   macro avg       0.86      0.85      0.85        27
weighted avg       0.86      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
0.32089265837321423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), LogisticRegression(), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8296296296296297
F1: 0.7934057498565508
======================================================
Running heart 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), LogisticRegression(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8222222222222223
F1: 0.7966026936026935
======================================================
Running heart 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8444444444444444
F1: 0.8164566158479202
======================================================
Running heart 100 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73        18
           1       0.50      0.67      0.57         9

    accuracy                           0.67        27
   macro avg       0.65      0.67      0.65        27
weighted avg       0.70      0.67      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.77      0.71        13
           1       0.75      0.64      0.69        14

    accuracy                           0.70        27
   macro avg       0.71      0.71      0.70        27
weighted avg       0.71      0.70      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73        18
           1       0.50      0.67      0.57         9

    accuracy                           0.67        27
   macro avg       0.65      0.67      0.65        27
weighted avg       0.70      0.67      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7666666666666667
F1: 0.7129417249417249
======================================================
Running heart 100 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), SVC(probability=True), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.825925925925926
F1: 0.7933312640406462
======================================================
Running heart 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.62      0.65        16
           1       0.50      0.55      0.52        11

    accuracy                           0.59        27
   macro avg       0.58      0.59      0.58        27
weighted avg       0.60      0.59      0.59        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GradientBoostingClassifier(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8037037037037038
F1: 0.773630717108978
======================================================
Running heart 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.94      0.97        16
           1       0.92      1.00      0.96        11

    accuracy                           0.96        27
   macro avg       0.96      0.97      0.96        27
weighted avg       0.97      0.96      0.96        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        17
           1       0.50      0.60      0.55        10

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.65      0.63      0.63        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), RandomForestClassifier(), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7962962962962963
F1: 0.7678740824392998
======================================================
Running heart 100 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.13      0.50      0.21         4
           1       0.83      0.43      0.57        23

    accuracy                           0.44        27
   macro avg       0.48      0.47      0.39        27
weighted avg       0.73      0.44      0.52        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.33      0.30        12
           1       0.33      0.27      0.30        15

    accuracy                           0.30        27
   macro avg       0.30      0.30      0.30        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.07      1.00      0.12         1
           1       1.00      0.46      0.63        26

    accuracy                           0.48        27
   macro avg       0.53      0.73      0.38        27
weighted avg       0.97      0.48      0.61        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.20      0.60      0.30         5
           1       0.83      0.45      0.59        22

    accuracy                           0.48        27
   macro avg       0.52      0.53      0.44        27
weighted avg       0.72      0.48      0.53        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5925925925925927
F1: 0.5098337134714843
======================================================
Running heart 100 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), LogisticRegression(), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7259259259259261
F1: 0.5771340114993366
======================================================
Running heart 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.72        21
           1       0.33      0.67      0.44         6

    accuracy                           0.63        27
   macro avg       0.60      0.64      0.58        27
weighted avg       0.75      0.63      0.66        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GradientBoostingClassifier(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), RandomForestClassifier(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7222222222222222
F1: 0.5420745920745922
======================================================
Running heart 100 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), RandomForestClassifier(), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7296296296296297
F1: 0.5104241652067738
======================================================
Running heart 100 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.72        21
           1       0.33      0.67      0.44         6

    accuracy                           0.63        27
   macro avg       0.60      0.64      0.58        27
weighted avg       0.75      0.63      0.66        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), SVC(probability=True)]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6518518518518518
F1: 0.4036813375822663
======================================================
Running heart 100 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
CBEG               precision    recall  f1-score   support

           0       0.80      0.55      0.65        22
           1       0.17      0.40      0.24         5

    accuracy                           0.52        27
   macro avg       0.48      0.47      0.44        27
weighted avg       0.68      0.52      0.57        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6185185185185185
F1: 0.34353279073867304
======================================================
Running heart 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
CBEG               precision    recall  f1-score   support

           0       0.67      0.45      0.54        22
           1       0.00      0.00      0.00         5

    accuracy                           0.37        27
   macro avg       0.33      0.23      0.27        27
weighted avg       0.54      0.37      0.44        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
CBEG               precision    recall  f1-score   support

           0       0.80      0.55      0.65        22
           1       0.17      0.40      0.24         5

    accuracy                           0.52        27
   macro avg       0.48      0.47      0.44        27
weighted avg       0.68      0.52      0.57        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.548148148148148
F1: 0.2009087481146305
======================================================
Running heart 100 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
CBEG               precision    recall  f1-score   support

           0       0.67      0.45      0.54        22
           1       0.00      0.00      0.00         5

    accuracy                           0.37        27
   macro avg       0.33      0.23      0.27        27
weighted avg       0.54      0.37      0.44        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
CBEG               precision    recall  f1-score   support

           0       0.80      0.55      0.65        22
           1       0.17      0.40      0.24         5

    accuracy                           0.52        27
   macro avg       0.48      0.47      0.44        27
weighted avg       0.68      0.52      0.57        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.548148148148148
F1: 0.2009087481146305
======================================================
Running heart 100 2 majority_voting default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.38      0.36        13
           1       0.33      0.29      0.31        14

    accuracy                           0.33        27
   macro avg       0.33      0.34      0.33        27
weighted avg       0.33      0.33      0.33        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.40      0.43      0.41        14
           1       0.33      0.31      0.32        13

    accuracy                           0.37        27
   macro avg       0.37      0.37      0.37        27
weighted avg       0.37      0.37      0.37        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5518518518518518
F1: 0.398816565787154
======================================================
Running heart 100 3 majority_voting default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3149326974900053
0.3149326974900053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
0.32089265837321423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.92      0.79      0.85        14

    accuracy                           0.85        27
   macro avg       0.86      0.85      0.85        27
weighted avg       0.86      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), GaussianNB(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8222222222222222
F1: 0.7894882937217033
======================================================
Running heart 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8222222222222222
F1: 0.7810735930735931
======================================================
Running heart 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression(), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8407407407407407
F1: 0.8072722022447423
======================================================
Running heart 75 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        17
           1       0.50      0.60      0.55        10

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.65      0.63      0.63        27

Selected Base Classifiers: [GaussianNB(), DecisionTreeClassifier(), LogisticRegression(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7851851851851851
F1: 0.7532531269053008
======================================================
Running heart 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        15
           1       1.00      1.00      1.00        12

    accuracy                           1.00        27
   macro avg       1.00      1.00      1.00        27
weighted avg       1.00      1.00      1.00        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7814814814814814
F1: 0.7341859903381642
======================================================
Running heart 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.82      0.69        11
           1       0.83      0.62      0.71        16

    accuracy                           0.70        27
   macro avg       0.72      0.72      0.70        27
weighted avg       0.74      0.70      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), RandomForestClassifier(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7703703703703704
F1: 0.7039781722965867
======================================================
Running heart 75 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7407407407407407
F1: 0.6017754167057573
======================================================
Running heart 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), LogisticRegression(), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.674074074074074
F1: 0.43058874390143737
======================================================
Running heart 75 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        24
           1       0.25      1.00      0.40         3

    accuracy                           0.67        27
   macro avg       0.62      0.81      0.58        27
weighted avg       0.92      0.67      0.73        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6925925925925925
F1: 0.4591987965594777
======================================================
Running heart 75 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 majority_voting default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.38      0.36        13
           1       0.33      0.29      0.31        14

    accuracy                           0.33        27
   macro avg       0.33      0.34      0.33        27
weighted avg       0.33      0.33      0.33        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.40      0.43      0.41        14
           1       0.33      0.31      0.32        13

    accuracy                           0.37        27
   macro avg       0.37      0.37      0.37        27
weighted avg       0.37      0.37      0.37        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5592592592592592
F1: 0.43606352934990705
======================================================
Running heart 75 3 majority_voting default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3149326974900053
0.3149326974900053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.94      0.97        16
           1       0.92      1.00      0.96        11

    accuracy                           0.96        27
   macro avg       0.96      0.97      0.96        27
weighted avg       0.97      0.96      0.96        27

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.82      0.69        11
           1       0.83      0.62      0.71        16

    accuracy                           0.70        27
   macro avg       0.72      0.72      0.70        27
weighted avg       0.74      0.70      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
0.32089265837321423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.77      0.71        13
           1       0.75      0.64      0.69        14

    accuracy                           0.70        27
   macro avg       0.71      0.71      0.70        27
weighted avg       0.71      0.70      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), RandomForestClassifier(), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7962962962962963
F1: 0.7670711816363991
======================================================
Running heart 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.61      0.67        18
           1       0.42      0.56      0.48         9

    accuracy                           0.59        27
   macro avg       0.57      0.58      0.57        27
weighted avg       0.63      0.59      0.60        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), RandomForestClassifier(), LogisticRegression(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7814814814814814
F1: 0.738969860548808
======================================================
Running heart 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
0.26702487342502257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25998915817868573
0.25998915817868573
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26535972446952705
0.26535972446952705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      1.00      0.93        13
           1       1.00      0.86      0.92        14

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), GaussianNB()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.61      0.67        18
           1       0.42      0.56      0.48         9

    accuracy                           0.59        27
   macro avg       0.57      0.58      0.57        27
weighted avg       0.63      0.59      0.60        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), SVC(probability=True), LogisticRegression(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7888888888888889
F1: 0.7405436249486593
======================================================
Running heart 50 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        24
           1       0.25      1.00      0.40         3

    accuracy                           0.67        27
   macro avg       0.62      0.81      0.58        27
weighted avg       0.92      0.67      0.73        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        15
           1       1.00      1.00      1.00        12

    accuracy                           1.00        27
   macro avg       1.00      1.00      1.00        27
weighted avg       1.00      1.00      1.00        27

Selected Base Classifiers: [KNeighborsClassifier(), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.77      0.71        13
           1       0.75      0.64      0.69        14

    accuracy                           0.70        27
   macro avg       0.71      0.71      0.70        27
weighted avg       0.71      0.70      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), LogisticRegression(), GaussianNB(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7888888888888889
F1: 0.7354009758357584
======================================================
Running heart 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.77      0.71        13
           1       0.75      0.64      0.69        14

    accuracy                           0.70        27
   macro avg       0.71      0.71      0.70        27
weighted avg       0.71      0.70      0.70        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), GaussianNB(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7851851851851851
F1: 0.7638327936154024
======================================================
Running heart 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.73      0.73        15
           1       0.67      0.67      0.67        12

    accuracy                           0.70        27
   macro avg       0.70      0.70      0.70        27
weighted avg       0.70      0.70      0.70        27

Selected Base Classifiers: [GradientBoostingClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), SVC(probability=True), GaussianNB(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8000000000000002
F1: 0.7798813505335244
======================================================
Running heart 50 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        24
           1       0.25      1.00      0.40         3

    accuracy                           0.67        27
   macro avg       0.62      0.81      0.58        27
weighted avg       0.92      0.67      0.73        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3122348497794666
0.3122348497794666
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [KNeighborsClassifier(), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3115847375562811
0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.3207446269020011
0.3207446269020011
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
0.3546621903185521
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), RandomForestClassifier(), GaussianNB(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7333333333333333
F1: 0.5794607945112723
======================================================
Running heart 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73        18
           1       0.50      0.67      0.57         9

    accuracy                           0.67        27
   macro avg       0.65      0.67      0.65        27
weighted avg       0.70      0.67      0.68        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), SVC(probability=True), GaussianNB(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.662962962962963
F1: 0.3921144773698953
======================================================
Running heart 50 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26673956009733435
0.26673956009733435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.54      0.68        26
           1       0.00      0.00      0.00         1

    accuracy                           0.52        27
   macro avg       0.47      0.27      0.34        27
weighted avg       0.90      0.52      0.66        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25849279091601896
0.25849279091601896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2675267885939606
0.2675267885939606
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [113, 130]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26459321506937095
0.26459321506937095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.2656135643397757
0.2656135643397757
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26345339456272493
0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26189708438492765
0.26189708438492765
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.25905783262976834
0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('spectral', SpectralClustering(n_clusters=2))
Best evaluation: 0.26395615995452293
0.26395615995452293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: spectral
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
0.27789795524745475
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), SVC(probability=True), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 20, 52, 59, 37, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.674074074074074
F1: 0.4230203714414241
======================================================
Running heart 50 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 majority_voting default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.53      0.42      0.47        19
           1       0.08      0.12      0.10         8

    accuracy                           0.33        27
   macro avg       0.31      0.27      0.29        27
weighted avg       0.40      0.33      0.36        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.53      0.50      0.52        16
           1       0.33      0.36      0.35        11

    accuracy                           0.44        27
   macro avg       0.43      0.43      0.43        27
weighted avg       0.45      0.44      0.45        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6259259259259259
F1: 0.461930782159615
======================================================
Running heart 50 3 majority_voting default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
