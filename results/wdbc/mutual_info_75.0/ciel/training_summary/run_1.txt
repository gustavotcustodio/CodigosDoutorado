============== Classifiers Parameters ==============
[{'n_estimators': 298, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 7, 'learning_rate': 0.26266214508943675}, {'n_estimators': 487, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 9, 'learning_rate': 0.41170863611940306}, {'n_estimators': 268, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 9, 'learning_rate': 0.31893495564024466}]

Optimal clusterer: kmeans

External clustering metrics:
adjusted_rand_score: 0.7156794165766568
normalized_mutual_info_score: 0.6124589578585113
v_measure_score: 0.6124589578585113
fowlkes_mallows_score: 0.8715049096973392

Internal clustering metrics:
silhouette: 0.3742260507561356
davies_bouldin: 1.1686906682500302
calinski_harabasz_score: 304.44520675452145

Base classifier: gb
========== Cluster 0 ==========

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]

========== Cluster 1 ==========

Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1
 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0
 0 0 1 0 0 0 1 1 1 0 0 0 1]

========== Cluster 2 ==========

Labels: [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]

