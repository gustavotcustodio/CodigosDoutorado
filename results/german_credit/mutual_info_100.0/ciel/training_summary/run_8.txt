============== Classifiers Parameters ==============
[{'n_estimators': 287, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 8, 'learning_rate': 0.41067363528602807}, {'n_estimators': 197, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 10, 'learning_rate': 0.33562066361141507}, {'n_estimators': 338, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10, 'learning_rate': 0.3264239013162835}, {'n_estimators': 377, 'max_depth': 1, 'min_samples_split': 4, 'min_samples_leaf': 7, 'learning_rate': 0.7863621453761487}, {'n_estimators': 20, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 4, 'learning_rate': 0.13300445549341258}]

Optimal clusterer: kmeans

External clustering metrics:
adjusted_rand_score: 0.04212526818398264
normalized_mutual_info_score: 0.08231270256255468
v_measure_score: 0.08231270256255467
fowlkes_mallows_score: 0.6622197562568125

Internal clustering metrics:
silhouette: 0.24364582111627855
davies_bouldin: 0.6839460849301885
calinski_harabasz_score: 6.483259307009318

Base classifier: gb
========== Cluster 0 ==========

Labels: [1]

========== Cluster 1 ==========

Labels: [0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0
 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1
 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0
 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0]

========== Cluster 2 ==========

Labels: [0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0]

========== Cluster 3 ==========

Labels: [0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0
 1 1 1 1]

========== Cluster 4 ==========

Labels: [1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0
 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0
 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1
 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0
 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0
 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0
 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1
 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1
 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0
 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0
 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0]

