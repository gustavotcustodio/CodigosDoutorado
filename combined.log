======================================================
Running australian_credit 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.7908734550730504
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [1, 316, 4, 1, 299]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.7366776009749936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        39
           1       0.77      0.80      0.79        30

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [6, 304, 1, 310]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.7430833048759669
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        41
           1       0.71      0.79      0.75        28

    accuracy                           0.78        69
   macro avg       0.78      0.78      0.78        69
weighted avg       0.79      0.78      0.78        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [334, 1, 3, 283]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6297026259526776
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.91      0.83        32
           1       0.90      0.76      0.82        37

    accuracy                           0.83        69
   macro avg       0.83      0.83      0.83        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [166, 6, 160, 283, 1, 4, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.6901293000432025
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.95      0.95        38
           1       0.94      0.94      0.94        31

    accuracy                           0.94        69
   macro avg       0.94      0.94      0.94        69
weighted avg       0.94      0.94      0.94        69

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 305, 1, 2, 306, 2]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6722933552524231
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [6, 317, 3, 288, 7]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6539911757058261
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [316, 303, 2]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.6205900091355302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.78      0.80        41
           1       0.70      0.75      0.72        28

    accuracy                           0.77        69
   macro avg       0.76      0.77      0.76        69
weighted avg       0.77      0.77      0.77        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [4, 229, 75, 313]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.7376989601867352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.78      0.80        41
           1       0.70      0.75      0.72        28

    accuracy                           0.77        69
   macro avg       0.76      0.77      0.76        69
weighted avg       0.77      0.77      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [319, 1, 300, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.7170127269491214
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [2, 47, 1, 1, 269, 301]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8376811594202899
F1: 0.8155683536333915
======================================================
Running australian_credit 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        41
           1       0.74      0.82      0.78        28

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35672849579378785
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [306, 1, 314]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.40056005528790495
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.87        49
           1       0.65      1.00      0.78        20

    accuracy                           0.84        69
   macro avg       0.82      0.89      0.83        69
weighted avg       0.90      0.84      0.85        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [6, 329, 4, 282]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.32646751684258674
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [60, 1, 238, 322]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3501845386135837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [1, 309, 311]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3613200870956544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [322, 3, 296]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3097918947316993
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [6, 300, 2, 1, 311, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35877341623012676
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.80      0.81        40
           1       0.73      0.76      0.75        29

    accuracy                           0.78        69
   macro avg       0.78      0.78      0.78        69
weighted avg       0.78      0.78      0.78        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [307, 1, 313]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.32033532524714353
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [298, 8, 2, 310, 1, 2]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.846376811594203
F1: 0.8212841548389719
======================================================
Running australian_credit 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35026735735186826
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [317, 1, 303]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35678133406920826
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [304, 1, 316]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.36338353021383435
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        45
           1       0.68      0.88      0.76        24

    accuracy                           0.81        69
   macro avg       0.80      0.83      0.80        69
weighted avg       0.84      0.81      0.82        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [6, 280, 6, 100, 229]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.3176585171223923
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [2, 128, 1, 32, 67, 162, 229]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.84      0.84        38
           1       0.81      0.81      0.81        31

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.34050970806832703
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [2, 303, 1, 315]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.36148875260065555
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.90      0.80        31
           1       0.90      0.71      0.79        38

    accuracy                           0.80        69
   macro avg       0.81      0.81      0.80        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [307, 11, 303]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8376811594202899
F1: 0.8181021052624832
======================================================
Running australian_credit 100 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.79      0.88      0.83        34
           1       0.87      0.77      0.82        35

    accuracy                           0.83        69
   macro avg       0.83      0.83      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.79      0.83      0.81        36
           1       0.81      0.76      0.78        33

    accuracy                           0.80        69
   macro avg       0.80      0.80      0.80        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.84      0.84        38
           1       0.81      0.81      0.81        31

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.72      0.76      0.74        37
           1       0.70      0.66      0.68        32

    accuracy                           0.71        69
   macro avg       0.71      0.71      0.71        69
weighted avg       0.71      0.71      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67        39
           1       0.57      0.57      0.57        30

    accuracy                           0.62        69
   macro avg       0.62      0.62      0.62        69
weighted avg       0.62      0.62      0.62        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8
F1: 0.7788852998359712
======================================================
Running australian_credit 100 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.84      0.77        32
           1       0.84      0.70      0.76        37

    accuracy                           0.77        69
   macro avg       0.77      0.77      0.77        69
weighted avg       0.78      0.77      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.85      0.85        39
           1       0.80      0.80      0.80        30

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8507246376811594
F1: 0.8341221877245681
======================================================
Running australian_credit 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.87        33
           1       0.94      0.81      0.87        36

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.86      0.89        42
           1       0.80      0.89      0.84        27

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8666666666666668
F1: 0.8504935716748347
======================================================
Running australian_credit 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.87        33
           1       0.94      0.81      0.87        36

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.88      0.89        40
           1       0.83      0.86      0.85        29

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8637681159420291
F1: 0.8445130016130225
======================================================
Running australian_credit 100 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.37      0.50      0.42        28
           1       0.55      0.41      0.47        41

    accuracy                           0.45        69
   macro avg       0.46      0.46      0.45        69
weighted avg       0.48      0.45      0.45        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.53      0.56      0.54        36
           1       0.48      0.45      0.47        33

    accuracy                           0.51        69
   macro avg       0.51      0.51      0.50        69
weighted avg       0.51      0.51      0.51        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.76      0.72      0.74        40
           1       0.65      0.69      0.67        29

    accuracy                           0.71        69
   macro avg       0.70      0.71      0.71        69
weighted avg       0.71      0.71      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.68      0.68        38
           1       0.61      0.61      0.61        31

    accuracy                           0.65        69
   macro avg       0.65      0.65      0.65        69
weighted avg       0.65      0.65      0.65        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.74      0.71        35
           1       0.71      0.65      0.68        34

    accuracy                           0.70        69
   macro avg       0.70      0.69      0.69        69
weighted avg       0.70      0.70      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.65      0.76        52
           1       0.42      0.76      0.54        17

    accuracy                           0.68        69
   macro avg       0.66      0.71      0.65        69
weighted avg       0.78      0.68      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.53      0.46        30
           1       0.53      0.41      0.46        39

    accuracy                           0.46        69
   macro avg       0.47      0.47      0.46        69
weighted avg       0.48      0.46      0.46        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.64      0.76        56
           1       0.33      0.77      0.47        13

    accuracy                           0.67        69
   macro avg       0.63      0.71      0.61        69
weighted avg       0.81      0.67      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6246376811594204
F1: 0.5479127364407992
======================================================
Running australian_credit 100 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.70      0.81        53
           1       0.48      0.94      0.64        16

    accuracy                           0.75        69
   macro avg       0.73      0.82      0.73        69
weighted avg       0.86      0.75      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.83      0.85        41
           1       0.77      0.82      0.79        28

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        60
           1       0.30      1.00      0.46         9

    accuracy                           0.70        69
   macro avg       0.65      0.82      0.62        69
weighted avg       0.91      0.70      0.75        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.86      0.89        42
           1       0.80      0.89      0.84        27

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8115942028985508
F1: 0.734240496745445
======================================================
Running australian_credit 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.82      0.89        45
           1       0.74      0.96      0.84        24

    accuracy                           0.87        69
   macro avg       0.86      0.89      0.86        69
weighted avg       0.89      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        48
           1       0.68      1.00      0.81        21

    accuracy                           0.86        69
   macro avg       0.84      0.90      0.85        69
weighted avg       0.90      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        50
           1       0.63      1.00      0.78        19

    accuracy                           0.84        69
   macro avg       0.82      0.89      0.83        69
weighted avg       0.90      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8420289855072463
F1: 0.8024874290287825
======================================================
Running australian_credit 100 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        47
           1       0.61      0.86      0.72        22

    accuracy                           0.78        69
   macro avg       0.77      0.80      0.77        69
weighted avg       0.82      0.78      0.79        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.77      0.85        47
           1       0.65      0.91      0.75        22

    accuracy                           0.81        69
   macro avg       0.80      0.84      0.80        69
weighted avg       0.85      0.81      0.82        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        48
           1       0.68      1.00      0.81        21

    accuracy                           0.86        69
   macro avg       0.84      0.90      0.85        69
weighted avg       0.90      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        43
           1       0.73      0.85      0.79        26

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.97      0.93        36
           1       0.97      0.88      0.92        33

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8362318840579709
F1: 0.7960953302462737
======================================================
Running australian_credit 100 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.70      0.81        53
           1       0.48      0.94      0.64        16

    accuracy                           0.75        69
   macro avg       0.73      0.82      0.73        69
weighted avg       0.86      0.75      0.77        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.90      0.92        40
           1       0.87      0.93      0.90        29

    accuracy                           0.91        69
   macro avg       0.91      0.92      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        47
           1       0.68      0.95      0.79        22

    accuracy                           0.84        69
   macro avg       0.83      0.87      0.83        69
weighted avg       0.88      0.84      0.85        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.73      0.82        49
           1       0.57      0.85      0.68        20

    accuracy                           0.77        69
   macro avg       0.74      0.79      0.75        69
weighted avg       0.82      0.77      0.78        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        60
           1       0.30      1.00      0.46         9

    accuracy                           0.70        69
   macro avg       0.65      0.82      0.62        69
weighted avg       0.91      0.70      0.75        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.90      0.91        40
           1       0.87      0.90      0.88        29

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.808695652173913
F1: 0.725983288211976
======================================================
Running australian_credit 100 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 100 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
CBEG               precision    recall  f1-score   support

           0       0.82      0.58      0.68        53
           1       0.29      0.56      0.38        16

    accuracy                           0.58        69
   macro avg       0.55      0.57      0.53        69
weighted avg       0.69      0.58      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.67        60
           1       0.13      0.44      0.20         9

    accuracy                           0.54        69
   macro avg       0.50      0.50      0.44        69
weighted avg       0.77      0.54      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        64
           1       0.10      0.60      0.17         5

    accuracy                           0.58        69
   macro avg       0.52      0.59      0.44        69
weighted avg       0.89      0.58      0.68        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6579710144927536
F1: 0.4360211475637007
======================================================
Running australian_credit 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        57
           1       0.39      1.00      0.56        12

    accuracy                           0.72        69
   macro avg       0.69      0.83      0.68        69
weighted avg       0.89      0.72      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
CBEG               precision    recall  f1-score   support

           0       0.95      0.68      0.79        53
           1       0.45      0.88      0.60        16

    accuracy                           0.72        69
   macro avg       0.70      0.78      0.69        69
weighted avg       0.83      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        50
           1       0.58      0.95      0.72        19

    accuracy                           0.80        69
   macro avg       0.78      0.84      0.78        69
weighted avg       0.87      0.80      0.81        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
CBEG               precision    recall  f1-score   support

           0       0.95      0.70      0.80        53
           1       0.47      0.88      0.61        16

    accuracy                           0.74        69
   macro avg       0.71      0.79      0.71        69
weighted avg       0.84      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7246376811594204
F1: 0.5839825796583198
======================================================
Running australian_credit 100 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        57
           1       0.39      1.00      0.56        12

    accuracy                           0.72        69
   macro avg       0.69      0.83      0.68        69
weighted avg       0.89      0.72      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
CBEG               precision    recall  f1-score   support

           0       0.95      0.68      0.79        53
           1       0.45      0.88      0.60        16

    accuracy                           0.72        69
   macro avg       0.70      0.78      0.69        69
weighted avg       0.83      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        50
           1       0.58      0.95      0.72        19

    accuracy                           0.80        69
   macro avg       0.78      0.84      0.78        69
weighted avg       0.87      0.80      0.81        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        51
           1       0.48      0.83      0.61        18

    accuracy                           0.72        69
   macro avg       0.70      0.76      0.70        69
weighted avg       0.81      0.72      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
CBEG               precision    recall  f1-score   support

           0       0.95      0.70      0.80        53
           1       0.47      0.88      0.61        16

    accuracy                           0.74        69
   macro avg       0.71      0.79      0.71        69
weighted avg       0.84      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7246376811594204
F1: 0.5839825796583198
======================================================
Running australian_credit 100 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.58      0.68        53
           1       0.29      0.56      0.38        16

    accuracy                           0.58        69
   macro avg       0.55      0.57      0.53        69
weighted avg       0.69      0.58      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.55      0.67        60
           1       0.13      0.44      0.20         9

    accuracy                           0.54        69
   macro avg       0.50      0.50      0.44        69
weighted avg       0.77      0.54      0.61        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.67      0.77        54
           1       0.40      0.80      0.53        15

    accuracy                           0.70        69
   macro avg       0.66      0.73      0.65        69
weighted avg       0.81      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        64
           1       0.10      0.60      0.17         5

    accuracy                           0.58        69
   macro avg       0.52      0.59      0.44        69
weighted avg       0.89      0.58      0.68        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.95      0.65      0.77        57
           1       0.33      0.83      0.48        12

    accuracy                           0.68        69
   macro avg       0.64      0.74      0.62        69
weighted avg       0.84      0.68      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6579710144927536
F1: 0.4360211475637007
======================================================
Running australian_credit 100 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5590279606171238
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        45
           1       0.68      0.88      0.76        24

    accuracy                           0.81        69
   macro avg       0.80      0.83      0.80        69
weighted avg       0.84      0.81      0.82        69

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [303, 14, 1, 303]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6511337415627835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [315, 1, 305]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6551030351636811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.84      0.90        44
           1       0.77      0.96      0.86        25

    accuracy                           0.88        69
   macro avg       0.87      0.90      0.88        69
weighted avg       0.90      0.88      0.89        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), RandomForestClassifier()]
Number of samples by cluster: [1, 279, 13, 6, 2, 5, 315]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6704065482974139
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        38
           1       0.77      0.77      0.77        31

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [322, 291, 1, 1, 6]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6515480423618305
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [313, 1, 307]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6697653817483177
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.81      0.85        42
           1       0.74      0.85      0.79        27

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [287, 322, 3, 8, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.7401105434359166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.87        33
           1       0.94      0.81      0.87        36

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [315, 1, 304, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6227364678838868
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.79      0.81        42
           1       0.70      0.78      0.74        27

    accuracy                           0.78        69
   macro avg       0.77      0.78      0.78        69
weighted avg       0.79      0.78      0.78        69

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [11, 3, 303, 1, 303]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6493680673348599
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.85      0.85        39
           1       0.80      0.80      0.80        30

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [300, 4, 317]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5962058331959423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        37
           1       0.90      0.84      0.87        32

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [307, 2, 299, 6, 2, 5]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.844927536231884
F1: 0.8203493190302833
======================================================
Running australian_credit 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3439300131534324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 313, 305, 1, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.34071570680631663
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [2, 304, 1, 314]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41658838185049535
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [1, 5, 283, 1, 331]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3156781543804449
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [296, 4, 321]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.36251089113906737
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.84      0.84        38
           1       0.81      0.81      0.81        31

    accuracy                           0.83        69
   macro avg       0.82      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 329, 287, 1, 2]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.31873166821215637
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.80      0.81        40
           1       0.73      0.76      0.75        29

    accuracy                           0.78        69
   macro avg       0.78      0.78      0.78        69
weighted avg       0.78      0.78      0.78        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [309, 1, 8, 1, 302]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.35051311204513286
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        39
           1       0.77      0.77      0.77        30

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [9, 298, 1, 2, 311]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8521739130434783
F1: 0.8347141149355473
======================================================
Running australian_credit 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.34071570680631663
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 304, 314, 2]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4052444279131008
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [11, 329, 1, 2, 278]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3503161528149735
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [1, 1, 327, 292]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.92        36
           1       0.94      0.88      0.91        33

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.31220166671007743
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.84      0.83        37
           1       0.81      0.78      0.79        32

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [324, 264, 5, 1, 27]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3363085108002408
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.79      0.81        42
           1       0.70      0.78      0.74        27

    accuracy                           0.78        69
   macro avg       0.77      0.78      0.78        69
weighted avg       0.79      0.78      0.78        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [2, 2, 310, 304, 3]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        43
           1       0.73      0.85      0.79        26

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8492753623188406
F1: 0.8276757521388252
======================================================
Running australian_credit 75 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.85      0.81        34
           1       0.84      0.74      0.79        35

    accuracy                           0.80        69
   macro avg       0.80      0.80      0.80        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.92        36
           1       0.94      0.88      0.91        33

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.85      0.88        41
           1       0.80      0.86      0.83        28

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        40
           1       0.80      0.83      0.81        29

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8579710144927535
F1: 0.8404515302628752
======================================================
Running australian_credit 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.92      0.89        36
           1       0.90      0.85      0.88        33

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.87      0.86        38
           1       0.83      0.81      0.82        31

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        36
           1       0.87      0.79      0.83        33

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8623188405797102
F1: 0.8456595402731706
======================================================
Running australian_credit 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.86      0.82        35
           1       0.84      0.76      0.80        34

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.87      0.86        38
           1       0.83      0.81      0.82        31

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        37
           1       0.83      0.78      0.81        32

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8536231884057971
F1: 0.8361321879248902
======================================================
Running australian_credit 75 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.73      0.83        51
           1       0.55      0.94      0.69        18

    accuracy                           0.78        69
   macro avg       0.76      0.83      0.76        69
weighted avg       0.86      0.78      0.80        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.66      0.79        56
           1       0.39      0.92      0.55        13

    accuracy                           0.71        69
   macro avg       0.68      0.79      0.67        69
weighted avg       0.86      0.71      0.74        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        60
           1       0.30      1.00      0.46         9

    accuracy                           0.70        69
   macro avg       0.65      0.82      0.62        69
weighted avg       0.91      0.70      0.75        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8159420289855073
F1: 0.7490657309487715
======================================================
Running australian_credit 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.88      0.93        42
           1       0.84      0.96      0.90        27

    accuracy                           0.91        69
   macro avg       0.91      0.92      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        39
           1       0.77      0.80      0.79        30

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        41
           1       0.74      0.82      0.78        28

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.86        45
           1       0.70      0.88      0.78        24

    accuracy                           0.83        69
   macro avg       0.81      0.84      0.82        69
weighted avg       0.85      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        44
           1       0.67      0.80      0.73        25

    accuracy                           0.78        69
   macro avg       0.77      0.79      0.77        69
weighted avg       0.80      0.78      0.79        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8405797101449275
F1: 0.806979684368758
======================================================
Running australian_credit 75 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.88      0.91        41
           1       0.84      0.93      0.88        28

    accuracy                           0.90        69
   macro avg       0.89      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        46
           1       0.63      0.83      0.72        23

    accuracy                           0.78        69
   macro avg       0.77      0.79      0.77        69
weighted avg       0.81      0.78      0.79        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.80      0.89        49
           1       0.67      1.00      0.80        20

    accuracy                           0.86        69
   macro avg       0.83      0.90      0.84        69
weighted avg       0.90      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8492753623188406
F1: 0.8148588145165189
======================================================
Running australian_credit 75 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 75 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.57      0.67        54
           1       0.26      0.53      0.35        15

    accuracy                           0.57        69
   macro avg       0.54      0.55      0.51        69
weighted avg       0.69      0.57      0.60        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        62
           1       0.16      0.71      0.26         7

    accuracy                           0.59        69
   macro avg       0.55      0.65      0.49        69
weighted avg       0.87      0.59      0.67        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.67      0.77        52
           1       0.43      0.76      0.55        17

    accuracy                           0.70        69
   macro avg       0.67      0.72      0.66        69
weighted avg       0.78      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.58      0.73        65
           1       0.10      0.75      0.18         4

    accuracy                           0.59        69
   macro avg       0.54      0.67      0.45        69
weighted avg       0.92      0.59      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.64      0.76        58
           1       0.30      0.82      0.44        11

    accuracy                           0.67        69
   macro avg       0.62      0.73      0.60        69
weighted avg       0.85      0.67      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6565217391304348
F1: 0.42304962753600883
======================================================
Running australian_credit 75 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6482378822990735
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        38
           1       0.87      0.87      0.87        31

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [314, 304, 3]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.7388810746530079
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.77      0.83        44
           1       0.68      0.84      0.75        25

    accuracy                           0.80        69
   macro avg       0.79      0.81      0.79        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [313, 305, 2, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.6943648821821053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        41
           1       0.74      0.82      0.78        28

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.82      0.81      0.81        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [1, 277, 1, 8, 2, 2, 3, 327]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5622951053021071
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [GaussianNB(), GaussianNB(), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 15, 322, 278, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.6330410832595101
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.92      0.94        39
           1       0.90      0.93      0.92        30

    accuracy                           0.93        69
   macro avg       0.93      0.93      0.93        69
weighted avg       0.93      0.93      0.93        69

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [5, 308, 1, 307]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6650950436619538
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        39
           1       0.77      0.80      0.79        30

    accuracy                           0.81        69
   macro avg       0.81      0.81      0.81        69
weighted avg       0.81      0.81      0.81        69

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [273, 1, 1, 289, 57]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5956170933602735
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [1, 19, 288, 313]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6549397422585196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.84        44
           1       0.70      0.84      0.76        25

    accuracy                           0.81        69
   macro avg       0.80      0.82      0.80        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [304, 3, 314]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5410912888182041
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        43
           1       0.73      0.85      0.79        26

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [3, 1, 6, 311, 300]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6556533100624496
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.97      0.86        31
           1       0.97      0.76      0.85        38

    accuracy                           0.86        69
   macro avg       0.87      0.87      0.86        69
weighted avg       0.88      0.86      0.85        69

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [33, 285, 301, 1, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8405797101449275
F1: 0.8140252986749233
======================================================
Running australian_credit 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35022885614436305
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [316, 304, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.89      0.86        36
           1       0.87      0.82      0.84        33

    accuracy                           0.86        69
   macro avg       0.86      0.85      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.37389506261594924
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.91      0.86        34
           1       0.90      0.80      0.85        35

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.86      0.86      0.85        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [2, 292, 1, 326]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.94      0.89        34
           1       0.94      0.83      0.88        35

    accuracy                           0.88        69
   macro avg       0.89      0.88      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.36208612728009204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [290, 3, 328]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35201591509712604
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.82        42
           1       0.71      0.81      0.76        27

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.81      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [314, 306, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.37684724191984825
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        43
           1       0.70      0.81      0.75        26

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.81      0.80      0.80        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [1, 1, 317, 302]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3901999494594905
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [2, 4, 316, 299]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.846376811594203
F1: 0.8231867108218273
======================================================
Running australian_credit 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35022885614436305
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [316, 304, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.31510941874930587
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [313, 22, 285, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        40
           1       0.77      0.83      0.80        29

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.35354677576265925
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.91      0.85        33
           1       0.90      0.78      0.84        36

    accuracy                           0.84        69
   macro avg       0.85      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [1, 322, 65, 2, 231]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3479970349045121
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.77      0.86      0.81        28

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [1, 7, 324, 289]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35199309129722617
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [304, 1, 316]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3313074585972016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.84      0.88        43
           1       0.77      0.88      0.82        26

    accuracy                           0.86        69
   macro avg       0.84      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [305, 2, 5, 308, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.32390716904698813
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.77      0.80        43
           1       0.67      0.77      0.71        26

    accuracy                           0.77        69
   macro avg       0.76      0.77      0.76        69
weighted avg       0.78      0.77      0.77        69

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [56, 1, 301, 263]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.35274037322484286
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.94      0.86        33
           1       0.93      0.78      0.85        36

    accuracy                           0.86        69
   macro avg       0.86      0.86      0.85        69
weighted avg       0.87      0.86      0.85        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [303, 317, 1]
Selected clustering_algorithm: fcm
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.846376811594203
F1: 0.823705329716485
======================================================
Running australian_credit 50 2 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 meta_classifier crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand meta_classifier default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 meta_classifier default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        43
           1       0.74      0.88      0.81        26

    accuracy                           0.84        69
   macro avg       0.83      0.85      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.90      0.79        30
           1       0.90      0.72      0.80        39

    accuracy                           0.80        69
   macro avg       0.81      0.81      0.80        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.92      0.91        37
           1       0.90      0.88      0.89        32

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.90      0.93        41
           1       0.87      0.93      0.90        28

    accuracy                           0.91        69
   macro avg       0.91      0.92      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8565217391304347
F1: 0.8401952754657598
======================================================
Running australian_credit 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.91      0.88        35
           1       0.90      0.82      0.86        34

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.94      0.87        33
           1       0.94      0.81      0.87        36

    accuracy                           0.87        69
   macro avg       0.88      0.87      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.86      0.84        36
           1       0.84      0.79      0.81        33

    accuracy                           0.83        69
   macro avg       0.83      0.82      0.83        69
weighted avg       0.83      0.83      0.83        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        43
           1       0.70      0.81      0.75        26

    accuracy                           0.80        69
   macro avg       0.79      0.80      0.79        69
weighted avg       0.81      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.90      0.90        39
           1       0.87      0.87      0.87        30

    accuracy                           0.88        69
   macro avg       0.88      0.88      0.88        69
weighted avg       0.88      0.88      0.88        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8536231884057971
F1: 0.832988061394679
======================================================
Running australian_credit 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.83      0.88        42
           1       0.77      0.89      0.83        27

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.92      0.91        37
           1       0.90      0.88      0.89        32

    accuracy                           0.90        69
   macro avg       0.90      0.90      0.90        69
weighted avg       0.90      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.87      0.79      0.83        34

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        38
           1       0.90      0.90      0.90        31

    accuracy                           0.91        69
   macro avg       0.91      0.91      0.91        69
weighted avg       0.91      0.91      0.91        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.88      0.90        40
           1       0.84      0.90      0.87        29

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.88        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        37
           1       0.84      0.81      0.83        32

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        42
           1       0.77      0.85      0.81        27

    accuracy                           0.84        69
   macro avg       0.83      0.84      0.84        69
weighted avg       0.85      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.90      0.80        31
           1       0.90      0.71      0.79        38

    accuracy                           0.80        69
   macro avg       0.81      0.81      0.80        69
weighted avg       0.82      0.80      0.80        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.97      0.89        33
           1       0.97      0.81      0.88        36

    accuracy                           0.88        69
   macro avg       0.89      0.89      0.88        69
weighted avg       0.90      0.88      0.88        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8594202898550725
F1: 0.8422456694776127
======================================================
Running australian_credit 50 2 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 weighted_membership crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand weighted_membership default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 weighted_membership default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.69584204e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 3.91389432e-03]]),
       n_clusters=2))
Best evaluation: 0.4642914022200595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.71      0.80        49
           1       0.55      0.85      0.67        20

    accuracy                           0.75        69
   macro avg       0.73      0.78      0.74        69
weighted avg       0.81      0.75      0.76        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 2.89299538e-01, 5.97014925e-04, 9.81616372e-02,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.11000000e-01, 2.00000000e-03]]),
       n_clusters=2))
Best evaluation: 0.46514975326044117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        50
           1       0.58      0.95      0.72        19

    accuracy                           0.80        69
   macro avg       0.78      0.84      0.78        69
weighted avg       0.87      0.80      0.81        69

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 3.54850793e-01, 6.32238466e-02, 1.67533819e-01,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        3.79310345e-01, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.47643704370476936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.82      0.88        44
           1       0.74      0.92      0.82        25

    accuracy                           0.86        69
   macro avg       0.84      0.87      0.85        69
weighted avg       0.87      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.18516669e-01, 4.74653503e-03, 8.39403399e-03,
        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,
        7.00000000e-02, 2.58000000e-03]]),
       n_clusters=2))
Best evaluation: 0.4801237547297652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        38
           1       0.84      0.84      0.84        31

    accuracy                           0.86        69
   macro avg       0.85      0.85      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.70233487e-01, 3.98708942e-03, 3.60360360e-04,
        1.00000000e+00, 1.00000000e+00, 1.04477612e-01, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4754299577766323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.87      0.88        39
           1       0.84      0.87      0.85        30

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 3.38244475e-01, 6.01860642e-02, 1.27297954e-01,
        1.00000000e+00, 1.00000000e+00, 1.79104478e-01, 1.00000000e+00,
        2.91500000e-01, 7.13000000e-03]]),
       n_clusters=2))
Best evaluation: 0.47332092962168004
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.46263340577177964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.85      0.86        39
           1       0.81      0.83      0.82        30

    accuracy                           0.84        69
   macro avg       0.84      0.84      0.84        69
weighted avg       0.84      0.84      0.84        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4656158335875339
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.85        46
           1       0.67      0.87      0.75        23

    accuracy                           0.81        69
   macro avg       0.79      0.83      0.80        69
weighted avg       0.84      0.81      0.82        69

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00,...
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,
        1.00000000e+00, 1.49831440e-03, 7.59445605e-05, 2.88935137e-01,
        1.00000000e+00, 1.00000000e+00, 2.98507463e-02, 1.00000000e+00,
        9.05000000e-02, 0.00000000e+00]]),
       n_clusters=2))
Best evaluation: 0.4810905239955211
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.60      0.73        62
           1       0.17      0.71      0.27         7

    accuracy                           0.61        69
   macro avg       0.56      0.66      0.50        69
weighted avg       0.87      0.61      0.69        69

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4620886213059368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8173913043478261
F1: 0.7497630941576566
======================================================
Running australian_credit 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.84      0.89        43
           1       0.77      0.92      0.84        26

    accuracy                           0.87        69
   macro avg       0.86      0.88      0.87        69
weighted avg       0.88      0.87      0.87        69

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        45
           1       0.71      0.92      0.80        24

    accuracy                           0.84        69
   macro avg       0.83      0.86      0.83        69
weighted avg       0.86      0.84      0.84        69

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        38
           1       0.77      0.77      0.77        31

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.89        41
           1       0.81      0.89      0.85        28

    accuracy                           0.87        69
   macro avg       0.86      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.86      0.90        42
           1       0.81      0.93      0.86        27

    accuracy                           0.88        69
   macro avg       0.88      0.89      0.88        69
weighted avg       0.89      0.88      0.89        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        46
           1       0.71      0.96      0.81        23

    accuracy                           0.86        69
   macro avg       0.84      0.88      0.85        69
weighted avg       0.89      0.86      0.86        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        47
           1       0.63      0.86      0.73        22

    accuracy                           0.80        69
   macro avg       0.78      0.81      0.78        69
weighted avg       0.83      0.80      0.80        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.80      0.87        46
           1       0.70      0.91      0.79        23

    accuracy                           0.84        69
   macro avg       0.82      0.86      0.83        69
weighted avg       0.87      0.84      0.84        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.85      0.97      0.90        34
           1       0.97      0.83      0.89        35

    accuracy                           0.90        69
   macro avg       0.91      0.90      0.90        69
weighted avg       0.91      0.90      0.90        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.844927536231884
F1: 0.8086939203030525
======================================================
Running australian_credit 50 rand majority_voting crossval...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30713806612687655
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.75      0.84        48
           1       0.61      0.90      0.73        21

    accuracy                           0.80        69
   macro avg       0.78      0.83      0.78        69
weighted avg       0.85      0.80      0.80        69

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3079566499835147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.89      0.88        37
           1       0.87      0.84      0.86        32

    accuracy                           0.87        69
   macro avg       0.87      0.87      0.87        69
weighted avg       0.87      0.87      0.87        69

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [478, 143]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30863369750585623
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [147, 474]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30996785755268363
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        38
           1       0.77      0.77      0.77        31

    accuracy                           0.80        69
   macro avg       0.79      0.79      0.79        69
weighted avg       0.80      0.80      0.80        69

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [465, 156]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3074872858509005
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.80      0.85        44
           1       0.71      0.88      0.79        25

    accuracy                           0.83        69
   macro avg       0.82      0.84      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30916531233293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [143, 478]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30957368351559544
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.85      0.87        40
           1       0.81      0.86      0.83        29

    accuracy                           0.86        69
   macro avg       0.85      0.86      0.85        69
weighted avg       0.86      0.86      0.86        69

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.31079148438681625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.84        44
           1       0.70      0.84      0.76        25

    accuracy                           0.81        69
   macro avg       0.80      0.82      0.80        69
weighted avg       0.83      0.81      0.81        69

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30517844391073107
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        43
           1       0.73      0.85      0.79        26

    accuracy                           0.83        69
   macro avg       0.82      0.83      0.82        69
weighted avg       0.84      0.83      0.83        69

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [471, 150]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30907032538196444
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.97      0.92        35
           1       0.97      0.85      0.91        34

    accuracy                           0.91        69
   macro avg       0.92      0.91      0.91        69
weighted avg       0.92      0.91      0.91        69

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [477, 144]
Selected clustering_algorithm: kmeans
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8376811594202899
F1: 0.8055801523745071
======================================================
Running australian_credit 50 2 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 3 majority_voting crossval
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 rand majority_voting default...
======================================================
python cbeg.py -d australian_credit -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running australian_credit 50 2 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.57      0.67        54
           1       0.26      0.53      0.35        15

    accuracy                           0.57        69
   macro avg       0.54      0.55      0.51        69
weighted avg       0.69      0.57      0.60        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [290, 331]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.58      0.72        62
           1       0.16      0.71      0.26         7

    accuracy                           0.59        69
   macro avg       0.55      0.65      0.49        69
weighted avg       0.87      0.59      0.67        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [295, 326]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.65      0.78        57
           1       0.35      0.92      0.51        12

    accuracy                           0.70        69
   macro avg       0.66      0.78      0.65        69
weighted avg       0.87      0.70      0.73        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [252, 369]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        60
           1       0.26      0.89      0.40         9

    accuracy                           0.65        69
   macro avg       0.62      0.75      0.58        69
weighted avg       0.88      0.65      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 365]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.69      0.80        52
           1       0.48      0.88      0.62        17

    accuracy                           0.74        69
   macro avg       0.72      0.79      0.71        69
weighted avg       0.83      0.74      0.76        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [257, 364]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.73        63
           1       0.16      0.83      0.27         6

    accuracy                           0.61        69
   macro avg       0.57      0.71      0.50        69
weighted avg       0.90      0.61      0.69        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 247]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.67      0.80        55
           1       0.42      0.93      0.58        14

    accuracy                           0.72        69
   macro avg       0.70      0.80      0.69        69
weighted avg       0.86      0.72      0.75        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [152, 469]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.67      0.77        52
           1       0.43      0.76      0.55        17

    accuracy                           0.70        69
   macro avg       0.67      0.72      0.66        69
weighted avg       0.78      0.70      0.72        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [150, 471]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.59      0.74        64
           1       0.13      0.80      0.23         5

    accuracy                           0.61        69
   macro avg       0.55      0.70      0.48        69
weighted avg       0.91      0.61      0.70        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [282, 339]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.64      0.76        58
           1       0.30      0.82      0.44        11

    accuracy                           0.67        69
   macro avg       0.62      0.73      0.60        69
weighted avg       0.85      0.67      0.71        69

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [144, 477]
Selected clustering_algorithm: kmeans++
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/australian_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6550724637681159
F1: 0.4216447244895189
======================================================
Running australian_credit 50 3 majority_voting default
======================================================
python cbeg.py -d australian_credit -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.7349725237679952
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.84      0.85        73
           1       0.60      0.67      0.63        27

    accuracy                           0.79       100
   macro avg       0.74      0.75      0.74       100
weighted avg       0.80      0.79      0.79       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [1, 1, 1, 4, 1, 34, 384, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6699454594529037
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        90
           1       0.20      0.60      0.30        10

    accuracy                           0.72       100
   macro avg       0.57      0.67      0.56       100
weighted avg       0.87      0.72      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [408, 2, 468, 18, 4]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.6240004501580169
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [463, 3, 1, 2, 413, 18]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6645647472229417
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [1, 459, 326, 3, 2, 103, 6]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.688385522564725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        72
           1       0.57      0.61      0.59        28

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.71       100
weighted avg       0.77      0.76      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [414, 1, 2, 9, 474]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6751770570320114
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.69      0.73        78
           1       0.20      0.27      0.23        22

    accuracy                           0.60       100
   macro avg       0.49      0.48      0.48       100
weighted avg       0.65      0.60      0.62       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [174, 2, 472, 240, 1, 10, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.6708522007632244
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.75      0.73        67
           1       0.43      0.39      0.41        33

    accuracy                           0.63       100
   macro avg       0.57      0.57      0.57       100
weighted avg       0.62      0.63      0.63       100

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [3, 411, 5, 1, 21, 1, 1, 452, 5]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6785243149692705
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.83      0.85        72
           1       0.60      0.64      0.62        28

    accuracy                           0.78       100
   macro avg       0.73      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 3, 421, 404, 1, 8, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.7208864722329381
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [7, 396, 1, 339, 2, 155]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6680057700387586
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.83      0.84        71
           1       0.60      0.62      0.61        29

    accuracy                           0.77       100
   macro avg       0.72      0.73      0.72       100
weighted avg       0.77      0.77      0.77       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [6, 453, 24, 7, 410]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7299999999999999
F1: 0.4993122735095728
======================================================
Running german_credit 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.30744994162704925
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.87      0.86        68
           1       0.70      0.66      0.68        32

    accuracy                           0.80       100
   macro avg       0.77      0.76      0.77       100
weighted avg       0.80      0.80      0.80       100

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [78, 432, 2, 1, 43, 344]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.35966766021096264
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.83      0.79        64
           1       0.63      0.53      0.58        36

    accuracy                           0.72       100
   macro avg       0.70      0.68      0.68       100
weighted avg       0.71      0.72      0.71       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 472, 423, 3, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.2809965055919345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.73      0.80        83
           1       0.27      0.47      0.34        17

    accuracy                           0.69       100
   macro avg       0.57      0.60      0.57       100
weighted avg       0.77      0.69      0.72       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [8, 462, 426, 4]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.2875666770663238
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), LogisticRegression(), GradientBoostingClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [133, 396, 82, 56, 231, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.3391842260653098
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.81      0.80        68
           1       0.57      0.53      0.55        32

    accuracy                           0.72       100
   macro avg       0.68      0.67      0.67       100
weighted avg       0.72      0.72      0.72       100

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [8, 5, 1, 398, 1, 27, 459, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.31692788328930016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.74      0.78        77
           1       0.33      0.43      0.38        23

    accuracy                           0.67       100
   macro avg       0.57      0.59      0.58       100
weighted avg       0.70      0.67      0.68       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 1, 474, 400, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3363159760138078
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.75      0.71        63
           1       0.47      0.38      0.42        37

    accuracy                           0.61       100
   macro avg       0.57      0.56      0.56       100
weighted avg       0.60      0.61      0.60       100

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [415, 3, 477, 2, 1, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.3264300925241596
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.83      0.87        77
           1       0.57      0.74      0.64        23

    accuracy                           0.81       100
   macro avg       0.74      0.79      0.76       100
weighted avg       0.83      0.81      0.82       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DecisionTreeClassifier()]
Number of samples by cluster: [1, 2, 11, 458, 7, 5, 1, 1, 397, 17]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3205248389990693
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.78      0.84        82
           1       0.40      0.67      0.50        18

    accuracy                           0.76       100
   macro avg       0.66      0.72      0.67       100
weighted avg       0.82      0.76      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [480, 418, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.33246176904697416
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [2, 4, 9, 408, 477]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.727
F1: 0.5124222477029414
======================================================
Running german_credit 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.33176709135085797
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.84      0.84        70
           1       0.63      0.63      0.63        30

    accuracy                           0.78       100
   macro avg       0.74      0.74      0.74       100
weighted avg       0.78      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [321, 5, 7, 3, 163, 401]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3386942801679931
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.79      0.78        68
           1       0.53      0.50      0.52        32

    accuracy                           0.70       100
   macro avg       0.65      0.65      0.65       100
weighted avg       0.70      0.70      0.70       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 92, 470, 334, 3]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3025719945597155
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.73      0.82        89
           1       0.20      0.55      0.29        11

    accuracy                           0.71       100
   macro avg       0.56      0.64      0.56       100
weighted avg       0.85      0.71      0.76       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [1, 29, 468, 402]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.28204883706742423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.86      0.85        69
           1       0.67      0.65      0.66        31

    accuracy                           0.79       100
   macro avg       0.75      0.75      0.75       100
weighted avg       0.79      0.79      0.79       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GradientBoostingClassifier(), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [3, 96, 14, 407, 380]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3201441603144333
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.77      0.76        69
           1       0.47      0.45      0.46        31

    accuracy                           0.67       100
   macro avg       0.61      0.61      0.61       100
weighted avg       0.67      0.67      0.67       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [417, 471, 1, 6, 5]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3480283030608556
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        68
           1       0.37      0.34      0.35        32

    accuracy                           0.60       100
   macro avg       0.53      0.53      0.53       100
weighted avg       0.59      0.60      0.60       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [420, 478, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.2989207036754855
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.75      0.81        81
           1       0.33      0.53      0.41        19

    accuracy                           0.71       100
   macro avg       0.60      0.64      0.61       100
weighted avg       0.77      0.71      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [171, 1, 314, 414]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3424274202863607
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        72
           1       0.57      0.61      0.59        28

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.71       100
weighted avg       0.77      0.76      0.76       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [482, 6, 412]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3598061959967399
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.82      0.82        71
           1       0.57      0.59      0.58        29

    accuracy                           0.75       100
   macro avg       0.70      0.70      0.70       100
weighted avg       0.75      0.75      0.75       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [54, 1, 3, 6, 404, 432]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.3088434381094085
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.81      0.76        62
           1       0.60      0.47      0.53        38

    accuracy                           0.68       100
   macro avg       0.66      0.64      0.64       100
weighted avg       0.67      0.68      0.67       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [389, 6, 5, 462, 1, 2, 14, 21]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7150000000000001
F1: 0.5011791213463148
======================================================
Running german_credit 100 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.69      0.81        98
           1       0.00      0.00      0.00         2

    accuracy                           0.68       100
   macro avg       0.49      0.35      0.40       100
weighted avg       0.95      0.68      0.79       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.70      0.79        90
           1       0.10      0.30      0.15        10

    accuracy                           0.66       100
   macro avg       0.50      0.50      0.47       100
weighted avg       0.82      0.66      0.72       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.79      0.66      0.72        83
           1       0.07      0.12      0.09        17

    accuracy                           0.57       100
   macro avg       0.43      0.39      0.40       100
weighted avg       0.66      0.57      0.61       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.70      0.78        88
           1       0.13      0.33      0.19        12

    accuracy                           0.66       100
   macro avg       0.51      0.52      0.49       100
weighted avg       0.80      0.66      0.71       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.68      0.75        87
           1       0.07      0.15      0.09        13

    accuracy                           0.61       100
   macro avg       0.45      0.42      0.42       100
weighted avg       0.74      0.61      0.67       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.71      0.78        86
           1       0.17      0.36      0.23        14

    accuracy                           0.66       100
   macro avg       0.52      0.53      0.50       100
weighted avg       0.77      0.66      0.70       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        86
           1       0.13      0.29      0.18        14

    accuracy                           0.64       100
   macro avg       0.50      0.49      0.48       100
weighted avg       0.76      0.64      0.69       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.69      0.78        91
           1       0.07      0.22      0.10         9

    accuracy                           0.65       100
   macro avg       0.48      0.46      0.44       100
weighted avg       0.82      0.65      0.72       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        99
           1       0.03      1.00      0.06         1

    accuracy                           0.71       100
   macro avg       0.52      0.85      0.45       100
weighted avg       0.99      0.71      0.82       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.71      0.78        84
           1       0.20      0.38      0.26        16

    accuracy                           0.66       100
   macro avg       0.53      0.54      0.52       100
weighted avg       0.75      0.66      0.70       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6500000000000001
F1: 0.13556465351735286
======================================================
Running german_credit 100 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.83      0.87        77
           1       0.57      0.74      0.64        23

    accuracy                           0.81       100
   macro avg       0.74      0.79      0.76       100
weighted avg       0.83      0.81      0.82       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.73      0.80        85
           1       0.23      0.47      0.31        15

    accuracy                           0.69       100
   macro avg       0.56      0.60      0.56       100
weighted avg       0.79      0.69      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        79
           1       0.47      0.67      0.55        21

    accuracy                           0.77       100
   macro avg       0.68      0.73      0.70       100
weighted avg       0.81      0.77      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        75
           1       0.53      0.64      0.58        25

    accuracy                           0.77       100
   macro avg       0.70      0.73      0.71       100
weighted avg       0.79      0.77      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        82
           1       0.27      0.44      0.33        18

    accuracy                           0.68       100
   macro avg       0.56      0.59      0.56       100
weighted avg       0.75      0.68      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.74      0.80        82
           1       0.30      0.50      0.38        18

    accuracy                           0.70       100
   macro avg       0.59      0.62      0.59       100
weighted avg       0.77      0.70      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        76
           1       0.53      0.67      0.59        24

    accuracy                           0.78       100
   macro avg       0.71      0.74      0.72       100
weighted avg       0.80      0.78      0.79       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        74
           1       0.57      0.65      0.61        26

    accuracy                           0.78       100
   macro avg       0.72      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7450000000000001
F1: 0.49496298846018966
======================================================
Running german_credit 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.83      0.86        75
           1       0.57      0.68      0.62        25

    accuracy                           0.79       100
   macro avg       0.73      0.75      0.74       100
weighted avg       0.81      0.79      0.80       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.82      0.86        78
           1       0.53      0.73      0.62        22

    accuracy                           0.80       100
   macro avg       0.72      0.77      0.74       100
weighted avg       0.83      0.80      0.81       100

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        85
           1       0.20      0.40      0.27        15

    accuracy                           0.67       100
   macro avg       0.54      0.56      0.53       100
weighted avg       0.77      0.67      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.78      0.87        89
           1       0.33      0.91      0.49        11

    accuracy                           0.79       100
   macro avg       0.66      0.84      0.68       100
weighted avg       0.91      0.79      0.83       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        82
           1       0.27      0.44      0.33        18

    accuracy                           0.68       100
   macro avg       0.56      0.59      0.56       100
weighted avg       0.75      0.68      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.74      0.78        77
           1       0.33      0.43      0.38        23

    accuracy                           0.67       100
   macro avg       0.57      0.59      0.58       100
weighted avg       0.70      0.67      0.68       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        75
           1       0.53      0.64      0.58        25

    accuracy                           0.77       100
   macro avg       0.70      0.73      0.71       100
weighted avg       0.79      0.77      0.78       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.82      0.85        74
           1       0.57      0.65      0.61        26

    accuracy                           0.78       100
   macro avg       0.72      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7390000000000001
F1: 0.48695090229604726
======================================================
Running german_credit 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.78      0.87        89
           1       0.33      0.91      0.49        11

    accuracy                           0.79       100
   macro avg       0.66      0.84      0.68       100
weighted avg       0.91      0.79      0.83       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.73      0.80        85
           1       0.23      0.47      0.31        15

    accuracy                           0.69       100
   macro avg       0.56      0.60      0.56       100
weighted avg       0.79      0.69      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        79
           1       0.47      0.67      0.55        21

    accuracy                           0.77       100
   macro avg       0.68      0.73      0.70       100
weighted avg       0.81      0.77      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.79      0.83        77
           1       0.47      0.61      0.53        23

    accuracy                           0.75       100
   macro avg       0.67      0.70      0.68       100
weighted avg       0.78      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.74      0.78        78
           1       0.33      0.45      0.38        22

    accuracy                           0.68       100
   macro avg       0.58      0.60      0.58       100
weighted avg       0.72      0.68      0.70       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.74      0.81        84
           1       0.27      0.50      0.35        16

    accuracy                           0.70       100
   macro avg       0.58      0.62      0.58       100
weighted avg       0.79      0.70      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        75
           1       0.53      0.64      0.58        25

    accuracy                           0.77       100
   macro avg       0.70      0.73      0.71       100
weighted avg       0.79      0.77      0.78       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.82      0.84        73
           1       0.57      0.63      0.60        27

    accuracy                           0.77       100
   macro avg       0.71      0.73      0.72       100
weighted avg       0.78      0.77      0.77       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.77      0.83        82
           1       0.37      0.61      0.46        18

    accuracy                           0.74       100
   macro avg       0.63      0.69      0.64       100
weighted avg       0.80      0.74      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7440000000000001
F1: 0.4786988365255745
======================================================
Running german_credit 100 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.29      0.74      0.41        27
           1       0.77      0.32      0.45        73

    accuracy                           0.43       100
   macro avg       0.53      0.53      0.43       100
weighted avg       0.64      0.43      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.68      0.36        25
           1       0.73      0.29      0.42        75

    accuracy                           0.39       100
   macro avg       0.49      0.49      0.39       100
weighted avg       0.61      0.39      0.40       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.65      0.35        26
           1       0.70      0.28      0.40        74

    accuracy                           0.38       100
   macro avg       0.47      0.47      0.38       100
weighted avg       0.58      0.38      0.39       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.24      0.63      0.35        27
           1       0.67      0.27      0.39        73

    accuracy                           0.37       100
   macro avg       0.45      0.45      0.37       100
weighted avg       0.55      0.37      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.31      0.76      0.44        29
           1       0.77      0.32      0.46        71

    accuracy                           0.45       100
   macro avg       0.54      0.54      0.45       100
weighted avg       0.64      0.45      0.45       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.88      0.48        26
           1       0.90      0.36      0.52        74

    accuracy                           0.50       100
   macro avg       0.61      0.62      0.50       100
weighted avg       0.75      0.50      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.79      0.40        24
           1       0.83      0.33      0.47        76

    accuracy                           0.44       100
   macro avg       0.55      0.56      0.44       100
weighted avg       0.70      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.20      0.61      0.30        23
           1       0.70      0.27      0.39        77

    accuracy                           0.35       100
   macro avg       0.45      0.44      0.35       100
weighted avg       0.58      0.35      0.37       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.14      0.91      0.25        11
           1       0.97      0.33      0.49        89

    accuracy                           0.39       100
   macro avg       0.55      0.62      0.37       100
weighted avg       0.88      0.39      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.23      0.70      0.34        23
           1       0.77      0.30      0.43        77

    accuracy                           0.39       100
   macro avg       0.50      0.50      0.39       100
weighted avg       0.64      0.39      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.409
F1: 0.4414044520722474
======================================================
Running german_credit 100 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.78      0.87        89
           1       0.33      0.91      0.49        11

    accuracy                           0.79       100
   macro avg       0.66      0.84      0.68       100
weighted avg       0.91      0.79      0.83       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.71      0.83        97
           1       0.07      0.67      0.12         3

    accuracy                           0.71       100
   macro avg       0.53      0.69      0.47       100
weighted avg       0.96      0.71      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.72      0.82        95
           1       0.10      0.60      0.17         5

    accuracy                           0.71       100
   macro avg       0.54      0.66      0.50       100
weighted avg       0.93      0.71      0.79       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        88
           1       0.30      0.75      0.43        12

    accuracy                           0.76       100
   macro avg       0.63      0.76      0.64       100
weighted avg       0.88      0.76      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.76      0.82        82
           1       0.33      0.56      0.42        18

    accuracy                           0.72       100
   macro avg       0.61      0.66      0.62       100
weighted avg       0.79      0.72      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        88
           1       0.17      0.42      0.24        12

    accuracy                           0.68       100
   macro avg       0.53      0.57      0.52       100
weighted avg       0.81      0.68      0.73       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.73      0.81        86
           1       0.23      0.50      0.32        14

    accuracy                           0.70       100
   macro avg       0.57      0.62      0.56       100
weighted avg       0.81      0.70      0.74       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        86
           1       0.40      0.86      0.55        14

    accuracy                           0.80       100
   macro avg       0.69      0.82      0.71       100
weighted avg       0.89      0.80      0.83       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.84        88
           1       0.27      0.67      0.38        12

    accuracy                           0.74       100
   macro avg       0.60      0.71      0.61       100
weighted avg       0.86      0.74      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.77      0.82        81
           1       0.37      0.58      0.45        19

    accuracy                           0.73       100
   macro avg       0.63      0.67      0.64       100
weighted avg       0.79      0.73      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.734
F1: 0.3557347240448286
======================================================
Running german_credit 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.71      0.83        97
           1       0.07      0.67      0.12         3

    accuracy                           0.71       100
   macro avg       0.53      0.69      0.47       100
weighted avg       0.96      0.71      0.81       100

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.75      0.84        89
           1       0.27      0.73      0.39        11

    accuracy                           0.75       100
   macro avg       0.61      0.74      0.62       100
weighted avg       0.88      0.75      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.75      0.83        85
           1       0.30      0.60      0.40        15

    accuracy                           0.73       100
   macro avg       0.61      0.68      0.61       100
weighted avg       0.82      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        86
           1       0.13      0.29      0.18        14

    accuracy                           0.64       100
   macro avg       0.50      0.49      0.48       100
weighted avg       0.76      0.64      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        91
           1       0.17      0.56      0.26         9

    accuracy                           0.71       100
   macro avg       0.55      0.64      0.54       100
weighted avg       0.87      0.71      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        86
           1       0.40      0.86      0.55        14

    accuracy                           0.80       100
   macro avg       0.69      0.82      0.71       100
weighted avg       0.89      0.80      0.83       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.76      0.85        88
           1       0.30      0.75      0.43        12

    accuracy                           0.76       100
   macro avg       0.63      0.76      0.64       100
weighted avg       0.88      0.76      0.80       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.75      0.83        85
           1       0.30      0.60      0.40        15

    accuracy                           0.73       100
   macro avg       0.61      0.68      0.61       100
weighted avg       0.82      0.73      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.728
F1: 0.33712012559789967
======================================================
Running german_credit 100 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.81      0.85        78
           1       0.50      0.68      0.58        22

    accuracy                           0.78       100
   macro avg       0.70      0.74      0.71       100
weighted avg       0.81      0.78      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.76      0.84        85
           1       0.33      0.67      0.44        15

    accuracy                           0.75       100
   macro avg       0.63      0.72      0.64       100
weighted avg       0.84      0.75      0.78       100

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.73      0.84        96
           1       0.13      1.00      0.24         4

    accuracy                           0.74       100
   macro avg       0.57      0.86      0.54       100
weighted avg       0.97      0.74      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.75      0.83        85
           1       0.30      0.60      0.40        15

    accuracy                           0.73       100
   macro avg       0.61      0.68      0.61       100
weighted avg       0.82      0.73      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.70      0.78        87
           1       0.13      0.31      0.19        13

    accuracy                           0.65       100
   macro avg       0.50      0.50      0.48       100
weighted avg       0.78      0.65      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.75      0.83        87
           1       0.27      0.62      0.37        13

    accuracy                           0.73       100
   macro avg       0.60      0.68      0.60       100
weighted avg       0.84      0.73      0.77       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.78      0.87        87
           1       0.37      0.85      0.51        13

    accuracy                           0.79       100
   macro avg       0.67      0.81      0.69       100
weighted avg       0.89      0.79      0.82       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.84        88
           1       0.27      0.67      0.38        12

    accuracy                           0.74       100
   macro avg       0.60      0.71      0.61       100
weighted avg       0.86      0.74      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.736
F1: 0.368093071958721
======================================================
Running german_credit 100 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        90
           1       0.27      0.80      0.40        10

    accuracy                           0.76       100
   macro avg       0.62      0.78      0.62       100
weighted avg       0.90      0.76      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.86        89
           1       0.30      0.82      0.44        11

    accuracy                           0.77       100
   macro avg       0.64      0.79      0.65       100
weighted avg       0.90      0.77      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.71      0.83        97
           1       0.07      0.67      0.12         3

    accuracy                           0.71       100
   macro avg       0.53      0.69      0.47       100
weighted avg       0.96      0.71      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.74      0.85        94
           1       0.20      1.00      0.33         6

    accuracy                           0.76       100
   macro avg       0.60      0.87      0.59       100
weighted avg       0.95      0.76      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.77      0.80        77
           1       0.40      0.52      0.45        23

    accuracy                           0.71       100
   macro avg       0.62      0.64      0.63       100
weighted avg       0.74      0.71      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        82
           1       0.23      0.39      0.29        18

    accuracy                           0.66       100
   macro avg       0.54      0.55      0.53       100
weighted avg       0.73      0.66      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        91
           1       0.17      0.56      0.26         9

    accuracy                           0.71       100
   macro avg       0.55      0.64      0.54       100
weighted avg       0.87      0.71      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.78      0.87        88
           1       0.37      0.92      0.52        12

    accuracy                           0.80       100
   macro avg       0.68      0.85      0.70       100
weighted avg       0.91      0.80      0.83       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.77      0.86        90
           1       0.30      0.90      0.45        10

    accuracy                           0.78       100
   macro avg       0.64      0.83      0.66       100
weighted avg       0.92      0.78      0.82       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.77      0.83        82
           1       0.37      0.61      0.46        18

    accuracy                           0.74       100
   macro avg       0.63      0.69      0.64       100
weighted avg       0.80      0.74      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.74
F1: 0.3726619813688383
======================================================
Running german_credit 100 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 100 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
CBEG               precision    recall  f1-score   support

           0       0.50      0.70      0.58        50
           1       0.50      0.30      0.38        50

    accuracy                           0.50       100
   macro avg       0.50      0.50      0.48       100
weighted avg       0.50      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
CBEG               precision    recall  f1-score   support

           0       0.47      0.65      0.55        51
           1       0.40      0.24      0.30        49

    accuracy                           0.45       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
CBEG               precision    recall  f1-score   support

           0       0.40      0.68      0.50        41
           1       0.57      0.29      0.38        59

    accuracy                           0.45       100
   macro avg       0.48      0.49      0.44       100
weighted avg       0.50      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48200000000000004
F1: 0.3958830841974384
======================================================
Running german_credit 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
CBEG               precision    recall  f1-score   support

           0       0.50      0.70      0.58        50
           1       0.50      0.30      0.38        50

    accuracy                           0.50       100
   macro avg       0.50      0.50      0.48       100
weighted avg       0.50      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
CBEG               precision    recall  f1-score   support

           0       0.47      0.65      0.55        51
           1       0.40      0.24      0.30        49

    accuracy                           0.45       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
CBEG               precision    recall  f1-score   support

           0       0.36      0.68      0.47        37
           1       0.60      0.29      0.39        63

    accuracy                           0.43       100
   macro avg       0.48      0.48      0.43       100
weighted avg       0.51      0.43      0.42       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48
F1: 0.396390514425782
======================================================
Running german_credit 100 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
CBEG               precision    recall  f1-score   support

           0       0.50      0.70      0.58        50
           1       0.50      0.30      0.38        50

    accuracy                           0.50       100
   macro avg       0.50      0.50      0.48       100
weighted avg       0.50      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
CBEG               precision    recall  f1-score   support

           0       0.47      0.65      0.55        51
           1       0.40      0.24      0.30        49

    accuracy                           0.45       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
CBEG               precision    recall  f1-score   support

           0       0.36      0.68      0.47        37
           1       0.60      0.29      0.39        63

    accuracy                           0.43       100
   macro avg       0.48      0.48      0.43       100
weighted avg       0.51      0.43      0.42       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48
F1: 0.396390514425782
======================================================
Running german_credit 100 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.69      0.57        49
           1       0.50      0.29      0.37        51

    accuracy                           0.49       100
   macro avg       0.49      0.49      0.47       100
weighted avg       0.49      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.44      0.72      0.55        43
           1       0.60      0.32      0.41        57

    accuracy                           0.49       100
   macro avg       0.52      0.52      0.48       100
weighted avg       0.53      0.49      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.46      0.65      0.54        49
           1       0.43      0.25      0.32        51

    accuracy                           0.45       100
   macro avg       0.45      0.45      0.43       100
weighted avg       0.45      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.47      0.72      0.57        46
           1       0.57      0.31      0.40        54

    accuracy                           0.50       100
   macro avg       0.52      0.52      0.49       100
weighted avg       0.52      0.50      0.48       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.54      0.79      0.64        48
           1       0.67      0.38      0.49        52

    accuracy                           0.58       100
   macro avg       0.60      0.59      0.57       100
weighted avg       0.61      0.58      0.56       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.47      0.77      0.58        43
           1       0.67      0.35      0.46        57

    accuracy                           0.53       100
   macro avg       0.57      0.56      0.52       100
weighted avg       0.58      0.53      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.64      0.50        45
           1       0.47      0.25      0.33        55

    accuracy                           0.43       100
   macro avg       0.44      0.45      0.42       100
weighted avg       0.44      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.26      0.82      0.39        22
           1       0.87      0.33      0.48        78

    accuracy                           0.44       100
   macro avg       0.56      0.58      0.44       100
weighted avg       0.73      0.44      0.46       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.40      0.68      0.50        41
           1       0.57      0.29      0.38        59

    accuracy                           0.45       100
   macro avg       0.48      0.49      0.44       100
weighted avg       0.50      0.45      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.479
F1: 0.3979815508696206
======================================================
Running german_credit 100 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.647589970462251
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.83        73
           1       0.53      0.59      0.56        27

    accuracy                           0.75       100
   macro avg       0.69      0.70      0.69       100
weighted avg       0.76      0.75      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [5, 346, 1, 67, 474, 7]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.6824508421811406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.76      0.78        74
           1       0.40      0.46      0.43        26

    accuracy                           0.68       100
   macro avg       0.60      0.61      0.60       100
weighted avg       0.70      0.68      0.69       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 4, 459, 4, 1, 11, 417, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6732203795727213
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        84
           1       0.30      0.56      0.39        16

    accuracy                           0.72       100
   macro avg       0.60      0.66      0.60       100
weighted avg       0.80      0.72      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [410, 467, 1, 1, 21]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6625572305906491
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [414, 6, 475, 3, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6597336662750459
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.86      0.84        66
           1       0.70      0.62      0.66        34

    accuracy                           0.78       100
   macro avg       0.76      0.74      0.75       100
weighted avg       0.78      0.78      0.78       100

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [466, 2, 1, 1, 407, 1, 22]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6758075297562447
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.69      0.73        80
           1       0.17      0.25      0.20        20

    accuracy                           0.60       100
   macro avg       0.48      0.47      0.47       100
weighted avg       0.66      0.60      0.63       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GradientBoostingClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [1, 471, 416, 2, 2, 1, 7]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6994101800201488
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.74      0.78        77
           1       0.33      0.43      0.38        23

    accuracy                           0.67       100
   macro avg       0.57      0.59      0.58       100
weighted avg       0.70      0.67      0.68       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [10, 1, 5, 2, 472, 392, 18]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.6997179628303682
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), SVC(probability=True), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [1, 6, 3, 1, 14, 415, 65, 392, 3]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.6257903051196348
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.82      0.80        67
           1       0.60      0.55      0.57        33

    accuracy                           0.73       100
   macro avg       0.69      0.68      0.69       100
weighted avg       0.72      0.73      0.73       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [481, 1, 407, 11]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.6461714930396788
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.70      0.78        88
           1       0.13      0.33      0.19        12

    accuracy                           0.66       100
   macro avg       0.51      0.52      0.49       100
weighted avg       0.80      0.66      0.71       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [1, 470, 1, 330, 90, 8]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.701
F1: 0.43222470830947907
======================================================
Running german_credit 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.30014245985536797
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.87      0.86        68
           1       0.70      0.66      0.68        32

    accuracy                           0.80       100
   macro avg       0.77      0.76      0.77       100
weighted avg       0.80      0.80      0.80       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [6, 4, 3, 6, 461, 410, 10]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3487280564825166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.80      0.77        65
           1       0.57      0.49      0.52        35

    accuracy                           0.69       100
   macro avg       0.65      0.64      0.65       100
weighted avg       0.68      0.69      0.68       100

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [473, 426, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.2919670930045789
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        79
           1       0.33      0.48      0.39        21

    accuracy                           0.69       100
   macro avg       0.59      0.61      0.59       100
weighted avg       0.74      0.69      0.71       100

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [8, 461, 4, 417, 10]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.33900683658825853
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 1, 1, 46, 404, 1, 7, 433, 6]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.31104995584206485
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.81      0.81        69
           1       0.57      0.55      0.56        31

    accuracy                           0.73       100
   macro avg       0.68      0.68      0.68       100
weighted avg       0.73      0.73      0.73       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [2, 469, 416, 6, 7]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3758015571095322
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.72      0.73        72
           1       0.33      0.36      0.34        28

    accuracy                           0.62       100
   macro avg       0.54      0.54      0.54       100
weighted avg       0.63      0.62      0.62       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 477, 1, 420, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.29182994703830434
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [1, 408, 8, 483]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.30630639113047314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.84      0.85        73
           1       0.60      0.67      0.63        27

    accuracy                           0.79       100
   macro avg       0.74      0.75      0.74       100
weighted avg       0.80      0.79      0.79       100

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 40, 450, 4, 379, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.37947344962208596
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.83      0.78        63
           1       0.63      0.51      0.57        37

    accuracy                           0.71       100
   macro avg       0.69      0.67      0.67       100
weighted avg       0.70      0.71      0.70       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [410, 2, 2, 484, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.32618942713599597
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [8, 1, 11, 470, 410]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.719
F1: 0.5174120383040334
======================================================
Running german_credit 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.31349075859954045
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.83      0.81        66
           1       0.63      0.56      0.59        34

    accuracy                           0.74       100
   macro avg       0.71      0.70      0.70       100
weighted avg       0.73      0.74      0.74       100

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [433, 410, 1, 1, 27, 25, 3]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3372889460045491
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.80      0.84        76
           1       0.50      0.62      0.56        24

    accuracy                           0.76       100
   macro avg       0.69      0.71      0.70       100
weighted avg       0.78      0.76      0.77       100

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [471, 420, 9]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.2873309225269216
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [36, 364, 50, 448, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.29884882105319077
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        85
           1       0.37      0.73      0.49        15

    accuracy                           0.77       100
   macro avg       0.65      0.75      0.67       100
weighted avg       0.86      0.77      0.80       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression(), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 356, 60, 16, 463, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3236125833716697
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.83      0.77        60
           1       0.67      0.50      0.57        40

    accuracy                           0.70       100
   macro avg       0.69      0.67      0.67       100
weighted avg       0.70      0.70      0.69       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [6, 12, 466, 196, 2, 218]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3313177686559264
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.73      0.76        75
           1       0.33      0.40      0.36        25

    accuracy                           0.65       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.67      0.65      0.66       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [12, 4, 466, 1, 1, 416]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.2830549298644913
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [20, 464, 2, 23, 1, 10, 380]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.30680236505276554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.79      0.84        78
           1       0.47      0.64      0.54        22

    accuracy                           0.76       100
   macro avg       0.68      0.72      0.69       100
weighted avg       0.79      0.76      0.77       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [480, 407, 2, 11]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.33864454316977033
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        76
           1       0.43      0.54      0.48        24

    accuracy                           0.72       100
   macro avg       0.64      0.66      0.64       100
weighted avg       0.74      0.72      0.73       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 475, 4, 1, 3, 1, 22, 391, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.28597170780651043
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.81      0.80        68
           1       0.57      0.53      0.55        32

    accuracy                           0.72       100
   macro avg       0.68      0.67      0.67       100
weighted avg       0.72      0.72      0.72       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier(), GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [403, 30, 58, 373, 3, 31, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.732
F1: 0.524873235336945
======================================================
Running german_credit 75 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.81      0.86        79
           1       0.50      0.71      0.59        21

    accuracy                           0.79       100
   macro avg       0.71      0.76      0.72       100
weighted avg       0.83      0.79      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        83
           1       0.43      0.76      0.55        17

    accuracy                           0.79       100
   macro avg       0.69      0.78      0.71       100
weighted avg       0.86      0.79      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.74      0.78        78
           1       0.33      0.45      0.38        22

    accuracy                           0.68       100
   macro avg       0.58      0.60      0.58       100
weighted avg       0.72      0.68      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.81      0.88        84
           1       0.47      0.88      0.61        16

    accuracy                           0.82       100
   macro avg       0.72      0.84      0.75       100
weighted avg       0.89      0.82      0.84       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.73      0.76        75
           1       0.33      0.40      0.36        25

    accuracy                           0.65       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.67      0.65      0.66       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.79        81
           1       0.30      0.47      0.37        19

    accuracy                           0.69       100
   macro avg       0.58      0.61      0.58       100
weighted avg       0.75      0.69      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.79      0.84        78
           1       0.47      0.64      0.54        22

    accuracy                           0.76       100
   macro avg       0.68      0.72      0.69       100
weighted avg       0.79      0.76      0.77       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        81
           1       0.40      0.63      0.49        19

    accuracy                           0.75       100
   macro avg       0.65      0.70      0.66       100
weighted avg       0.81      0.75      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.79      0.79        71
           1       0.50      0.52      0.51        29

    accuracy                           0.71       100
   macro avg       0.65      0.65      0.65       100
weighted avg       0.71      0.71      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.738
F1: 0.49024531557805934
======================================================
Running german_credit 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.80      0.86        81
           1       0.47      0.74      0.57        19

    accuracy                           0.79       100
   macro avg       0.70      0.77      0.72       100
weighted avg       0.84      0.79      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        87
           1       0.30      0.69      0.42        13

    accuracy                           0.75       100
   macro avg       0.62      0.73      0.63       100
weighted avg       0.86      0.75      0.79       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.74      0.78        78
           1       0.33      0.45      0.38        22

    accuracy                           0.68       100
   macro avg       0.58      0.60      0.58       100
weighted avg       0.72      0.68      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.81      0.88        84
           1       0.47      0.88      0.61        16

    accuracy                           0.82       100
   macro avg       0.72      0.84      0.75       100
weighted avg       0.89      0.82      0.84       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        77
           1       0.43      0.57      0.49        23

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.65       100
weighted avg       0.76      0.73      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.76      0.79        76
           1       0.40      0.50      0.44        24

    accuracy                           0.70       100
   macro avg       0.61      0.63      0.62       100
weighted avg       0.73      0.70      0.71       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.76      0.79        76
           1       0.40      0.50      0.44        24

    accuracy                           0.70       100
   macro avg       0.61      0.63      0.62       100
weighted avg       0.73      0.70      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        80
           1       0.40      0.60      0.48        20

    accuracy                           0.74       100
   macro avg       0.64      0.69      0.65       100
weighted avg       0.79      0.74      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        77
           1       0.43      0.57      0.49        23

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.65       100
weighted avg       0.76      0.73      0.74       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7380000000000001
F1: 0.48518837422597655
======================================================
Running german_credit 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        80
           1       0.40      0.60      0.48        20

    accuracy                           0.74       100
   macro avg       0.64      0.69      0.65       100
weighted avg       0.79      0.74      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        87
           1       0.30      0.69      0.42        13

    accuracy                           0.75       100
   macro avg       0.62      0.73      0.63       100
weighted avg       0.86      0.75      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        80
           1       0.33      0.50      0.40        20

    accuracy                           0.70       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.75      0.70      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        89
           1       0.37      1.00      0.54        11

    accuracy                           0.81       100
   macro avg       0.68      0.89      0.71       100
weighted avg       0.93      0.81      0.84       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        70
           1       0.53      0.53      0.53        30

    accuracy                           0.72       100
   macro avg       0.67      0.67      0.67       100
weighted avg       0.72      0.72      0.72       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        78
           1       0.37      0.50      0.42        22

    accuracy                           0.70       100
   macro avg       0.60      0.63      0.61       100
weighted avg       0.74      0.70      0.71       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        80
           1       0.30      0.45      0.36        20

    accuracy                           0.68       100
   macro avg       0.57      0.59      0.57       100
weighted avg       0.73      0.68      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.734
F1: 0.4742573026164164
======================================================
Running german_credit 75 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        92
           1       0.20      0.75      0.32         8

    accuracy                           0.74       100
   macro avg       0.59      0.74      0.58       100
weighted avg       0.91      0.74      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.85        87
           1       0.33      0.77      0.47        13

    accuracy                           0.77       100
   macro avg       0.65      0.77      0.66       100
weighted avg       0.88      0.77      0.80       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.73      0.82        89
           1       0.20      0.55      0.29        11

    accuracy                           0.71       100
   macro avg       0.56      0.64      0.56       100
weighted avg       0.85      0.71      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.74      0.85        94
           1       0.20      1.00      0.33         6

    accuracy                           0.76       100
   macro avg       0.60      0.87      0.59       100
weighted avg       0.95      0.76      0.82       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        90
           1       0.20      0.60      0.30        10

    accuracy                           0.72       100
   macro avg       0.57      0.67      0.56       100
weighted avg       0.87      0.72      0.77       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.71      0.76        80
           1       0.23      0.35      0.28        20

    accuracy                           0.64       100
   macro avg       0.52      0.53      0.52       100
weighted avg       0.70      0.64      0.66       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        91
           1       0.17      0.56      0.26         9

    accuracy                           0.71       100
   macro avg       0.55      0.64      0.54       100
weighted avg       0.87      0.71      0.77       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.78      0.87        87
           1       0.37      0.85      0.51        13

    accuracy                           0.79       100
   macro avg       0.67      0.81      0.69       100
weighted avg       0.89      0.79      0.82       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.85        87
           1       0.33      0.77      0.47        13

    accuracy                           0.77       100
   macro avg       0.65      0.77      0.66       100
weighted avg       0.88      0.77      0.80       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.734
F1: 0.36906646906674656
======================================================
Running german_credit 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.74      0.85        93
           1       0.20      0.86      0.32         7

    accuracy                           0.75       100
   macro avg       0.59      0.80      0.59       100
weighted avg       0.93      0.75      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.76      0.84        85
           1       0.33      0.67      0.44        15

    accuracy                           0.75       100
   macro avg       0.63      0.72      0.64       100
weighted avg       0.84      0.75      0.78       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.71      0.82        94
           1       0.10      0.50      0.17         6

    accuracy                           0.70       100
   macro avg       0.53      0.61      0.49       100
weighted avg       0.91      0.70      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.77      0.87        91
           1       0.30      1.00      0.46         9

    accuracy                           0.79       100
   macro avg       0.65      0.88      0.67       100
weighted avg       0.94      0.79      0.83       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.75      0.79        77
           1       0.37      0.48      0.42        23

    accuracy                           0.69       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.72      0.69      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.72      0.81        90
           1       0.17      0.50      0.25        10

    accuracy                           0.70       100
   macro avg       0.55      0.61      0.53       100
weighted avg       0.85      0.70      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), RandomForestClassifier()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.78      0.86        86
           1       0.37      0.79      0.50        14

    accuracy                           0.78       100
   macro avg       0.66      0.78      0.68       100
weighted avg       0.87      0.78      0.81       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.85        87
           1       0.33      0.77      0.47        13

    accuracy                           0.77       100
   macro avg       0.65      0.77      0.66       100
weighted avg       0.88      0.77      0.80       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.74      0.85        93
           1       0.20      0.86      0.32         7

    accuracy                           0.75       100
   macro avg       0.59      0.80      0.59       100
weighted avg       0.93      0.75      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7369999999999999
F1: 0.3556637045118835
======================================================
Running german_credit 75 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.77      0.86        90
           1       0.30      0.90      0.45        10

    accuracy                           0.78       100
   macro avg       0.64      0.83      0.66       100
weighted avg       0.92      0.78      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.72      0.82        95
           1       0.10      0.60      0.17         5

    accuracy                           0.71       100
   macro avg       0.54      0.66      0.50       100
weighted avg       0.93      0.71      0.79       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.74      0.83        89
           1       0.23      0.64      0.34        11

    accuracy                           0.73       100
   macro avg       0.59      0.69      0.59       100
weighted avg       0.86      0.73      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.77      0.87        91
           1       0.30      1.00      0.46         9

    accuracy                           0.79       100
   macro avg       0.65      0.88      0.67       100
weighted avg       0.94      0.79      0.83       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.75      0.79        77
           1       0.37      0.48      0.42        23

    accuracy                           0.69       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.72      0.69      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.72      0.81        90
           1       0.17      0.50      0.25        10

    accuracy                           0.70       100
   macro avg       0.55      0.61      0.53       100
weighted avg       0.85      0.70      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), SVC(probability=True)]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        85
           1       0.40      0.80      0.53        15

    accuracy                           0.79       100
   macro avg       0.68      0.79      0.70       100
weighted avg       0.87      0.79      0.81       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.75      0.83        85
           1       0.30      0.60      0.40        15

    accuracy                           0.73       100
   macro avg       0.61      0.68      0.61       100
weighted avg       0.82      0.73      0.76       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7369999999999999
F1: 0.3596407378316938
======================================================
Running german_credit 75 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 75 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.43      0.68      0.53        44
           1       0.53      0.29      0.37        56

    accuracy                           0.46       100
   macro avg       0.48      0.48      0.45       100
weighted avg       0.49      0.46      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.71      0.48        35
           1       0.67      0.31      0.42        65

    accuracy                           0.45       100
   macro avg       0.51      0.51      0.45       100
weighted avg       0.56      0.45      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.62      0.45        40
           1       0.50      0.25      0.33        60

    accuracy                           0.40       100
   macro avg       0.43      0.44      0.39       100
weighted avg       0.44      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.36      0.62      0.45        40
           1       0.50      0.25      0.33        60

    accuracy                           0.40       100
   macro avg       0.43      0.44      0.39       100
weighted avg       0.44      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.70      0.66        63
           1       0.37      0.30      0.33        37

    accuracy                           0.55       100
   macro avg       0.50      0.50      0.50       100
weighted avg       0.53      0.55      0.54       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.51      0.84      0.64        43
           1       0.77      0.40      0.53        57

    accuracy                           0.59       100
   macro avg       0.64      0.62      0.58       100
weighted avg       0.66      0.59      0.58       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.73      0.68        60
           1       0.47      0.35      0.40        40

    accuracy                           0.58       100
   macro avg       0.55      0.54      0.54       100
weighted avg       0.56      0.58      0.57       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.67      0.48        39
           1       0.57      0.28      0.37        61

    accuracy                           0.43       100
   macro avg       0.47      0.47      0.43       100
weighted avg       0.49      0.43      0.41       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.23      0.80      0.36        20
           1       0.87      0.33      0.47        80

    accuracy                           0.42       100
   macro avg       0.55      0.56      0.41       100
weighted avg       0.74      0.42      0.45       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.68      0.48        38
           1       0.60      0.29      0.39        62

    accuracy                           0.44       100
   macro avg       0.49      0.49      0.44       100
weighted avg       0.51      0.44      0.43       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4720000000000001
F1: 0.3954564156820293
======================================================
Running german_credit 75 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6745194792356441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        76
           1       0.57      0.71      0.63        24

    accuracy                           0.80       100
   macro avg       0.73      0.77      0.75       100
weighted avg       0.82      0.80      0.81       100

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [18, 406, 1, 474, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.7299180694982289
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [417, 1, 5, 4, 469, 4]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6733466308297128
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [1, 3, 17, 462, 417]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.7132925363929442
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.79      0.81        75
           1       0.47      0.56      0.51        25

    accuracy                           0.73       100
   macro avg       0.65      0.67      0.66       100
weighted avg       0.75      0.73      0.74       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [1, 36, 409, 3, 1, 450]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.6398363371848302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.78      0.80        73
           1       0.47      0.52      0.49        27

    accuracy                           0.71       100
   macro avg       0.64      0.65      0.64       100
weighted avg       0.72      0.71      0.71       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [478, 417, 5]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5799597691438303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.74      0.76        73
           1       0.37      0.41      0.39        27

    accuracy                           0.65       100
   macro avg       0.57      0.57      0.57       100
weighted avg       0.66      0.65      0.66       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [388, 478, 31, 3]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6002674370565425
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [1, 390, 11, 392, 1, 93, 12]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.8190621750878044
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.79      0.80        72
           1       0.50      0.54      0.52        28

    accuracy                           0.72       100
   macro avg       0.66      0.66      0.66       100
weighted avg       0.73      0.72      0.72       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 475, 421, 1, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.673119811625536
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.80      0.82        74
           1       0.50      0.58      0.54        26

    accuracy                           0.74       100
   macro avg       0.67      0.69      0.68       100
weighted avg       0.75      0.74      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [4, 3, 17, 480, 396]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.59912704274346
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.79      0.79        71
           1       0.50      0.52      0.51        29

    accuracy                           0.71       100
   macro avg       0.65      0.65      0.65       100
weighted avg       0.71      0.71      0.71       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [411, 472, 2, 9, 6]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.723
F1: 0.5067940203068936
======================================================
Running german_credit 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.3513859371127612
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.84      0.86        74
           1       0.60      0.69      0.64        26

    accuracy                           0.80       100
   macro avg       0.74      0.77      0.75       100
weighted avg       0.81      0.80      0.80       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [329, 459, 88, 13, 2, 5, 2, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3921545227807574
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.83        73
           1       0.53      0.59      0.56        27

    accuracy                           0.75       100
   macro avg       0.69      0.70      0.69       100
weighted avg       0.76      0.75      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 2, 422, 470, 4]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.33549434639587855
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.77      0.79        74
           1       0.43      0.50      0.46        26

    accuracy                           0.70       100
   macro avg       0.62      0.64      0.63       100
weighted avg       0.72      0.70      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [425, 3, 472]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.28489506880626353
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.78      0.81        74
           1       0.47      0.54      0.50        26

    accuracy                           0.72       100
   macro avg       0.65      0.66      0.65       100
weighted avg       0.73      0.72      0.73       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [459, 1, 1, 411, 23, 1, 4]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3266372250452049
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.74      0.73        69
           1       0.40      0.39      0.39        31

    accuracy                           0.63       100
   macro avg       0.56      0.56      0.56       100
weighted avg       0.63      0.63      0.63       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [2, 481, 402, 2, 13]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.32193722018839743
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.70      0.71        71
           1       0.30      0.31      0.31        29

    accuracy                           0.59       100
   macro avg       0.51      0.51      0.51       100
weighted avg       0.59      0.59      0.59       100

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [429, 1, 470]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3461942659187962
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.75      0.79        77
           1       0.37      0.48      0.42        23

    accuracy                           0.69       100
   macro avg       0.60      0.62      0.60       100
weighted avg       0.72      0.69      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [413, 8, 477, 1, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.3590654592347348
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        79
           1       0.47      0.67      0.55        21

    accuracy                           0.77       100
   macro avg       0.68      0.73      0.70       100
weighted avg       0.81      0.77      0.78       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 1, 27, 2, 398, 469, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.3555037947065501
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.78      0.82        78
           1       0.43      0.59      0.50        22

    accuracy                           0.74       100
   macro avg       0.65      0.69      0.66       100
weighted avg       0.78      0.74      0.75       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [1, 3, 6, 6, 481, 403]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=3))
Best evaluation: 0.3322858383146481
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.76      0.79        75
           1       0.40      0.48      0.44        25

    accuracy                           0.69       100
   macro avg       0.61      0.62      0.61       100
weighted avg       0.71      0.69      0.70       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [4, 415, 481]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.708
F1: 0.4767551318457734
======================================================
Running german_credit 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3438195607698504
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        76
           1       0.53      0.67      0.59        24

    accuracy                           0.78       100
   macro avg       0.71      0.74      0.72       100
weighted avg       0.80      0.78      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [414, 473, 1, 9, 3]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3803329071868209
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.77      0.77        70
           1       0.47      0.47      0.47        30

    accuracy                           0.68       100
   macro avg       0.62      0.62      0.62       100
weighted avg       0.68      0.68      0.68       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [429, 2, 467, 2]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3504300144927507
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        78
           1       0.37      0.50      0.42        22

    accuracy                           0.70       100
   macro avg       0.60      0.63      0.61       100
weighted avg       0.74      0.70      0.71       100

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [468, 1, 430, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.3244419382530178
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.83      0.85        72
           1       0.60      0.64      0.62        28

    accuracy                           0.78       100
   macro avg       0.73      0.74      0.73       100
weighted avg       0.79      0.78      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [398, 1, 1, 11, 479, 2, 8]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.3674303994313215
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.81      0.80        68
           1       0.57      0.53      0.55        32

    accuracy                           0.72       100
   macro avg       0.68      0.67      0.67       100
weighted avg       0.72      0.72      0.72       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [513, 383, 3, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3295637877101025
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.73      0.77        78
           1       0.30      0.41      0.35        22

    accuracy                           0.66       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.70      0.66      0.68       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [1, 1, 21, 476, 401]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.32760195813357607
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.75      0.77        73
           1       0.40      0.44      0.42        27

    accuracy                           0.67       100
   macro avg       0.59      0.60      0.60       100
weighted avg       0.68      0.67      0.68       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [1, 415, 1, 372, 111]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.3820820399549818
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        74
           1       0.53      0.62      0.57        26

    accuracy                           0.76       100
   macro avg       0.70      0.71      0.70       100
weighted avg       0.77      0.76      0.77       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [6, 11, 414, 468, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.3636530861193353
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.77      0.80        77
           1       0.40      0.52      0.45        23

    accuracy                           0.71       100
   macro avg       0.62      0.64      0.63       100
weighted avg       0.74      0.71      0.72       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 10, 1, 2, 462, 1, 1, 19, 400, 1]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.31486777115903214
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.78      0.76        67
           1       0.50      0.45      0.48        33

    accuracy                           0.67       100
   macro avg       0.62      0.62      0.62       100
weighted avg       0.66      0.67      0.67       100

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [6, 5, 1, 410, 25, 1, 452]
Selected clustering_algorithm: fcm
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.713
F1: 0.4919068648313877
======================================================
Running german_credit 50 2 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 meta_classifier crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand meta_classifier default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 meta_classifier default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        76
           1       0.57      0.71      0.63        24

    accuracy                           0.80       100
   macro avg       0.73      0.77      0.75       100
weighted avg       0.82      0.80      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        80
           1       0.53      0.80      0.64        20

    accuracy                           0.82       100
   macro avg       0.74      0.81      0.76       100
weighted avg       0.86      0.82      0.83       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.77      0.80        75
           1       0.43      0.52      0.47        25

    accuracy                           0.71       100
   macro avg       0.63      0.65      0.64       100
weighted avg       0.73      0.71      0.72       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.73      0.78        79
           1       0.30      0.43      0.35        21

    accuracy                           0.67       100
   macro avg       0.56      0.58      0.57       100
weighted avg       0.72      0.67      0.69       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.73      0.74        71
           1       0.37      0.38      0.37        29

    accuracy                           0.63       100
   macro avg       0.55      0.56      0.56       100
weighted avg       0.63      0.63      0.63       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        81
           1       0.40      0.63      0.49        19

    accuracy                           0.75       100
   macro avg       0.65      0.70      0.66       100
weighted avg       0.81      0.75      0.77       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.77      0.77      0.77        70
           1       0.47      0.47      0.47        30

    accuracy                           0.68       100
   macro avg       0.62      0.62      0.62       100
weighted avg       0.68      0.68      0.68       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.726
F1: 0.47335157088041957
======================================================
Running german_credit 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        76
           1       0.57      0.71      0.63        24

    accuracy                           0.80       100
   macro avg       0.73      0.77      0.75       100
weighted avg       0.82      0.80      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.74      0.78        78
           1       0.33      0.45      0.38        22

    accuracy                           0.68       100
   macro avg       0.58      0.60      0.58       100
weighted avg       0.72      0.68      0.70       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        80
           1       0.53      0.80      0.64        20

    accuracy                           0.82       100
   macro avg       0.74      0.81      0.76       100
weighted avg       0.86      0.82      0.83       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.73      0.77        78
           1       0.30      0.41      0.35        22

    accuracy                           0.66       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.70      0.66      0.68       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.73      0.76        75
           1       0.33      0.40      0.36        25

    accuracy                           0.65       100
   macro avg       0.56      0.57      0.56       100
weighted avg       0.67      0.65      0.66       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.81      0.84        77
           1       0.50      0.65      0.57        23

    accuracy                           0.77       100
   macro avg       0.69      0.73      0.70       100
weighted avg       0.80      0.77      0.78       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7369999999999999
F1: 0.4996913918489946
======================================================
Running german_credit 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.86        76
           1       0.57      0.71      0.63        24

    accuracy                           0.80       100
   macro avg       0.73      0.77      0.75       100
weighted avg       0.82      0.80      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        75
           1       0.50      0.60      0.55        25

    accuracy                           0.75       100
   macro avg       0.68      0.70      0.69       100
weighted avg       0.77      0.75      0.76       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        88
           1       0.17      0.42      0.24        12

    accuracy                           0.68       100
   macro avg       0.53      0.57      0.52       100
weighted avg       0.81      0.68      0.73       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        80
           1       0.53      0.80      0.64        20

    accuracy                           0.82       100
   macro avg       0.74      0.81      0.76       100
weighted avg       0.86      0.82      0.83       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.79      0.79        71
           1       0.50      0.52      0.51        29

    accuracy                           0.71       100
   macro avg       0.65      0.65      0.65       100
weighted avg       0.71      0.71      0.71       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        78
           1       0.37      0.50      0.42        22

    accuracy                           0.70       100
   macro avg       0.60      0.63      0.61       100
weighted avg       0.74      0.70      0.71       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.73      0.74        71
           1       0.37      0.38      0.37        29

    accuracy                           0.63       100
   macro avg       0.55      0.56      0.56       100
weighted avg       0.63      0.63      0.63       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        80
           1       0.43      0.65      0.52        20

    accuracy                           0.76       100
   macro avg       0.67      0.72      0.68       100
weighted avg       0.81      0.76      0.78       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.79      0.82        76
           1       0.47      0.58      0.52        24

    accuracy                           0.74       100
   macro avg       0.66      0.69      0.67       100
weighted avg       0.76      0.74      0.75       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.737
F1: 0.4917869917413028
======================================================
Running german_credit 50 2 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 weighted_membership crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand weighted_membership default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 weighted_membership default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45966657921648235
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.80      0.87        84
           1       0.43      0.81      0.57        16

    accuracy                           0.80       100
   macro avg       0.70      0.81      0.72       100
weighted avg       0.87      0.80      0.82       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.57142857,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45805385928531817
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        86
           1       0.33      0.71      0.45        14

    accuracy                           0.76       100
   macro avg       0.64      0.74      0.65       100
weighted avg       0.86      0.76      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.4595577508677494
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.73      0.82        89
           1       0.20      0.55      0.29        11

    accuracy                           0.71       100
   macro avg       0.56      0.64      0.56       100
weighted avg       0.85      0.71      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4595877211424027
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.45930050306083486
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        88
           1       0.23      0.58      0.33        12

    accuracy                           0.72       100
   macro avg       0.58      0.66      0.58       100
weighted avg       0.85      0.72      0.76       100

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45743954645920193
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.72      0.79        86
           1       0.20      0.43      0.27        14

    accuracy                           0.68       100
   macro avg       0.54      0.57      0.53       100
weighted avg       0.79      0.68      0.72       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [524, 376]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.4594043084247761
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.45686733694198467
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.81      0.88        83
           1       0.47      0.82      0.60        17

    accuracy                           0.81       100
   macro avg       0.71      0.82      0.74       100
weighted avg       0.87      0.81      0.83       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.47494521850793864
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.75      0.85        92
           1       0.23      0.88      0.37         8

    accuracy                           0.76       100
   macro avg       0.61      0.81      0.61       100
weighted avg       0.93      0.76      0.81       100

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.11764706,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 1.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.4596313989648865
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.82        83
           1       0.33      0.59      0.43        17

    accuracy                           0.73       100
   macro avg       0.62      0.67      0.62       100
weighted avg       0.80      0.73      0.76       100

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.742
F1: 0.3955694847189376
======================================================
Running german_credit 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.84        88
           1       0.27      0.67      0.38        12

    accuracy                           0.74       100
   macro avg       0.60      0.71      0.61       100
weighted avg       0.86      0.74      0.78       100

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.77      0.82        79
           1       0.40      0.57      0.47        21

    accuracy                           0.73       100
   macro avg       0.64      0.67      0.64       100
weighted avg       0.77      0.73      0.75       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.71      0.81        91
           1       0.13      0.44      0.21         9

    accuracy                           0.69       100
   macro avg       0.53      0.58      0.51       100
weighted avg       0.86      0.69      0.75       100

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        88
           1       0.33      0.83      0.48        12

    accuracy                           0.78       100
   macro avg       0.65      0.80      0.67       100
weighted avg       0.89      0.78      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.74      0.84        90
           1       0.23      0.70      0.35        10

    accuracy                           0.74       100
   macro avg       0.60      0.72      0.59       100
weighted avg       0.88      0.74      0.79       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        82
           1       0.23      0.39      0.29        18

    accuracy                           0.66       100
   macro avg       0.54      0.55      0.53       100
weighted avg       0.73      0.66      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.79      0.86        82
           1       0.43      0.72      0.54        18

    accuracy                           0.78       100
   macro avg       0.68      0.76      0.70       100
weighted avg       0.84      0.78      0.80       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.99      0.76      0.86        91
           1       0.27      0.89      0.41         9

    accuracy                           0.77       100
   macro avg       0.63      0.82      0.63       100
weighted avg       0.92      0.77      0.82       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.77      0.85        87
           1       0.33      0.77      0.47        13

    accuracy                           0.77       100
   macro avg       0.65      0.77      0.66       100
weighted avg       0.88      0.77      0.80       100

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.735
F1: 0.3870635087666551
======================================================
Running german_credit 50 rand majority_voting crossval...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2658850739689016
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        85
           1       0.40      0.80      0.53        15

    accuracy                           0.79       100
   macro avg       0.68      0.79      0.70       100
weighted avg       0.87      0.79      0.81       100

Selected Base Classifiers: [GradientBoostingClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2655206027660675
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.74      0.82        86
           1       0.27      0.57      0.36        14

    accuracy                           0.72       100
   macro avg       0.59      0.66      0.59       100
weighted avg       0.82      0.72      0.76       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [526, 374]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2668982856979438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.72      0.82        95
           1       0.10      0.60      0.17         5

    accuracy                           0.71       100
   macro avg       0.54      0.66      0.50       100
weighted avg       0.93      0.71      0.79       100

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [360, 540]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.20588235,
        0.        , 0.33333333, 1.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.2672579768121278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.77      0.86        88
           1       0.33      0.83      0.48        12

    accuracy                           0.78       100
   macro avg       0.65      0.80      0.67       100
weighted avg       0.89      0.78      0.81       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26658040879126427
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.73      0.83        92
           1       0.17      0.62      0.26         8

    accuracy                           0.72       100
   macro avg       0.56      0.68      0.55       100
weighted avg       0.89      0.72      0.78       100

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [358, 542]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26590585696557345
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        82
           1       0.23      0.39      0.29        18

    accuracy                           0.66       100
   macro avg       0.54      0.55      0.53       100
weighted avg       0.73      0.66      0.69       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.47058824,
        0.        , 0.33333333, 1.        , 1.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.26654381171417696
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.72      0.80        87
           1       0.20      0.46      0.28        13

    accuracy                           0.69       100
   macro avg       0.55      0.59      0.54       100
weighted avg       0.81      0.69      0.73       100

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26575670066090074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        85
           1       0.37      0.73      0.49        15

    accuracy                           0.77       100
   macro avg       0.65      0.75      0.67       100
weighted avg       0.86      0.77      0.80       100

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 1.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,...
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 1.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 0.        ,
        1.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 1.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ,
        0.        , 1.        , 0.        , 0.        , 1.        ,
        0.        , 1.        , 0.        , 1.        , 0.        ,
        1.        , 0.        , 1.        , 0.        , 0.33823529,
        0.        , 1.        , 1.        , 0.        , 0.        ,
        1.        , 1.        , 0.        , 0.        , 1.        ]]),
       n_clusters=2))
Best evaluation: 0.2726206807208598
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.79      0.86        84
           1       0.40      0.75      0.52        16

    accuracy                           0.78       100
   macro avg       0.67      0.77      0.69       100
weighted avg       0.86      0.78      0.80       100

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2666857228648399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.78      0.83        79
           1       0.43      0.62      0.51        21

    accuracy                           0.75       100
   macro avg       0.66      0.70      0.67       100
weighted avg       0.79      0.75      0.76       100

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [545, 355]
Selected clustering_algorithm: kmeans
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.737
F1: 0.3898915014326413
======================================================
Running german_credit 50 2 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 3 majority_voting crossval
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 rand majority_voting default...
======================================================
python cbeg.py -d german_credit -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running german_credit 50 2 majority_voting default
======================================================
python cbeg.py -d german_credit -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.70      0.45        33
           1       0.67      0.30      0.41        67

    accuracy                           0.43       100
   macro avg       0.50      0.50      0.43       100
weighted avg       0.56      0.43      0.42       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [366, 534]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.30      0.75      0.43        28
           1       0.77      0.32      0.45        72

    accuracy                           0.44       100
   macro avg       0.53      0.53      0.44       100
weighted avg       0.64      0.44      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [376, 524]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.75      0.68        59
           1       0.50      0.37      0.42        41

    accuracy                           0.59       100
   macro avg       0.56      0.56      0.55       100
weighted avg       0.58      0.59      0.58       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [365, 535]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.62      0.46        42
           1       0.47      0.24      0.32        58

    accuracy                           0.40       100
   macro avg       0.42      0.43      0.39       100
weighted avg       0.43      0.40      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 555]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.68      0.68        69
           1       0.27      0.26      0.26        31

    accuracy                           0.55       100
   macro avg       0.47      0.47      0.47       100
weighted avg       0.55      0.55      0.55       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [362, 538]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.84      0.51        31
           1       0.83      0.36      0.51        69

    accuracy                           0.51       100
   macro avg       0.60      0.60      0.51       100
weighted avg       0.69      0.51      0.51       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [374, 526]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.73      0.70        64
           1       0.43      0.36      0.39        36

    accuracy                           0.60       100
   macro avg       0.55      0.55      0.55       100
weighted avg       0.59      0.60      0.59       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [357, 543]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.30      0.64      0.41        33
           1       0.60      0.27      0.37        67

    accuracy                           0.39       100
   macro avg       0.45      0.45      0.39       100
weighted avg       0.50      0.39      0.38       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [355, 545]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.24      0.77      0.37        22
           1       0.83      0.32      0.46        78

    accuracy                           0.42       100
   macro avg       0.54      0.55      0.42       100
weighted avg       0.70      0.42      0.44       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [256, 644]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.40      0.74      0.52        38
           1       0.67      0.32      0.43        62

    accuracy                           0.48       100
   macro avg       0.53      0.53      0.48       100
weighted avg       0.57      0.48      0.47       100

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [369, 531]
Selected clustering_algorithm: kmeans++
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/german_credit/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.48100000000000004
F1: 0.4034233128861189
======================================================
Running german_credit 50 3 majority_voting default
======================================================
python cbeg.py -d german_credit -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.42737393992707223
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.63      0.62        60
           1       0.32      0.46      0.38        24
           2       0.56      0.45      0.50        64

    accuracy                           0.53       148
   macro avg       0.50      0.51      0.50       148
weighted avg       0.54      0.53      0.53       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=RandomForestClassifier())]
Number of samples by cluster: [1, 4, 212, 302, 202, 40, 426, 1, 1, 1, 135]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.41515265235294746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.67      0.66        61
           1       0.44      0.62      0.52        24
           2       0.71      0.57      0.63        63

    accuracy                           0.62       148
   macro avg       0.60      0.62      0.60       148
weighted avg       0.64      0.62      0.63       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 532, 257, 356, 178, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5527916114566394
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.58      0.59        66
           1       0.35      0.48      0.41        25
           2       0.49      0.44      0.46        57

    accuracy                           0.51       148
   macro avg       0.48      0.50      0.49       148
weighted avg       0.52      0.51      0.51       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 2, 1, 1, 2, 346, 250, 530, 190, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.3986064573644763
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.63      0.68        75
           1       0.36      0.57      0.44        21
           2       0.45      0.45      0.45        51

    accuracy                           0.56       147
   macro avg       0.52      0.55      0.53       147
weighted avg       0.59      0.56      0.57       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 185, 8, 507, 4, 264, 1, 354, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.498090908375842
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.60      0.67        80
           1       0.36      0.50      0.42        24
           2       0.47      0.56      0.51        43

    accuracy                           0.57       147
   macro avg       0.53      0.55      0.53       147
weighted avg       0.61      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [243, 343, 1, 1, 1, 197, 540]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.44177631741403567
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.63      0.64        65
           1       0.45      0.48      0.47        31
           2       0.45      0.45      0.45        51

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

Number of samples by cluster: [10, 2, 204, 445, 365, 298, 1, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.4603547083094234
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        67
           1       0.27      0.36      0.31        25
           2       0.51      0.47      0.49        55

    accuracy                           0.55       147
   macro avg       0.50      0.51      0.50       147
weighted avg       0.57      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=DecisionTreeClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [249, 8, 1, 1, 1, 1, 542, 342, 20, 161]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4992432904432017
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.68      0.62        53
           1       0.30      0.30      0.30        33
           2       0.39      0.33      0.36        61

    accuracy                           0.45       147
   macro avg       0.42      0.44      0.43       147
weighted avg       0.44      0.45      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [359, 1, 199, 2, 1, 274, 490]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.41561250918525844
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.54      0.54        63
           1       0.42      0.41      0.42        34
           2       0.31      0.32      0.32        50

    accuracy                           0.44       147
   macro avg       0.43      0.42      0.42       147
weighted avg       0.44      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 414, 1, 394, 198, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.45440751501523796
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.64      0.61        58
           1       0.36      0.34      0.35        35
           2       0.51      0.48      0.50        54

    accuracy                           0.51       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [195, 350, 2, 1, 262, 1, 5, 1, 508, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5267650303364589
F1: 0.5238598170800541
======================================================
Running contraceptive 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.62      0.63        65
           1       0.44      0.47      0.45        32
           2       0.52      0.53      0.52        51

    accuracy                           0.55       148
   macro avg       0.54      0.54      0.54       148
weighted avg       0.56      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.23965820574953367
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.65      0.65        63
           1       0.44      0.47      0.45        32
           2       0.59      0.57      0.58        53

    accuracy                           0.58       148
   macro avg       0.56      0.56      0.56       148
weighted avg       0.58      0.58      0.58       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1, 257, 1, 1, 177, 532, 356]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.52      0.52        63
           1       0.32      0.32      0.32        34
           2       0.39      0.39      0.39        51

    accuracy                           0.43       148
   macro avg       0.41      0.41      0.41       148
weighted avg       0.43      0.43      0.43       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.58      0.63        74
           1       0.36      0.50      0.42        24
           2       0.43      0.45      0.44        49

    accuracy                           0.52       147
   macro avg       0.49      0.51      0.50       147
weighted avg       0.55      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.2531215588478982
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.45      0.42        29
           2       0.53      0.61      0.57        44

    accuracy                           0.60       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.62      0.60      0.61       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1, 1, 539, 195, 338, 1, 1, 243, 7]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.65      0.63        60
           1       0.42      0.34      0.38        41
           2       0.49      0.54      0.52        46

    accuracy                           0.53       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.52      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.60        68
           1       0.45      0.52      0.48        29
           2       0.53      0.54      0.53        50

    accuracy                           0.55       147
   macro avg       0.53      0.54      0.54       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.2480815998389737
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.69      0.61        49
           1       0.42      0.36      0.39        39
           2       0.43      0.37      0.40        59

    accuracy                           0.48       147
   macro avg       0.47      0.48      0.47       147
weighted avg       0.47      0.48      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=RandomForestClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [188, 238, 2, 1, 1, 1, 562, 1, 331, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.48      0.57      0.52        53
           1       0.48      0.40      0.44        40
           2       0.47      0.44      0.46        54

    accuracy                           0.48       147
   macro avg       0.48      0.47      0.47       147
weighted avg       0.48      0.48      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.61      0.56        54
           1       0.36      0.39      0.38        31
           2       0.51      0.42      0.46        62

    accuracy                           0.48       147
   macro avg       0.47      0.47      0.47       147
weighted avg       0.48      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5207023349880493
F1: 0.5208472967532757
======================================================
Running contraceptive 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.63      0.61        59
           1       0.47      0.57      0.52        28
           2       0.56      0.48      0.51        61

    accuracy                           0.55       148
   macro avg       0.54      0.56      0.55       148
weighted avg       0.56      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.58      0.60        67
           1       0.35      0.46      0.40        26
           2       0.51      0.47      0.49        55

    accuracy                           0.52       148
   macro avg       0.49      0.51      0.50       148
weighted avg       0.53      0.52      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.24715730368200356
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.60      0.62        67
           1       0.41      0.47      0.44        30
           2       0.49      0.49      0.49        51

    accuracy                           0.53       148
   macro avg       0.51      0.52      0.51       148
weighted avg       0.54      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [489, 1, 319, 50, 466]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.58      0.63        74
           1       0.39      0.52      0.45        25
           2       0.45      0.48      0.46        48

    accuracy                           0.54       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.56      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.36      0.46      0.41        26
           2       0.53      0.63      0.57        43

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.55       147
weighted avg       0.62      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.23420300013683854
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.65      0.65        63
           1       0.42      0.44      0.43        32
           2       0.51      0.50      0.50        52

    accuracy                           0.55       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.55      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=RandomForestClassifier())]
Number of samples by cluster: [162, 347, 226, 399, 1, 15, 1, 2, 173]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.63      0.63        63
           1       0.42      0.47      0.44        30
           2       0.57      0.54      0.55        54

    accuracy                           0.56       147
   macro avg       0.54      0.55      0.54       147
weighted avg       0.57      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.68      0.64        56
           1       0.33      0.31      0.32        35
           2       0.41      0.38      0.39        56

    accuracy                           0.48       147
   macro avg       0.45      0.46      0.45       147
weighted avg       0.47      0.48      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.51      0.55      0.53        58
           1       0.39      0.41      0.40        32
           2       0.43      0.39      0.41        57

    accuracy                           0.46       147
   macro avg       0.44      0.45      0.45       147
weighted avg       0.45      0.46      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.64      0.63        61
           1       0.36      0.39      0.38        31
           2       0.47      0.44      0.45        55

    accuracy                           0.51       147
   macro avg       0.48      0.49      0.49       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5288380216951646
F1: 0.5275546714788659
======================================================
Running contraceptive 100 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.65      0.61      0.62        66
           1       0.41      0.54      0.47        26
           2       0.48      0.45      0.46        56

    accuracy                           0.53       148
   macro avg       0.51      0.53      0.52       148
weighted avg       0.54      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.61      0.64        69
           1       0.26      0.31      0.29        29
           2       0.49      0.50      0.50        50

    accuracy                           0.51       148
   macro avg       0.47      0.47      0.47       148
weighted avg       0.53      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.60      0.58      0.59        65
           1       0.44      0.45      0.45        33
           2       0.47      0.48      0.48        50

    accuracy                           0.52       148
   macro avg       0.50      0.51      0.51       148
weighted avg       0.52      0.52      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.57      0.61        74
           1       0.45      0.65      0.54        23
           2       0.43      0.44      0.44        50

    accuracy                           0.54       147
   macro avg       0.52      0.55      0.53       147
weighted avg       0.55      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.76      0.59      0.67        81
           1       0.33      0.44      0.38        25
           2       0.45      0.56      0.50        41

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.60      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.65      0.59      0.62        69
           1       0.42      0.44      0.43        32
           2       0.41      0.46      0.43        46

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.49       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.58      0.62        72
           1       0.33      0.44      0.38        25
           2       0.47      0.48      0.48        50

    accuracy                           0.52       147
   macro avg       0.49      0.50      0.49       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.56      0.64      0.59        55
           1       0.39      0.43      0.41        30
           2       0.47      0.39      0.42        62

    accuracy                           0.49       147
   macro avg       0.47      0.49      0.48       147
weighted avg       0.49      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.54      0.53      0.54        64
           1       0.36      0.34      0.35        35
           2       0.39      0.42      0.40        48

    accuracy                           0.45       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.45      0.45      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.62        65
           1       0.33      0.44      0.38        25
           2       0.61      0.54      0.57        57

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.57      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5200220628792058
F1: 0.5161867741849928
======================================================
Running contraceptive 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.70      0.67        57
           1       0.29      0.45      0.36        22
           2       0.63      0.48      0.55        69

    accuracy                           0.56       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.59      0.56      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.69      0.70        65
           1       0.41      0.52      0.46        27
           2       0.59      0.54      0.56        56

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.65        61
           1       0.29      0.42      0.34        24
           2       0.59      0.48      0.53        63

    accuracy                           0.54       148
   macro avg       0.51      0.52      0.51       148
weighted avg       0.56      0.54      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.62      0.64        66
           1       0.48      0.57      0.52        28
           2       0.53      0.51      0.52        53

    accuracy                           0.57       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.58      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.59      0.69        88
           1       0.27      0.50      0.35        18
           2       0.39      0.49      0.43        41

    accuracy                           0.55       147
   macro avg       0.50      0.53      0.49       147
weighted avg       0.64      0.55      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.63      0.62        60
           1       0.39      0.42      0.41        31
           2       0.57      0.52      0.54        56

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.55      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.54      0.46        24
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.57      0.59      0.58       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        61
           1       0.42      0.56      0.48        25
           2       0.57      0.48      0.52        61

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.57       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.61      0.57        56
           1       0.52      0.52      0.52        33
           2       0.57      0.50      0.53        58

    accuracy                           0.54       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.55      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        62
           1       0.33      0.37      0.35        30
           2       0.51      0.47      0.49        55

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5641478212906784
F1: 0.5592315306475403
======================================================
Running contraceptive 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.70      0.67        57
           1       0.38      0.50      0.43        26
           2       0.58      0.46      0.51        65

    accuracy                           0.56       148
   macro avg       0.53      0.55      0.54       148
weighted avg       0.57      0.56      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.69      0.70        65
           1       0.41      0.52      0.46        27
           2       0.59      0.54      0.56        56

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        62
           1       0.29      0.38      0.33        26
           2       0.55      0.47      0.50        60

    accuracy                           0.53       148
   macro avg       0.49      0.50      0.49       148
weighted avg       0.54      0.53      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.62      0.64        66
           1       0.48      0.57      0.52        28
           2       0.53      0.51      0.52        53

    accuracy                           0.57       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.58      0.57      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.64      0.72        81
           1       0.42      0.52      0.47        27
           2       0.45      0.59      0.51        39

    accuracy                           0.61       147
   macro avg       0.57      0.58      0.57       147
weighted avg       0.65      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.63      0.62        60
           1       0.39      0.42      0.41        31
           2       0.57      0.52      0.54        56

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.55      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.54      0.46        24
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.57      0.59      0.58       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        61
           1       0.42      0.56      0.48        25
           2       0.57      0.48      0.52        61

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.57       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.58      0.57        60
           1       0.48      0.44      0.46        36
           2       0.49      0.49      0.49        51

    accuracy                           0.52       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.69      0.66        58
           1       0.36      0.41      0.39        29
           2       0.57      0.48      0.52        60

    accuracy                           0.55       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.55      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5682386468100754
F1: 0.565394725777855
======================================================
Running contraceptive 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.68      0.64        56
           1       0.32      0.46      0.38        24
           2       0.62      0.47      0.53        68

    accuracy                           0.55       148
   macro avg       0.52      0.54      0.52       148
weighted avg       0.57      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.69      0.70        65
           1       0.41      0.52      0.46        27
           2       0.59      0.54      0.56        56

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.61      0.60      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.63      0.61        59
           1       0.24      0.35      0.28        23
           2       0.53      0.41      0.46        66

    accuracy                           0.49       148
   macro avg       0.45      0.46      0.45       148
weighted avg       0.51      0.49      0.49       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.59      0.60        64
           1       0.39      0.52      0.45        25
           2       0.53      0.47      0.50        58

    accuracy                           0.53       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.54      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.59      0.69        88
           1       0.27      0.50      0.35        18
           2       0.39      0.49      0.43        41

    accuracy                           0.55       147
   macro avg       0.50      0.53      0.49       147
weighted avg       0.64      0.55      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.65      0.67        68
           1       0.39      0.45      0.42        29
           2       0.53      0.54      0.53        50

    accuracy                           0.57       147
   macro avg       0.54      0.55      0.54       147
weighted avg       0.58      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.65      0.70        74
           1       0.39      0.54      0.46        24
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.57      0.59      0.58       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.72      0.71        61
           1       0.42      0.56      0.48        25
           2       0.57      0.48      0.52        61

    accuracy                           0.59       147
   macro avg       0.56      0.59      0.57       147
weighted avg       0.60      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.58      0.57        60
           1       0.48      0.44      0.46        36
           2       0.49      0.49      0.49        51

    accuracy                           0.52       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.63      0.63        63
           1       0.30      0.31      0.31        32
           2       0.47      0.46      0.47        52

    accuracy                           0.50       147
   macro avg       0.47      0.47      0.47       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5512686155543298
F1: 0.54628722383034
======================================================
Running contraceptive 100 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.52      0.36        33
           1       0.62      0.41      0.49        51
           2       0.52      0.42      0.47        64

    accuracy                           0.44       148
   macro avg       0.47      0.45      0.44       148
weighted avg       0.50      0.44      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.68      0.61      0.65        70
           1       0.44      0.50      0.47        30
           2       0.57      0.60      0.59        48

    accuracy                           0.59       148
   macro avg       0.56      0.57      0.57       148
weighted avg       0.60      0.59      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.64      0.44        33
           1       0.59      0.33      0.42        61
           2       0.51      0.48      0.50        54

    accuracy                           0.45       148
   macro avg       0.48      0.48      0.45       148
weighted avg       0.50      0.45      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.25      0.62      0.36        26
           1       0.73      0.41      0.52        59
           2       0.63      0.52      0.57        62

    accuracy                           0.49       147
   macro avg       0.54      0.51      0.48       147
weighted avg       0.60      0.49      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.60      0.47        40
           1       0.48      0.36      0.42        44
           2       0.55      0.44      0.49        63

    accuracy                           0.46       147
   macro avg       0.47      0.47      0.46       147
weighted avg       0.48      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.50      0.35        34
           1       0.52      0.30      0.38        57
           2       0.47      0.43      0.45        56

    accuracy                           0.39       147
   macro avg       0.42      0.41      0.39       147
weighted avg       0.44      0.39      0.40       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.65      0.48        37
           1       0.64      0.41      0.50        51
           2       0.53      0.46      0.49        59

    accuracy                           0.49       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.53      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.41      0.79      0.54        33
           1       0.55      0.39      0.46        46
           2       0.55      0.41      0.47        68

    accuracy                           0.49       147
   macro avg       0.50      0.53      0.49       147
weighted avg       0.52      0.49      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.30      0.50      0.38        38
           1       0.67      0.23      0.34        96
           2       0.06      0.23      0.09        13

    accuracy                           0.30       147
   macro avg       0.34      0.32      0.27       147
weighted avg       0.52      0.30      0.33       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.14      0.47      0.22        19
           1       0.70      0.28      0.40        81
           2       0.35      0.38      0.37        47

    accuracy                           0.34       147
   macro avg       0.40      0.38      0.33       147
weighted avg       0.52      0.34      0.37       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.44457161242875526
F1: 0.4355690045184327
======================================================
Running contraceptive 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.60      0.68        84
           1       0.53      0.56      0.55        32
           2       0.31      0.50      0.38        32

    accuracy                           0.57       148
   macro avg       0.55      0.55      0.54       148
weighted avg       0.64      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.75        84
           1       0.47      0.53      0.50        30
           2       0.43      0.65      0.52        34

    accuracy                           0.63       148
   macro avg       0.59      0.61      0.59       148
weighted avg       0.69      0.63      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.51      0.60        88
           1       0.21      0.27      0.23        26
           2       0.27      0.41      0.33        34

    accuracy                           0.45       148
   macro avg       0.40      0.40      0.39       148
weighted avg       0.52      0.45      0.47       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.56      0.64        86
           1       0.58      0.46      0.51        41
           2       0.24      0.60      0.34        20

    accuracy                           0.54       147
   macro avg       0.52      0.54      0.50       147
weighted avg       0.64      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.53      0.67       110
           1       0.27      0.50      0.35        18
           2       0.22      0.58      0.31        19

    accuracy                           0.53       147
   macro avg       0.47      0.54      0.45       147
weighted avg       0.75      0.53      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.66        89
           1       0.39      0.38      0.39        34
           2       0.20      0.42      0.27        24

    accuracy                           0.50       147
   macro avg       0.46      0.45      0.44       147
weighted avg       0.60      0.50      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.68        94
           1       0.42      0.48      0.45        29
           2       0.29      0.62      0.40        24

    accuracy                           0.56       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.67      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.48      0.59      0.53        27
           2       0.35      0.49      0.41        37

    accuracy                           0.56       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.62      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.51      0.59        84
           1       0.36      0.36      0.36        33
           2       0.33      0.57      0.42        30

    accuracy                           0.49       147
   macro avg       0.46      0.48      0.46       147
weighted avg       0.54      0.49      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.62      0.69        77
           1       0.45      0.45      0.45        33
           2       0.47      0.65      0.55        37

    accuracy                           0.59       147
   macro avg       0.56      0.58      0.56       147
weighted avg       0.62      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5410599374885088
F1: 0.5166584525584417
======================================================
Running contraceptive 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.61      0.69        80
           1       0.59      0.57      0.58        35
           2       0.33      0.52      0.40        33

    accuracy                           0.58       148
   macro avg       0.57      0.57      0.56       148
weighted avg       0.64      0.58      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.75        84
           1       0.47      0.53      0.50        30
           2       0.43      0.65      0.52        34

    accuracy                           0.63       148
   macro avg       0.59      0.61      0.59       148
weighted avg       0.69      0.63      0.64       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.54      0.62        85
           1       0.29      0.43      0.35        23
           2       0.43      0.55      0.48        40

    accuracy                           0.53       148
   macro avg       0.49      0.51      0.49       148
weighted avg       0.58      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.57      0.65        84
           1       0.58      0.49      0.53        39
           2       0.31      0.67      0.43        24

    accuracy                           0.56       147
   macro avg       0.55      0.58      0.54       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.55      0.68       104
           1       0.42      0.56      0.48        25
           2       0.25      0.72      0.38        18

    accuracy                           0.57       147
   macro avg       0.53      0.61      0.51       147
weighted avg       0.74      0.57      0.61       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.66        89
           1       0.39      0.38      0.39        34
           2       0.20      0.42      0.27        24

    accuracy                           0.50       147
   macro avg       0.46      0.45      0.44       147
weighted avg       0.60      0.50      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.68        94
           1       0.42      0.48      0.45        29
           2       0.29      0.62      0.40        24

    accuracy                           0.56       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.67      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.48      0.59      0.53        27
           2       0.35      0.49      0.41        37

    accuracy                           0.56       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.62      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.51      0.55        72
           1       0.52      0.42      0.47        40
           2       0.29      0.43      0.35        35

    accuracy                           0.47       147
   macro avg       0.47      0.46      0.45       147
weighted avg       0.50      0.47      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.54      0.63        89
           1       0.39      0.41      0.40        32
           2       0.29      0.58      0.39        26

    accuracy                           0.52       147
   macro avg       0.48      0.51      0.47       147
weighted avg       0.60      0.52      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5477983085125941
F1: 0.5261067763655545
======================================================
Running contraceptive 100 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.60      0.68        84
           1       0.53      0.56      0.55        32
           2       0.31      0.50      0.38        32

    accuracy                           0.57       148
   macro avg       0.55      0.55      0.54       148
weighted avg       0.64      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.70      0.77        79
           1       0.41      0.48      0.44        29
           2       0.55      0.70      0.62        40

    accuracy                           0.66       148
   macro avg       0.61      0.63      0.61       148
weighted avg       0.70      0.66      0.67       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.51      0.60        88
           1       0.21      0.27      0.23        26
           2       0.27      0.41      0.33        34

    accuracy                           0.45       148
   macro avg       0.40      0.40      0.39       148
weighted avg       0.52      0.45      0.47       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.56      0.64        86
           1       0.58      0.46      0.51        41
           2       0.24      0.60      0.34        20

    accuracy                           0.54       147
   macro avg       0.52      0.54      0.50       147
weighted avg       0.64      0.54      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.55      0.68       104
           1       0.42      0.56      0.48        25
           2       0.25      0.72      0.38        18

    accuracy                           0.57       147
   macro avg       0.53      0.61      0.51       147
weighted avg       0.74      0.57      0.61       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.56      0.66        89
           1       0.39      0.38      0.39        34
           2       0.20      0.42      0.27        24

    accuracy                           0.50       147
   macro avg       0.46      0.45      0.44       147
weighted avg       0.60      0.50      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.68        94
           1       0.42      0.48      0.45        29
           2       0.29      0.62      0.40        24

    accuracy                           0.56       147
   macro avg       0.52      0.56      0.51       147
weighted avg       0.67      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.59      0.67        83
           1       0.48      0.59      0.53        27
           2       0.35      0.49      0.41        37

    accuracy                           0.56       147
   macro avg       0.54      0.56      0.54       147
weighted avg       0.62      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.51      0.55        72
           1       0.52      0.42      0.47        40
           2       0.29      0.43      0.35        35

    accuracy                           0.47       147
   macro avg       0.47      0.46      0.45       147
weighted avg       0.50      0.47      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.39      0.39      0.39        33
           2       0.43      0.61      0.51        36

    accuracy                           0.56       147
   macro avg       0.52      0.54      0.52       147
weighted avg       0.59      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5424020959735245
F1: 0.5201712604621997
======================================================
Running contraceptive 100 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.69      0.63      0.66        68
           1       0.50      0.59      0.54        29
           2       0.50      0.51      0.50        51

    accuracy                           0.58       148
   macro avg       0.56      0.58      0.57       148
weighted avg       0.59      0.58      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.82      0.73        50
           1       0.26      0.53      0.35        17
           2       0.78      0.49      0.61        81

    accuracy                           0.61       148
   macro avg       0.57      0.61      0.56       148
weighted avg       0.68      0.61      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.60      0.59        60
           1       0.24      0.32      0.27        25
           2       0.55      0.44      0.49        63

    accuracy                           0.49       148
   macro avg       0.45      0.45      0.45       148
weighted avg       0.51      0.49      0.49       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.63      0.67        71
           1       0.48      0.55      0.52        29
           2       0.43      0.47      0.45        47

    accuracy                           0.56       147
   macro avg       0.54      0.55      0.55       147
weighted avg       0.58      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.58      0.67        86
           1       0.30      0.67      0.42        15
           2       0.49      0.54      0.52        46

    accuracy                           0.58       147
   macro avg       0.53      0.60      0.53       147
weighted avg       0.65      0.58      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.64      0.65        66
           1       0.33      0.35      0.34        31
           2       0.47      0.48      0.48        50

    accuracy                           0.52       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.53      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.69      0.69        64
           1       0.36      0.43      0.39        28
           2       0.57      0.53      0.55        55

    accuracy                           0.58       147
   macro avg       0.54      0.55      0.54       147
weighted avg       0.59      0.58      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.71      0.67        56
           1       0.39      0.54      0.46        24
           2       0.59      0.45      0.51        67

    accuracy                           0.56       147
   macro avg       0.54      0.57      0.55       147
weighted avg       0.57      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.62      0.59        56
           1       0.55      0.60      0.57        30
           2       0.59      0.49      0.54        61

    accuracy                           0.56       147
   macro avg       0.56      0.57      0.57       147
weighted avg       0.57      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.64      0.66        67
           1       0.33      0.38      0.35        29
           2       0.51      0.51      0.51        51

    accuracy                           0.54       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.55      0.54      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5594043022614451
F1: 0.5547001876670642
======================================================
Running contraceptive 100 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.82      0.41      0.55        68
           2       0.21      0.65      0.32        17

    accuracy                           0.50       148
   macro avg       0.53      0.54      0.48       148
weighted avg       0.64      0.50      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.56      0.43      0.49        44
           2       0.29      0.58      0.39        26

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.51       148
weighted avg       0.61      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
CBEG               precision    recall  f1-score   support

           0       0.54      0.50      0.52        68
           1       0.65      0.31      0.42        70
           2       0.12      0.60      0.20        10

    accuracy                           0.42       148
   macro avg       0.43      0.47      0.38       148
weighted avg       0.56      0.42      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.59        69
           1       0.70      0.43      0.53        54
           2       0.25      0.54      0.35        24

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.59      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
CBEG               precision    recall  f1-score   support

           0       0.75      0.57      0.65        82
           1       0.64      0.44      0.52        48
           2       0.20      0.59      0.29        17

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.49       147
weighted avg       0.65      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
CBEG               precision    recall  f1-score   support

           0       0.56      0.49      0.52        72
           1       0.55      0.30      0.38        61
           2       0.16      0.57      0.25        14

    accuracy                           0.41       147
   macro avg       0.42      0.45      0.38       147
weighted avg       0.51      0.41      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.76      0.45      0.57        55
           2       0.27      0.58      0.37        24

    accuracy                           0.56       147
   macro avg       0.57      0.56      0.53       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.67      0.43      0.52        51
           2       0.25      0.57      0.35        23

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.53       147
weighted avg       0.65      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
CBEG               precision    recall  f1-score   support

           0       0.43      0.51      0.47        53
           1       0.61      0.30      0.40        67
           2       0.25      0.48      0.33        27

    accuracy                           0.41       147
   macro avg       0.43      0.43      0.40       147
weighted avg       0.48      0.41      0.41       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.55      0.27      0.36        66
           2       0.24      0.52      0.32        23

    accuracy                           0.44       147
   macro avg       0.44      0.46      0.42       147
weighted avg       0.49      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488798492369921
F1: 0.46911264360560995
======================================================
Running contraceptive 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.82      0.41      0.55        68
           2       0.21      0.65      0.32        17

    accuracy                           0.50       148
   macro avg       0.53      0.54      0.48       148
weighted avg       0.64      0.50      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.56      0.43      0.49        44
           2       0.29      0.58      0.39        26

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.51       148
weighted avg       0.61      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
CBEG               precision    recall  f1-score   support

           0       0.54      0.50      0.52        68
           1       0.65      0.31      0.42        70
           2       0.12      0.60      0.20        10

    accuracy                           0.42       148
   macro avg       0.43      0.47      0.38       148
weighted avg       0.56      0.42      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.59        69
           1       0.70      0.43      0.53        54
           2       0.25      0.54      0.35        24

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.59      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
CBEG               precision    recall  f1-score   support

           0       0.75      0.57      0.65        82
           1       0.64      0.44      0.52        48
           2       0.20      0.59      0.29        17

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.49       147
weighted avg       0.65      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
CBEG               precision    recall  f1-score   support

           0       0.56      0.49      0.52        72
           1       0.55      0.30      0.38        61
           2       0.16      0.57      0.25        14

    accuracy                           0.41       147
   macro avg       0.42      0.45      0.38       147
weighted avg       0.51      0.41      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.76      0.45      0.57        55
           2       0.27      0.58      0.37        24

    accuracy                           0.56       147
   macro avg       0.57      0.56      0.53       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.67      0.43      0.52        51
           2       0.25      0.57      0.35        23

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.53       147
weighted avg       0.65      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
CBEG               precision    recall  f1-score   support

           0       0.43      0.51      0.47        53
           1       0.61      0.30      0.40        67
           2       0.25      0.48      0.33        27

    accuracy                           0.41       147
   macro avg       0.43      0.43      0.40       147
weighted avg       0.48      0.41      0.41       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.55      0.27      0.36        66
           2       0.24      0.52      0.32        23

    accuracy                           0.44       147
   macro avg       0.44      0.46      0.42       147
weighted avg       0.49      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488798492369921
F1: 0.46911264360560995
======================================================
Running contraceptive 100 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        63
           1       0.82      0.41      0.55        68
           2       0.21      0.65      0.32        17

    accuracy                           0.50       148
   macro avg       0.53      0.54      0.48       148
weighted avg       0.64      0.50      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
CBEG               precision    recall  f1-score   support

           0       0.75      0.60      0.67        78
           1       0.56      0.43      0.49        44
           2       0.29      0.58      0.39        26

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.51       148
weighted avg       0.61      0.55      0.56       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
CBEG               precision    recall  f1-score   support

           0       0.54      0.50      0.52        68
           1       0.65      0.31      0.42        70
           2       0.12      0.60      0.20        10

    accuracy                           0.42       148
   macro avg       0.43      0.47      0.38       148
weighted avg       0.56      0.42      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
CBEG               precision    recall  f1-score   support

           0       0.62      0.57      0.59        69
           1       0.70      0.43      0.53        54
           2       0.25      0.54      0.35        24

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.49       147
weighted avg       0.59      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
CBEG               precision    recall  f1-score   support

           0       0.75      0.57      0.65        82
           1       0.64      0.44      0.52        48
           2       0.20      0.59      0.29        17

    accuracy                           0.53       147
   macro avg       0.53      0.53      0.49       147
weighted avg       0.65      0.53      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
CBEG               precision    recall  f1-score   support

           0       0.56      0.49      0.52        72
           1       0.55      0.30      0.38        61
           2       0.16      0.57      0.25        14

    accuracy                           0.41       147
   macro avg       0.42      0.45      0.38       147
weighted avg       0.51      0.41      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
CBEG               precision    recall  f1-score   support

           0       0.68      0.63      0.66        68
           1       0.76      0.45      0.57        55
           2       0.27      0.58      0.37        24

    accuracy                           0.56       147
   macro avg       0.57      0.56      0.53       147
weighted avg       0.64      0.56      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
CBEG               precision    recall  f1-score   support

           0       0.76      0.66      0.71        73
           1       0.67      0.43      0.52        51
           2       0.25      0.57      0.35        23

    accuracy                           0.56       147
   macro avg       0.56      0.55      0.53       147
weighted avg       0.65      0.56      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
CBEG               precision    recall  f1-score   support

           0       0.43      0.51      0.47        53
           1       0.61      0.30      0.40        67
           2       0.25      0.48      0.33        27

    accuracy                           0.41       147
   macro avg       0.43      0.43      0.40       147
weighted avg       0.48      0.41      0.41       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
CBEG               precision    recall  f1-score   support

           0       0.54      0.59      0.56        58
           1       0.55      0.27      0.36        66
           2       0.24      0.52      0.32        23

    accuracy                           0.44       147
   macro avg       0.44      0.46      0.42       147
weighted avg       0.49      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488798492369921
F1: 0.46911264360560995
======================================================
Running contraceptive 100 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 100 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.50      0.58      0.54        53
           1       0.79      0.47      0.59        58
           2       0.38      0.54      0.45        37

    accuracy                           0.53       148
   macro avg       0.56      0.53      0.53       148
weighted avg       0.59      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.81      0.57      0.67        89
           1       0.41      0.52      0.46        27
           2       0.35      0.56      0.43        32

    accuracy                           0.56       148
   macro avg       0.52      0.55      0.52       148
weighted avg       0.64      0.56      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.44      0.58      0.50        48
           1       0.53      0.31      0.39        58
           2       0.45      0.55      0.49        42

    accuracy                           0.47       148
   macro avg       0.47      0.48      0.46       148
weighted avg       0.48      0.47      0.46       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.65      0.48        37
           1       0.73      0.44      0.55        55
           2       0.55      0.51      0.53        55

    accuracy                           0.52       147
   macro avg       0.55      0.53      0.52       147
weighted avg       0.57      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.61      0.54        51
           1       0.58      0.45      0.51        42
           2       0.51      0.48      0.50        54

    accuracy                           0.52       147
   macro avg       0.53      0.51      0.52       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.51      0.44        47
           1       0.48      0.29      0.36        55
           2       0.43      0.49      0.46        45

    accuracy                           0.42       147
   macro avg       0.43      0.43      0.42       147
weighted avg       0.44      0.42      0.42       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.38      0.60      0.47        40
           1       0.58      0.40      0.47        47
           2       0.51      0.43      0.47        60

    accuracy                           0.47       147
   macro avg       0.49      0.48      0.47       147
weighted avg       0.50      0.47      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.49      0.70      0.58        44
           1       0.55      0.41      0.47        44
           2       0.47      0.41      0.44        59

    accuracy                           0.50       147
   macro avg       0.50      0.51      0.49       147
weighted avg       0.50      0.50      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.63      0.48      0.54        84
           1       0.55      0.30      0.38        61
           2       0.02      0.50      0.04         2

    accuracy                           0.40       147
   macro avg       0.40      0.42      0.32       147
weighted avg       0.59      0.40      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.54      0.55      0.54        62
           1       0.61      0.31      0.41        64
           2       0.25      0.62      0.36        21

    accuracy                           0.46       147
   macro avg       0.47      0.49      0.44       147
weighted avg       0.53      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4832965618679904
F1: 0.47488802214421666
======================================================
Running contraceptive 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c meta_classifier -p crossval
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.31869307836362704
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.65      0.68        68
           1       0.32      0.46      0.38        24
           2       0.58      0.54      0.56        56

    accuracy                           0.57       148
   macro avg       0.54      0.55      0.54       148
weighted avg       0.60      0.57      0.58       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), LogisticRegression(), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), LogisticRegression(), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [1, 462, 4, 206, 1, 10, 283, 358]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=13))
Best evaluation: 0.36426227491198976
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.68      0.69        65
           1       0.35      0.40      0.38        30
           2       0.55      0.53      0.54        53

    accuracy                           0.57       148
   macro avg       0.53      0.54      0.53       148
weighted avg       0.57      0.57      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), GaussianNB(), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [205, 1, 327, 199, 4, 6, 3, 1, 2, 131, 443, 1, 2]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.5019456365469138
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.60      0.57        57
           1       0.53      0.44      0.48        41
           2       0.39      0.40      0.40        50

    accuracy                           0.49       148
   macro avg       0.49      0.48      0.48       148
weighted avg       0.49      0.49      0.49       148

Selected Base Classifiers: [GaussianNB(), OneVsRestClassifier(estimator=RandomForestClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [4, 529, 5, 1, 189, 1, 2, 344, 250]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.3300939139872478
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.62      0.63        64
           1       0.42      0.50      0.46        28
           2       0.49      0.45      0.47        55

    accuracy                           0.54       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 2, 1, 271, 357, 202, 489, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.3996001808189196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.65      0.71        77
           1       0.33      0.48      0.39        23
           2       0.55      0.60      0.57        47

    accuracy                           0.61       147
   macro avg       0.56      0.57      0.56       147
weighted avg       0.64      0.61      0.62       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [238, 4, 1, 333, 4, 547, 197, 1, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.28635254458906534
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.59      0.63        71
           1       0.45      0.45      0.45        33
           2       0.37      0.44      0.40        43

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=AdaBoostClassifier())]/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]

Number of samples by cluster: [410, 1, 3, 198, 392, 322]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.3266725255191144
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.61      0.65        72
           1       0.15      0.22      0.18        23
           2       0.47      0.46      0.47        52

    accuracy                           0.50       147
   macro avg       0.44      0.43      0.43       147
weighted avg       0.53      0.50      0.51       147

Selected Base Classifiers: [GaussianNB(), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [2, 7, 560, 240, 1, 1, 180, 335]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.5042651945933182
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.66      0.63        58
           1       0.30      0.28      0.29        36
           2       0.35      0.34      0.35        53

    accuracy                           0.45       147
   macro avg       0.42      0.42      0.42       147
weighted avg       0.44      0.45      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=RandomForestClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [545, 244, 343, 2, 1, 1, 185, 3, 2]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.4157608830841409
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.60      0.56        55
           1       0.48      0.39      0.43        41
           2       0.39      0.39      0.39        51

    accuracy                           0.47       147
   macro avg       0.47      0.46      0.46       147
weighted avg       0.47      0.47      0.47       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1, 491, 359, 266, 1, 208]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.4185962921513784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.62      0.58        55
           1       0.33      0.37      0.35        30
           2       0.55      0.45      0.50        62

    accuracy                           0.50       147
   macro avg       0.47      0.48      0.47       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True)), GaussianNB(), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 189, 262, 504, 2, 11, 1, 4, 346, 3, 3]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5199806949806949
F1: 0.5164020466751054
======================================================
Running contraceptive 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.24302056784940407
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.63      0.62        60
           1       0.41      0.52      0.46        27
           2       0.54      0.46      0.50        61

    accuracy                           0.54       148
   macro avg       0.52      0.54      0.53       148
weighted avg       0.55      0.54      0.54       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 178, 555, 5, 1, 1, 247, 336, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.67      0.69        67
           1       0.29      0.53      0.38        19
           2       0.65      0.53      0.58        62

    accuracy                           0.59       148
   macro avg       0.55      0.58      0.55       148
weighted avg       0.63      0.59      0.61       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.54      0.58        72
           1       0.32      0.35      0.34        31
           2       0.41      0.47      0.44        45

    accuracy                           0.48       148
   macro avg       0.45      0.45      0.45       148
weighted avg       0.49      0.48      0.48       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.55      0.56        65
           1       0.45      0.48      0.47        31
           2       0.47      0.47      0.47        51

    accuracy                           0.51       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=12))
Best evaluation: 0.2320318035065659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.63      0.70        79
           1       0.30      0.53      0.38        19
           2       0.57      0.59      0.58        49

    accuracy                           0.61       147
   macro avg       0.56      0.58      0.56       147
weighted avg       0.66      0.61      0.62       147

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 1, 546, 1, 1, 197, 2, 1, 239, 1, 333, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=12))
Best evaluation: 0.28082867492035823
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.68      0.67        60
           1       0.36      0.40      0.38        30
           2       0.57      0.51      0.54        57

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [1, 1, 1, 189, 1, 1, 557, 241, 1, 324, 1, 8]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.65      0.65        63
           1       0.24      0.27      0.25        30
           2       0.45      0.43      0.44        54

    accuracy                           0.49       147
   macro avg       0.45      0.45      0.45       147
weighted avg       0.49      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.67      0.66        61
           1       0.48      0.40      0.44        40
           2       0.35      0.39      0.37        46

    accuracy                           0.51       147
   macro avg       0.50      0.49      0.49       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.48      0.56      0.51        54
           1       0.42      0.38      0.40        37
           2       0.43      0.39      0.41        56

    accuracy                           0.45       147
   macro avg       0.44      0.44      0.44       147
weighted avg       0.45      0.45      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.62      0.62        63
           1       0.36      0.39      0.38        31
           2       0.51      0.49      0.50        53

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5261123368266225
F1: 0.5227847329790909
======================================================
Running contraceptive 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c meta_classifier -p crossval
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.58      0.59      0.59        61
           1       0.44      0.52      0.48        29
           2       0.58      0.52      0.55        58

    accuracy                           0.55       148
   macro avg       0.53      0.54      0.54       148
weighted avg       0.55      0.55      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.23965820574953367
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.65      0.64        62
           1       0.38      0.48      0.43        27
           2       0.53      0.46      0.49        59

    accuracy                           0.54       148
   macro avg       0.52      0.53      0.52       148
weighted avg       0.55      0.54      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [532, 1, 1, 356, 1, 257, 177]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.56      0.57        66
           1       0.29      0.32      0.31        31
           2       0.51      0.51      0.51        51

    accuracy                           0.49       148
   macro avg       0.46      0.46      0.46       148
weighted avg       0.50      0.49      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.58      0.56        59
           1       0.48      0.46      0.47        35
           2       0.47      0.45      0.46        53

    accuracy                           0.50       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.25773717474911945
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.60      0.65        75
           1       0.27      0.41      0.33        22
           2       0.59      0.60      0.59        50

    accuracy                           0.57       147
   macro avg       0.53      0.54      0.52       147
weighted avg       0.61      0.57      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [246, 1, 2, 1, 1, 2, 1, 343, 531, 198]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=12))
Best evaluation: 0.24321968279652412
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.60      0.60        63
           1       0.39      0.45      0.42        29
           2       0.51      0.47      0.49        55

    accuracy                           0.52       147
   macro avg       0.50      0.51      0.50       147
weighted avg       0.53      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [510, 1, 2, 1, 1, 256, 344, 2, 1, 3, 5, 200]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]

Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.65      0.65        63
           1       0.24      0.27      0.25        30
           2       0.45      0.43      0.44        54

    accuracy                           0.49       147
   macro avg       0.45      0.45      0.45       147
weighted avg       0.49      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.31034666482469936
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.65      0.63        60
           1       0.45      0.41      0.43        37
           2       0.43      0.44      0.44        50

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.52      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [238, 2, 562, 331, 1, 1, 1, 1, 188, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.44      0.53      0.48        53
           1       0.42      0.38      0.40        37
           2       0.47      0.42      0.44        57

    accuracy                           0.45       147
   macro avg       0.45      0.44      0.44       147
weighted avg       0.45      0.45      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.24673284450477997
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.62      0.57        53
           1       0.33      0.35      0.34        31
           2       0.53      0.43      0.47        63

    accuracy                           0.48       147
   macro avg       0.46      0.47      0.46       147
weighted avg       0.49      0.48      0.48       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 204, 355, 271, 2, 1, 3, 488, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5118496047067476
F1: 0.5106166955495396
======================================================
Running contraceptive 75 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.71      0.68        56
           1       0.35      0.52      0.42        23
           2       0.63      0.48      0.55        69

    accuracy                           0.57       148
   macro avg       0.54      0.57      0.55       148
weighted avg       0.59      0.57      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.71      0.70        62
           1       0.38      0.57      0.46        23
           2       0.65      0.52      0.58        63

    accuracy                           0.61       148
   macro avg       0.58      0.60      0.58       148
weighted avg       0.63      0.61      0.61       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.49      0.55        80
           1       0.26      0.38      0.31        24
           2       0.35      0.41      0.38        44

    accuracy                           0.45       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.48      0.45      0.46       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.56      0.57        64
           1       0.58      0.56      0.57        34
           2       0.47      0.49      0.48        49

    accuracy                           0.54       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.56      0.68        96
           1       0.27      0.47      0.35        19
           2       0.27      0.44      0.34        32

    accuracy                           0.52       147
   macro avg       0.47      0.49      0.45       147
weighted avg       0.65      0.52      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.66      0.64        59
           1       0.30      0.42      0.35        24
           2       0.67      0.53      0.59        64

    accuracy                           0.56       147
   macro avg       0.53      0.54      0.53       147
weighted avg       0.59      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.66      0.66        64
           1       0.33      0.44      0.38        25
           2       0.57      0.50      0.53        58

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.57      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.68      0.70        66
           1       0.39      0.45      0.42        29
           2       0.45      0.44      0.45        52

    accuracy                           0.55       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.60      0.58        58
           1       0.42      0.44      0.43        32
           2       0.53      0.47      0.50        57

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.67      0.68        64
           1       0.30      0.42      0.35        24
           2       0.59      0.51      0.55        59

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5444704908990623
F1: 0.536865568187906
======================================================
Running contraceptive 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.71      0.68        56
           1       0.35      0.52      0.42        23
           2       0.63      0.48      0.55        69

    accuracy                           0.57       148
   macro avg       0.54      0.57      0.55       148
weighted avg       0.59      0.57      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.73      0.70        59
           1       0.35      0.57      0.44        21
           2       0.71      0.53      0.61        68

    accuracy                           0.61       148
   macro avg       0.58      0.61      0.58       148
weighted avg       0.65      0.61      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.49      0.55        80
           1       0.24      0.38      0.29        21
           2       0.39      0.43      0.41        47

    accuracy                           0.45       148
   macro avg       0.42      0.43      0.41       148
weighted avg       0.49      0.45      0.47       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.48      0.61      0.54        49
           1       0.61      0.56      0.58        36
           2       0.55      0.45      0.50        62

    accuracy                           0.53       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.54      0.53      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.61      0.69        80
           1       0.30      0.43      0.36        23
           2       0.37      0.43      0.40        44

    accuracy                           0.53       147
   macro avg       0.48      0.49      0.48       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.64      0.67        69
           1       0.21      0.41      0.28        17
           2       0.65      0.54      0.59        61

    accuracy                           0.57       147
   macro avg       0.52      0.53      0.51       147
weighted avg       0.62      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.70      0.71        66
           1       0.36      0.48      0.41        25
           2       0.57      0.52      0.54        56

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.56       147
weighted avg       0.61      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.68      0.70        66
           1       0.39      0.45      0.42        29
           2       0.45      0.44      0.45        52

    accuracy                           0.55       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.49      0.66      0.56        47
           1       0.58      0.46      0.51        41
           2       0.61      0.53      0.56        59

    accuracy                           0.55       147
   macro avg       0.56      0.55      0.55       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.67      0.68        64
           1       0.30      0.42      0.35        24
           2       0.59      0.51      0.55        59

    accuracy                           0.56       147
   macro avg       0.52      0.53      0.52       147
weighted avg       0.58      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5533048354476927
F1: 0.546349495692007
======================================================
Running contraceptive 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.71      0.68        56
           1       0.35      0.52      0.42        23
           2       0.63      0.48      0.55        69

    accuracy                           0.57       148
   macro avg       0.54      0.57      0.55       148
weighted avg       0.59      0.57      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.70      0.72        67
           1       0.32      0.58      0.42        19
           2       0.67      0.55      0.60        62

    accuracy                           0.62       148
   macro avg       0.58      0.61      0.58       148
weighted avg       0.66      0.62      0.63       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.49      0.55        80
           1       0.26      0.38      0.31        24
           2       0.35      0.41      0.38        44

    accuracy                           0.45       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.48      0.45      0.46       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.56      0.57        64
           1       0.58      0.56      0.57        34
           2       0.47      0.49      0.48        49

    accuracy                           0.54       147
   macro avg       0.54      0.54      0.54       147
weighted avg       0.54      0.54      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.61      0.69        80
           1       0.30      0.43      0.36        23
           2       0.37      0.43      0.40        44

    accuracy                           0.53       147
   macro avg       0.48      0.49      0.48       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.64      0.67        69
           1       0.21      0.41      0.28        17
           2       0.65      0.54      0.59        61

    accuracy                           0.57       147
   macro avg       0.52      0.53      0.51       147
weighted avg       0.62      0.57      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.70      0.71        66
           1       0.36      0.48      0.41        25
           2       0.57      0.52      0.54        56

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.56       147
weighted avg       0.61      0.59      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.68      0.70        66
           1       0.39      0.45      0.42        29
           2       0.45      0.44      0.45        52

    accuracy                           0.55       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.51      0.60      0.55        53
           1       0.52      0.42      0.47        40
           2       0.51      0.48      0.50        54

    accuracy                           0.51       147
   macro avg       0.51      0.50      0.50       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.69      0.67        59
           1       0.36      0.35      0.36        34
           2       0.51      0.48      0.50        54

    accuracy                           0.54       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.53      0.54      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5471823864681008
F1: 0.5407275495374196
======================================================
Running contraceptive 75 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.60      0.69        81
           1       0.59      0.61      0.60        33
           2       0.31      0.47      0.37        34

    accuracy                           0.57       148
   macro avg       0.56      0.56      0.55       148
weighted avg       0.63      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.64      0.74        86
           1       0.32      0.61      0.42        18
           2       0.59      0.68      0.63        44

    accuracy                           0.65       148
   macro avg       0.59      0.64      0.60       148
weighted avg       0.72      0.65      0.67       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.46      0.59       113
           1       0.29      0.37      0.33        27
           2       0.06      0.38      0.10         8

    accuracy                           0.44       148
   macro avg       0.39      0.40      0.34       148
weighted avg       0.69      0.44      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.56      0.63        80
           1       0.64      0.44      0.52        48
           2       0.25      0.68      0.37        19

    accuracy                           0.54       147
   macro avg       0.54      0.56      0.51       147
weighted avg       0.63      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.52      0.66       109
           1       0.33      0.52      0.41        21
           2       0.12      0.35      0.18        17

    accuracy                           0.50       147
   macro avg       0.45      0.47      0.42       147
weighted avg       0.73      0.50      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.58      0.67        86
           1       0.30      0.38      0.34        26
           2       0.33      0.49      0.40        35

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.47       147
weighted avg       0.60      0.52      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.59      0.66        79
           1       0.48      0.46      0.47        35
           2       0.35      0.55      0.43        33

    accuracy                           0.55       147
   macro avg       0.53      0.53      0.52       147
weighted avg       0.60      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.54      0.66       100
           1       0.52      0.52      0.52        33
           2       0.08      0.29      0.12        14

    accuracy                           0.51       147
   macro avg       0.48      0.45      0.43       147
weighted avg       0.71      0.51      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.52      0.60        86
           1       0.58      0.38      0.46        50
           2       0.04      0.18      0.06        11

    accuracy                           0.45       147
   macro avg       0.44      0.36      0.38       147
weighted avg       0.62      0.45      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.62      0.68        76
           1       0.39      0.41      0.40        32
           2       0.39      0.51      0.44        39

    accuracy                           0.54       147
   macro avg       0.51      0.51      0.51       147
weighted avg       0.58      0.54      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5281209781209781
F1: 0.4896778925261535
======================================================
Running contraceptive 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.60      0.69        81
           1       0.59      0.61      0.60        33
           2       0.31      0.47      0.37        34

    accuracy                           0.57       148
   macro avg       0.56      0.56      0.55       148
weighted avg       0.63      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.63      0.72        82
           1       0.47      0.52      0.49        31
           2       0.41      0.60      0.49        35

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.65      0.60      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.46      0.59       113
           1       0.29      0.37      0.33        27
           2       0.06      0.38      0.10         8

    accuracy                           0.44       148
   macro avg       0.39      0.40      0.34       148
weighted avg       0.69      0.44      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.58      0.64        77
           1       0.67      0.45      0.54        49
           2       0.27      0.67      0.39        21

    accuracy                           0.55       147
   macro avg       0.55      0.57      0.52       147
weighted avg       0.64      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.52      0.66       109
           1       0.33      0.52      0.41        21
           2       0.12      0.35      0.18        17

    accuracy                           0.50       147
   macro avg       0.45      0.47      0.42       147
weighted avg       0.73      0.50      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.53      0.64        94
           1       0.21      0.39      0.27        18
           2       0.33      0.49      0.40        35

    accuracy                           0.50       147
   macro avg       0.45      0.47      0.44       147
weighted avg       0.61      0.50      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.62      0.68        78
           1       0.42      0.47      0.44        30
           2       0.37      0.49      0.42        39

    accuracy                           0.55       147
   macro avg       0.52      0.52      0.52       147
weighted avg       0.59      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.54      0.66       100
           1       0.52      0.52      0.52        33
           2       0.08      0.29      0.12        14

    accuracy                           0.51       147
   macro avg       0.48      0.45      0.43       147
weighted avg       0.71      0.51      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.52      0.60        86
           1       0.58      0.38      0.46        50
           2       0.04      0.18      0.06        11

    accuracy                           0.45       147
   macro avg       0.44      0.36      0.38       147
weighted avg       0.62      0.45      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.58      0.66        83
           1       0.33      0.42      0.37        26
           2       0.43      0.58      0.49        38

    accuracy                           0.55       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.60      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5233912483912484
F1: 0.48443852467729476
======================================================
Running contraceptive 75 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.60      0.69        81
           1       0.59      0.61      0.60        33
           2       0.31      0.47      0.37        34

    accuracy                           0.57       148
   macro avg       0.56      0.56      0.55       148
weighted avg       0.63      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.63      0.72        82
           1       0.47      0.52      0.49        31
           2       0.41      0.60      0.49        35

    accuracy                           0.60       148
   macro avg       0.57      0.58      0.57       148
weighted avg       0.65      0.60      0.62       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.46      0.59       113
           1       0.29      0.37      0.33        27
           2       0.06      0.38      0.10         8

    accuracy                           0.44       148
   macro avg       0.39      0.40      0.34       148
weighted avg       0.69      0.44      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.56      0.63        80
           1       0.64      0.44      0.52        48
           2       0.25      0.68      0.37        19

    accuracy                           0.54       147
   macro avg       0.54      0.56      0.51       147
weighted avg       0.63      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.52      0.66       109
           1       0.33      0.52      0.41        21
           2       0.12      0.35      0.18        17

    accuracy                           0.50       147
   macro avg       0.45      0.47      0.42       147
weighted avg       0.73      0.50      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.53      0.64        94
           1       0.21      0.39      0.27        18
           2       0.33      0.49      0.40        35

    accuracy                           0.50       147
   macro avg       0.45      0.47      0.44       147
weighted avg       0.61      0.50      0.54       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.59      0.66        79
           1       0.48      0.46      0.47        35
           2       0.35      0.55      0.43        33

    accuracy                           0.55       147
   macro avg       0.53      0.53      0.52       147
weighted avg       0.60      0.55      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.54      0.66       100
           1       0.52      0.52      0.52        33
           2       0.08      0.29      0.12        14

    accuracy                           0.51       147
   macro avg       0.48      0.45      0.43       147
weighted avg       0.71      0.51      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.53      0.58        78
           1       0.61      0.35      0.44        57
           2       0.06      0.25      0.10        12

    accuracy                           0.44       147
   macro avg       0.44      0.38      0.37       147
weighted avg       0.59      0.44      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.58      0.66        83
           1       0.33      0.42      0.37        26
           2       0.43      0.58      0.49        38

    accuracy                           0.55       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.60      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5206701599558741
F1: 0.4826497425384484
======================================================
Running contraceptive 75 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 75 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.53      0.52        60
           1       0.76      0.43      0.55        61
           2       0.25      0.48      0.33        27

    accuracy                           0.48       148
   macro avg       0.51      0.48      0.47       148
weighted avg       0.57      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.56      0.67        95
           1       0.35      0.55      0.43        22
           2       0.33      0.55      0.41        31

    accuracy                           0.55       148
   macro avg       0.51      0.55      0.50       148
weighted avg       0.66      0.55      0.58       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.55      0.58        69
           1       0.62      0.33      0.43        64
           2       0.14      0.47      0.21        15

    accuracy                           0.45       148
   macro avg       0.45      0.45      0.41       148
weighted avg       0.56      0.45      0.48       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.38      0.69      0.49        35
           1       0.55      0.39      0.46        46
           2       0.57      0.44      0.50        66

    accuracy                           0.48       147
   macro avg       0.50      0.51      0.48       147
weighted avg       0.52      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.49      0.61      0.54        51
           1       0.61      0.44      0.51        45
           2       0.47      0.47      0.47        51

    accuracy                           0.51       147
   macro avg       0.52      0.51      0.51       147
weighted avg       0.52      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.41      0.60      0.49        43
           1       0.48      0.35      0.41        46
           2       0.51      0.45      0.48        58

    accuracy                           0.46       147
   macro avg       0.47      0.47      0.46       147
weighted avg       0.47      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.62      0.64        68
           1       0.55      0.40      0.46        45
           2       0.33      0.50      0.40        34

    accuracy                           0.52       147
   macro avg       0.52      0.51      0.50       147
weighted avg       0.55      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.63      0.63        63
           1       0.48      0.43      0.46        37
           2       0.33      0.36      0.35        47

    accuracy                           0.50       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.46      0.56        97
           1       0.39      0.50      0.44        26
           2       0.20      0.42      0.27        24

    accuracy                           0.46       147
   macro avg       0.43      0.46      0.42       147
weighted avg       0.57      0.46      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.51      0.59        84
           1       0.39      0.29      0.33        45
           2       0.18      0.50      0.26        18

    accuracy                           0.44       147
   macro avg       0.42      0.43      0.39       147
weighted avg       0.53      0.44      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.486068211068211
F1: 0.4727927716422469
======================================================
Running contraceptive 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c meta_classifier -p crossval
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/metrics/_scorer.py", line 140, in __call__
    score = scorer._score(
        cached_call, estimator, *args, **routed_params.get(name).score
    )
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/metrics/_scorer.py", line 388, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 216, in wrapper
    return func(*args, **kwargs)
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/metrics/_ranking.py", line 616, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
    ~~~~~~~~~~~~~~~~~~^
        array,
        ^^^^^^
    ...<2 lines>...
        allow_nan=ensure_all_finite == "allow-nan",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        X,
        ^^
    ...<4 lines>...
        input_name=input_name,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=14))
Best evaluation: 0.3391232889188861
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.60      0.61        65
           1       0.29      0.48      0.36        21
           2       0.58      0.48      0.53        62

    accuracy                           0.53       148
   macro avg       0.50      0.52      0.50       148
weighted avg       0.56      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=KNeighborsClassifier(n_neighbors=7)), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=LogisticRegression()), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), OneVsRestClassifier(estimator=RandomForestClassifier()), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [132, 427, 5, 14, 206, 307, 2, 5, 1, 205, 2, 16, 1, 2]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.46722496842753314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.67      0.63        55
           1       0.38      0.39      0.39        33
           2       0.55      0.47      0.50        60

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.51       148
weighted avg       0.53      0.53      0.52       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=RandomForestClassifier()), OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1, 1, 417, 6, 1, 217, 1, 145, 191, 345]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=16))
Best evaluation: 0.37409331479923835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.63      0.66        70
           1       0.35      0.41      0.38        29
           2       0.45      0.47      0.46        49

    accuracy                           0.53       148
   macro avg       0.50      0.50      0.50       148
weighted avg       0.55      0.53      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=GaussianNB()), GaussianNB(), OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [16, 1, 203, 4, 3, 306, 19, 409, 2, 2, 9, 1, 209, 1, 14, 126]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.36470018853382613
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.49      0.54        75
           1       0.30      0.37      0.33        27
           2       0.35      0.40      0.38        45

    accuracy                           0.44       147
   macro avg       0.41      0.42      0.41       147
weighted avg       0.46      0.44      0.45       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [4, 2, 7, 1, 183, 3, 499, 9, 264, 354]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.498777967604323
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.63      0.69        76
           1       0.36      0.46      0.41        26
           2       0.51      0.58      0.54        45

    accuracy                           0.59       147
   macro avg       0.55      0.56      0.55       147
weighted avg       0.61      0.59      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=KNeighborsClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [211, 485, 361, 1, 1, 2, 265]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=12))
Best evaluation: 0.3855296892408961
Performing feature selection.../home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]
/home/gustavo/.venv/experimentos_doutorado/lib/python3.13/site-packages/sklearn/multiclass.py:557: RuntimeWarning: invalid value encountered in divide
  Y /= np.sum(Y, axis=1)[:, np.newaxis]

Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.59      0.59        63
           1       0.30      0.30      0.30        33
           2       0.39      0.39      0.39        51

    accuracy                           0.46       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.46      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [505, 2, 1, 3, 256, 1, 2, 3, 188, 16, 343, 6]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.34932534123720926
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.62      0.61        61
           1       0.27      0.31      0.29        29
           2       0.57      0.51      0.54        57

    accuracy                           0.52       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=LogisticRegression()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), GaussianNB(), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [357, 256, 1, 1, 193, 509, 3, 6]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4989697422344429
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.62      0.60        58
           1       0.48      0.43      0.46        37
           2       0.43      0.42      0.43        52

    accuracy                           0.50       147
   macro avg       0.50      0.49      0.49       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [188, 339, 1, 241, 554, 1, 2]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5600099932531672
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.60      0.59        60
           1       0.45      0.42      0.43        36
           2       0.47      0.47      0.47        51

    accuracy                           0.51       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1, 3, 351, 1, 202, 4, 260, 2, 1, 501]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.27213582862391705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.59      0.60        64
           1       0.39      0.37      0.38        35
           2       0.43      0.46      0.44        48

    accuracy                           0.50       147
   macro avg       0.48      0.47      0.48       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=KNeighborsClassifier(n_neighbors=7)), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [389, 206, 314, 1, 412, 4]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5104798676227248
F1: 0.5077391257699322
======================================================
Running contraceptive 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.58      0.60      0.59        60
           1       0.38      0.39      0.39        33
           2       0.44      0.42      0.43        55

    accuracy                           0.49       148
   macro avg       0.47      0.47      0.47       148
weighted avg       0.49      0.49      0.49       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.62      0.56      0.59        70
           1       0.26      0.32      0.29        28
           2       0.35      0.36      0.36        50

    accuracy                           0.45       148
   macro avg       0.41      0.41      0.41       148
weighted avg       0.46      0.45      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.58      0.59        65
           1       0.32      0.35      0.34        31
           2       0.53      0.52      0.52        52

    accuracy                           0.51       148
   macro avg       0.49      0.49      0.49       148
weighted avg       0.52      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.58      0.62        72
           1       0.39      0.46      0.43        28
           2       0.43      0.47      0.45        47

    accuracy                           0.52       147
   macro avg       0.50      0.51      0.50       147
weighted avg       0.54      0.52      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.54      0.56        69
           1       0.30      0.50      0.38        20
           2       0.47      0.41      0.44        58

    accuracy                           0.48       147
   macro avg       0.45      0.48      0.46       147
weighted avg       0.50      0.48      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.66      0.65        61
           1       0.42      0.40      0.41        35
           2       0.43      0.43      0.43        51

    accuracy                           0.52       147
   macro avg       0.50      0.50      0.50       147
weighted avg       0.51      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.63      0.56      0.60        71
           1       0.30      0.37      0.33        27
           2       0.43      0.45      0.44        49

    accuracy                           0.49       147
   macro avg       0.46      0.46      0.46       147
weighted avg       0.51      0.49      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.67      0.63        55
           1       0.39      0.43      0.41        30
           2       0.51      0.42      0.46        62

    accuracy                           0.52       147
   macro avg       0.50      0.51      0.50       147
weighted avg       0.52      0.52      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.48      0.62      0.54        48
           1       0.42      0.42      0.42        33
           2       0.55      0.42      0.48        66

    accuracy                           0.49       147
   macro avg       0.48      0.49      0.48       147
weighted avg       0.50      0.49      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.52      0.60      0.56        55
           1       0.21      0.23      0.22        31
           2       0.49      0.41      0.45        61

    accuracy                           0.44       147
   macro avg       0.41      0.41      0.41       147
weighted avg       0.44      0.44      0.44       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.49085309799595517
F1: 0.48932876978079987
======================================================
Running contraceptive 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.61      0.63      0.62        60
           1       0.35      0.41      0.38        29
           2       0.48      0.42      0.45        59

    accuracy                           0.51       148
   macro avg       0.48      0.49      0.48       148
weighted avg       0.51      0.51      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.54      0.56        69
           1       0.26      0.32      0.29        28
           2       0.39      0.39      0.39        51

    accuracy                           0.45       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.46      0.45      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=RandomForestClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=13))
Best evaluation: 0.2861932798317688
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.61      0.59        59
           1       0.50      0.41      0.45        41
           2       0.39      0.42      0.40        48

    accuracy                           0.49       148
   macro avg       0.49      0.48      0.48       148
weighted avg       0.49      0.49      0.49       148

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier()), GaussianNB(), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=SVC(probability=True)), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 243, 2, 186, 551, 1, 1, 1, 1, 1, 1, 335, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.56      0.57        66
           1       0.45      0.58      0.51        26
           2       0.47      0.44      0.45        55

    accuracy                           0.52       147
   macro avg       0.50      0.52      0.51       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.3086738067417848
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.57      0.64        80
           1       0.36      0.48      0.41        25
           2       0.43      0.52      0.47        42

    accuracy                           0.54       147
   macro avg       0.51      0.53      0.51       147
weighted avg       0.58      0.54      0.56       147

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=GradientBoostingClassifier()), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 2, 1, 531, 344, 197, 1, 1, 1, 246, 1]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.61      0.61        62
           1       0.45      0.38      0.42        39
           2       0.39      0.43      0.41        46

    accuracy                           0.50       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.50      0.50      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.58      0.59        66
           1       0.27      0.35      0.31        26
           2       0.47      0.44      0.45        55

    accuracy                           0.48       147
   macro avg       0.45      0.45      0.45       147
weighted avg       0.50      0.48      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.2562465271091705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.62      0.61        61
           1       0.27      0.36      0.31        25
           2       0.47      0.39      0.43        61

    accuracy                           0.48       147
   macro avg       0.45      0.46      0.45       147
weighted avg       0.49      0.48      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=LogisticRegression()), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [568, 234, 1, 2, 192, 1, 1, 327]
Selected clustering_algorithm: fcm
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.48      0.56      0.51        54
           1       0.36      0.36      0.36        33
           2       0.47      0.40      0.43        60

    accuracy                           0.45       147
   macro avg       0.44      0.44      0.44       147
weighted avg       0.45      0.45      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.59      0.60      0.59        62
           1       0.24      0.28      0.26        29
           2       0.45      0.41      0.43        56

    accuracy                           0.46       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.47      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.488132009560581
F1: 0.4860196629746073
======================================================
Running contraceptive 50 2 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 meta_classifier crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand meta_classifier default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 meta_classifier default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.58      0.55      0.57        65
           1       0.44      0.52      0.48        29
           2       0.46      0.44      0.45        54

    accuracy                           0.51       148
   macro avg       0.49      0.51      0.50       148
weighted avg       0.51      0.51      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.55      0.62        82
           1       0.35      0.46      0.40        26
           2       0.35      0.45      0.40        40

    accuracy                           0.51       148
   macro avg       0.47      0.49      0.47       148
weighted avg       0.55      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        80
           1       0.29      0.38      0.33        26
           2       0.33      0.40      0.37        42

    accuracy                           0.44       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.47      0.44      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        62
           1       0.48      0.57      0.52        28
           2       0.49      0.44      0.46        57

    accuracy                           0.52       147
   macro avg       0.51      0.52      0.52       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.54      0.65        92
           1       0.30      0.48      0.37        21
           2       0.27      0.41      0.33        34

    accuracy                           0.50       147
   macro avg       0.46      0.48      0.45       147
weighted avg       0.60      0.50      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.55      0.56        66
           1       0.33      0.37      0.35        30
           2       0.41      0.41      0.41        51

    accuracy                           0.46       147
   macro avg       0.44      0.44      0.44       147
weighted avg       0.47      0.46      0.46       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=RandomForestClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.62      0.67        74
           1       0.30      0.53      0.38        19
           2       0.51      0.48      0.50        54

    accuracy                           0.56       147
   macro avg       0.51      0.54      0.52       147
weighted avg       0.59      0.56      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.71      0.70        62
           1       0.39      0.41      0.40        32
           2       0.49      0.47      0.48        53

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.60      0.60        63
           1       0.36      0.43      0.39        28
           2       0.49      0.45      0.47        56

    accuracy                           0.51       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.45      0.58       110
           1       0.03      0.20      0.05         5
           2       0.20      0.31      0.24        32

    accuracy                           0.41       147
   macro avg       0.34      0.32      0.29       147
weighted avg       0.64      0.41      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.49765122265122264
F1: 0.48363381676863054
======================================================
Running contraceptive 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.58      0.55      0.57        65
           1       0.44      0.52      0.48        29
           2       0.46      0.44      0.45        54

    accuracy                           0.51       148
   macro avg       0.49      0.51      0.50       148
weighted avg       0.51      0.51      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.54      0.61        84
           1       0.32      0.39      0.35        28
           2       0.29      0.42      0.34        36

    accuracy                           0.48       148
   macro avg       0.44      0.45      0.44       148
weighted avg       0.54      0.48      0.50       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        80
           1       0.29      0.38      0.33        26
           2       0.33      0.40      0.37        42

    accuracy                           0.44       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.47      0.44      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.46      0.62      0.53        47
           1       0.52      0.57      0.54        30
           2       0.57      0.41      0.48        70

    accuracy                           0.51       147
   macro avg       0.51      0.53      0.52       147
weighted avg       0.52      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.55      0.61        78
           1       0.06      0.40      0.11         5
           2       0.47      0.38      0.42        64

    accuracy                           0.47       147
   macro avg       0.40      0.44      0.38       147
weighted avg       0.57      0.47      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.57      0.53      0.55        68
           1       0.33      0.37      0.35        30
           2       0.43      0.45      0.44        49

    accuracy                           0.47       147
   macro avg       0.45      0.45      0.45       147
weighted avg       0.48      0.47      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.63      0.68        75
           1       0.21      0.39      0.27        18
           2       0.53      0.50      0.51        54

    accuracy                           0.55       147
   macro avg       0.50      0.51      0.49       147
weighted avg       0.60      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.71      0.70        62
           1       0.39      0.41      0.40        32
           2       0.49      0.47      0.48        53

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.60      0.60        63
           1       0.36      0.43      0.39        28
           2       0.49      0.45      0.47        56

    accuracy                           0.51       147
   macro avg       0.49      0.49      0.49       147
weighted avg       0.51      0.51      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.44      0.57       116
           1       0.03      0.20      0.05         5
           2       0.18      0.35      0.23        26

    accuracy                           0.41       147
   macro avg       0.34      0.33      0.29       147
weighted avg       0.67      0.41      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.49086688729545874
F1: 0.4741972828373509
======================================================
Running contraceptive 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.58      0.55      0.57        65
           1       0.44      0.52      0.48        29
           2       0.46      0.44      0.45        54

    accuracy                           0.51       148
   macro avg       0.49      0.51      0.50       148
weighted avg       0.51      0.51      0.51       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.55      0.62        82
           1       0.35      0.46      0.40        26
           2       0.35      0.45      0.40        40

    accuracy                           0.51       148
   macro avg       0.47      0.49      0.47       148
weighted avg       0.55      0.51      0.52       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        80
           1       0.29      0.38      0.33        26
           2       0.33      0.40      0.37        42

    accuracy                           0.44       148
   macro avg       0.41      0.42      0.41       148
weighted avg       0.47      0.44      0.45       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.56      0.56      0.56        62
           1       0.48      0.57      0.52        28
           2       0.49      0.44      0.46        57

    accuracy                           0.52       147
   macro avg       0.51      0.52      0.52       147
weighted avg       0.52      0.52      0.52       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.55      0.60        74
           1       0.30      0.37      0.33        27
           2       0.33      0.37      0.35        46

    accuracy                           0.46       147
   macro avg       0.43      0.43      0.43       147
weighted avg       0.49      0.46      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.56      0.61        77
           1       0.33      0.41      0.37        27
           2       0.37      0.44      0.40        43

    accuracy                           0.50       147
   macro avg       0.46      0.47      0.46       147
weighted avg       0.53      0.50      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.62      0.66        73
           1       0.21      0.44      0.29        16
           2       0.51      0.45      0.48        58

    accuracy                           0.53       147
   macro avg       0.48      0.50      0.47       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.71      0.70        62
           1       0.39      0.41      0.40        32
           2       0.49      0.47      0.48        53

    accuracy                           0.56       147
   macro avg       0.53      0.53      0.53       147
weighted avg       0.56      0.56      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.49      0.66      0.56        47
           1       0.58      0.46      0.51        41
           2       0.61      0.53      0.56        59

    accuracy                           0.55       147
   macro avg       0.56      0.55      0.55       147
weighted avg       0.56      0.55      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.71      0.47      0.57        95
           1       0.03      0.20      0.05         5
           2       0.29      0.32      0.31        47

    accuracy                           0.41       147
   macro avg       0.35      0.33      0.31       147
weighted avg       0.56      0.41      0.47       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4983314947600662
F1: 0.4870484065831504
======================================================
Running contraceptive 50 2 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 weighted_membership crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand weighted_membership default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 weighted_membership default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16771636397738277
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.54      0.65        93
           1       0.53      0.53      0.53        34
           2       0.19      0.48      0.27        21

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.48       148
weighted avg       0.66      0.53      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16646332167448175
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.56      0.68        98
           1       0.47      0.50      0.48        32
           2       0.24      0.67      0.35        18

    accuracy                           0.56       148
   macro avg       0.53      0.58      0.51       148
weighted avg       0.71      0.56      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16750419936114364
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.45      0.59       117
           1       0.29      0.36      0.32        28
           2       0.00      0.00      0.00         3

    accuracy                           0.43       148
   macro avg       0.38      0.27      0.30       148
weighted avg       0.72      0.43      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16650368711585095
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.53      0.64        94
           1       0.39      0.65      0.49        20
           2       0.35      0.55      0.43        33

    accuracy                           0.55       147
   macro avg       0.51      0.58      0.52       147
weighted avg       0.64      0.55      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16822955575409038
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       101
           1       0.33      0.50      0.40        22
           2       0.25      0.54      0.35        24

    accuracy                           0.54       147
   macro avg       0.49      0.53      0.47       147
weighted avg       0.69      0.54      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16861721392755052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.51      0.62        98
           1       0.33      0.34      0.34        32
           2       0.14      0.41      0.21        17

    accuracy                           0.46       147
   macro avg       0.42      0.42      0.39       147
weighted avg       0.62      0.46      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16396795468477654
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.54      0.67       106
           1       0.39      0.48      0.43        27
           2       0.20      0.71      0.31        14

    accuracy                           0.54       147
   macro avg       0.50      0.58      0.47       147
weighted avg       0.74      0.54      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16679957368406406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       101
           1       0.52      0.52      0.52        33
           2       0.12      0.46      0.19        13

    accuracy                           0.53       147
   macro avg       0.50      0.51      0.46       147
weighted avg       0.73      0.53      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16809170690622727
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.53      0.58        78
           1       0.61      0.35      0.44        57
           2       0.06      0.25      0.10        12

    accuracy                           0.44       147
   macro avg       0.44      0.38      0.37       147
weighted avg       0.59      0.44      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.16726351550544472
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.49      0.62       109
           1       0.24      0.53      0.33        15
           2       0.20      0.43      0.27        23

    accuracy                           0.48       147
   macro avg       0.43      0.48      0.41       147
weighted avg       0.68      0.48      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5057731200588342
F1: 0.4553980649440973
======================================================
Running contraceptive 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.54      0.65        93
           1       0.53      0.53      0.53        34
           2       0.19      0.48      0.27        21

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.48       148
weighted avg       0.66      0.53      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.56      0.68        98
           1       0.47      0.50      0.48        32
           2       0.24      0.67      0.35        18

    accuracy                           0.56       148
   macro avg       0.53      0.58      0.51       148
weighted avg       0.71      0.56      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.45      0.59       117
           1       0.29      0.36      0.32        28
           2       0.00      0.00      0.00         3

    accuracy                           0.43       148
   macro avg       0.38      0.27      0.30       148
weighted avg       0.72      0.43      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.95      0.46      0.62       131
           1       0.12      0.57      0.20         7
           2       0.12      0.67      0.20         9

    accuracy                           0.48       147
   macro avg       0.40      0.57      0.34       147
weighted avg       0.86      0.48      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.56      0.69       102
           1       0.33      0.69      0.45        16
           2       0.29      0.52      0.38        29

    accuracy                           0.56       147
   macro avg       0.51      0.59      0.50       147
weighted avg       0.72      0.56      0.60       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.79      0.51      0.62        98
           1       0.33      0.34      0.34        32
           2       0.14      0.41      0.21        17

    accuracy                           0.46       147
   macro avg       0.42      0.42      0.39       147
weighted avg       0.62      0.46      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.52      0.66       110
           1       0.33      0.48      0.39        23
           2       0.18      0.64      0.28        14

    accuracy                           0.52       147
   macro avg       0.47      0.55      0.44       147
weighted avg       0.75      0.52      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.48      0.63       123
           1       0.15      0.62      0.24         8
           2       0.14      0.44      0.21        16

    accuracy                           0.48       147
   macro avg       0.41      0.51      0.36       147
weighted avg       0.81      0.48      0.57       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.65      0.53      0.58        78
           1       0.61      0.35      0.44        57
           2       0.06      0.25      0.10        12

    accuracy                           0.44       147
   macro avg       0.44      0.38      0.37       147
weighted avg       0.59      0.44      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.48      0.63       116
           1       0.24      0.62      0.35        13
           2       0.12      0.33      0.17        18

    accuracy                           0.48       147
   macro avg       0.42      0.48      0.38       147
weighted avg       0.74      0.48      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.49352822209965064
F1: 0.4309442718950117
======================================================
Running contraceptive 50 rand majority_voting crossval...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22682886863845625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.54      0.65        93
           1       0.53      0.53      0.53        34
           2       0.19      0.48      0.27        21

    accuracy                           0.53       148
   macro avg       0.51      0.51      0.48       148
weighted avg       0.66      0.53      0.57       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [337, 988]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22735708593211673
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.56      0.68        98
           1       0.47      0.50      0.48        32
           2       0.24      0.67      0.35        18

    accuracy                           0.56       148
   macro avg       0.53      0.58      0.51       148
weighted avg       0.71      0.56      0.60       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 989]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22683830712179204
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.45      0.59       117
           1       0.29      0.36      0.32        28
           2       0.00      0.00      0.00         3

    accuracy                           0.43       148
   macro avg       0.38      0.27      0.30       148
weighted avg       0.72      0.43      0.53       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=LogisticRegression())]
Number of samples by cluster: [996, 329]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22690966634725576
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.46      0.62       134
           1       0.09      0.50      0.15         6
           2       0.10      0.71      0.17         7

    accuracy                           0.47       147
   macro avg       0.39      0.56      0.32       147
weighted avg       0.89      0.47      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [1000, 326]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2285626081146608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       101
           1       0.33      0.50      0.40        22
           2       0.25      0.54      0.35        24

    accuracy                           0.54       147
   macro avg       0.49      0.53      0.47       147
weighted avg       0.69      0.54      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [995, 331]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22781360878486318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.50      0.59        92
           1       0.21      0.39      0.27        18
           2       0.29      0.41      0.34        37

    accuracy                           0.46       147
   macro avg       0.41      0.43      0.40       147
weighted avg       0.56      0.46      0.49       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [991, 335]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2259189580111986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.52      0.66       110
           1       0.33      0.48      0.39        23
           2       0.18      0.64      0.28        14

    accuracy                           0.52       147
   macro avg       0.47      0.55      0.44       147
weighted avg       0.75      0.52      0.58       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=SVC(probability=True)), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [336, 990]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22580432286979624
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.54      0.67       101
           1       0.52      0.52      0.52        33
           2       0.12      0.46      0.19        13

    accuracy                           0.53       147
   macro avg       0.50      0.51      0.46       147
weighted avg       0.73      0.53      0.59       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=GradientBoostingClassifier())]
Number of samples by cluster: [328, 998]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.22837856518060431
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.54      0.60        80
           1       0.55      0.44      0.49        41
           2       0.27      0.54      0.36        26

    accuracy                           0.51       147
   macro avg       0.50      0.50      0.48       147
weighted avg       0.57      0.51      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GradientBoostingClassifier()), OneVsRestClassifier(estimator=AdaBoostClassifier())]
Number of samples by cluster: [333, 993]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2278897314597301
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.49      0.62       109
           1       0.24      0.53      0.33        15
           2       0.20      0.43      0.27        23

    accuracy                           0.48       147
   macro avg       0.43      0.48      0.41       147
weighted avg       0.68      0.48      0.53       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=AdaBoostClassifier()), OneVsRestClassifier(estimator=SVC(probability=True))]
Number of samples by cluster: [330, 996]
Selected clustering_algorithm: kmeans
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5030520316234603
F1: 0.4487239777322804
======================================================
Running contraceptive 50 2 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 majority_voting crossval
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 rand majority_voting default...
======================================================
python cbeg.py -d contraceptive -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 2 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running contraceptive 50 3 majority_voting default
======================================================
python cbeg.py -d contraceptive -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.68      0.57      0.62        74
           1       0.59      0.51      0.55        39
           2       0.33      0.49      0.39        35

    accuracy                           0.53       148
   macro avg       0.53      0.52      0.52       148
weighted avg       0.57      0.53      0.55       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [197, 854, 274]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.56      0.66        91
           1       0.35      0.50      0.41        24
           2       0.41      0.64      0.50        33

    accuracy                           0.57       148
   macro avg       0.52      0.57      0.53       148
weighted avg       0.65      0.57      0.59       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [327, 589, 409]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.58      0.65        79
           1       0.62      0.36      0.45        59
           2       0.10      0.50      0.16        10

    accuracy                           0.49       148
   macro avg       0.48      0.48      0.42       148
weighted avg       0.64      0.49      0.54       148

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [269, 858, 198]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.54      0.64        91
           1       0.55      0.46      0.50        39
           2       0.14      0.41      0.21        17

    accuracy                           0.50       147
   macro avg       0.49      0.47      0.45       147
weighted avg       0.64      0.50      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [263, 866, 197]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.37      0.49      0.42        47
           1       0.24      0.80      0.37        10
           2       0.67      0.38      0.48        90

    accuracy                           0.44       147
   macro avg       0.42      0.56      0.42       147
weighted avg       0.54      0.44      0.45       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [265, 201, 860]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.54      0.61      0.57        56
           1       0.42      0.34      0.38        41
           2       0.47      0.48      0.48        50

    accuracy                           0.49       147
   macro avg       0.48      0.48      0.48       147
weighted avg       0.48      0.49      0.48       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [268, 858, 200]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.62      0.69        79
           1       0.48      0.41      0.44        39
           2       0.29      0.52      0.38        29

    accuracy                           0.54       147
   macro avg       0.52      0.52      0.50       147
weighted avg       0.60      0.54      0.56       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [273, 859, 194]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.62      0.67        74
           1       0.55      0.45      0.49        40
           2       0.27      0.42      0.33        33

    accuracy                           0.53       147
   macro avg       0.52      0.50      0.50       147
weighted avg       0.58      0.53      0.55       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [270, 194, 862]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.47      0.57        97
           1       0.48      0.55      0.52        29
           2       0.14      0.33      0.19        21

    accuracy                           0.47       147
   macro avg       0.45      0.45      0.43       147
weighted avg       0.60      0.47      0.51       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [330, 561, 435]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.49      0.56        86
           1       0.27      0.36      0.31        25
           2       0.39      0.56      0.46        36

    accuracy                           0.48       147
   macro avg       0.44      0.47      0.44       147
weighted avg       0.53      0.48      0.50       147

Selected Base Classifiers: [OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB()), OneVsRestClassifier(estimator=GaussianNB())]
Number of samples by cluster: [329, 492, 505]
Selected clustering_algorithm: kmeans++
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/contraceptive/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5050422871851443
F1: 0.48288040459337517
======================================================
Running wine 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.62      0.71         8
           1       0.71      0.71      0.71         7
           2       0.60      1.00      0.75         3

    accuracy                           0.72        18
   macro avg       0.72      0.78      0.73        18
weighted avg       0.75      0.72      0.72        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [37, 22, 19, 37, 45]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535066
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.71      0.71      0.71         7
           2       0.60      0.75      0.67         4

    accuracy                           0.78        18
   macro avg       0.77      0.77      0.77        18
weighted avg       0.80      0.78      0.78        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 37, 21, 35, 22]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.83      0.77         6
           2       0.80      1.00      0.89         4

    accuracy                           0.83        18
   macro avg       0.84      0.86      0.84        18
weighted avg       0.86      0.83      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6695550800443301
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.44      0.53         9
           1       0.57      0.57      0.57         7
           2       0.00      0.00      0.00         2

    accuracy                           0.44        18
   macro avg       0.41      0.34      0.37        18
weighted avg       0.56      0.44      0.49        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 38, 42, 38, 21]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6490015686411414
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [23, 17, 46, 39, 35]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       1.00      0.88      0.93         8
           2       0.80      1.00      0.89         4

    accuracy                           0.89        18
   macro avg       0.88      0.90      0.89        18
weighted avg       0.90      0.89      0.89        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.59736842, 0.19367589, 0.4171123 , 0.32989691, 0.26086957,
        0.48965517, 0.39029536, 0.28      , 0.29652997, 0.2278157 ,
        0.43902439, 0.54945055, 0.71825963],
       [0.64736842, 0.56324111, 0.44385027, 0.45876289, 0.19565217,
        0.22068966, 0.02953586, 0.9       , 0.14826498, 0.37713311,
        0.26829268, 0.2014652 , 0.21540656],
       [0.33157895, 0.13241107, 0.3315508 , 0.27835052, 0.16304348,
        0.54137931, 0.4556962 , 0.32      , 0.42902208, 0.13822526,
        0.6097561 , 0.53846154, 0.10699001],
       [0.67105263, 0.18181818, 0.53475936, 0.43814433, 0.39130435,
        0.64827586, 0.60126582, 0.18      , 0.48580442, 0.47952218,
        0.49593496, 0.58974359, 0.88231098]]),
       n_clusters=4))
Best evaluation: 0.567772796203821
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.71      0.71         7
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.77      0.82      0.77        18
weighted avg       0.82      0.78      0.78        18

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 50, 51, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.71      0.77         7
           1       0.71      0.83      0.77         6
           2       1.00      1.00      1.00         5

    accuracy                           0.83        18
   macro avg       0.85      0.85      0.85        18
weighted avg       0.84      0.83      0.83        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       0.86      0.86      0.86         7
           2       0.75      0.60      0.67         5

    accuracy                           0.82        17
   macro avg       0.81      0.82      0.81        17
weighted avg       0.82      0.82      0.82        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.88      1.00      0.93         7
           2       1.00      1.00      1.00         4

    accuracy                           0.94        17
   macro avg       0.96      0.94      0.95        17
weighted avg       0.95      0.94      0.94        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7986928104575164
F1: 0.793576789949339
======================================================
Running wine 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.71      0.83      0.77         6
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.77      0.83      0.77        18
weighted avg       0.84      0.78      0.78        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [22, 37, 45, 19, 37]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41297413582197956
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.71      0.71      0.71         7
           2       0.60      0.75      0.67         4

    accuracy                           0.78        18
   macro avg       0.77      0.77      0.77        18
weighted avg       0.80      0.78      0.78        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 21, 45, 22, 35]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.71      1.00      0.83         5
           2       0.80      1.00      0.89         4

    accuracy                           0.83        18
   macro avg       0.84      0.89      0.84        18
weighted avg       0.88      0.83      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.44      0.53         9
           1       0.57      0.57      0.57         7
           2       0.00      0.00      0.00         2

    accuracy                           0.44        18
   macro avg       0.41      0.34      0.37        18
weighted avg       0.56      0.44      0.49        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [42, 21, 38, 21, 38]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.78      0.88         9
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.93      0.88        18
weighted avg       0.93      0.89      0.90        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       1.00      1.00      1.00         7
           2       0.80      1.00      0.89         4

    accuracy                           0.94        18
   macro avg       0.93      0.95      0.94        18
weighted avg       0.96      0.94      0.95        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      1.00      0.92         6
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.95      0.95      0.95        18
weighted avg       0.95      0.94      0.94        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       0.86      0.86      0.86         7
           2       0.75      0.60      0.67         5

    accuracy                           0.82        17
   macro avg       0.81      0.82      0.81        17
weighted avg       0.82      0.82      0.82        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.19210526, 0.39511202, 0.8342246 , 0.48453608, 0.35869565,
        0.26551724, 0.35654008, 0.88679245, 0.20189274, 0.21501706,
        0.6097561 , 0.45054945, 0.23466476],
       [0.64473684, 0.21792261, 0.56149733, 0.51030928, 0.32608696,
        0.59310345, 0.55696203, 0.24528302, 0.45741325, 0.32593857,
        0.45528455, 0.80586081, 0.45791726],
       [0.41315789, 0.3503055 , 0.44919786, 0.40721649...
        0.22068966, 0.06751055, 0.94339623, 0.16719243, 0.49658703,
        0.20325203, 0.11355311, 0.29743224],
       [0.44473684, 0.20570265, 0.49197861, 0.61340206, 0.15217391,
        0.13793103, 0.29957806, 0.66037736, 0.38485804, 0.17235495,
        0.32520325, 0.42124542, 0.14978602],
       [0.62368421, 0.78615071, 0.80213904, 0.74226804, 0.45652174,
        0.34482759, 0.13080169, 0.26415094, 0.22082019, 0.61604096,
        0.15447154, 0.23809524, 0.2510699 ]]),
       n_clusters=5))
Best evaluation: 0.4252354376663423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      1.00      0.89         4
           1       1.00      0.89      0.94         9
           2       1.00      1.00      1.00         4

    accuracy                           0.94        17
   macro avg       0.93      0.96      0.94        17
weighted avg       0.95      0.94      0.94        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 57, 29, 37, 17]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8375816993464051
F1: 0.8322636693585366
======================================================
Running wine 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.71      0.83      0.77         6
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.77      0.83      0.77        18
weighted avg       0.84      0.78      0.78        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 45, 37, 22, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41127676811404223
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       0.86      0.75      0.80         8
           2       0.60      0.75      0.67         4

    accuracy                           0.83        18
   macro avg       0.82      0.83      0.82        18
weighted avg       0.85      0.83      0.84        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 34, 23, 21, 37]
Selected clustering_algorithm: fcm
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.71      1.00      0.83         5
           2       0.80      1.00      0.89         4

    accuracy                           0.83        18
   macro avg       0.84      0.89      0.84        18
weighted avg       0.88      0.83      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.62368421, 0.62648221, 0.59893048, 0.63917526, 0.34782609,
        0.25179856, 0.06073753, 0.56603774, 0.31545741, 0.51365188,
        0.17886179, 0.10943396, 0.36595068],
       [0.66578947, 0.1916996 , 0.50802139, 0.28865979, 0.51086957,
        0.73741007, 0.61171367, 0.39622642, 0.60883281, 0.41382253,
        0.38211382, 0.79622642, 0.4017502 ],
       [0.47894737, 0.5       , 0.65240642, 0.58762887, 0.39130435,
        0.19784173, 0.02819957, 0.88679245, 0.17350158, 0.3668942 ,
        0.31707317, 0.31698113, 0.22275259],
       [0.83421053, 0.20158103, 0.5828877 , 0.2371134 , 0.45652174,
        0.78057554, 0.63340564, 0.39622642, 0.49211356, 0.46672355,
        0.46341463, 0.59622642, 0.92283214]]),
       n_clusters=4))
Best evaluation: 0.5124074935584704
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.43      0.46         7
           1       0.86      0.86      0.86         7
           2       0.20      0.25      0.22         4

    accuracy                           0.56        18
   macro avg       0.52      0.51      0.51        18
weighted avg       0.57      0.56      0.56        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 32, 35, 50]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       1.00      0.78      0.88         9
           2       0.60      1.00      0.75         3

    accuracy                           0.83        18
   macro avg       0.81      0.87      0.82        18
weighted avg       0.88      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       1.00      1.00      1.00         7
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.92      0.87        18
weighted avg       0.93      0.89      0.89        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.78      0.88         9
           2       0.80      1.00      0.89         4

    accuracy                           0.89        18
   macro avg       0.88      0.93      0.89        18
weighted avg       0.91      0.89      0.89        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      1.00      0.92         6
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.95      0.95      0.95        18
weighted avg       0.95      0.94      0.94        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.67      0.44         3
           1       0.86      0.67      0.75         9
           2       0.50      0.40      0.44         5

    accuracy                           0.59        17
   macro avg       0.56      0.58      0.55        17
weighted avg       0.66      0.59      0.61        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         8
           2       1.00      1.00      1.00         4

    accuracy                           1.00        17
   macro avg       1.00      1.00      1.00        17
weighted avg       1.00      1.00      1.00        17

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8143790849673203
F1: 0.810459007223713
======================================================
Running wine 100 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.86      0.86      0.86         7
           2       0.40      1.00      0.57         2

    accuracy                           0.78        18
   macro avg       0.75      0.84      0.74        18
weighted avg       0.88      0.78      0.80        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [55, 59, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.71      0.83      0.77         6
           2       0.80      0.80      0.80         5

    accuracy                           0.83        18
   macro avg       0.84      0.83      0.83        18
weighted avg       0.85      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [57, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.57      0.67      0.62         6
           2       0.60      0.75      0.67         4

    accuracy                           0.72        18
   macro avg       0.72      0.72      0.71        18
weighted avg       0.77      0.72      0.73        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [46, 55, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      1.00      0.80         4
           1       1.00      0.88      0.93         8
           2       1.00      0.83      0.91         6

    accuracy                           0.89        18
   macro avg       0.89      0.90      0.88        18
weighted avg       0.93      0.89      0.90        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [58, 56, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      0.62      0.71         8
           1       0.71      0.71      0.71         7
           2       0.60      1.00      0.75         3

    accuracy                           0.72        18
   macro avg       0.72      0.78      0.73        18
weighted avg       0.75      0.72      0.72        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 54, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.71      1.00      0.83         5
           2       0.40      1.00      0.57         2

    accuracy                           0.72        18
   macro avg       0.70      0.85      0.70        18
weighted avg       0.85      0.72      0.73        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [56, 58, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [59, 46, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.44      0.53         9
           1       0.71      0.83      0.77         6
           2       0.20      0.33      0.25         3

    accuracy                           0.56        18
   macro avg       0.53      0.54      0.52        18
weighted avg       0.60      0.56      0.56        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 55, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         4

    accuracy                           1.00        17
   macro avg       1.00      1.00      1.00        17
weighted avg       1.00      1.00      1.00        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [2, 98, 61]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.50      1.00      0.67         4
           2       1.00      0.57      0.73         7

    accuracy                           0.76        17
   macro avg       0.83      0.80      0.77        17
weighted avg       0.88      0.76      0.78        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 47, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7931372549019609
F1: 0.7864832008949657
======================================================
Running wine 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4653450890660529
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.14      0.20        18
weighted avg       0.78      0.33      0.47        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 42, 45, 22, 39]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.62634409, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.43542435, 0.35805991],
       [0.66666667, 0.20948617, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.30188679, 0.35646688, 0.24914676,
        0.50406504, 0.58302583, 0.58273894],
       [0.26075269, 0.53162055, 0.34224599, 0.43298969, 0.18478261,
        0.35172414, 0.2742616 , 0.45283019, 0.46056782, 0.        ,
        0.36585366, 0.64944649, 0.20399429],
       [0.57258065, 0.3201581 , 0.70053476, 0.41237113, 0.33695652,
        0.62758621, 0.61181435, 0.32075472, 0.75709779, 0.37542662,
        0.44715447, 0.69372694, 0.64693295]]),
       n_clusters=4))
Best evaluation: 0.5599709024279664
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 28, 55, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.97894737, 0.19565217, 0.55080214, 0.04123711, 0.22826087,
        0.71942446, 0.69848156, 0.56603774, 0.75709779, 0.35153584,
        0.62601626, 0.5509434 , 0.68416866],
       [0.45789474, 0.53162055, 0.3315508 , 0.27835052, 0.10869565,
        0.19064748, 0.1691974 , 0.56603774, 0.13249211, 0.18088737,
        0.17886179, 0.32075472, 0.06523469],
       [0.35263158, 0.09288538, 0.64171123, 0.38659794, 0.30434783,
        0.47482014, 0.47288503, 0.45283019, 0.52681388, 0.28327645,
        0.57723577, 0.38867925, 0.30867144],
       [0.68421053, 0.21146245, 0.71657754, 0.34020619, 0.45652174,
        0.6294964 , 0.52928416, 0.32075472, 0.33123028, 0.51365188,
        0.6504065 , 0.60754717, 0.81145585]]),
       n_clusters=4))
Best evaluation: 0.5700360906880176
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [22, 49, 56, 33]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.83157895, 0.16798419, 0.59893048, 0.30412371, 0.41304348,
        0.8       , 0.75738397, 0.38      , 0.45741325, 0.6331058 ,
        0.6097561 , 0.56776557, 1.        ],
       [0.1       , 0.        , 0.60962567, 0.53608247, 0.19565217,
        0.51724138, 0.35232068, 0.58      , 0.32492114, 0.15358362,
        0.50406504, 0.38095238, 0.11126961],
       [0.37368421, 0.45256917, 0.68449198, 0.84536082, 0.29347826,
        0.31724138, 0.05063291, 1.        , 0.23028391, 0.53071672,
        0.15447154, 0.16849817, 0.42938659],
       [0.53157895, 0.20355731, 0.39572193, 0.32989691, 0.40217391,
        0.69655172, 0.56118143, 0.3       , 0.51104101, 0.32081911,
        0.32520325, 0.76190476, 0.43295292]]),
       n_clusters=4))
Best evaluation: 0.5527999689282258
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [48, 38, 45, 29]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.22105263, 0.69653768, 0.55080214, 0.53608247, 0.13043478,
        0.64827586, 0.56751055, 0.1509434 , 0.87108014, 0.12969283,
        0.2195122 , 0.86813187, 0.07275321],
       [0.69736842, 0.19144603, 0.53475936, 0.34020619, 0.36956522,
        0.49655172, 0.49578059, 0.54716981, 0.54355401, 0.21843003,
        0.6097561 , 0.58608059, 0.50784593],
       [0.67105263, 0.15682281, 0.53475936, 0.43814433...
        0.64827586, 0.60126582, 0.16981132, 0.53658537, 0.47952218,
        0.49593496, 0.58974359, 0.88231098],
       [0.24473684, 0.0407332 , 0.5026738 , 0.53608247, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.43205575, 0.16467577,
        0.41463415, 0.68131868, 0.43366619],
       [0.48684211, 0.42769857, 0.55614973, 0.48453608, 0.36956522,
        0.11034483, 0.18565401, 0.20754717, 0.14634146, 0.35153584,
        0.21138211, 0.05494505, 0.17974322]]),
       n_clusters=5))
Best evaluation: 0.6446094444964562
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [16, 27, 40, 32, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.32105263, 0.20162933, 0.40641711, 0.43298969, 0.10869565,
        0.23103448, 0.35654008, 0.45283019, 0.38485804, 0.18088737,
        0.42276423, 0.6959707 , 0.16547789],
       [0.63684211, 0.60285132, 0.6631016 , 0.63917526, 0.44565217,
        0.24827586, 0.12236287, 0.56603774, 0.33123028, 0.80204778,
        0.30081301, 0.10622711, 0.29743224],
       [0.64473684, 0.21792261, 0.56149733, 0.5103092...
        0.59310345, 0.55696203, 0.24528302, 0.45741325, 0.32593857,
        0.45528455, 0.80586081, 0.45791726],
       [0.83421053, 0.20773931, 0.5828877 , 0.2371134 , 0.45652174,
        0.78965517, 0.64345992, 0.39622642, 0.49211356, 0.46672355,
        0.46341463, 0.57875458, 0.83594864],
       [0.37894737, 0.15885947, 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.4981685 , 0.4700428 ]]),
       n_clusters=5))
Best evaluation: 0.6400174254642641
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [40, 46, 29, 42, 4]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.365032679738562
F1: 0.23930013570880443
======================================================
Running wine 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.79      0.56      0.65        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3600583718121295
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.79      0.56      0.65        18

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25526316, 0.15217391, 0.56684492, 0.58762887, 0.17391304,
        0.12589928, 0.1691974 , 0.69811321, 0.38485804, 0.19795222,
        0.46341463, 0.52075472, 0.12728719],
       [0.75526316, 0.18577075, 0.40641711, 0.27835052, 0.33695652,
        0.71942446, 0.63340564, 0.1509434 , 0.54574132, 0.4112628 ,
        0.3495935 , 0.77735849, 0.55290374],
       [0.58947368, 0.69960474, 0.48128342, 0.48453608,...
        0.17625899, 0.04772234, 0.56603774, 0.29652997, 0.76109215,
        0.08943089, 0.10943396, 0.433572  ],
       [0.35263158, 0.09288538, 0.64171123, 0.38659794, 0.30434783,
        0.47482014, 0.47288503, 0.45283019, 0.52681388, 0.28327645,
        0.57723577, 0.38867925, 0.30867144],
       [0.35263158, 0.08498024, 0.29946524, 0.46391753, 0.08695652,
        0.36330935, 0.3318872 , 0.26415094, 0.19873817, 0.29010239,
        0.5203252 , 0.83396226, 0.17501989]]),
       n_clusters=5))
Best evaluation: 0.44333445166561714
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 50, 42, 22, 25]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.29736842, 0.17718941, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.36277603, 0.09982935,
        0.69105691, 0.36263736, 0.15477889],
       [0.81315789, 0.15071283, 0.51336898, 0.31958763, 0.27173913,
        0.42068966, 0.44092827, 0.24528302, 0.3659306 , 0.31740614,
        0.56097561, 0.56776557, 0.7146933 ],
       [0.63684211, 0.60285132, 0.6631016 , 0.63917526,...
        0.24827586, 0.12236287, 0.56603774, 0.33123028, 0.80204778,
        0.30081301, 0.10622711, 0.29743224],
       [0.65526316, 0.49490835, 0.72727273, 0.66494845, 0.29347826,
        0.19655172, 0.03797468, 0.69811321, 0.04416404, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.34210526, 0.0509165 , 0.31550802, 0.21649485, 0.7173913 ,
        0.31724138, 0.3185654 , 0.41509434, 0.74132492, 0.18088737,
        0.47154472, 0.38095238, 0.33666191]]),
       n_clusters=5))
Best evaluation: 0.4394904936916008
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 59, 24, 27, 5]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.403921568627451
F1: 0.2752893643450919
======================================================
Running wine 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.78684211, 0.18577075, 0.33333333, 0.24731183, 0.2826087 ,
        0.57586207, 0.41983122, 0.24528302, 0.49367089, 0.29180887,
        0.45528455, 0.84981685, 0.53994294],
       [0.60263158, 0.49407115, 0.44444444, 0.54301075, 0.23913043,
        0.32758621, 0.08860759, 0.60377358, 0.26265823, 0.60921502,
        0.05691057, 0.12820513, 0.26533524],
       [0.11052632, 0.32806324, 0.47058824, 0.46236559, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.44620253, 0.16808874,
        0.2601626 , 0.77655678, 0.24750357],
       [0.37894737, 0.1541502 , 0.32679739, 0.40860215, 1.        ,
        0.52413793, 0.407173  , 0.35849057, 0.90506329, 0.11262799,
        0.55284553, 0.4981685 , 0.4700428 ]]),
       n_clusters=4))
Best evaluation: 0.4386061770314367
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.12      0.18        18
weighted avg       0.89      0.33      0.48        18

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [55, 47, 53, 5]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3600583718121295
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.50      0.59        10
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.42      0.48        18
weighted avg       0.84      0.61      0.71        18

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.67105263, 0.18181818, 0.53475936, 0.43814433, 0.39130435,
        0.63309353, 0.59002169, 0.16981132, 0.48580442, 0.47952218,
        0.49593496, 0.60754717, 0.97454256],
       [0.43947368, 0.61857708, 0.55614973, 0.63917526, 0.33695652,
        0.62230216, 0.45119306, 0.56603774, 0.48580442, 0.11006826,
        0.57723577, 0.70188679, 0.13762928],
       [0.46315789, 0.38142292, 0.59893048, 0.58762887, 0.45652174,
        0.13669065, 0.19305857, 0.20754717, 0.2681388 , 0.81228669,
        0.        , 0.0754717 , 0.15115354],
       [0.71315789, 0.18379447, 0.47593583, 0.29896907, 0.52173913,
        0.53956835, 0.52711497, 0.1509434 , 0.38170347, 0.38993174,
        0.35772358, 0.72830189, 0.61256961]]),
       n_clusters=4))
Best evaluation: 0.4113619651453793
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [50, 39, 45, 26]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.20789474, 0.14426877, 0.3368984 , 0.5257732 , 0.0952381 ,
        0.34482759, 0.26582278, 0.32075472, 0.3533123 , 0.05716724,
        0.35042735, 0.75457875, 0.15477889],
       [0.83421053, 0.20158103, 0.5828877 , 0.2371134 , 0.4047619 ,
        0.78965517, 0.64345992, 0.39622642, 0.49211356, 0.46672355,
        0.43589744, 0.57875458, 0.83594864],
       [0.70526316, 0.97035573, 0.5828877 , 0.51030928, 0.20...
        0.24137931, 0.05696203, 0.73584906, 0.20504732, 0.54778157,
        0.08547009, 0.17216117, 0.32952924],
       [0.5       , 0.60474308, 0.68983957, 0.41237113, 0.28571429,
        0.49310345, 0.43670886, 0.22641509, 0.49526814, 0.27474403,
        0.41880342, 0.82417582, 0.35092725],
       [0.47631579, 0.43873518, 0.6684492 , 0.69072165, 0.27380952,
        0.46206897, 0.05485232, 0.75471698, 0.12618297, 0.3105802 ,
        0.2991453 , 0.32234432, 0.22253923]]),
       n_clusters=5))
Best evaluation: 0.43223262184269706
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [39, 50, 28, 16, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.45      0.59        11
           1       0.14      0.14      0.14         7
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.20      0.24        18
weighted avg       0.56      0.33      0.42        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.62321792, 0.68983957, 0.41237113, 0.34782609,
        0.49310345, 0.43670886, 0.22641509, 0.49526814, 0.27474403,
        0.44715447, 0.82417582, 0.35092725],
       [0.47894737, 0.51527495, 0.65240642, 0.58762887, 0.39130435,
        0.23103448, 0.05485232, 0.88679245, 0.17350158, 0.3668942 ,
        0.31707317, 0.30769231, 0.20827389],
       [0.27631579, 0.13238289, 0.60962567, 0.61340206, 0.15...
        0.54482759, 0.41139241, 0.56603774, 0.19873817, 0.13822526,
        0.36585366, 0.7032967 , 0.07631954],
       [0.67105263, 0.37474542, 0.71122995, 0.71649485, 0.38043478,
        0.19655172, 0.10548523, 0.49056604, 0.35646688, 0.62969283,
        0.21138211, 0.19413919, 0.33666191],
       [0.72105263, 0.23625255, 0.70588235, 0.33505155, 0.48913043,
        0.69655172, 0.51687764, 0.49056604, 0.40063091, 0.42832765,
        0.52845528, 0.60805861, 0.78245364]]),
       n_clusters=5))
Best evaluation: 0.41526692088801775
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 24, 41, 22, 48]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.38725490196078427
F1: 0.2648625285389991
======================================================
Running wine 100 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.43      0.43      0.43         7
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.32      0.38        18
weighted avg       0.78      0.50      0.60        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 59, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [58, 56, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.55      0.67        11
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.47      0.53        18
weighted avg       0.91      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [56, 55, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.54      0.70        13
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.61      0.51      0.54        18
weighted avg       0.95      0.67      0.76        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 57, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.86      0.50      0.63        12
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.56      0.44      0.49        18
weighted avg       0.85      0.61      0.70        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 47, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [58, 56, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [55, 59, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 46, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.33      0.31         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.43      0.29      0.34        17
weighted avg       0.75      0.47      0.57        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [58, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [59, 47, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4820261437908496
F1: 0.3785465066779945
======================================================
Running wine 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4653450890660529
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.55      0.67        11
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.47      0.53        18
weighted avg       0.91      0.67      0.77        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 42, 45, 22, 39]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.85752688, 0.64229249, 0.61497326, 0.13402062, 0.63043478,
        0.69655172, 0.56962025, 0.13207547, 0.52681388, 0.32593857,
        0.33333333, 0.82656827, 0.34379458],
       [0.51075269, 0.40909091, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.37638376, 0.2296719 ],
       [0.33870968, 0.48023715, 0.45454545, 0.3814433...
        0.64482759, 0.55907173, 0.60377358, 0.75709779, 0.08703072,
        0.76422764, 0.56826568, 0.09129815],
       [0.65053763, 0.58498024, 0.6631016 , 0.63917526, 0.44565217,
        0.24827586, 0.12236287, 0.56603774, 0.33123028, 0.80204778,
        0.30081301, 0.099631  , 0.29743224],
       [0.66397849, 0.21146245, 0.6684492 , 0.48453608, 0.2826087 ,
        0.53448276, 0.47890295, 0.28301887, 0.39432177, 0.19112628,
        0.5203252 , 0.93357934, 0.40442225]]),
       n_clusters=5))
Best evaluation: 0.6485872237971781
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [31, 21, 40, 41, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25526316, 0.15217391, 0.56684492, 0.58762887, 0.17391304,
        0.12589928, 0.1691974 , 0.69811321, 0.38485804, 0.19795222,
        0.46341463, 0.52075472, 0.12728719],
       [0.74473684, 0.15217391, 0.70053476, 0.74226804, 0.17391304,
        0.66546763, 0.51843818, 0.1509434 , 0.46056782, 0.17918089,
        0.71544715, 0.71320755, 0.09546539],
       [0.84210526, 0.1916996 , 0.57219251, 0.25773196...
        0.61151079, 0.56182213, 0.28301887, 0.59305994, 0.37201365,
        0.45528455, 1.        , 0.61654733],
       [0.32105263, 0.78656126, 0.63101604, 0.53608247, 0.20652174,
        0.10071942, 0.        , 0.75471698, 0.12302839, 0.21928328,
        0.2195122 , 0.        , 0.34208433],
       [0.54736842, 0.22924901, 0.74331551, 0.76804124, 0.5       ,
        0.39568345, 0.17570499, 0.24528302, 0.36277603, 0.49658703,
        0.10569106, 0.02264151, 0.10739857]]),
       n_clusters=5))
Best evaluation: 0.6392675369880065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [40, 26, 50, 28, 16]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.53157895, 0.19565217, 0.36363636, 0.09278351, 0.16666667,
        0.6       , 0.61814346, 0.0754717 , 0.78864353, 0.50511945,
        0.4957265 , 0.6007326 , 0.62196862],
       [0.5       , 0.40909091, 0.71657754, 0.53608247, 0.21428571,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.1965812 , 0.38095238, 0.2296719 ],
       [0.69736842, 0.21541502, 0.53475936, 0.34020619, 0.30952381,
        0.49...56, 0.21843003,
        0.58974359, 0.58608059, 0.50784593],
       [0.64736842, 0.18181818, 0.47058824, 0.69072165, 0.10714286,
        0.31034483, 0.3164557 , 0.26415094, 0.1955836 , 0.20989761,
        0.37606838, 0.55311355, 0.13837375],
       [0.87894737, 0.23913043, 0.60962567, 0.31958763, 0.41666667,
        0.98965517, 0.66455696, 0.20754717, 0.55835962, 0.55631399,
        0.27350427, 0.7985348 , 0.85734665]]),
       n_clusters=5))
Best evaluation: 0.6504519593662104
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 45, 25, 38, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25526316, 0.03557312, 0.34224599, 0.43298969, 0.17391304,
        0.49655172, 0.40506329, 0.34      , 0.32176656, 0.10409556,
        0.73170732, 0.67765568, 0.        ],
       [0.67105263, 0.36363636, 0.71122995, 0.71649485, 0.38043478,
        0.19655172, 0.10548523, 0.52      , 0.35646688, 0.62969283,
        0.21138211, 0.19413919, 0.33666191],
       [0.20789474, 0.14426877, 0.3368984 , 0.5257732 , 0.17391304,
        0.34482...0.34      , 0.3533123 , 0.05716724,
        0.38211382, 0.75457875, 0.15477889],
       [0.88421053, 0.22332016, 0.5828877 , 0.20618557, 0.2826087 ,
        0.52413793, 0.45991561, 0.34      , 0.49526814, 0.3387372 ,
        0.43902439, 0.84615385, 0.72182596],
       [0.58157895, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.62758621, 0.49578059, 0.52      , 0.44479495, 0.25938567,
        0.45528455, 0.60805861, 0.32596291]]),
       n_clusters=5))
Best evaluation: 0.6462268421030327
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [21, 47, 35, 42, 15]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.38947368, 0.17107943, 0.3315508 , 0.51030928, 0.16304348,
        0.42068966, 0.33333333, 0.35849057, 0.3728223 , 0.14163823,
        0.45528455, 0.84249084, 0.2810271 ],
       [0.82368421, 0.3299389 , 0.59893048, 0.48453608, 0.22826087,
        0.24137931, 0.07594937, 0.58490566, 0.28919861, 0.71843003,
        0.11382114, 0.16117216, 0.2724679 ],
       [0.97894737, 0.17107943, 0.55080214, 0.04123711, 0.22826087,
        0.73103448, 0.70675105, 0.56603774, 0.83623693, 0.35153584,
        0.62601626, 0.53479853, 0.62196862],
       [0.80789474, 0.23014257, 0.55614973, 0.42268041, 0.35869565,
        0.61034483, 0.5443038 , 0.35849057, 0.68641115, 0.41979522,
        0.4796748 , 0.54212454, 0.55777461]]),
       n_clusters=4))
Best evaluation: 0.5687693268345544
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [56, 49, 11, 44]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36470588235294116
F1: 0.205145129569682
======================================================
Running wine 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.21774194, 0.02964427, 0.65240642, 0.3814433 , 0.26086957,
        0.42068966, 0.39451477, 0.16981132, 0.61198738, 0.15102389,
        0.25203252, 0.66051661, 0.17261056],
       [0.62634409, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.43542435, 0.35805991],
       [0.58333333, 0.2055336 , 0.4171123 , 0.03092784, 0.32608696,
        0.57586207, 0.51054852, 0.24528302, 0.27444795, 0.26450512,
        0.46341463, 0.77859779, 0.55064194],
       [0.28225806, 0.21541502, 0.51336898, 0.40721649, 0.11956522,
        0.2137931 , 0.24472574, 0.73584906, 0.38801262, 0.09556314,
        0.48780488, 0.36162362, 0.14407989]]),
       n_clusters=4))
Best evaluation: 0.3975188634349425
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 44, 49, 29]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.87105263, 0.18577075, 0.71657754, 0.80446927, 0.30434783,
        0.62758621, 0.20464135, 0.75      , 0.72239748, 1.        ,
        0.07317073, 0.25274725, 0.2724679 ],
       [0.35263158, 0.08498024, 0.29946524, 0.5027933 , 0.08695652,
        0.38965517, 0.35021097, 0.25      , 0.19873817, 0.29010239,
        0.5203252 , 0.80952381, 0.16547789],
       [0.7       , 0.49802372, 0.63101604, 0.52513966, 0.40217391,
        0.29310345, 0.0464135 , 0.69230769, 0.12302839, 0.39249147,
        0.3902439 , 0.2014652 , 0.28673324],
       [0.59473684, 0.243083  , 0.70588235, 0.34636872, 0.34782609,
        0.69655172, 0.60970464, 0.32692308, 0.39432177, 0.40273038,
        0.4796748 , 0.57509158, 0.70756063]]),
       n_clusters=4))
Best evaluation: 0.4254839713117063
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [2, 56, 48, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3480392156862745
F1: 0.1908309252554777
======================================================
Running wine 100 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.58      0.74        12
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.53      0.58        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.90053763, 0.56324111, 0.49197861, 0.27835052, 0.34782609,
        0.78275862, 0.59704641, 0.26415094, 0.5615142 , 0.30887372,
        0.45528455, 0.79335793, 0.56134094],
       [0.47849462, 0.31027668, 0.55614973, 0.69072165, 0.30434783,
        0.05862069, 0.15822785, 0.26415094, 0.13249211, 0.37713311,
        0.14634146, 0.02583026, 0.20114123],
       [0.33870968, 0.48023715, 0.45454545, 0.3814433 , 0.19565217,
        0.64482759, 0.55907173, 0.60377358, 0.75709779, 0.08703072,
        0.76422764, 0.56826568, 0.09129815],
       [0.35215054, 0.33794466, 0.58823529, 0.53608247, 0.30434783,
        0.54482759, 0.37341772, 0.39622642, 0.28391167, 0.12969283,
        0.2601626 , 0.77121771, 0.11412268]]),
       n_clusters=4))
Best evaluation: 0.4069054786662437
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [49, 45, 26, 40]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.53157895, 0.17107943, 0.36363636, 0.09278351, 0.23913043,
        0.6       , 0.61814346, 0.0754717 , 0.87108014, 0.50511945,
        0.5203252 , 0.6007326 , 0.62196862],
       [0.65526316, 0.46435845, 0.72727273, 0.66494845, 0.29347826,
        0.19655172, 0.03797468, 0.69811321, 0.04878049, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.27368421, 0.2586558 , 0.43315508, 0.53608247, 0.16304348,
        0.55862069, 0.48734177, 0.45283019, 0.32752613, 0.12627986,
        0.30894309, 0.73626374, 0.07132668],
       [0.71052632, 0.12423625, 0.71657754, 0.61340206, 0.33695652,
        0.69655172, 0.61392405, 0.30188679, 0.68641115, 0.37713311,
        0.57723577, 0.52747253, 0.71825963]]),
       n_clusters=4))
Best evaluation: 0.4027007791100457
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 46, 38, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.39210526, 0.34419552, 0.43315508, 0.53608247, 0.19565217,
        0.54137931, 0.407173  , 0.24528302, 0.2555205 , 0.06143345,
        0.34146341, 0.55311355, 0.03352354],
       [0.11052632, 0.33808554, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.44794953, 0.16808874,
        0.2601626 , 0.77655678, 0.24750357],
       [0.79736842, 0.18126273, 0.49197861, 0.27835052, 0...
        0.69655172, 0.59704641, 0.20754717, 0.53312303, 0.37286689,
        0.49593496, 0.89377289, 0.35805991],
       [0.50789474, 0.55193483, 0.52941176, 0.40721649, 0.39130435,
        0.14137931, 0.07594937, 0.50943396, 0.16719243, 0.34129693,
        0.16260163, 0.17582418, 0.2831669 ],
       [0.47894737, 0.17515275, 0.62032086, 0.37113402, 0.27173913,
        0.51724138, 0.42827004, 0.24528302, 0.33123028, 0.22610922,
        0.49593496, 0.86446886, 0.5256776 ]]),
       n_clusters=5))
Best evaluation: 0.4112382181573758
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [39, 21, 26, 46, 29]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3702614379084967
F1: 0.21043827696809259
======================================================
Running wine 100 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [56, 45, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.71      0.56      0.62         9
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.41      0.48        18
weighted avg       0.86      0.61      0.71        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [57, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.50      0.40         4
           1       0.71      0.36      0.48        14
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.35      0.29      0.29        18
weighted avg       0.63      0.39      0.46        18

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [56, 55, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.25      0.29         8
           1       0.14      0.10      0.12        10
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.16      0.12      0.13        18
weighted avg       0.23      0.17      0.19        18

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.67      0.44         3
           1       0.86      0.40      0.55        15
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.40      0.36      0.33        18
weighted avg       0.77      0.44      0.53        18

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [47, 54, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [59, 55, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.55      0.67        11
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.47      0.53        18
weighted avg       0.91      0.67      0.77        18

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 59, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.60      0.71        10
           2       0.00      0.00      0.00         0

    accuracy                           0.71        17
   macro avg       0.62      0.49      0.54        17
weighted avg       0.92      0.71      0.80        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [57, 46, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [51, 56, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4666666666666667
F1: 0.37496038579516083
======================================================
Running wine 100 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.43684211, 0.15612648, 0.36601307, 0.5       , 0.10869565,
        0.13793103, 0.23628692, 0.8490566 , 0.37974684, 0.15102389,
        0.3902439 , 0.28937729, 0.15477889],
       [0.59736842, 0.19367589, 0.2875817 , 0.30107527, 0.26086957,
        0.48965517, 0.39029536, 0.26415094, 0.2943038 , 0.2278157 ,
        0.43902439, 0.54945055, 0.71825963],
       [0.25526316, 0.03557312, 0.19607843, 0.40860215, 0.17391304,
        0.49655172, 0.40506329, 0.32075472, 0.31962025, 0.10409556,
        0.73170732, 0.67765568, 0.        ],
       [0.63684211, 0.58498024, 0.58823529, 0.62365591, 0.44565217,
        0.24827586, 0.12236287, 0.56603774, 0.32911392, 0.80204778,
        0.30081301, 0.10622711, 0.29743224],
       [0.68684211, 0.46640316, 0.5620915 , 0.20430108, 0.5       ,
        0.59310345, 0.56751055, 0.0754717 , 0.39240506, 0.32593857,
        0.3902439 , 0.76556777, 0.40442225]]),
       n_clusters=5))
Best evaluation: 0.6445583089752437
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [20, 32, 44, 39, 25]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.80376344, 0.18577075, 0.45454545, 0.27835052, 0.2826087 ,
        0.57586207, 0.41983122, 0.24528302, 0.49526814, 0.29180887,
        0.45528455, 0.84870849, 0.53994294],
       [0.21774194, 0.42490119, 0.46524064, 0.3814433 , 0.45652174,
        0.25517241, 0.20675105, 0.56603774, 0.170347  , 0.1168942 ,
        0.3902439 , 0.45387454, 0.15834522],
       [0.60215054, 0.69960474, 0.48128342, 0.48453608, 0....
        0.21034483, 0.07383966, 0.56603774, 0.29652997, 0.76109215,
        0.08943089, 0.099631  , 0.39728959],
       [0.33870968, 0.13241107, 0.3315508 , 0.27835052, 0.16304348,
        0.54137931, 0.4556962 , 0.30188679, 0.42902208, 0.13822526,
        0.6097561 , 0.53505535, 0.10699001],
       [0.75268817, 0.16403162, 0.67379679, 0.48453608, 0.48913043,
        0.67931034, 0.64556962, 0.50943396, 0.41324921, 0.45392491,
        0.52845528, 0.47232472, 0.60770328]]),
       n_clusters=5))
Best evaluation: 0.646609459874748
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [25, 21, 40, 44, 30]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.70789474, 0.13636364, 0.60962567, 0.34078212, 0.41304348,
        0.83448276, 0.70253165, 0.09615385, 0.51419558, 0.47098976,
        0.33333333, 0.58608059, 0.71825963],
       [0.62368421, 0.62648221, 0.59893048, 0.69273743, 0.34782609,
        0.28275862, 0.08649789, 0.55769231, 0.31545741, 0.51365188,
        0.17886179, 0.10622711, 0.33666191],
       [0.33157895, 0.48023715, 0.45454545, 0.41340782, 0.19565217,
        0.64482759, 0.55907173, 0.59615385, 0.75709779, 0.08703072,
        0.76422764, 0.57142857, 0.09129815],
       [0.16052632, 0.26086957, 0.58823529, 0.61452514, 0.15217391,
        0.33448276, 0.28481013, 0.65384615, 0.29652997, 0.12969283,
        0.42276423, 0.54212454, 0.28673324]]),
       n_clusters=4))
Best evaluation: 0.5526403343343806
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [51, 45, 28, 36]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3600583718121295
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.47105263, 0.51976285, 0.5026738 , 0.4972067 , 0.19565217,
        0.17241379, 0.06751055, 0.5       , 0.17665615, 0.7662116 ,
        0.19512195, 0.17582418, 0.29029957],
       [0.56052632, 0.3201581 , 0.70053476, 0.44692737, 0.33695652,
        0.62758621, 0.61181435, 0.30769231, 0.75709779, 0.37542662,
        0.44715447, 0.6959707 , 0.64693295],
       [0.78684211, 0.18577075, 0.45454545, 0.30167598, 0.2826087 ,
        0.57586207, 0.41983122, 0.23076923, 0.49526814, 0.29180887,
        0.45528455, 0.84981685, 0.53994294],
       [0.16052632, 0.26086957, 0.58823529, 0.61452514, 0.15217391,
        0.33448276, 0.28481013, 0.65384615, 0.29652997, 0.12969283,
        0.42276423, 0.54212454, 0.28673324],
       [0.35263158, 0.09288538, 0.64171123, 0.41899441, 0.30434783,
        0.49655172, 0.48734177, 0.44230769, 0.52681388, 0.28327645,
        0.57723577, 0.37728938, 0.2853067 ]]),
       n_clusters=5))
Best evaluation: 0.4192738346132612
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 18, 37, 23, 37]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.37894737, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.52413793, 0.407173  , 0.38      , 0.90536278, 0.11262799,
        0.55284553, 0.4981685 , 0.4700428 ],
       [0.57105263, 0.2055336 , 0.4171123 , 0.03092784, 0.32608696,
        0.57586207, 0.51054852, 0.26      , 0.27444795, 0.26450512,
        0.46341463, 0.78021978, 0.55064194],
       [0.5       , 0.40909091, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.8       , 0.10725552, 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ],
       [0.21315789, 0.42490119, 0.46524064, 0.3814433 , 0.45652174,
        0.25517241, 0.20675105, 0.6       , 0.170347  , 0.1168942 ,
        0.3902439 , 0.45787546, 0.15834522]]),
       n_clusters=4))
Best evaluation: 0.4082488802499098
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [28, 49, 45, 38]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71929825, 0.22924901, 0.77419355, 0.45360825, 0.40217391,
        0.68641115, 0.73259053, 0.45283019, 0.42586751, 0.24511545,
        0.79381443, 0.78021978, 0.45435093],
       [0.79532164, 0.66403162, 0.74193548, 0.71649485, 0.2826087 ,
        0.3728223 , 0.11699164, 0.81132075, 0.29652997, 0.6625222 ,
        0.13402062, 0.12087912, 0.20114123],
       [0.23391813, 0.08893281, 0.20967742, 0.31958763, 0.88043478,
        0.30313589, 0.26183844, 0.01886792, 0.65930599, 0.09857904,
        0.82474227, 0.65934066, 0.31383738],
       [0.23684211, 0.10869565, 0.31182796, 0.43298969, 0.23913043,
        0.48083624, 0.4735376 , 0.49056604, 0.52681388, 0.08525755,
        0.39175258, 0.64102564, 0.02425107]]),
       n_clusters=4))
Best evaluation: 0.4295577278876218
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 46, 4, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.47105263, 0.53564155, 0.5026738 , 0.45876289, 0.19565217,
        0.17241379, 0.06751055, 0.50943396, 0.17665615, 0.7662116 ,
        0.19512195, 0.17582418, 0.29029957],
       [0.57105263, 0.21181263, 0.4171123 , 0.03092784, 0.32608696,
        0.57586207, 0.51054852, 0.24528302, 0.27444795, 0.26450512,
        0.46341463, 0.78021978, 0.55064194],
       [0.38947368, 0.20162933, 0.3315508 , 0.51030928,...
        0.42068966, 0.33333333, 0.35849057, 0.33753943, 0.14163823,
        0.45528455, 0.84249084, 0.2810271 ],
       [0.53157895, 0.26680244, 0.99465241, 0.74226804, 0.58695652,
        0.56896552, 0.49367089, 0.64150943, 0.47634069, 0.19624573,
        0.52845528, 0.70695971, 0.39372325],
       [0.20789474, 0.19959267, 0.27807487, 0.45876289, 0.17391304,
        0.52413793, 0.2742616 , 0.45283019, 0.31861199, 0.0665529 ,
        0.37398374, 0.42857143, 0.09771755]]),
       n_clusters=5))
Best evaluation: 0.4371934616244026
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 51, 32, 6, 26]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3702614379084967
F1: 0.22244708687163933
======================================================
Running wine 100 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.85752688, 0.18972332, 0.5026738 , 0.29381443, 0.52173913,
        0.76551724, 0.56118143, 0.24528302, 0.51104101, 0.43515358,
        0.37398374, 0.74538745, 0.4935806 ],
       [0.21774194, 0.42490119, 0.46524064, 0.3814433 , 0.45652174,
        0.25517241, 0.20675105, 0.56603774, 0.170347  , 0.1168942 ,
        0.3902439 , 0.45387454, 0.15834522],
       [0.55107527, 0.62450593, 0.53475936, 0.56185567, 0.4673913 ,
        0.14827586, 0.22151899, 0.39622642, 0.23028391, 0.69283276,
        0.07317073, 0.01476015, 0.19400856],
       [0.26075269, 0.03557312, 0.34224599, 0.43298969, 0.17391304,
        0.49655172, 0.40506329, 0.32075472, 0.32176656, 0.10409556,
        0.73170732, 0.67527675, 0.        ]]),
       n_clusters=4))
Best evaluation: 0.401648331591717
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [55, 21, 40, 44]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.58947368, 0.69960474, 0.48128342, 0.48453608, 0.54347826,
        0.17625899, 0.04772234, 0.56603774, 0.29652997, 0.76109215,
        0.08943089, 0.10943396, 0.433572  ],
       [0.27631579, 0.1284585 , 0.60962567, 0.61340206, 0.15217391,
        0.52517986, 0.39479393, 0.56603774, 0.19873817, 0.13822526,
        0.36585366, 0.7245283 , 0.07557677],
       [1.        , 0.17786561, 0.43315508, 0.17525773, 0.29347826,
        0.61151079, 0.54446855, 0.30188679, 0.49526814, 0.33447099,
        0.48780488, 0.59622642, 0.60063644],
       [0.11052632, 0.32806324, 0.56684492, 0.48453608, 0.2826087 ,
        0.64748201, 0.5032538 , 0.35849057, 0.44794953, 0.16808874,
        0.2601626 , 0.8       , 0.26650756],
       [0.69473684, 0.10079051, 0.29946524, 0.3814433 , 0.26086957,
        0.35971223, 0.28633406, 0.35849057, 0.10094637, 0.21501706,
        0.6097561 , 0.4490566 , 0.27048528]]),
       n_clusters=5))
Best evaluation: 0.4581297286047851
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [42, 30, 50, 21, 17]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.25526316, 0.15682281, 0.56684492, 0.58762887, 0.17391304,
        0.16206897, 0.19198312, 0.69811321, 0.38485804, 0.19795222,
        0.46341463, 0.50549451, 0.12268188],
       [0.76578947, 0.20162933, 0.48663102, 0.35051546, 0.41304348,
        0.65517241, 0.67510549, 0.35849057, 0.52681388, 0.65017065,
        0.5203252 , 0.67032967, 0.70042796],
       [0.75      , 0.87576375, 0.46524064, 0.48453608, 0.1...
        0.        , 0.        , 0.50943396, 0.0851735 , 0.30887372,
        0.08130081, 0.02197802, 0.09771755],
       [0.67105263, 0.37474542, 0.71122995, 0.71649485, 0.38043478,
        0.19655172, 0.10548523, 0.49056604, 0.35646688, 0.62969283,
        0.21138211, 0.19413919, 0.33666191],
       [0.47894737, 0.17515275, 0.62032086, 0.37113402, 0.27173913,
        0.51724138, 0.42827004, 0.24528302, 0.33123028, 0.22610922,
        0.49593496, 0.86446886, 0.5256776 ]]),
       n_clusters=5))
Best evaluation: 0.41344097053155615
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [37, 48, 25, 21, 30]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19673280115735362
======================================================
Running wine 100 2 majority_voting default
======================================================
python cbeg.py -d wine -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 100 3 majority_voting default
======================================================
python cbeg.py -d wine -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.14      1.00      0.25         1
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.45      0.26        18
weighted avg       0.95      0.39      0.51        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 56, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 46, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.15      0.21        18
weighted avg       0.72      0.33      0.46        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [62, 3, 95]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 58, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.25      0.29         8
           1       0.14      0.10      0.12        10
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.16      0.12      0.13        18
weighted avg       0.23      0.17      0.19        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [59, 54, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [56, 58, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.33      0.33         6
           1       0.43      0.25      0.32        12
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.25      0.19      0.22        18
weighted avg       0.40      0.28      0.32        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 50, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       1.00      1.00      1.00         7
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.52      0.57        18
weighted avg       1.00      0.72      0.82        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 60, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.59        17
   macro avg       0.52      0.49      0.45        17
weighted avg       0.90      0.59      0.65        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 58, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [51, 54, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.42712418300653593
F1: 0.340824631426664
======================================================
Running wine 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.50      0.57         8
           1       0.57      1.00      0.73         4
           2       0.80      0.67      0.73         6

    accuracy                           0.67        18
   macro avg       0.68      0.72      0.68        18
weighted avg       0.69      0.67      0.66        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 45, 37, 22, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      1.00      0.83         5
           2       0.80      0.80      0.80         5

    accuracy                           0.83        18
   macro avg       0.84      0.85      0.83        18
weighted avg       0.87      0.83      0.83        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [22, 21, 37, 35, 45]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.71      0.71         7
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.77      0.82      0.77        18
weighted avg       0.82      0.78      0.78        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71842105, 0.15612648, 0.71657754, 0.45876289, 0.67391304,
        0.66546763, 0.49240781, 0.69811321, 0.29652997, 0.35153584,
        0.62601626, 0.65283019, 0.75178998],
       [0.62631579, 0.61264822, 0.40641711, 0.42268041, 0.2173913 ,
        0.48561151, 0.47939262, 0.26415094, 0.33753943, 0.2559727 ,
        0.3495935 , 0.65283019, 0.59268099],
       [0.47105263, 0.51976285, 0.5026738 , 0.45876289,...
        0.13669065, 0.04121475, 0.50943396, 0.17665615, 0.7662116 ,
        0.19512195, 0.18113208, 0.31424025],
       [0.5       , 0.40909091, 0.71657754, 0.53608247, 0.2826087 ,
        0.15827338, 0.00650759, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.39245283, 0.24661893],
       [0.15263158, 0.12055336, 0.71657754, 0.48453608, 0.26086957,
        0.58992806, 0.53145336, 0.30188679, 0.65615142, 0.1168942 ,
        0.3902439 , 0.7509434 , 0.31026253]]),
       n_clusters=5))
Best evaluation: 0.6516116012214248
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.80      0.73         5
           1       0.86      0.75      0.80         8
           2       1.00      1.00      1.00         5

    accuracy                           0.83        18
   macro avg       0.84      0.85      0.84        18
weighted avg       0.84      0.83      0.84        18

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 28, 31, 30, 44]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6490015686411414
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 46, 23, 17, 35]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       0.86      0.75      0.80         8
           2       0.60      0.75      0.67         4

    accuracy                           0.83        18
   macro avg       0.82      0.83      0.82        18
weighted avg       0.85      0.83      0.84        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.88      0.93         8
           2       0.80      1.00      0.89         4

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.96      0.94      0.95        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.60      0.55         5
           1       0.71      0.62      0.67         8
           2       1.00      1.00      1.00         5

    accuracy                           0.72        18
   macro avg       0.74      0.74      0.74        18
weighted avg       0.73      0.72      0.73        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.86      0.75      0.80         8
           2       0.50      0.67      0.57         3

    accuracy                           0.76        17
   macro avg       0.73      0.75      0.73        17
weighted avg       0.79      0.76      0.77        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.80789474, 0.2892057 , 0.5026738 , 0.3814433 , 0.38043478,
        0.67931034, 0.62869198, 0.16981132, 0.6214511 , 0.38139932,
        0.62601626, 0.6959707 , 0.87874465],
       [0.20526316, 0.28105906, 0.73796791, 0.56185567, 0.69565217,
        0.2137931 , 0.1371308 , 0.01886792, 0.36277603, 0.10409556,
        0.38211382, 0.36263736, 0.24750357],
       [0.70526316, 1.        , 0.5828877 , 0.51030928, 0.27173913,
        0...0.20504732, 0.54778157,
        0.1300813 , 0.17216117, 0.32952924],
       [0.42368421, 0.12627291, 0.35294118, 0.31958763, 0.32608696,
        0.35862069, 0.2257384 , 0.75471698, 0.06624606, 0.38139932,
        0.40650407, 0.11721612, 0.12268188],
       [0.5       , 0.42158859, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ]]),
       n_clusters=5))
Best evaluation: 0.6451102573695399
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.62      1.00      0.77         5
           2       1.00      1.00      1.00         4

    accuracy                           0.82        17
   macro avg       0.88      0.88      0.85        17
weighted avg       0.89      0.82      0.82        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [50, 26, 34, 29, 22]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8199346405228758
F1: 0.818368111554386
======================================================
Running wine 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.62      0.71         8
           1       0.86      0.86      0.86         7
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.76      0.83      0.77        18
weighted avg       0.80      0.78      0.78        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [22, 19, 37, 37, 45]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219796
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.71      0.71         7
           2       0.40      0.67      0.50         3

    accuracy                           0.72        18
   macro avg       0.70      0.71      0.69        18
weighted avg       0.79      0.72      0.74        18

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 35, 21, 37, 22]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      0.71      0.71         7
           2       0.60      1.00      0.75         3

    accuracy                           0.78        18
   macro avg       0.77      0.82      0.77        18
weighted avg       0.82      0.78      0.78        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.43      0.46         7
           1       0.57      0.80      0.67         5
           2       0.80      0.67      0.73         6

    accuracy                           0.61        18
   macro avg       0.62      0.63      0.62        18
weighted avg       0.62      0.61      0.61        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [38, 42, 21, 38, 21]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.70      0.82        10
           2       0.60      1.00      0.75         3

    accuracy                           0.83        18
   macro avg       0.81      0.90      0.83        18
weighted avg       0.89      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       0.86      0.55      0.67        11
           2       0.60      1.00      0.75         3

    accuracy                           0.67        18
   macro avg       0.65      0.77      0.67        18
weighted avg       0.73      0.67      0.67        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.85672515, 0.18577075, 0.72043011, 0.74226804, 0.30434783,
        0.63414634, 0.27019499, 0.75471698, 0.72239748, 1.        ,
        0.09278351, 0.25274725, 0.2724679 ],
       [0.27192982, 0.33794466, 0.59139785, 0.53608247, 0.30434783,
        0.55052265, 0.49303621, 0.39622642, 0.28391167, 0.09413854,
        0.32989691, 0.77289377, 0.11412268],
       [0.66666667, 0.49802372, 0.6344086 , 0.48453608, 0.40217391,
        0.29616725, 0.06128134, 0.69811321, 0.12302839, 0.36767318,
        0.49484536, 0.2014652 , 0.28673324],
       [0.37426901, 0.15612648, 0.48387097, 0.52061856, 0.10869565,
        0.13937282, 0.31197772, 0.8490566 , 0.38170347, 0.11634103,
        0.49484536, 0.28937729, 0.15477889]]),
       n_clusters=4))
Best evaluation: 0.41844529836123007
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         4

    accuracy                           0.94        17
   macro avg       0.94      0.96      0.95        17
weighted avg       0.95      0.94      0.94        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 58, 44, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.75      1.00      0.86         6
           2       1.00      1.00      1.00         4

    accuracy                           0.88        17
   macro avg       0.92      0.90      0.90        17
weighted avg       0.91      0.88      0.88        17

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.815686274509804
F1: 0.8136299539240716
======================================================
Running wine 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.71      0.62      0.67         8
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.38      0.43        18
weighted avg       0.78      0.56      0.64        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 37, 22, 37, 19]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4129741358219795
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      1.00      0.73         4
           2       0.80      0.80      0.80         5

    accuracy                           0.78        18
   macro avg       0.79      0.82      0.78        18
weighted avg       0.85      0.78      0.78        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 22, 21, 45, 37]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      1.00      0.83         5
           2       0.80      0.80      0.80         5

    accuracy                           0.83        18
   macro avg       0.84      0.85      0.83        18
weighted avg       0.87      0.83      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.49327786613681507
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.43      0.46         7
           1       0.57      0.80      0.67         5
           2       0.80      0.67      0.73         6

    accuracy                           0.61        18
   macro avg       0.62      0.63      0.62        18
weighted avg       0.62      0.61      0.61        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 21, 38, 20, 43]
Selected clustering_algorithm: fcm
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.70      0.82        10
           2       0.60      1.00      0.75         3

    accuracy                           0.83        18
   macro avg       0.81      0.90      0.83        18
weighted avg       0.89      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       1.00      1.00      1.00         7
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.92      0.87        18
weighted avg       0.93      0.89      0.89        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.36842105, 0.13034623, 0.4973262 , 0.56185567, 0.17391304,
        0.60689655, 0.592827  , 0.49056604, 0.4738676 , 0.22696246,
        0.17073171, 0.57509158, 0.05278174],
       [0.58947368, 0.6904277 , 0.48128342, 0.48453608, 0.54347826,
        0.21034483, 0.07383966, 0.56603774, 0.32752613, 0.76109215,
        0.08943089, 0.10622711, 0.39728959],
       [0.83947368, 0.16496945, 0.5026738 , 0.29381443, 0.52173913,
        0.76551724, 0.56118143, 0.24528302, 0.56445993, 0.43515358,
        0.37398374, 0.74725275, 0.4935806 ],
       [0.31052632, 0.0610998 , 0.20855615, 0.31958763, 0.88043478,
        0.3       , 0.19831224, 0.01886792, 0.728223  , 0.13395904,
        0.6504065 , 0.65934066, 0.31383738]]),
       n_clusters=4))
Best evaluation: 0.42745515160264497
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.57      0.62         7
           1       0.57      0.67      0.62         6
           2       1.00      1.00      1.00         5

    accuracy                           0.72        18
   macro avg       0.75      0.75      0.74        18
weighted avg       0.73      0.72      0.72        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [55, 47, 54, 4]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.86      0.75      0.80         8
           2       0.50      0.67      0.57         3

    accuracy                           0.76        17
   macro avg       0.73      0.75      0.73        17
weighted avg       0.79      0.76      0.77        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.75      1.00      0.86         6
           2       1.00      1.00      1.00         4

    accuracy                           0.88        17
   macro avg       0.92      0.90      0.90        17
weighted avg       0.91      0.88      0.88        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7869281045751635
F1: 0.7764966460554696
======================================================
Running wine 75 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.35263158, 0.08498024, 0.14379085, 0.44086022, 0.08695652,
        0.38965517, 0.35021097, 0.26415094, 0.19620253, 0.29010239,
        0.5203252 , 0.80952381, 0.16547789],
       [0.75      , 0.84980237, 0.34640523, 0.46236559, 0.10869565,
        0.        , 0.        , 0.50943396, 0.08227848, 0.30887372,
        0.08130081, 0.02197802, 0.09771755],
       [0.73684211, 0.16403162, 0.60130719, 0.46236559, 0.48913043,
        0.679310...1, 0.45392491,
        0.52845528, 0.47619048, 0.60770328],
       [0.27631579, 0.0770751 , 0.52941176, 0.67741935, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31012658, 0.07849829,
        0.67479675, 0.53113553, 0.2510699 ],
       [0.88157895, 0.56324111, 0.37908497, 0.24731183, 0.34782609,
        0.78275862, 0.59704641, 0.26415094, 0.56012658, 0.30887372,
        0.45528455, 0.79487179, 0.56134094]]),
       n_clusters=5))
Best evaluation: 0.46958775395457664
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.14      0.20        18
weighted avg       0.78      0.33      0.47        18

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 45, 17, 23, 38]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.32795699, 0.19565217, 0.40641711, 0.43298969, 0.10869565,
        0.23103448, 0.35654008, 0.45283019, 0.38485804, 0.18088737,
        0.42276423, 0.69372694, 0.16547789],
       [0.90053763, 0.56324111, 0.49197861, 0.27835052, 0.34782609,
        0.78275862, 0.59704641, 0.26415094, 0.5615142 , 0.30887372,
        0.45528455, 0.79335793, 0.56134094],
       [0.46774194, 0.32608696, 0.49197861, 0.45876289, 0.17391304,
        0.14137931, 0.03586498, 0.66037736, 0.07255521, 0.7354948 ,
        0.07317073, 0.12546125, 0.13694722]]),
       n_clusters=3))
Best evaluation: 0.41229901121635026
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [58, 56, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.80789474, 0.28063241, 0.5026738 , 0.3814433 , 0.38043478,
        0.66546763, 0.61822126, 0.16981132, 0.6214511 , 0.38139932,
        0.62601626, 0.71698113, 0.97056484],
       [0.41315789, 0.11857708, 0.28877005, 0.40721649, 0.19565217,
        0.12589928, 0.19305857, 0.30188679, 0.29652997, 0.09982935,
        0.45528455, 0.56603774, 0.21638823],
       [0.58947368, 0.69960474, 0.48128342, 0.48453608...
        0.17625899, 0.04772234, 0.56603774, 0.29652997, 0.76109215,
        0.08943089, 0.10943396, 0.433572  ],
       [0.58157895, 0.36561265, 0.80748663, 0.53608247, 0.52173913,
        0.61151079, 0.48156182, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.62641509, 0.3540175 ],
       [0.47631579, 0.43873518, 0.6684492 , 0.69072165, 0.33695652,
        0.43884892, 0.02819957, 0.75471698, 0.12618297, 0.3105802 ,
        0.33333333, 0.33207547, 0.23866348]]),
       n_clusters=5))
Best evaluation: 0.6467745425839164
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [50, 35, 26, 21, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.42105263, 0.16996047, 0.62365591, 0.37113402, 0.27173913,
        0.52264808, 0.56545961, 0.24528302, 0.33123028, 0.19449378,
        0.62886598, 0.86446886, 0.5256776 ],
       [0.37426901, 0.15612648, 0.48387097, 0.52061856, 0.10869565,
        0.13937282, 0.31197772, 0.8490566 , 0.38170347, 0.11634103,
        0.49484536, 0.28937729, 0.15477889],
       [0.42690058, 0.76482213, 0.60215054, 0.5618556...
        0.25087108, 0.08635097, 0.64150943, 0.14195584, 0.52486679,
        0.06185567, 0.21611722, 0.24750357],
       [0.63450292, 0.18181818, 0.53763441, 0.43814433, 0.39130435,
        0.65505226, 0.79387187, 0.16981132, 0.48580442, 0.45825933,
        0.62886598, 0.58974359, 0.88231098],
       [0.87134503, 0.22332016, 0.58602151, 0.20618557, 0.2826087 ,
        0.52961672, 0.60724234, 0.32075472, 0.49526814, 0.31172291,
        0.55670103, 0.84615385, 0.72182596]]),
       n_clusters=5))
Best evaluation: 0.6386562618803733
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.15      0.21        17
weighted avg       0.76      0.35      0.48        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [31, 31, 45, 16, 38]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.80789474, 0.26069246, 0.55614973, 0.42268041, 0.35869565,
        0.61034483, 0.5443038 , 0.35849057, 0.6214511 , 0.41979522,
        0.4796748 , 0.54212454, 0.55777461],
       [0.75      , 0.87576375, 0.46524064, 0.48453608, 0.10869565,
        0.        , 0.        , 0.50943396, 0.0851735 , 0.30887372,
        0.08130081, 0.02197802, 0.09771755],
       [0.24473684, 0.0712831 , 0.5026738 , 0.53608247, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.39116719, 0.16467577,
        0.41463415, 0.68131868, 0.43366619],
       [0.33157895, 0.49490835, 0.45454545, 0.3814433 , 0.19565217,
        0.64482759, 0.55907173, 0.60377358, 0.75709779, 0.08703072,
        0.76422764, 0.57142857, 0.09129815]]),
       n_clusters=4))
Best evaluation: 0.5578827774973397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [56, 46, 37, 22]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36470588235294116
F1: 0.2343221931147627
======================================================
Running wine 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.87105263, 0.18577075, 0.65359477, 0.7311828 , 0.30434783,
        0.62758621, 0.20464135, 0.75471698, 0.72151899, 1.        ,
        0.07317073, 0.25274725, 0.2724679 ],
       [0.27631579, 0.21541502, 0.40522876, 0.38172043, 0.11956522,
        0.2137931 , 0.24472574, 0.73584906, 0.38607595, 0.09556314,
        0.48780488, 0.36630037, 0.14407989],
       [0.50789474, 0.53557312, 0.4248366 , 0.38172043, 0.39130435,
        0.14137931, 0.07594937, 0.50943396, 0.16455696, 0.34129693,
        0.16260163, 0.17582418, 0.2831669 ],
       [0.71578947, 0.19565217, 0.46405229, 0.24731183, 0.20652174,
        0.55862069, 0.51054852, 0.30188679, 0.43987342, 0.36860068,
        0.54471545, 0.5970696 , 0.74322397]]),
       n_clusters=4))
Best evaluation: 0.4214352268564791
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [2, 56, 43, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.21236559, 0.14426877, 0.3368984 , 0.5257732 , 0.17391304,
        0.34482759, 0.26582278, 0.32075472, 0.3533123 , 0.05716724,
        0.38211382, 0.75276753, 0.15477889],
       [0.63709677, 0.62648221, 0.59893048, 0.63917526, 0.34782609,
        0.28275862, 0.08649789, 0.56603774, 0.31545741, 0.51365188,
        0.17886179, 0.099631  , 0.33666191],
       [0.90053763, 0.22332016, 0.54545455, 0.07216495, 0...
        0.8       , 0.69620253, 0.30188679, 0.8044164 , 0.53071672,
        0.58536585, 0.63099631, 0.90513552],
       [0.36021505, 0.09288538, 0.64171123, 0.38659794, 0.30434783,
        0.49655172, 0.48734177, 0.45283019, 0.52681388, 0.28327645,
        0.57723577, 0.37269373, 0.2853067 ],
       [0.6344086 , 0.20355731, 0.67379679, 0.28350515, 0.25      ,
        0.64482759, 0.54852321, 0.39622642, 0.32807571, 0.3003413 ,
        0.35772358, 0.71217712, 0.65406562]]),
       n_clusters=5))
Best evaluation: 0.4200053580908023
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.13      0.19        18
weighted avg       0.83      0.33      0.48        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [37, 46, 10, 22, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.38947368, 0.19565217, 0.3315508 , 0.51030928, 0.16304348,
        0.39568345, 0.31453362, 0.35849057, 0.33753943, 0.14163823,
        0.45528455, 0.86792453, 0.30389817],
       [0.62368421, 0.62648221, 0.59893048, 0.63917526, 0.34782609,
        0.25179856, 0.06073753, 0.56603774, 0.31545741, 0.51365188,
        0.17886179, 0.10943396, 0.36595068],
       [0.53684211, 0.15019763, 0.39572193, 0.25257732, 0.30434783,
        0.4676259 , 0.47071584, 0.28301887, 0.30283912, 0.20648464,
        0.56910569, 0.53584906, 0.58074781],
       [0.71052632, 0.15019763, 0.71657754, 0.61340206, 0.33695652,
        0.68345324, 0.60303688, 0.30188679, 0.6214511 , 0.37713311,
        0.57723577, 0.54339623, 0.79156722]]),
       n_clusters=4))
Best evaluation: 0.41136196514537937
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.45      0.59        11
           1       0.14      0.14      0.14         7
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.20      0.24        18
weighted avg       0.56      0.33      0.42        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [39, 45, 26, 50]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.29736842, 0.14663951, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.40069686, 0.09982935,
        0.69105691, 0.36263736, 0.15477889],
       [0.68421053, 0.18737271, 0.71657754, 0.34020619, 0.45652174,
        0.64482759, 0.54219409, 0.32075472, 0.36585366, 0.51365188,
        0.6504065 , 0.58974359, 0.7360913 ],
       [0.72368421, 0.3808554 , 0.5026738 , 0.58762887, 0...
        0.12758621, 0.07172996, 0.52830189, 0.21602787, 0.70819113,
        0.17886179, 0.15018315, 0.2403709 ],
       [0.11052632, 0.30753564, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.49477352, 0.16808874,
        0.2601626 , 0.77655678, 0.24750357],
       [0.70526316, 0.19755601, 0.53475936, 0.30927835, 0.33695652,
        0.56206897, 0.53586498, 0.26415094, 0.44599303, 0.21501706,
        0.51219512, 1.        , 0.53994294]]),
       n_clusters=5))
Best evaluation: 0.4147425379435084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.14      0.20        18
weighted avg       0.78      0.33      0.47        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [36, 29, 45, 23, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.38      0.43      0.40         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.46      0.31      0.36        17
weighted avg       0.74      0.47      0.56        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.37712418300653594
F1: 0.25567388178843287
======================================================
Running wine 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.35263158, 0.06521739, 0.26143791, 0.38172043, 0.19565217,
        0.87586207, 0.71940928, 0.20754717, 0.48417722, 0.27474403,
        0.45528455, 0.54945055, 0.2724679 ],
       [0.53157895, 0.61660079, 0.40522876, 0.59677419, 0.16304348,
        0.23103448, 0.26371308, 0.90566038, 0.37974684, 0.3003413 ,
        0.29268293, 0.27106227, 0.16904422],
       [0.20789474, 0.14426877, 0.18954248, 0.50537634, 0.17391304,
        0.34482759, 0.26582278, 0.32075472, 0.35126582, 0.05716724,
        0.38211382, 0.75457875, 0.15477889]]),
       n_clusters=3))
Best evaluation: 0.3651069374684057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 46, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.37634409, 0.15612648, 0.4973262 , 0.56185567, 0.17391304,
        0.60689655, 0.592827  , 0.49056604, 0.42902208, 0.22696246,
        0.17073171, 0.57195572, 0.05278174],
       [0.68548387, 0.36363636, 0.71122995, 0.71649485, 0.38043478,
        0.19655172, 0.10548523, 0.49056604, 0.35646688, 0.62969283,
        0.21138211, 0.18819188, 0.33666191],
       [0.72311828, 0.13636364, 0.60962567, 0.31443299...
        0.83448276, 0.70253165, 0.11320755, 0.51419558, 0.47098976,
        0.33333333, 0.58302583, 0.71825963],
       [0.7016129 , 0.46640316, 0.64171123, 0.2371134 , 0.5       ,
        0.59310345, 0.56751055, 0.0754717 , 0.39432177, 0.32593857,
        0.3902439 , 0.76383764, 0.40442225],
       [0.28225806, 0.1284585 , 0.60962567, 0.61340206, 0.15217391,
        0.54482759, 0.41139241, 0.56603774, 0.19873817, 0.13822526,
        0.36585366, 0.70110701, 0.07631954]]),
       n_clusters=5))
Best evaluation: 0.4165617045197151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.13      0.19        18
weighted avg       0.83      0.33      0.48        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 45, 25, 30, 35]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.64736842, 0.18181818, 0.47058824, 0.69072165, 0.18478261,
        0.31034483, 0.3164557 , 0.28      , 0.1955836 , 0.20989761,
        0.40650407, 0.55311355, 0.13837375],
       [0.15263158, 0.12055336, 0.71657754, 0.48453608, 0.26086957,
        0.60689655, 0.5443038 , 0.32      , 0.65615142, 0.1168942 ,
        0.3902439 , 0.72893773, 0.28673324],
       [0.53947368, 0.62450593, 0.53475936, 0.56185567, 0.4673913 ,
        0.1...0.42      , 0.23028391, 0.69283276,
        0.07317073, 0.02197802, 0.19400856],
       [0.84210526, 0.1916996 , 0.57219251, 0.25773196, 0.61956522,
        0.62758621, 0.57383966, 0.3       , 0.59305994, 0.37201365,
        0.45528455, 0.97069597, 0.56134094],
       [0.68157895, 0.83201581, 0.52941176, 0.48453608, 0.23913043,
        0.35172414, 0.09704641, 0.68      , 0.19242902, 0.2662116 ,
        0.3495935 , 0.28571429, 0.19400856]]),
       n_clusters=5))
Best evaluation: 0.4224711404422601
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.14      0.20      0.17         5
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.76      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [34, 31, 25, 49, 21]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.45      0.59        11
           1       0.14      0.14      0.14         7
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.20      0.24        18
weighted avg       0.56      0.33      0.42        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.88157895, 0.58044807, 0.49197861, 0.27835052, 0.34782609,
        0.78275862, 0.59704641, 0.26415094, 0.5615142 , 0.30887372,
        0.45528455, 0.79487179, 0.56134094],
       [0.33157895, 0.17718941, 0.45454545, 0.50515464, 0.35869565,
        0.04137931, 0.14345992, 0.45283019, 0.33123028, 0.15102389,
        0.34634146, 0.2014652 , 0.42225392],
       [0.24473684, 0.0712831 , 0.5026738 , 0.53608247, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.39116719, 0.16467577,
        0.41463415, 0.68131868, 0.43366619],
       [0.27631579, 0.07942974, 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31230284, 0.07849829,
        0.67479675, 0.53113553, 0.2510699 ]]),
       n_clusters=4))
Best evaluation: 0.40376789486010944
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.38      0.43      0.40         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        17
   macro avg       0.46      0.31      0.36        17
weighted avg       0.74      0.47      0.56        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 46, 26, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3826797385620915
F1: 0.26403324077214685
======================================================
Running wine 75 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4653450890660529
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.62      0.71         8
           1       0.57      0.40      0.47        10
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.47      0.34      0.39        18
weighted avg       0.69      0.50      0.58        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 42, 45, 22, 39]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.85752688, 0.18972332, 0.5026738 , 0.29381443, 0.52173913,
        0.76551724, 0.56118143, 0.24528302, 0.51104101, 0.43515358,
        0.37398374, 0.74538745, 0.4935806 ],
       [0.57526882, 0.36561265, 0.54010695, 0.48453608, 0.54347826,
        0.23103448, 0.07172996, 0.75471698, 0.33123028, 0.68430034,
        0.09756098, 0.12177122, 0.40085592],
       [0.28225806, 0.26482213, 0.18181818, 0.3556701 , 0.29347826,
        0.43103448, 0.38607595, 0.24528302, 0.31230284, 0.17235495,
        0.64227642, 0.61623616, 0.30813124],
       [0.62634409, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.43542435, 0.35805991]]),
       n_clusters=4))
Best evaluation: 0.5712566931535152
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 28, 49, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.60263158, 0.49407115, 0.54545455, 0.60893855, 0.23913043,
        0.32758621, 0.08860759, 0.59615385, 0.26498423, 0.60921502,
        0.05691057, 0.12820513, 0.26533524],
       [0.70526316, 0.22134387, 0.53475936, 0.33519553, 0.33695652,
        0.56206897, 0.53586498, 0.25      , 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294],
       [0.39210526, 0.33399209, 0.43315508, 0.58100559, 0.19565217,
        0.54137931, 0.407173  , 0.23076923, 0.2555205 , 0.06143345,
        0.34146341, 0.55311355, 0.03352354],
       [0.59473684, 0.243083  , 0.70588235, 0.34636872, 0.34782609,
        0.69655172, 0.60970464, 0.32692308, 0.39432177, 0.40273038,
        0.4796748 , 0.57509158, 0.70756063],
       [0.26578947, 0.70355731, 0.54545455, 0.63687151, 0.10869565,
        0.3862069 , 0.29746835, 0.53846154, 0.29652997, 0.11262799,
        0.25203252, 0.47619048, 0.21540656]]),
       n_clusters=5))
Best evaluation: 0.6481172255803207
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DecisionTreeClassifier()]
Number of samples by cluster: [41, 25, 45, 29, 20]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61315789, 0.35968379, 0.52941176, 0.48453608, 0.2345679 ,
        0.14482759, 0.03375527, 0.45283019, 0.07255521, 0.45378151,
        0.17886179, 0.43956044, 0.35805991],
       [0.83947368, 0.18972332, 0.5026738 , 0.29381443, 0.59259259,
        0.76551724, 0.56118143, 0.24528302, 0.51104101, 0.53571429,
        0.37398374, 0.74725275, 0.4935806 ],
       [0.24473684, 0.06916996, 0.5026738 , 0.53608247,...
        0.82758621, 0.37974684, 0.        , 0.39116719, 0.20273109,
        0.41463415, 0.68131868, 0.43366619],
       [0.36842105, 0.15612648, 0.4973262 , 0.56185567, 0.19753086,
        0.60689655, 0.592827  , 0.49056604, 0.42902208, 0.27941176,
        0.17073171, 0.57509158, 0.05278174],
       [0.81578947, 0.66403162, 0.73796791, 0.71649485, 0.32098765,
        0.36896552, 0.08860759, 0.81132075, 0.29652997, 0.83193277,
        0.10569106, 0.12087912, 0.20114123]]),
       n_clusters=5))
Best evaluation: 0.6547543695083942
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 43, 25, 41, 24]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.1       , 0.        , 0.60962567, 0.53608247, 0.19565217,
        0.51724138, 0.35232068, 0.54716981, 0.32492114, 0.15358362,
        0.50406504, 0.38095238, 0.11126961],
       [0.67105263, 0.18737271, 0.53475936, 0.43814433, 0.39130435,
        0.64827586, 0.60126582, 0.16981132, 0.48580442, 0.47952218,
        0.49593496, 0.58974359, 0.88231098],
       [0.33157895, 0.17718941, 0.45454545, 0.50515464, 0.35869565,
        0.04137931, 0.14345992, 0.45283019, 0.33123028, 0.15102389,
        0.34634146, 0.2014652 , 0.42225392],
       [0.65263158, 0.21588595, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.30188679, 0.35646688, 0.24914676,
        0.50406504, 0.58608059, 0.58273894]]),
       n_clusters=4))
Best evaluation: 0.5589907591249714
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [52, 27, 47, 35]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3480392156862745
F1: 0.1905601502788204
======================================================
Running wine 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.11315789, 0.59288538, 0.07843137, 0.43548387, 0.40217391,
        0.75862069, 0.47257384, 0.20754717, 1.        , 0.13822526,
        0.2195122 , 0.56410256, 0.20256776],
       [0.65526316, 0.48023715, 0.66666667, 0.65053763, 0.29347826,
        0.19655172, 0.03797468, 0.69811321, 0.04113924, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.53684211, 0.15019763, 0.26143791, 0.22043011, 0.30434783,
        0.48965517, 0.48523207, 0.28301887, 0.30063291, 0.20648464,
        0.56910569, 0.52014652, 0.52924394],
       [0.27631579, 0.21541502, 0.40522876, 0.38172043, 0.11956522,
        0.2137931 , 0.24472574, 0.73584906, 0.38607595, 0.09556314,
        0.48780488, 0.36630037, 0.14407989]]),
       n_clusters=4))
Best evaluation: 0.4300770718511404
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 45, 59, 53]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.6155914 , 0.49407115, 0.54545455, 0.56185567, 0.23913043,
        0.32758621, 0.08860759, 0.60377358, 0.26498423, 0.60921502,
        0.05691057, 0.12177122, 0.26533524],
       [0.66397849, 0.21146245, 0.6684492 , 0.48453608, 0.2826087 ,
        0.53448276, 0.47890295, 0.28301887, 0.39432177, 0.19112628,
        0.5203252 , 0.93357934, 0.40442225],
       [0.21236559, 0.19367589, 0.27807487, 0.45876289, 0.17391304,
        0.52413793, 0.2742616 , 0.45283019, 0.31861199, 0.0665529 ,
        0.37398374, 0.42435424, 0.09771755],
       [0.48924731, 0.5       , 0.65240642, 0.58762887, 0.39130435,
        0.23103448, 0.05485232, 0.88679245, 0.17350158, 0.3668942 ,
        0.31707317, 0.30258303, 0.20827389]]),
       n_clusters=4))
Best evaluation: 0.3989390961021294
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [39, 55, 45, 21]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 75 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.67105263, 0.36363636, 0.64705882, 0.70430108, 0.38043478,
        0.19655172, 0.10548523, 0.49056604, 0.35443038, 0.62969283,
        0.21138211, 0.19413919, 0.33666191],
       [0.59210526, 0.17786561, 0.74509804, 0.22043011, 0.43478261,
        0.55862069, 0.49367089, 0.39622642, 0.29746835, 0.28327645,
        0.49593496, 0.55311355, 0.42938659],
       [0.25526316, 0.15217391, 0.47058824, 0.56989247, 0.17391304,
        0.16206897, 0.19198312, 0.69811321, 0.38291139, 0.19795222,
        0.46341463, 0.50549451, 0.12268188],
       [0.7       , 0.49802372, 0.54901961, 0.46236559, 0.40217391,
        0.29310345, 0.0464135 , 0.69811321, 0.12025316, 0.39249147,
        0.3902439 , 0.2014652 , 0.28673324]]),
       n_clusters=4))
Best evaluation: 0.39981004943064724
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [22, 59, 55, 24]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3600583718121295
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.15263158, 0.12055336, 0.71657754, 0.48453608, 0.26086957,
        0.60689655, 0.5443038 , 0.32      , 0.65615142, 0.1168942 ,
        0.3902439 , 0.72893773, 0.28673324],
       [0.41315789, 0.33992095, 0.44919786, 0.40721649, 0.26086957,
        0.22068966, 0.06751055, 1.        , 0.16719243, 0.49658703,
        0.20325203, 0.11355311, 0.29743224],
       [0.80789474, 0.25296443, 0.55614973, 0.42268041, 0.35869565,
        0....8 , 0.38      , 0.6214511 , 0.41979522,
        0.4796748 , 0.54212454, 0.55777461],
       [0.35263158, 0.08498024, 0.29946524, 0.46391753, 0.08695652,
        0.38965517, 0.35021097, 0.28      , 0.19873817, 0.29010239,
        0.5203252 , 0.80952381, 0.16547789],
       [0.47631579, 0.43873518, 0.6684492 , 0.69072165, 0.33695652,
        0.46206897, 0.05485232, 0.8       , 0.12618297, 0.3105802 ,
        0.33333333, 0.32234432, 0.22253923]]),
       n_clusters=5))
Best evaluation: 0.4323352788264243
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [20, 27, 49, 36, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19673280115735362
======================================================
Running wine 75 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 2 majority_voting default
======================================================
python cbeg.py -d wine -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 75 3 majority_voting default
======================================================
python cbeg.py -d wine -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       1.00      0.78      0.88         9
           2       0.00      0.00      0.00         0

    accuracy                           0.72        18
   macro avg       0.67      0.48      0.56        18
weighted avg       1.00      0.72      0.84        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [59, 45, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.50        18
   macro avg       0.48      0.47      0.39        18
weighted avg       0.90      0.50      0.58        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [46, 60, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.43      0.21      0.29        14
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.14      0.07      0.10        18
weighted avg       0.33      0.17      0.22        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 54, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.42      0.56        12
           1       0.00      0.00      0.00         6
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.28      0.14      0.19        18
weighted avg       0.56      0.28      0.37        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 54, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.17      0.17      0.17         6
           1       0.29      0.17      0.21        12
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.15      0.11      0.13        18
weighted avg       0.25      0.17      0.20        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 49, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.29      0.31         7
           1       0.29      0.18      0.22        11
           2       0.00      0.00      0.00         0

    accuracy                           0.22        18
   macro avg       0.21      0.16      0.18        18
weighted avg       0.30      0.22      0.26        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [53, 60, 47]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [58, 46, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.43      1.00      0.60         3
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.48      0.48      0.40        17
weighted avg       0.90      0.53      0.60        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 58, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 51, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3656862745098039
F1: 0.2767298744427228
======================================================
Running wine 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6451485640603953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       0.86      0.75      0.80         8
           2       0.20      1.00      0.33         1

    accuracy                           0.67        18
   macro avg       0.63      0.77      0.60        18
weighted avg       0.81      0.67      0.71        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 19, 37, 37, 22]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.6447924523535065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.43      1.00      0.60         3
           2       0.80      0.67      0.73         6

    accuracy                           0.72        18
   macro avg       0.74      0.78      0.71        18
weighted avg       0.84      0.72      0.74        18

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [22, 45, 21, 35, 37]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.83684211, 0.65217391, 0.57754011, 0.46368715, 0.44565217,
        0.64482759, 0.48734177, 0.30769231, 0.26498423, 0.33788396,
        0.31707317, 0.75457875, 0.57203994],
       [0.40789474, 0.10869565, 0.39572193, 0.52513966, 0.35869565,
        0.17241379, 0.05063291, 0.75      , 0.31230284, 0.53924915,
        0.08130081, 0.1025641 , 0.25820257],
       [0.33157895, 0.13241107, 0.3315508 , 0.30167598, 0.16...
        0.54137931, 0.4556962 , 0.28846154, 0.42902208, 0.13822526,
        0.6097561 , 0.53846154, 0.10699001],
       [0.41315789, 0.11857708, 0.28877005, 0.44134078, 0.19565217,
        0.16206897, 0.21518987, 0.28846154, 0.29652997, 0.09982935,
        0.45528455, 0.54945055, 0.20256776],
       [0.63684211, 0.58498024, 0.6631016 , 0.69273743, 0.44565217,
        0.24827586, 0.12236287, 0.55769231, 0.33123028, 0.80204778,
        0.30081301, 0.10622711, 0.29743224]]),
       n_clusters=5))
Best evaluation: 0.6507119063948821
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      1.00      0.92         6
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.95      0.95      0.95        18
weighted avg       0.95      0.94      0.94        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [51, 20, 31, 27, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.820998484203783
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.29      0.31         7
           1       0.57      0.57      0.57         7
           2       0.40      0.50      0.44         4

    accuracy                           0.44        18
   macro avg       0.43      0.45      0.44        18
weighted avg       0.44      0.44      0.44        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 21, 38, 43, 38]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.78      0.88         9
           2       0.80      1.00      0.89         4

    accuracy                           0.89        18
   macro avg       0.88      0.93      0.89        18
weighted avg       0.91      0.89      0.89        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      0.78      0.88         9
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.93      0.88        18
weighted avg       0.93      0.89      0.90        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.88      0.93         8
           2       1.00      1.00      1.00         5

    accuracy                           0.94        18
   macro avg       0.94      0.96      0.95        18
weighted avg       0.95      0.94      0.95        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71637427, 0.15217391, 0.70430108, 0.74226804, 0.17391304,
        0.68641115, 0.70194986, 0.1509434 , 0.46056782, 0.14564831,
        0.90721649, 0.69230769, 0.09415121],
       [0.66666667, 0.49802372, 0.6344086 , 0.48453608, 0.40217391,
        0.29616725, 0.06128134, 0.69811321, 0.12302839, 0.36767318,
        0.49484536, 0.2014652 , 0.28673324],
       [0.84502924, 0.23320158, 0.7311828 , 0.48453608,...
        0.63414634, 0.77994429, 0.37735849, 0.49211356, 0.39609236,
        0.60824742, 0.50549451, 0.7146933 ],
       [0.19590643, 0.26482213, 0.1827957 , 0.3556701 , 0.29347826,
        0.43554007, 0.5097493 , 0.24528302, 0.31230284, 0.13854352,
        0.81443299, 0.61904762, 0.30813124],
       [0.53216374, 0.50592885, 0.49462366, 0.40721649, 0.30434783,
        0.28571429, 0.13649025, 0.90566038, 0.46056782, 0.77975133,
        0.08247423, 0.08791209, 0.2831669 ]]),
       n_clusters=5))
Best evaluation: 0.649763326834959
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       0.86      0.86      0.86         7
           2       1.00      0.80      0.89         5

    accuracy                           0.88        17
   macro avg       0.90      0.89      0.89        17
weighted avg       0.89      0.88      0.88        17

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [26, 27, 49, 35, 24]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.20789474, 0.14867617, 0.3368984 , 0.5257732 , 0.17391304,
        0.34482759, 0.26582278, 0.32075472, 0.3533123 , 0.05716724,
        0.38211382, 0.75457875, 0.15477889],
       [0.64473684, 0.21792261, 0.56149733, 0.51030928, 0.32608696,
        0.59310345, 0.55696203, 0.24528302, 0.45741325, 0.32593857,
        0.45528455, 0.80586081, 0.45791726],
       [0.5       , 0.42158859, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ],
       [0.35      , 0.6293279 , 0.54545455, 0.53608247, 0.19565217,
        0.45517241, 0.12236287, 0.69811321, 0.19873817, 0.54351536,
        0.06504065, 0.11355311, 0.17261056]]),
       n_clusters=4))
Best evaluation: 0.5653056788880586
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         8
           2       1.00      1.00      1.00         4

    accuracy                           1.00        17
   macro avg       1.00      1.00      1.00        17
weighted avg       1.00      1.00      1.00        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [47, 57, 29, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8382352941176471
F1: 0.8319517954812072
======================================================
Running wine 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.57      1.00      0.73         4
           2       0.20      1.00      0.33         1

    accuracy                           0.61        18
   macro avg       0.59      0.82      0.56        18
weighted avg       0.86      0.61      0.64        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [37, 19, 37, 22, 45]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.11290323, 0.32806324, 0.56684492, 0.48453608, 0.2826087 ,
        0.66206897, 0.51687764, 0.35849057, 0.44794953, 0.16808874,
        0.2601626 , 0.77490775, 0.24750357],
       [0.4811828 , 0.51976285, 0.5026738 , 0.45876289, 0.19565217,
        0.17241379, 0.06751055, 0.50943396, 0.17665615, 0.7662116 ,
        0.19512195, 0.1697417 , 0.29029957],
       [0.86021505, 0.1916996 , 0.57219251, 0.25773196, 0.61956522,
        0.62758621, 0.57383966, 0.28301887, 0.59305994, 0.37201365,
        0.45528455, 0.9704797 , 0.56134094],
       [0.54301075, 0.25889328, 0.99465241, 0.74226804, 0.58695652,
        0.56896552, 0.49367089, 0.64150943, 0.47634069, 0.19624573,
        0.52845528, 0.70479705, 0.39372325]]),
       n_clusters=4))
Best evaluation: 0.4220333009886902
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      1.00      0.73         4
           2       1.00      1.00      1.00         5

    accuracy                           0.83        18
   macro avg       0.86      0.89      0.84        18
weighted avg       0.90      0.83      0.84        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [54, 46, 51, 9]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.43157895, 0.04743083, 0.47058824, 0.41340782, 0.31521739,
        0.42068966, 0.33755274, 0.30769231, 0.33123028, 0.11433447,
        0.6097561 , 0.69230769, 0.12268188],
       [0.82368421, 0.34980237, 0.59893048, 0.52513966, 0.22826087,
        0.24137931, 0.07594937, 0.57692308, 0.26182965, 0.71843003,
        0.11382114, 0.16117216, 0.2724679 ],
       [0.72105263, 0.22924901, 0.70588235, 0.3631284...
        0.69655172, 0.51687764, 0.48076923, 0.40063091, 0.42832765,
        0.52845528, 0.60805861, 0.78245364],
       [0.37368421, 0.45256917, 0.68449198, 0.91620112, 0.29347826,
        0.31724138, 0.05063291, 0.94230769, 0.23028391, 0.53071672,
        0.15447154, 0.16849817, 0.42938659],
       [0.84210526, 0.1916996 , 0.57219251, 0.27932961, 0.61956522,
        0.62758621, 0.57383966, 0.26923077, 0.59305994, 0.37201365,
        0.45528455, 0.97069597, 0.56134094]]),
       n_clusters=5))
Best evaluation: 0.4048451655204826
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       0.71      1.00      0.83         5
           2       1.00      1.00      1.00         5

    accuracy                           0.89        18
   macro avg       0.90      0.92      0.90        18
weighted avg       0.92      0.89      0.89        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [47, 35, 27, 23, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.29      0.31         7
           1       0.57      0.57      0.57         7
           2       0.40      0.50      0.44         4

    accuracy                           0.44        18
   macro avg       0.43      0.45      0.44        18
weighted avg       0.44      0.44      0.44        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [21, 38, 38, 42, 21]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.34210526, 0.04940711, 0.31550802, 0.21649485, 0.69047619,
        0.31724138, 0.3185654 , 0.41509434, 0.74132492, 0.18088737,
        0.44444444, 0.38095238, 0.33666191],
       [0.21315789, 0.42490119, 0.46524064, 0.3814433 , 0.4047619 ,
        0.25517241, 0.20675105, 0.56603774, 0.170347  , 0.1168942 ,
        0.35897436, 0.45787546, 0.15834522],
       [0.65263158, 0.20948617, 0.68983957, 0.43298969, 0....
        0.47241379, 0.46202532, 0.30188679, 0.35646688, 0.24914676,
        0.47863248, 0.58608059, 0.58273894],
       [0.72368421, 0.39920949, 0.5026738 , 0.58762887, 0.14285714,
        0.12758621, 0.07172996, 0.52830189, 0.1955836 , 0.70819113,
        0.13675214, 0.15018315, 0.2403709 ],
       [0.66578947, 0.19565217, 0.58823529, 0.51030928, 0.45238095,
        0.68275862, 0.51476793, 0.13207547, 0.64353312, 0.42406143,
        0.37606838, 0.64468864, 0.60057061]]),
       n_clusters=5))
Best evaluation: 0.4495286152361265
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       1.00      1.00      1.00         7
           2       1.00      1.00      1.00         5

    accuracy                           1.00        18
   macro avg       1.00      1.00      1.00        18
weighted avg       1.00      1.00      1.00        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 36, 25, 45, 49]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       1.00      0.88      0.93         8
           2       0.60      1.00      0.75         3

    accuracy                           0.89        18
   macro avg       0.87      0.91      0.87        18
weighted avg       0.93      0.89      0.90        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       0.86      0.67      0.75         9
           2       1.00      1.00      1.00         5

    accuracy                           0.78        18
   macro avg       0.79      0.81      0.78        18
weighted avg       0.82      0.78      0.79        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.27368421, 0.2586558 , 0.43315508, 0.53608247, 0.16304348,
        0.55862069, 0.48734177, 0.45283019, 0.32752613, 0.12627986,
        0.30894309, 0.73626374, 0.07132668],
       [0.83947368, 0.16496945, 0.5026738 , 0.29381443, 0.52173913,
        0.76551724, 0.56118143, 0.24528302, 0.56445993, 0.43515358,
        0.37398374, 0.74725275, 0.4935806 ],
       [0.5       , 0.3910387 , 0.71657754, 0.53608247, 0.28260...
        0.19310345, 0.03375527, 0.75471698, 0.1184669 , 0.28327645,
        0.23577236, 0.38095238, 0.2296719 ],
       [0.69736842, 0.19144603, 0.53475936, 0.34020619, 0.36956522,
        0.49655172, 0.49578059, 0.54716981, 0.54355401, 0.21843003,
        0.6097561 , 0.58608059, 0.50784593],
       [0.73947368, 0.65784114, 0.54545455, 0.45876289, 0.20652174,
        0.28275862, 0.10337553, 0.66037736, 0.40069686, 0.65955631,
        0.07317073, 0.13553114, 0.14407989]]),
       n_clusters=5))
Best evaluation: 0.4052070261394887
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      1.00      1.00         7
           2       1.00      0.83      0.91         6

    accuracy                           0.94        18
   macro avg       0.94      0.94      0.94        18
weighted avg       0.95      0.94      0.94        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 39, 28, 26, 24]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.80      0.73         5
           1       0.86      0.75      0.80         8
           2       0.25      0.25      0.25         4

    accuracy                           0.65        17
   macro avg       0.59      0.60      0.59        17
weighted avg       0.66      0.65      0.65        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         8
           2       1.00      1.00      1.00         4

    accuracy                           1.00        17
   macro avg       1.00      1.00      1.00        17
weighted avg       1.00      1.00      1.00        17

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8035947712418302
F1: 0.7986826449932746
======================================================
Running wine 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41126431414063647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         6
           1       0.86      0.75      0.80         8
           2       0.60      0.75      0.67         4

    accuracy                           0.83        18
   macro avg       0.82      0.83      0.82        18
weighted avg       0.85      0.83      0.84        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [19, 45, 37, 37, 22]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41297413582197956
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.57      0.62         7
           1       0.14      0.25      0.18         4
           2       0.80      0.57      0.67         7

    accuracy                           0.50        18
   macro avg       0.54      0.46      0.49        18
weighted avg       0.60      0.50      0.54        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 35, 22, 37, 21]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.78684211, 0.18577075, 0.45454545, 0.30167598, 0.2826087 ,
        0.57586207, 0.41983122, 0.23076923, 0.49526814, 0.29180887,
        0.45528455, 0.84981685, 0.53994294],
       [0.53157895, 0.61660079, 0.51336898, 0.66480447, 0.16304348,
        0.23103448, 0.26371308, 0.90384615, 0.38170347, 0.3003413 ,
        0.29268293, 0.27106227, 0.16904422],
       [0.56315789, 0.36561265, 0.54010695, 0.52513966, 0.54347826,
        0.23103448, 0.07172996, 0.75      , 0.33123028, 0.68430034,
        0.09756098, 0.12820513, 0.40085592],
       [0.25526316, 0.03557312, 0.34224599, 0.46927374, 0.17391304,
        0.49655172, 0.40506329, 0.30769231, 0.32176656, 0.10409556,
        0.73170732, 0.67765568, 0.        ]]),
       n_clusters=4))
Best evaluation: 0.4020622840484206
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.80      0.73         5
           1       0.86      0.75      0.80         8
           2       1.00      1.00      1.00         5

    accuracy                           0.83        18
   macro avg       0.84      0.85      0.84        18
weighted avg       0.84      0.83      0.84        18

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 21, 40, 45]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4180189624295053
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.29      0.31         7
           1       0.57      0.57      0.57         7
           2       0.40      0.50      0.44         4

    accuracy                           0.44        18
   macro avg       0.43      0.45      0.44        18
weighted avg       0.44      0.44      0.44        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 42, 21, 21, 38]
Selected clustering_algorithm: fcm
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      1.00      0.91         5
           1       1.00      0.78      0.88         9
           2       0.80      1.00      0.89         4

    accuracy                           0.89        18
   macro avg       0.88      0.93      0.89        18
weighted avg       0.91      0.89      0.89        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86         8
           1       1.00      0.88      0.93         8
           2       0.40      1.00      0.57         2

    accuracy                           0.83        18
   macro avg       0.80      0.88      0.79        18
weighted avg       0.93      0.83      0.86        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.50      0.75      0.60         4
           1       0.86      0.67      0.75         9
           2       1.00      1.00      1.00         5

    accuracy                           0.78        18
   macro avg       0.79      0.81      0.78        18
weighted avg       0.82      0.78      0.79        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.3       , 0.11405295, 0.62566845, 0.43298969, 0.36956522,
        0.3137931 , 0.29746835, 0.60377358, 0.21602787, 0.14249147,
        0.78861789, 0.35164835, 0.05492154],
       [0.88157895, 0.19959267, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.88850174, 0.53071672,
        0.58536585, 0.63369963, 0.90513552],
       [0.54736842, 0.02443992, 0.18181818, 0.22680412, 0.08695652,
        0.68965517, 0.59915612, 0.24528302, 0.65156794, 0.34300341,
        0.5203252 , 0.6996337 , 0.15977175],
       [0.40789474, 0.0814664 , 0.39572193, 0.48453608, 0.35869565,
        0.17241379, 0.05063291, 0.75471698, 0.34494774, 0.53924915,
        0.08130081, 0.1025641 , 0.25820257],
       [0.48421053, 0.75763747, 0.59893048, 0.56185567, 0.17391304,
        0.24827586, 0.06540084, 0.64150943, 0.15679443, 0.54351536,
        0.04878049, 0.21611722, 0.24750357]]),
       n_clusters=5))
Best evaluation: 0.4206596082785298
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.86      1.00      0.92         6
           2       0.60      1.00      0.75         3

    accuracy                           0.83        18
   macro avg       0.82      0.89      0.82        18
weighted avg       0.89      0.83      0.83        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [37, 49, 28, 19, 27]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.80      0.73         5
           1       0.71      1.00      0.83         5
           2       0.75      0.43      0.55         7

    accuracy                           0.71        17
   macro avg       0.71      0.74      0.70        17
weighted avg       0.71      0.71      0.68        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         8
           2       1.00      1.00      1.00         4

    accuracy                           1.00        17
   macro avg       1.00      1.00      1.00        17
weighted avg       1.00      1.00      1.00        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7650326797385621
F1: 0.7599418201624084
======================================================
Running wine 50 2 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 meta_classifier crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand meta_classifier default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 meta_classifier default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 meta_classifier default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.62368421, 0.76284585, 0.75816993, 0.7311828 , 0.45652174,
        0.34482759, 0.13080169, 0.26415094, 0.21835443, 0.61604096,
        0.15447154, 0.23809524, 0.2510699 ],
       [0.24473684, 0.06916996, 0.39215686, 0.51612903, 0.33695652,
        0.82758621, 0.37974684, 0.        , 0.38924051, 0.16467577,
        0.41463415, 0.68131868, 0.43366619],
       [0.53157895, 0.61660079, 0.40522876, 0.59677419, 0.16304348,
        0.23103448, 0.26371308, 0.90566038, 0.37974684, 0.3003413 ,
        0.29268293, 0.27106227, 0.16904422],
       [0.59210526, 0.17786561, 0.74509804, 0.22043011, 0.43478261,
        0.55862069, 0.49367089, 0.39622642, 0.29746835, 0.28327645,
        0.49593496, 0.55311355, 0.42938659]]),
       n_clusters=4))
Best evaluation: 0.564503995523541
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [27, 48, 30, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.86021505, 0.1916996 , 0.57219251, 0.25773196, 0.61956522,
        0.62758621, 0.57383966, 0.28301887, 0.59305994, 0.37201365,
        0.45528455, 0.9704797 , 0.56134094],
       [0.53763441, 0.03162055, 0.18716578, 0.27835052, 0.17391304,
        0.33448276, 0.35654008, 0.20754717, 0.33123028, 0.28327645,
        0.57723577, 0.43911439, 0.08131241],
       [0.59408602, 0.36561265, 0.80748663, 0.5360824...
        0.62758621, 0.49578059, 0.49056604, 0.44479495, 0.25938567,
        0.45528455, 0.60516605, 0.32596291],
       [0.73924731, 0.39920949, 0.5026738 , 0.58762887, 0.2173913 ,
        0.12758621, 0.07172996, 0.52830189, 0.1955836 , 0.70819113,
        0.17886179, 0.14391144, 0.2403709 ],
       [0.51075269, 0.40909091, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.37638376, 0.2296719 ]]),
       n_clusters=5))
Best evaluation: 0.6384240038707676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.12      0.17        18
weighted avg       0.94      0.33      0.49        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [49, 36, 18, 39, 18]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5521034684865687
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.65      , 0.47035573, 0.67379679, 0.69072165, 0.57608696,
        0.10791367, 0.23861171, 0.16981132, 0.26498423, 0.62457338,
        0.08943089, 0.01132075, 0.16706444],
       [0.83947368, 0.18972332, 0.5026738 , 0.29381443, 0.52173913,
        0.75539568, 0.54880694, 0.24528302, 0.51104101, 0.43515358,
        0.37398374, 0.76981132, 0.54097056],
       [0.61315789, 0.35968379, 0.52941176, 0.48453608, 0.20652174,
        0.10791367, 0.00650759, 0.45283019, 0.07255521, 0.36860068,
        0.17886179, 0.45283019, 0.38981702],
       [0.56052632, 0.3201581 , 0.70053476, 0.41237113, 0.33695652,
        0.61151079, 0.60086768, 0.32075472, 0.75709779, 0.37542662,
        0.44715447, 0.71698113, 0.71201273]]),
       n_clusters=4))
Best evaluation: 0.5707695526981238
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [42, 50, 29, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5527999689282257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5552194884058784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.45      0.59        11
           1       0.14      0.14      0.14         7
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.20      0.24        18
weighted avg       0.56      0.33      0.42        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.56052632, 0.57637475, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.2807571 , 0.23208191,
        0.09756098, 0.15018315, 0.39372325],
       [0.65263158, 0.21588595, 0.68983957, 0.43298969, 0.43478261,
        0.47241379, 0.46202532, 0.30188679, 0.35646688, 0.24914676,
        0.50406504, 0.58608059, 0.58273894],
       [0.29736842, 0.17718941, 0.50802139, 0.62886598, 0.2173913 ,
        0.27586207, 0.28481013, 0.56603774, 0.36277603, 0.09982935,
        0.69105691, 0.36263736, 0.15477889],
       [0.52631579, 0.03258656, 0.18716578, 0.27835052, 0.17391304,
        0.33448276, 0.35654008, 0.20754717, 0.33123028, 0.28327645,
        0.57723577, 0.44322344, 0.08131241]]),
       n_clusters=4))
Best evaluation: 0.5578827774973397
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.13      0.19        17
weighted avg       0.76      0.29      0.42        17

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 56, 25, 34]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3594771241830065
F1: 0.23008899155531717
======================================================
Running wine 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.43947368, 0.61857708, 0.45751634, 0.62365591, 0.33695652,
        0.63793103, 0.46624473, 0.56603774, 0.48417722, 0.11006826,
        0.57723577, 0.68131868, 0.13195435],
       [0.71315789, 0.18379447, 0.35947712, 0.2688172 , 0.52173913,
        0.55862069, 0.54008439, 0.1509434 , 0.37974684, 0.38993174,
        0.35772358, 0.70695971, 0.55777461],
       [0.30789474, 0.45256917, 0.40522876, 0.4086021...
        0.09310345, 0.03164557, 0.50943396, 0.09810127, 0.36006826,
        0.14634146, 0.20512821, 0.16547789],
       [0.69736842, 0.21541502, 0.43137255, 0.31182796, 0.36956522,
        0.49655172, 0.49578059, 0.54716981, 0.49050633, 0.21843003,
        0.6097561 , 0.58608059, 0.50784593],
       [0.47105263, 0.51976285, 0.39215686, 0.43548387, 0.19565217,
        0.17241379, 0.06751055, 0.50943396, 0.17405063, 0.7662116 ,
        0.19512195, 0.17582418, 0.29029957]]),
       n_clusters=5))
Best evaluation: 0.40113133782422505
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.12      0.17        18
weighted avg       0.94      0.33      0.49        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [44, 39, 24, 25, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3600583718121295
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 57, 57]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.73684211, 0.1798419 , 0.6631016 , 0.36871508, 0.26086957,
        0.50689655, 0.55907173, 0.15384615, 0.59305994, 0.36860068,
        0.61788618, 0.76923077, 0.70399429],
       [0.40789474, 0.10869565, 0.39572193, 0.52513966, 0.35869565,
        0.17241379, 0.05063291, 0.75      , 0.31230284, 0.53924915,
        0.08130081, 0.1025641 , 0.25820257],
       [0.38947368, 0.19565217, 0.3315508 , 0.55307263, 0.16304348,
        0.42068966, 0.33333333, 0.34615385, 0.33753943, 0.14163823,
        0.45528455, 0.84249084, 0.2810271 ],
       [0.43684211, 0.15612648, 0.48128342, 0.56424581, 0.10869565,
        0.13793103, 0.23628692, 0.84615385, 0.38170347, 0.15102389,
        0.3902439 , 0.28937729, 0.15477889]]),
       n_clusters=4))
Best evaluation: 0.40451489815031866
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 40, 45, 21]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.50      0.50      0.50         8
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.50      0.35      0.40        17
weighted avg       0.76      0.53      0.61        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3941176470588235
F1: 0.2707626370819039
======================================================
Running wine 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.57      0.44      0.50         9
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.79      0.56      0.65        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.54301075, 0.19565217, 0.36363636, 0.09278351, 0.23913043,
        0.6       , 0.61814346, 0.0754717 , 0.78864353, 0.50511945,
        0.5203252 , 0.59778598, 0.62196862],
       [0.4327957 , 0.12252964, 0.35294118, 0.31958763, 0.32608696,
        0.35862069, 0.2257384 , 0.75471698, 0.06624606, 0.38139932,
        0.40650407, 0.11070111, 0.12268188],
       [0.66397849, 0.47035573, 0.67379679, 0.69072165, 0.57608696,
        0.14482759, 0.25949367, 0.16981132, 0.26498423, 0.62457338,
        0.08943089, 0.00369004, 0.15834522],
       [0.28225806, 0.0770751 , 0.61497326, 0.69072165, 0.08695652,
        0.35172414, 0.26160338, 0.50943396, 0.31230284, 0.07849829,
        0.67479675, 0.52767528, 0.2510699 ]]),
       n_clusters=4))
Best evaluation: 0.4039045946454413
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [55, 21, 41, 43]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.29      0.29      0.29         7
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.28      0.33        18
weighted avg       0.72      0.44      0.54        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.29      1.00      0.44         2
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.46      0.33        18
weighted avg       0.92      0.44      0.53        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.14      0.17      0.15         6
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.22      0.27        18
weighted avg       0.71      0.39      0.50        18

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.50      0.62        10
           1       0.29      0.25      0.27         8
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.37      0.25      0.30        18
weighted avg       0.59      0.39      0.47        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.40      0.57        15
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.41        17
   macro avg       0.38      0.30      0.26        17
weighted avg       0.90      0.41      0.53        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.50      0.50      0.50         8
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.50      0.35      0.40        17
weighted avg       0.76      0.53      0.61        17

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.41633986928104577
F1: 0.29948244384518896
======================================================
Running wine 50 2 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 weighted_membership crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand weighted_membership default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 weighted_membership default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 weighted_membership default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4653450890660529
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.55        16
           1       0.14      0.50      0.22         2
           2       0.00      0.00      0.00         0

    accuracy                           0.39        18
   macro avg       0.38      0.29      0.26        18
weighted avg       0.90      0.39      0.51        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [12, 42, 45, 22, 39]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.54301075, 0.20355731, 0.39572193, 0.32989691, 0.40217391,
        0.69655172, 0.56118143, 0.28301887, 0.51104101, 0.32081911,
        0.32520325, 0.7601476 , 0.43295292],
       [0.54301075, 0.61660079, 0.51336898, 0.61340206, 0.16304348,
        0.23103448, 0.26371308, 0.90566038, 0.38170347, 0.3003413 ,
        0.29268293, 0.26568266, 0.16904422],
       [0.27956989, 0.28063241, 0.43315508, 0.5360824...
        0.55862069, 0.48734177, 0.45283019, 0.29652997, 0.12627986,
        0.30894309, 0.73431734, 0.07132668],
       [0.54301075, 0.1798419 , 0.63636364, 0.3814433 , 0.30434783,
        0.50689655, 0.44092827, 0.30188679, 0.32492114, 0.25341297,
        0.5203252 , 0.4501845 , 0.58987161],
       [0.6155914 , 0.49407115, 0.54545455, 0.56185567, 0.23913043,
        0.32758621, 0.08860759, 0.60377358, 0.26498423, 0.60921502,
        0.05691057, 0.12177122, 0.26533524]]),
       n_clusters=5))
Best evaluation: 0.6441418226189232
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 20, 45, 27, 39]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71052632, 0.71541502, 0.48128342, 0.66480447, 0.19565217,
        0.10344828, 0.02742616, 0.73076923, 0.23343849, 0.4556314 ,
        0.24390244, 0.17582418, 0.17261056],
       [0.75526316, 0.18577075, 0.40641711, 0.30167598, 0.33695652,
        0.73103448, 0.64345992, 0.13461538, 0.54574132, 0.4112628 ,
        0.3495935 , 0.75457875, 0.5042796 ],
       [0.35263158, 0.17588933, 0.5026738 , 0.77653631, 0.19565217,
        0.42758621, 0.44514768, 0.5       , 0.47003155, 0.07167235,
        0.33333333, 0.55311355, 0.04564907],
       [0.73684211, 0.1798419 , 0.6631016 , 0.36871508, 0.26086957,
        0.50689655, 0.55907173, 0.15384615, 0.59305994, 0.36860068,
        0.61788618, 0.76923077, 0.70399429]]),
       n_clusters=4))
Best evaluation: 0.5623564433109407
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 26, 57, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5526334434637257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6441752881023877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6472163815109635
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.97894737, 0.19565217, 0.55080214, 0.04123711, 0.22826087,
        0.73103448, 0.70675105, 0.6       , 0.75709779, 0.35153584,
        0.62601626, 0.53479853, 0.62196862],
       [0.65526316, 0.48023715, 0.72727273, 0.66494845, 0.29347826,
        0.19655172, 0.03797468, 0.74      , 0.04416404, 0.26194539,
        0.33333333, 0.28937729, 0.17261056],
       [0.15526316, 0.24703557, 0.49197861, 0.3814433 , 0.30434783,
        0.70344828, 0.40506329, 0.08      , 0.29652997, 0.16808874,
        0.55284553, 0.61904762, 0.04778887],
       [0.71578947, 0.19565217, 0.56149733, 0.27835052, 0.20652174,
        0.55862069, 0.51054852, 0.32      , 0.44164038, 0.36860068,
        0.54471545, 0.5970696 , 0.74322397],
       [0.70526316, 0.22134387, 0.53475936, 0.30927835, 0.33695652,
        0.56206897, 0.53586498, 0.28      , 0.40378549, 0.21501706,
        0.51219512, 1.        , 0.53994294]]),
       n_clusters=5))
Best evaluation: 0.6424038169413276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [11, 45, 38, 38, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.88157895, 0.19959267, 0.54545455, 0.07216495, 0.34782609,
        0.8       , 0.69620253, 0.30188679, 0.88850174, 0.53071672,
        0.58536585, 0.63369963, 0.90513552],
       [0.33157895, 0.39511202, 0.45989305, 0.3814433 , 0.19565217,
        0.50689655, 0.40295359, 0.22641509, 0.55052265, 0.07423208,
        0.54471545, 0.74358974, 0.0085592 ],
       [0.72368421, 0.3808554 , 0.5026738 , 0.58762887, 0.2173913 ,
        0.12758621, 0.07172996, 0.52830189, 0.21602787, 0.70819113,
        0.17886179, 0.15018315, 0.2403709 ],
       [0.56052632, 0.54582485, 0.42245989, 0.53608247, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.31010453, 0.23208191,
        0.09756098, 0.15018315, 0.39372325]]),
       n_clusters=4))
Best evaluation: 0.5712207265532465
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 51, 23, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.633438323506445
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5523418647952756
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3369281045751634
F1: 0.17527376636498548
======================================================
Running wine 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.31052632, 0.08893281, 0.03267974, 0.29032258, 0.88043478,
        0.3       , 0.19831224, 0.01886792, 0.65822785, 0.13395904,
        0.6504065 , 0.65934066, 0.31383738],
       [0.83684211, 0.65217391, 0.48366013, 0.40322581, 0.44565217,
        0.64482759, 0.48734177, 0.32075472, 0.26265823, 0.33788396,
        0.31707317, 0.75457875, 0.57203994],
       [0.56052632, 0.55928854, 0.29411765, 0.51612903, 0.34782609,
        0.17931034, 0.0443038 , 0.56603774, 0.27848101, 0.23208191,
        0.09756098, 0.15018315, 0.39372325],
       [0.27631579, 0.21541502, 0.40522876, 0.38172043, 0.11956522,
        0.2137931 , 0.24472574, 0.73584906, 0.38607595, 0.09556314,
        0.48780488, 0.36630037, 0.14407989]]),
       n_clusters=4))
Best evaluation: 0.43176906931885123
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [6, 57, 45, 52]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.37365591, 0.17193676, 0.44385027, 0.61340206, 0.41304348,
        0.35172414, 0.36919831, 0.39622642, 0.3785489 , 0.0665529 ,
        0.47154472, 0.61623616, 0.04778887],
       [0.35752688, 0.61067194, 0.54545455, 0.53608247, 0.19565217,
        0.45517241, 0.12236287, 0.69811321, 0.19873817, 0.54351536,
        0.06504065, 0.10701107, 0.17261056],
       [0.57258065, 0.3201581 , 0.70053476, 0.41237113, 0.33695652,
        0.62758621, 0.61181435, 0.32075472, 0.75709779, 0.37542662,
        0.44715447, 0.69372694, 0.64693295],
       [0.76344086, 0.22924901, 0.77005348, 0.45360825, 0.40217391,
        0.67931034, 0.55485232, 0.45283019, 0.42586751, 0.27474403,
        0.62601626, 0.77859779, 0.45435093]]),
       n_clusters=4))
Best evaluation: 0.3863235057518251
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [56, 46, 33, 25]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.30789474, 0.45256917, 0.51336898, 0.46927374, 0.2826087 ,
        0.09310345, 0.03164557, 0.5       , 0.10094637, 0.36006826,
        0.14634146, 0.20512821, 0.16547789],
       [0.62105263, 0.20355731, 0.67379679, 0.30726257, 0.25      ,
        0.64482759, 0.54852321, 0.38461538, 0.32807571, 0.3003413 ,
        0.35772358, 0.71428571, 0.65406562],
       [0.56052632, 0.3201581 , 0.70053476, 0.44692737, 0.33695652,
        0...75709779, 0.37542662,
        0.44715447, 0.6959707 , 0.64693295],
       [0.35263158, 0.08498024, 0.29946524, 0.5027933 , 0.08695652,
        0.38965517, 0.35021097, 0.25      , 0.19873817, 0.29010239,
        0.5203252 , 0.80952381, 0.16547789],
       [0.16052632, 0.26086957, 0.58823529, 0.61452514, 0.15217391,
        0.33448276, 0.28481013, 0.65384615, 0.29652997, 0.12969283,
        0.42276423, 0.54212454, 0.28673324]]),
       n_clusters=5))
Best evaluation: 0.44695522124181547
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 49, 13, 31, 22]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002622784241581
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [43, 34, 30, 53]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4406687379216253
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 37, 26, 13, 36]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40183528052450046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [24, 50, 46, 41]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33137254901960783
F1: 0.16511663954119196
======================================================
Running wine 50 rand majority_voting crossval...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3594879365989907
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.55      0.71        11
           1       0.57      0.57      0.57         7
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.37      0.43        18
weighted avg       0.83      0.56      0.65        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [59, 56, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.71236559, 0.21541502, 0.53475936, 0.34020619, 0.36956522,
        0.49655172, 0.49578059, 0.54716981, 0.49211356, 0.21843003,
        0.6097561 , 0.58302583, 0.50784593],
       [0.46774194, 0.32608696, 0.49197861, 0.45876289, 0.17391304,
        0.14137931, 0.03586498, 0.66037736, 0.07255521, 0.7354948 ,
        0.07317073, 0.12546125, 0.13694722],
       [0.51075269, 0.40909091, 0.71657754, 0.53608247, 0.2826087 ,
        0.19310345, 0.03375527, 0.75471698, 0.10725552, 0.28327645,
        0.23577236, 0.37638376, 0.2296719 ],
       [0.30645161, 0.14031621, 0.62566845, 0.43298969, 0.36956522,
        0.3137931 , 0.29746835, 0.60377358, 0.1955836 , 0.14249147,
        0.78861789, 0.34686347, 0.05492154]]),
       n_clusters=4))
Best evaluation: 0.39599055632777846
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 26, 22, 55]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4002097338204662
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [49, 26, 40, 45]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.37894737, 0.1541502 , 0.44919786, 0.43298969, 1.        ,
        0.50359712, 0.39045553, 0.35849057, 0.90536278, 0.11262799,
        0.55284553, 0.51320755, 0.51471758],
       [0.64736842, 0.18181818, 0.47058824, 0.69072165, 0.18478261,
        0.28057554, 0.29718004, 0.26415094, 0.1955836 , 0.20989761,
        0.40650407, 0.56981132, 0.14478918],
       [0.75526316, 0.18577075, 0.40641711, 0.27835052, 0.3369...
        0.71942446, 0.63340564, 0.1509434 , 0.54574132, 0.4112628 ,
        0.3495935 , 0.77735849, 0.55290374],
       [0.34473684, 0.33794466, 0.58823529, 0.53608247, 0.30434783,
        0.52517986, 0.35574837, 0.39622642, 0.28391167, 0.12969283,
        0.2601626 , 0.79622642, 0.11774065],
       [0.35      , 0.61067194, 0.54545455, 0.53608247, 0.19565217,
        0.43165468, 0.09761388, 0.69811321, 0.19873817, 0.54351536,
        0.06504065, 0.11698113, 0.18297534]]),
       n_clusters=5))
Best evaluation: 0.45692369097182317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 23, 50, 41, 41]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4313735364661639
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [24, 49, 31, 37, 19]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.31052632, 0.08893281, 0.20855615, 0.31958763, 1.        ,
        0.3       , 0.19831224, 0.01886792, 0.65930599, 0.16491597,
        0.6504065 , 0.65934066, 0.31383738],
       [0.65526316, 0.48023715, 0.72727273, 0.66494845, 0.33333333,
        0.19655172, 0.03797468, 0.69811321, 0.04416404, 0.32247899,
        0.33333333, 0.28937729, 0.17261056],
       [0.56052632, 0.3201581 , 0.70053476, 0.41237113, 0.38271605,
        0....75709779, 0.46218487,
        0.44715447, 0.6959707 , 0.64693295],
       [0.25526316, 0.03557312, 0.34224599, 0.43298969, 0.19753086,
        0.49655172, 0.40506329, 0.32075472, 0.32176656, 0.12815126,
        0.73170732, 0.67765568, 0.        ],
       [0.44473684, 0.21146245, 0.44919786, 0.42268041, 0.19753086,
        0.42068966, 0.46202532, 0.24528302, 0.42902208, 0.27521008,
        0.55284553, 0.68498168, 0.31098431]]),
       n_clusters=5))
Best evaluation: 0.45084391896787424
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [2, 46, 46, 38, 28]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4037893673503897
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 48, 45, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.40270077911004565
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        18
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        18
   macro avg       0.33      0.11      0.17        18
weighted avg       1.00      0.33      0.50        18

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [27, 49, 46, 38]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.41741565772166517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.35      0.52        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.35        17
   macro avg       0.33      0.12      0.17        17
weighted avg       1.00      0.35      0.52        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 29, 49, 24, 21]
Selected clustering_algorithm: kmeans
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.73421053, 0.20570265, 0.56684492, 0.17525773, 0.44565217,
        1.        , 0.71729958, 0.35849057, 0.46056782, 0.49232082,
        0.43089431, 0.72893773, 0.65049929],
       [0.45789474, 0.33604888, 0.49197861, 0.45876289, 0.17391304,
        0.14137931, 0.03586498, 0.66037736, 0.07255521, 0.7354948 ,
        0.07317073, 0.13186813, 0.13694722],
       [0.36578947, 0.17718941, 0.44385027, 0.61340206, 0.413...
        0.35172414, 0.36919831, 0.39622642, 0.3785489 , 0.0665529 ,
        0.47154472, 0.61904762, 0.04778887],
       [0.66578947, 0.19755601, 0.50802139, 0.28865979, 0.51086957,
        0.74827586, 0.62236287, 0.39622642, 0.60883281, 0.41382253,
        0.38211382, 0.77289377, 0.36875892],
       [0.80789474, 0.26069246, 0.55614973, 0.42268041, 0.35869565,
        0.61034483, 0.5443038 , 0.35849057, 0.6214511 , 0.41979522,
        0.4796748 , 0.54212454, 0.55777461]]),
       n_clusters=5))
Best evaluation: 0.4138644888782654
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.29      0.45        17
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.29        17
   macro avg       0.33      0.10      0.15        17
weighted avg       1.00      0.29      0.45        17

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 46, 42, 22, 31]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.35359477124183003
F1: 0.19420160686145344
======================================================
Running wine 50 2 majority_voting crossval
======================================================
python cbeg.py -d wine -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 majority_voting crossval
======================================================
python cbeg.py -d wine -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 rand majority_voting default...
======================================================
python cbeg.py -d wine -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 2 majority_voting default
======================================================
python cbeg.py -d wine -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wine 50 3 majority_voting default
======================================================
python cbeg.py -d wine -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92         7
           1       0.86      0.55      0.67        11
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.47      0.53        18
weighted avg       0.91      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 45, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.29      0.40      0.33         5
           2       0.00      0.00      0.00         0

    accuracy                           0.44        18
   macro avg       0.43      0.29      0.32        18
weighted avg       0.80      0.44      0.55        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 56, 58]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.43      0.60        14
           1       0.57      1.00      0.73         4
           2       0.00      0.00      0.00         0

    accuracy                           0.56        18
   macro avg       0.52      0.48      0.44        18
weighted avg       0.90      0.56      0.63        18

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 57, 46]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.43      0.21      0.29        14
           2       0.00      0.00      0.00         0

    accuracy                           0.17        18
   macro avg       0.14      0.07      0.10        18
weighted avg       0.33      0.17      0.22        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [54, 49, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.36      0.47        11
           1       0.00      0.00      0.00         7
           2       0.00      0.00      0.00         0

    accuracy                           0.22        18
   macro avg       0.22      0.12      0.16        18
weighted avg       0.41      0.22      0.29        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [47, 54, 59]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80         9
           1       0.86      0.67      0.75         9
           2       0.00      0.00      0.00         0

    accuracy                           0.67        18
   macro avg       0.62      0.44      0.52        18
weighted avg       0.93      0.67      0.77        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 58, 56]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.33      0.33         6
           1       0.43      0.25      0.32        12
           2       0.00      0.00      0.00         0

    accuracy                           0.28        18
   macro avg       0.25      0.19      0.22        18
weighted avg       0.40      0.28      0.32        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [57, 53, 50]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.46      0.63        13
           1       0.71      1.00      0.83         5
           2       0.00      0.00      0.00         0

    accuracy                           0.61        18
   macro avg       0.57      0.49      0.49        18
weighted avg       0.92      0.61      0.69        18

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 46, 54]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.71      1.00      0.83         5
           2       0.00      0.00      0.00         0

    accuracy                           0.65        17
   macro avg       0.57      0.50      0.50        17
weighted avg       0.92      0.65      0.72        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [58, 46, 57]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.50      1.00      0.67         4
           2       0.00      0.00      0.00         0

    accuracy                           0.53        17
   macro avg       0.50      0.46      0.41        17
weighted avg       0.88      0.53      0.58        17

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [61, 47, 53]
Selected clustering_algorithm: kmeans++
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wine/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.4787581699346405
F1: 0.4040317058815511
======================================================
Running pima 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.87      0.82        45
           1       0.78      0.66      0.71        32

    accuracy                           0.78        77
   macro avg       0.78      0.76      0.77        77
weighted avg       0.78      0.78      0.78        77

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4867019658649352
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [1, 5, 91, 160, 3, 157, 274]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.49535208235838213
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.74      0.76        53
           1       0.48      0.54      0.51        24

    accuracy                           0.68        77
   macro avg       0.63      0.64      0.63        77
weighted avg       0.69      0.68      0.68        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [1, 3, 155, 98, 1, 151, 272, 1, 9]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.49526624573774075
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.63      0.71      0.67        24

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.79      0.78      0.78        77

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [121, 2, 278, 93, 1, 49, 1, 144, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.4843932473905159
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.85      0.86        52
           1       0.70      0.76      0.73        25

    accuracy                           0.82        77
   macro avg       0.79      0.80      0.80        77
weighted avg       0.82      0.82      0.82        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [276, 82, 1, 165, 2, 164, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=12))
Best evaluation: 0.31573416442560337
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.73      0.76        55
           1       0.44      0.55      0.49        22

    accuracy                           0.68        77
   macro avg       0.62      0.64      0.63        77
weighted avg       0.70      0.68      0.68        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), AdaBoostClassifier(), LogisticRegression(), AdaBoostClassifier(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [3, 9, 261, 94, 105, 6, 1, 3, 54, 152, 1, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.49930318686715114
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [5, 277, 155, 1, 1, 89, 1, 1, 161]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.5562105946346394
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [1, 273, 1, 2, 1, 84, 154, 175]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.4372277498636159
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.46      0.71      0.56        17

    accuracy                           0.75        76
   macro avg       0.68      0.73      0.69        76
weighted avg       0.80      0.75      0.77        76

Selected Base Classifiers: [RandomForestClassifier(), DecisionTreeClassifier(), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [81, 7, 163, 162, 1, 274, 1, 3]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.29843264767320155
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.62      0.70      0.65        23

    accuracy                           0.78        76
   macro avg       0.74      0.75      0.74        76
weighted avg       0.79      0.78      0.78        76

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression(), SVC(probability=True), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [17, 153, 139, 238, 100, 3, 31, 3, 8]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7448393711551605
F1: 0.6093910427334573
======================================================
Running pima 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.80      0.79        49
           1       0.63      0.61      0.62        28

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.19566523141833994
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.76      0.77        51
           1       0.56      0.58      0.57        26

    accuracy                           0.70        77
   macro avg       0.67      0.67      0.67        77
weighted avg       0.70      0.70      0.70        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GradientBoostingClassifier(), RandomForestClassifier(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [1, 1, 6, 3, 1, 147, 157, 22, 81, 272]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.2303622331169415
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 84, 152, 281, 170, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.22869643104299003
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.59      0.84      0.70        19

    accuracy                           0.82        77
   macro avg       0.77      0.83      0.78        77
weighted avg       0.85      0.82      0.83        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), LogisticRegression(), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 101, 99, 142, 263, 77, 1, 2, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.21033046837251423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [277, 156, 1, 1, 2, 90, 162, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.2235401823777637
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.75      0.78        55
           1       0.48      0.59      0.53        22

    accuracy                           0.70        77
   macro avg       0.65      0.67      0.66        77
weighted avg       0.72      0.70      0.71        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [3, 5, 2, 1, 2, 149, 272, 1, 81, 175]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.196352706406411
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.58      0.75      0.65        20

    accuracy                           0.79        76
   macro avg       0.74      0.78      0.75        76
weighted avg       0.81      0.79      0.80        76

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DecisionTreeClassifier(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 162, 6, 81, 274, 3, 161, 2, 1, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.83      0.82        48
           1       0.69      0.64      0.67        28

    accuracy                           0.76        76
   macro avg       0.75      0.74      0.74        76
weighted avg       0.76      0.76      0.76        76

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7500683526999318
F1: 0.6213090563838848
======================================================
Running pima 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.80      0.79        49
           1       0.63      0.61      0.62        28

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.2163568633634591
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.80      0.79        49
           1       0.63      0.61      0.62        28

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 91, 160, 2, 1, 274, 161, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.74      0.76        53
           1       0.48      0.54      0.51        24

    accuracy                           0.68        77
   macro avg       0.63      0.64      0.63        77
weighted avg       0.69      0.68      0.68        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.23776923912188122
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [280, 171, 2, 1, 1, 83, 1, 152]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.2019427681158787
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.85      0.86        52
           1       0.70      0.76      0.73        25

    accuracy                           0.82        77
   macro avg       0.79      0.80      0.80        77
weighted avg       0.82      0.82      0.82        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), RandomForestClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 2, 2, 164, 1, 1, 275, 106, 133, 5, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.79      0.78        48
           1       0.63      0.59      0.61        29

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.54      0.64      0.58        22

    accuracy                           0.74        76
   macro avg       0.69      0.71      0.70        76
weighted avg       0.75      0.74      0.74        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.62      0.62      0.62        26

    accuracy                           0.74        76
   macro avg       0.71      0.71      0.71        76
weighted avg       0.74      0.74      0.74        76

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7343814080656185
F1: 0.6021395207520527
======================================================
Running pima 100 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.70      0.78      0.74        45
           1       0.63      0.53      0.58        32

    accuracy                           0.68        77
   macro avg       0.66      0.65      0.66        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.72      0.73      0.73        49
           1       0.52      0.50      0.51        28

    accuracy                           0.65        77
   macro avg       0.62      0.62      0.62        77
weighted avg       0.65      0.65      0.65        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        50
           1       0.67      0.67      0.67        27

    accuracy                           0.77        77
   macro avg       0.74      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.74      0.79      0.76        47
           1       0.63      0.57      0.60        30

    accuracy                           0.70        77
   macro avg       0.68      0.68      0.68        77
weighted avg       0.70      0.70      0.70        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.78      0.82        55
           1       0.56      0.68      0.61        22

    accuracy                           0.75        77
   macro avg       0.71      0.73      0.72        77
weighted avg       0.77      0.75      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.72      0.79        61
           1       0.37      0.62      0.47        16

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.63        77
weighted avg       0.77      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.58      0.71      0.64        21

    accuracy                           0.78        76
   macro avg       0.73      0.76      0.74        76
weighted avg       0.80      0.78      0.78        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.74      0.80      0.77        46
           1       0.65      0.57      0.61        30

    accuracy                           0.71        76
   macro avg       0.70      0.69      0.69        76
weighted avg       0.71      0.71      0.71        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7175153793574847
F1: 0.5760210785669551
======================================================
Running pima 100 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.76      0.73        46
           1       0.59      0.52      0.55        31

    accuracy                           0.66        77
   macro avg       0.65      0.64      0.64        77
weighted avg       0.66      0.66      0.66        77

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.91        53
           1       0.78      0.88      0.82        24

    accuracy                           0.88        77
   macro avg       0.86      0.88      0.87        77
weighted avg       0.89      0.88      0.88        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.58      0.68      0.62        22

    accuracy                           0.76        76
   macro avg       0.72      0.74      0.73        76
weighted avg       0.78      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.62      0.70      0.65        23

    accuracy                           0.78        76
   macro avg       0.74      0.75      0.74        76
weighted avg       0.79      0.78      0.78        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7656356801093643
F1: 0.6281886202756964
======================================================
Running pima 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.76      0.73        46
           1       0.59      0.52      0.55        31

    accuracy                           0.66        77
   macro avg       0.65      0.64      0.64        77
weighted avg       0.66      0.66      0.66        77

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.91        53
           1       0.78      0.88      0.82        24

    accuracy                           0.88        77
   macro avg       0.86      0.88      0.87        77
weighted avg       0.89      0.88      0.88        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.77      0.80        53
           1       0.56      0.62      0.59        24

    accuracy                           0.73        77
   macro avg       0.69      0.70      0.69        77
weighted avg       0.74      0.73      0.73        77

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7525803144224198
F1: 0.6031638909453164
======================================================
Running pima 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.75      0.76        52
           1       0.52      0.56      0.54        25

    accuracy                           0.69        77
   macro avg       0.65      0.66      0.65        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.91        53
           1       0.78      0.88      0.82        24

    accuracy                           0.88        77
   macro avg       0.86      0.88      0.87        77
weighted avg       0.89      0.88      0.88        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.56      0.65      0.60        23

    accuracy                           0.74        77
   macro avg       0.70      0.71      0.70        77
weighted avg       0.76      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.76      0.75        49
           1       0.56      0.54      0.55        28

    accuracy                           0.68        77
   macro avg       0.65      0.65      0.65        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7512816131237184
F1: 0.5989201003497439
======================================================
Running pima 100 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.83      0.82        48
           1       0.70      0.66      0.68        29

    accuracy                           0.77        77
   macro avg       0.75      0.74      0.75        77
weighted avg       0.76      0.77      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.78      0.74      0.76        53
           1       0.48      0.54      0.51        24

    accuracy                           0.68        77
   macro avg       0.63      0.64      0.63        77
weighted avg       0.69      0.68      0.68        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.83      0.87        54
           1       0.67      0.78      0.72        23

    accuracy                           0.82        77
   macro avg       0.78      0.81      0.79        77
weighted avg       0.83      0.82      0.82        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        56
           1       0.41      0.52      0.46        21

    accuracy                           0.66        77
   macro avg       0.60      0.62      0.61        77
weighted avg       0.69      0.66      0.67        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.78      0.81        54
           1       0.54      0.64      0.58        22

    accuracy                           0.74        76
   macro avg       0.69      0.71      0.70        76
weighted avg       0.75      0.74      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474538619275461
F1: 0.6081141761052247
======================================================
Running pima 100 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.44      0.67      0.53        18

    accuracy                           0.73        77
   macro avg       0.66      0.71      0.67        77
weighted avg       0.78      0.73      0.74        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.70      0.79        66
           1       0.26      0.64      0.37        11

    accuracy                           0.69        77
   macro avg       0.59      0.67      0.58        77
weighted avg       0.83      0.69      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.764354066985646
F1: 0.5907738129218625
======================================================
Running pima 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.74      0.81        61
           1       0.41      0.69      0.51        16

    accuracy                           0.73        77
   macro avg       0.65      0.71      0.66        77
weighted avg       0.80      0.73      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.70      0.79        66
           1       0.26      0.64      0.37        11

    accuracy                           0.69        77
   macro avg       0.59      0.67      0.58        77
weighted avg       0.83      0.69      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.54      0.70      0.61        20

    accuracy                           0.76        76
   macro avg       0.71      0.74      0.72        76
weighted avg       0.79      0.76      0.77        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7604579630895422
F1: 0.5790152158285838
======================================================
Running pima 100 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.52      0.67      0.58        21

    accuracy                           0.74        77
   macro avg       0.69      0.72      0.70        77
weighted avg       0.77      0.74      0.75        77

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.78      0.87        63
           1       0.48      0.93      0.63        14

    accuracy                           0.81        77
   macro avg       0.73      0.85      0.75        77
weighted avg       0.89      0.81      0.82        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.74      0.81        61
           1       0.41      0.69      0.51        16

    accuracy                           0.73        77
   macro avg       0.65      0.71      0.66        77
weighted avg       0.80      0.73      0.75        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.69      0.79        67
           1       0.22      0.60      0.32        10

    accuracy                           0.68        77
   macro avg       0.57      0.64      0.56        77
weighted avg       0.83      0.68      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.58      0.71      0.64        21

    accuracy                           0.78        76
   macro avg       0.73      0.76      0.74        76
weighted avg       0.80      0.78      0.78        76

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.50      0.81      0.62        16

    accuracy                           0.79        76
   macro avg       0.72      0.80      0.74        76
weighted avg       0.85      0.79      0.80        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.760475051264525
F1: 0.5755042086846608
======================================================
Running pima 100 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.83      0.89        58
           1       0.63      0.89      0.74        19

    accuracy                           0.84        77
   macro avg       0.79      0.86      0.81        77
weighted avg       0.88      0.84      0.85        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.58      0.71      0.64        21

    accuracy                           0.78        76
   macro avg       0.73      0.76      0.74        76
weighted avg       0.80      0.78      0.78        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7578263841421736
F1: 0.5747526340843729
======================================================
Running pima 100 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 100 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
CBEG               precision    recall  f1-score   support

           0       0.70      0.78      0.74        45
           1       0.63      0.53      0.58        32

    accuracy                           0.68        77
   macro avg       0.66      0.65      0.66        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
CBEG               precision    recall  f1-score   support

           0       0.70      0.74      0.72        47
           1       0.56      0.50      0.53        30

    accuracy                           0.65        77
   macro avg       0.63      0.62      0.62        77
weighted avg       0.64      0.65      0.65        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
CBEG               precision    recall  f1-score   support

           0       0.74      0.74      0.74        50
           1       0.52      0.52      0.52        27

    accuracy                           0.66        77
   macro avg       0.63      0.63      0.63        77
weighted avg       0.66      0.66      0.66        77

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7357313738892686
F1: 0.6052716876798738
======================================================
Running pima 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746120984278879
F1: 0.5972887978110538
======================================================
Running pima 100 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746120984278879
F1: 0.5972887978110538
======================================================
Running pima 100 2 majority_voting default
======================================================
python cbeg.py -d pima -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.63      0.74      0.68        23

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.81      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.44      0.60      0.51        20

    accuracy                           0.70        77
   macro avg       0.64      0.67      0.65        77
weighted avg       0.74      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.46      0.60      0.52        20

    accuracy                           0.71        76
   macro avg       0.65      0.68      0.66        76
weighted avg       0.74      0.71      0.72        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.84      0.85        51
           1       0.69      0.72      0.71        25

    accuracy                           0.80        76
   macro avg       0.78      0.78      0.78        76
weighted avg       0.80      0.80      0.80        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746120984278879
F1: 0.5951138569127087
======================================================
Running pima 100 3 majority_voting default
======================================================
python cbeg.py -d pima -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.19574696093703278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.79      0.76        47
           1       0.63      0.57      0.60        30

    accuracy                           0.70        77
   macro avg       0.68      0.68      0.68        77
weighted avg       0.70      0.70      0.70        77

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier(), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [119, 140, 112, 126, 1, 92, 46, 55]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.5878636378853968
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.63      0.71      0.67        24

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.79      0.78      0.78        77

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [110, 1, 102, 1, 78, 1, 3, 123, 1, 268, 3]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.4613912810820658
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.71      0.71        51
           1       0.44      0.46      0.45        26

    accuracy                           0.62        77
   macro avg       0.58      0.58      0.58        77
weighted avg       0.63      0.62      0.63        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), SVC(probability=True), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 1, 15, 4, 2, 150, 96, 270, 151, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.4020433863538245
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.82        52
           1       0.63      0.68      0.65        25

    accuracy                           0.77        77
   macro avg       0.73      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [78, 1, 2, 150, 289, 171]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5460624806454445
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [1, 268, 90, 1, 1, 1, 6, 161, 2, 160]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.43593400366390495
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.75      0.78        55
           1       0.48      0.59      0.53        22

    accuracy                           0.70        77
   macro avg       0.65      0.67      0.66        77
weighted avg       0.72      0.70      0.71        77

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier()]
Number of samples by cluster: [271, 75, 1, 2, 159, 161, 1, 21]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.3965465295028263
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.48      0.76      0.59        17

    accuracy                           0.77        77
   macro avg       0.70      0.77      0.71        77
weighted avg       0.82      0.77      0.78        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [1, 155, 3, 70, 1, 279, 12, 136, 34]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.6055171148330649
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.69      0.76        61
           1       0.30      0.50      0.37        16

    accuracy                           0.65        77
   macro avg       0.57      0.59      0.56        77
weighted avg       0.73      0.65      0.68        77

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [175, 1, 5, 1, 151, 1, 82, 2, 273]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.4045183280684841
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.50      0.65      0.57        20

    accuracy                           0.74        76
   macro avg       0.68      0.71      0.69        76
weighted avg       0.77      0.74      0.75        76

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [271, 1, 165, 160, 1, 94]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.3028080944547643
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.84      0.83        49
           1       0.69      0.67      0.68        27

    accuracy                           0.78        76
   macro avg       0.76      0.75      0.75        76
weighted avg       0.77      0.78      0.78        76

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), LogisticRegression(), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [1, 7, 94, 145, 159, 32, 8, 6, 240]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.729237867395762
F1: 0.5760085183691799
======================================================
Running pima 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.78      0.75        46
           1       0.63      0.55      0.59        31

    accuracy                           0.69        77
   macro avg       0.67      0.67      0.67        77
weighted avg       0.68      0.69      0.68        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.190014942972451
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.78      0.77        49
           1       0.59      0.57      0.58        28

    accuracy                           0.70        77
   macro avg       0.68      0.67      0.67        77
weighted avg       0.70      0.70      0.70        77

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [99, 5, 119, 267, 118, 1, 73, 1, 7, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.22352664028118188
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), KNeighborsClassifier(n_neighbors=7), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [280, 1, 3, 152, 83, 170, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.2158114586838438
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.70      0.73        54
           1       0.41      0.48      0.44        23

    accuracy                           0.64        77
   macro avg       0.58      0.59      0.59        77
weighted avg       0.65      0.64      0.64        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 3, 3, 94, 112, 155, 60, 261, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.82      0.83        51
           1       0.67      0.69      0.68        26

    accuracy                           0.78        77
   macro avg       0.75      0.76      0.76        77
weighted avg       0.78      0.78      0.78        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.19235245710338017
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [1, 4, 175, 84, 154, 1, 272]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.80      0.83        54
           1       0.58      0.68      0.62        22

    accuracy                           0.76        76
   macro avg       0.72      0.74      0.73        76
weighted avg       0.78      0.76      0.77        76

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.83      0.80        47
           1       0.69      0.62      0.65        29

    accuracy                           0.75        76
   macro avg       0.74      0.73      0.73        76
weighted avg       0.75      0.75      0.75        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7240430622009569
F1: 0.5823002928460398
======================================================
Running pima 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.78      0.78        50
           1       0.59      0.59      0.59        27

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.78      0.78        50
           1       0.59      0.59      0.59        27

    accuracy                           0.71        77
   macro avg       0.69      0.69      0.69        77
weighted avg       0.71      0.71      0.71        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.81      0.86        57
           1       0.59      0.80      0.68        20

    accuracy                           0.81        77
   macro avg       0.76      0.80      0.77        77
weighted avg       0.83      0.81      0.81        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.20623260377207728
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [262, 2, 155, 94, 113, 62, 1, 1, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.18931745889575816
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 91, 277, 156, 164, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.21406150673319002
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.71      0.77        59
           1       0.37      0.56      0.44        18

    accuracy                           0.68        77
   macro avg       0.61      0.63      0.61        77
weighted avg       0.73      0.68      0.69        77

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [175, 2, 2, 81, 5, 273, 1, 151, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.74      0.79        57
           1       0.42      0.58      0.49        19

    accuracy                           0.70        76
   macro avg       0.63      0.66      0.64        76
weighted avg       0.74      0.70      0.71        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.22168271704824088
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.83      0.84        52
           1       0.65      0.71      0.68        24

    accuracy                           0.79        76
   macro avg       0.76      0.77      0.76        76
weighted avg       0.79      0.79      0.79        76

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [3, 241, 163, 34, 1, 2, 148, 93, 7]
Selected clustering_algorithm: fcm
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7305023923444977
F1: 0.578144103959439
======================================================
Running pima 75 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.77      0.74        47
           1       0.59      0.53      0.56        30

    accuracy                           0.68        77
   macro avg       0.66      0.65      0.65        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.48      0.76      0.59        17

    accuracy                           0.77        77
   macro avg       0.70      0.77      0.71        77
weighted avg       0.82      0.77      0.78        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.80      0.88        61
           1       0.56      0.94      0.70        16

    accuracy                           0.83        77
   macro avg       0.77      0.87      0.79        77
weighted avg       0.89      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.48      0.72      0.58        18

    accuracy                           0.75        77
   macro avg       0.69      0.74      0.70        77
weighted avg       0.80      0.75      0.77        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.71      0.80        63
           1       0.33      0.64      0.44        14

    accuracy                           0.70        77
   macro avg       0.62      0.68      0.62        77
weighted avg       0.80      0.70      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.80        58
           1       0.42      0.61      0.50        18

    accuracy                           0.71        76
   macro avg       0.64      0.68      0.65        76
weighted avg       0.76      0.71      0.73        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.81      0.83        53
           1       0.62      0.70      0.65        23

    accuracy                           0.78        76
   macro avg       0.74      0.75      0.74        76
weighted avg       0.79      0.78      0.78        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7447881066302118
F1: 0.5803452895269198
======================================================
Running pima 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.77      0.74        47
           1       0.59      0.53      0.56        30

    accuracy                           0.68        77
   macro avg       0.66      0.65      0.65        77
weighted avg       0.67      0.68      0.67        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.85      0.90        55
           1       0.70      0.86      0.78        22

    accuracy                           0.86        77
   macro avg       0.82      0.86      0.84        77
weighted avg       0.87      0.86      0.86        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.83      0.90        59
           1       0.63      0.94      0.76        18

    accuracy                           0.86        77
   macro avg       0.80      0.89      0.83        77
weighted avg       0.90      0.86      0.87        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.44      0.75      0.56        16

    accuracy                           0.75        77
   macro avg       0.68      0.75      0.69        77
weighted avg       0.82      0.75      0.77        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.70      0.77        61
           1       0.33      0.56      0.42        16

    accuracy                           0.68        77
   macro avg       0.60      0.63      0.60        77
weighted avg       0.75      0.68      0.70        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.46      0.67      0.55        18

    accuracy                           0.74        76
   macro avg       0.67      0.71      0.68        76
weighted avg       0.78      0.74      0.75        76

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.62      0.73      0.67        22

    accuracy                           0.79        76
   macro avg       0.75      0.77      0.76        76
weighted avg       0.80      0.79      0.79        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7539302802460697
F1: 0.601350857962032
======================================================
Running pima 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.70      0.76      0.73        46
           1       0.59      0.52      0.55        31

    accuracy                           0.66        77
   macro avg       0.65      0.64      0.64        77
weighted avg       0.66      0.66      0.66        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.85      0.90        55
           1       0.70      0.86      0.78        22

    accuracy                           0.86        77
   macro avg       0.82      0.86      0.84        77
weighted avg       0.87      0.86      0.86        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.52      0.61      0.56        23

    accuracy                           0.71        77
   macro avg       0.67      0.68      0.67        77
weighted avg       0.73      0.71      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.81      0.88        59
           1       0.59      0.89      0.71        18

    accuracy                           0.83        77
   macro avg       0.78      0.85      0.80        77
weighted avg       0.87      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.79      0.85        58
           1       0.56      0.79      0.65        19

    accuracy                           0.79        77
   macro avg       0.74      0.79      0.75        77
weighted avg       0.83      0.79      0.80        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        62
           1       0.38      0.71      0.50        14

    accuracy                           0.74        76
   macro avg       0.65      0.73      0.66        76
weighted avg       0.82      0.74      0.76        76

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.81      0.85        54
           1       0.62      0.73      0.67        22

    accuracy                           0.79        76
   macro avg       0.75      0.77      0.76        76
weighted avg       0.80      0.79      0.79        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746138072453862
F1: 0.5904335791288029
======================================================
Running pima 75 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.74      0.82        62
           1       0.41      0.73      0.52        15

    accuracy                           0.74        77
   macro avg       0.66      0.74      0.67        77
weighted avg       0.82      0.74      0.76        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.78      0.87        63
           1       0.48      0.93      0.63        14

    accuracy                           0.81        77
   macro avg       0.73      0.85      0.75        77
weighted avg       0.89      0.81      0.82        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.83        63
           1       0.41      0.79      0.54        14

    accuracy                           0.75        77
   macro avg       0.67      0.77      0.68        77
weighted avg       0.84      0.75      0.78        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.58      0.83      0.68        18

    accuracy                           0.82        76
   macro avg       0.76      0.82      0.78        76
weighted avg       0.85      0.82      0.83        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7552802460697198
F1: 0.5657657163466426
======================================================
Running pima 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.72      0.82        65
           1       0.33      0.75      0.46        12

    accuracy                           0.73        77
   macro avg       0.64      0.74      0.64        77
weighted avg       0.85      0.73      0.76        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.77      0.86        64
           1       0.44      0.92      0.60        13

    accuracy                           0.79        77
   macro avg       0.71      0.84      0.73        77
weighted avg       0.89      0.79      0.82        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.72      0.78        60
           1       0.37      0.59      0.45        17

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.62        77
weighted avg       0.75      0.69      0.71        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.70      0.79        64
           1       0.30      0.62      0.40        13

    accuracy                           0.69        77
   macro avg       0.60      0.66      0.59        77
weighted avg       0.80      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.58      0.83      0.68        18

    accuracy                           0.82        76
   macro avg       0.76      0.82      0.78        76
weighted avg       0.85      0.82      0.83        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7500854408749146
F1: 0.5556507051732792
======================================================
Running pima 75 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.82        52
           1       0.63      0.68      0.65        25

    accuracy                           0.77        77
   macro avg       0.73      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.85      0.88        54
           1       0.70      0.83      0.76        23

    accuracy                           0.84        77
   macro avg       0.81      0.84      0.82        77
weighted avg       0.86      0.84      0.85        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.72      0.82        65
           1       0.33      0.75      0.46        12

    accuracy                           0.73        77
   macro avg       0.64      0.74      0.64        77
weighted avg       0.85      0.73      0.76        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.77      0.86        64
           1       0.44      0.92      0.60        13

    accuracy                           0.79        77
   macro avg       0.71      0.84      0.73        77
weighted avg       0.89      0.79      0.82        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.44      0.67      0.53        18

    accuracy                           0.73        77
   macro avg       0.66      0.71      0.67        77
weighted avg       0.78      0.73      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.71      0.80        63
           1       0.33      0.64      0.44        14

    accuracy                           0.70        77
   macro avg       0.62      0.68      0.62        77
weighted avg       0.80      0.70      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.58      0.83      0.68        18

    accuracy                           0.82        76
   macro avg       0.76      0.82      0.78        76
weighted avg       0.85      0.82      0.83        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.760475051264525
F1: 0.5793332647863005
======================================================
Running pima 75 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 75 2 majority_voting default
======================================================
python cbeg.py -d pima -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.76      0.81        58
           1       0.48      0.68      0.57        19

    accuracy                           0.74        77
   macro avg       0.68      0.72      0.69        77
weighted avg       0.78      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.73      0.76        55
           1       0.44      0.55      0.49        22

    accuracy                           0.68        77
   macro avg       0.62      0.64      0.63        77
weighted avg       0.70      0.68      0.68        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.52      0.70      0.60        20

    accuracy                           0.75        77
   macro avg       0.70      0.74      0.71        77
weighted avg       0.79      0.75      0.76        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.77      0.85        61
           1       0.48      0.81      0.60        16

    accuracy                           0.78        77
   macro avg       0.71      0.79      0.73        77
weighted avg       0.84      0.78      0.80        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.72      0.78        60
           1       0.37      0.59      0.45        17

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.62        77
weighted avg       0.75      0.69      0.71        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.79      0.84        57
           1       0.56      0.75      0.64        20

    accuracy                           0.78        77
   macro avg       0.73      0.77      0.74        77
weighted avg       0.81      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.73      0.81        63
           1       0.37      0.71      0.49        14

    accuracy                           0.73        77
   macro avg       0.65      0.72      0.65        77
weighted avg       0.82      0.73      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.58      0.83      0.68        18

    accuracy                           0.82        76
   macro avg       0.76      0.82      0.78        76
weighted avg       0.85      0.82      0.83        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474538619275461
F1: 0.569617011370971
======================================================
Running pima 75 3 majority_voting default
======================================================
python cbeg.py -d pima -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.2466358050339575
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.85      0.81        46
           1       0.74      0.65      0.69        31

    accuracy                           0.77        77
   macro avg       0.76      0.75      0.75        77
weighted avg       0.76      0.77      0.76        77

Selected Base Classifiers: [GaussianNB(), DecisionTreeClassifier(), GradientBoostingClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [101, 32, 43, 96, 1, 169, 71, 68, 40, 2, 68]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5465444321008158
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.78      0.79        51
           1       0.59      0.62      0.60        26

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), GradientBoostingClassifier()]
Number of samples by cluster: [1, 1, 2, 97, 1, 87, 1, 118, 269, 114]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.5165314123782182
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [3, 2, 163, 4, 84, 1, 1, 273, 160]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.43639291876086
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        60
           1       0.44      0.71      0.55        17

    accuracy                           0.74        77
   macro avg       0.67      0.73      0.68        77
weighted avg       0.80      0.74      0.76        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [1, 285, 2, 76, 1, 168, 9, 149]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5479294072910011
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [256, 1, 166, 166, 95, 1, 1, 3, 1, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.4374235156764261
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [74, 3, 2, 159, 270, 159, 2, 22]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.4056217053783608
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.87      0.90        54
           1       0.74      0.87      0.80        23

    accuracy                           0.87        77
   macro avg       0.84      0.87      0.85        77
weighted avg       0.88      0.87      0.87        77

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [91, 2, 164, 1, 156, 277]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.5495128316229406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.74      0.71      0.73        52
           1       0.44      0.48      0.46        25

    accuracy                           0.64        77
   macro avg       0.59      0.60      0.59        77
weighted avg       0.64      0.64      0.64        77

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [7, 85, 1, 4, 146, 2, 1, 171, 2, 272]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.6030379865067551
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.71      0.74        55
           1       0.38      0.48      0.43        21

    accuracy                           0.64        76
   macro avg       0.58      0.59      0.58        76
weighted avg       0.67      0.64      0.66        76

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 1, 95, 155, 1, 270, 163, 1, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=11))
Best evaluation: 0.4357332485188233
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.80      0.81        51
           1       0.62      0.64      0.63        25

    accuracy                           0.75        76
   macro avg       0.72      0.72      0.72        76
weighted avg       0.75      0.75      0.75        76

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier(), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [161, 4, 5, 150, 229, 96, 3, 22, 18, 2, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7290840738209159
F1: 0.5873720563737669
======================================================
Running pima 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.82      0.81        49
           1       0.67      0.64      0.65        28

    accuracy                           0.75        77
   macro avg       0.73      0.73      0.73        77
weighted avg       0.75      0.75      0.75        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.52      0.64      0.57        22

    accuracy                           0.73        77
   macro avg       0.68      0.70      0.69        77
weighted avg       0.75      0.73      0.73        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.2084557118228924
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.48      0.65      0.55        20

    accuracy                           0.73        77
   macro avg       0.67      0.70      0.68        77
weighted avg       0.76      0.73      0.74        77

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [150, 2, 287, 78, 1, 2, 1, 170]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.77      0.81        56
           1       0.52      0.67      0.58        21

    accuracy                           0.74        77
   macro avg       0.69      0.72      0.70        77
weighted avg       0.77      0.74      0.75        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.19830743634783318
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [150, 166, 97, 1, 277]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.2127661543443784
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [154, 1, 1, 175, 84, 272, 2, 2]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.83      0.80        47
           1       0.69      0.62      0.65        29

    accuracy                           0.75        76
   macro avg       0.74      0.73      0.73        76
weighted avg       0.75      0.75      0.75        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.50      0.62      0.55        21

    accuracy                           0.72        76
   macro avg       0.67      0.69      0.68        76
weighted avg       0.75      0.72      0.73        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7395762132604239
F1: 0.5906498075267071
======================================================
Running pima 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.83      0.79        46
           1       0.70      0.61      0.66        31

    accuracy                           0.74        77
   macro avg       0.73      0.72      0.72        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.23796684983522343
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.81      0.82        52
           1       0.63      0.68      0.65        25

    accuracy                           0.77        77
   macro avg       0.73      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [1, 146, 7, 154, 3, 1, 4, 278, 77, 20]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.19352885433655637
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.81      0.80        48
           1       0.67      0.62      0.64        29

    accuracy                           0.74        77
   macro avg       0.72      0.72      0.72        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [2, 148, 4, 154, 272, 81, 1, 25, 4]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.19528090450638888
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.73      0.80        62
           1       0.37      0.67      0.48        15

    accuracy                           0.71        77
   macro avg       0.64      0.70      0.64        77
weighted avg       0.80      0.71      0.74        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier()]
Number of samples by cluster: [1, 144, 3, 93, 2, 278, 121, 1, 48]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.74      0.77        54
           1       0.48      0.57      0.52        23

    accuracy                           0.69        77
   macro avg       0.64      0.65      0.64        77
weighted avg       0.70      0.69      0.69        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=9))
Best evaluation: 0.1973066563279402
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.52      0.70      0.60        20

    accuracy                           0.75        77
   macro avg       0.70      0.74      0.71        77
weighted avg       0.79      0.75      0.76        77

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [1, 256, 2, 4, 6, 177, 84, 158, 3]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.83      0.82        48
           1       0.70      0.66      0.68        29

    accuracy                           0.77        77
   macro avg       0.75      0.74      0.75        77
weighted avg       0.76      0.77      0.76        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=10))
Best evaluation: 0.20213876263413777
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.73      0.77        56
           1       0.44      0.57      0.50        21

    accuracy                           0.69        77
   macro avg       0.63      0.65      0.64        77
weighted avg       0.72      0.69      0.70        77

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [262, 1, 135, 78, 1, 134, 77, 1, 1, 1]
Selected clustering_algorithm: fcm
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.78      0.78        50
           1       0.58      0.58      0.58        26

    accuracy                           0.71        76
   macro avg       0.68      0.68      0.68        76
weighted avg       0.71      0.71      0.71        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.76      0.79        54
           1       0.50      0.59      0.54        22

    accuracy                           0.71        76
   macro avg       0.66      0.68      0.67        76
weighted avg       0.73      0.71      0.72        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7278195488721805
F1: 0.5840972039699113
======================================================
Running pima 50 2 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 meta_classifier crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand meta_classifier default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 meta_classifier default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 meta_classifier default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.72      0.78      0.75        46
           1       0.63      0.55      0.59        31

    accuracy                           0.69        77
   macro avg       0.67      0.67      0.67        77
weighted avg       0.68      0.69      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.74      0.76        53
           1       0.48      0.54      0.51        24

    accuracy                           0.68        77
   macro avg       0.63      0.64      0.63        77
weighted avg       0.69      0.68      0.68        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.75      0.79        56
           1       0.48      0.62      0.54        21

    accuracy                           0.71        77
   macro avg       0.66      0.68      0.67        77
weighted avg       0.74      0.71      0.72        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.73      0.80        62
           1       0.37      0.67      0.48        15

    accuracy                           0.71        77
   macro avg       0.64      0.70      0.64        77
weighted avg       0.80      0.71      0.74        77

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.75      0.83        61
           1       0.42      0.73      0.54        15

    accuracy                           0.75        76
   macro avg       0.67      0.74      0.68        76
weighted avg       0.82      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.50      0.62      0.55        21

    accuracy                           0.72        76
   macro avg       0.67      0.69      0.68        76
weighted avg       0.75      0.72      0.73        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7369788106630212
F1: 0.5739058981859121
======================================================
Running pima 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        50
           1       0.63      0.63      0.63        27

    accuracy                           0.74        77
   macro avg       0.71      0.71      0.71        77
weighted avg       0.74      0.74      0.74        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.82      0.88        57
           1       0.63      0.85      0.72        20

    accuracy                           0.83        77
   macro avg       0.78      0.84      0.80        77
weighted avg       0.86      0.83      0.84        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.72      0.77        57
           1       0.41      0.55      0.47        20

    accuracy                           0.68        77
   macro avg       0.61      0.63      0.62        77
weighted avg       0.71      0.68      0.69        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.70      0.76        60
           1       0.33      0.53      0.41        17

    accuracy                           0.66        77
   macro avg       0.59      0.61      0.59        77
weighted avg       0.73      0.66      0.69        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.75      0.81        59
           1       0.42      0.65      0.51        17

    accuracy                           0.72        76
   macro avg       0.65      0.70      0.66        76
weighted avg       0.78      0.72      0.74        76

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.77      0.82        57
           1       0.50      0.68      0.58        19

    accuracy                           0.75        76
   macro avg       0.69      0.73      0.70        76
weighted avg       0.79      0.75      0.76        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7382775119617226
F1: 0.5677251973065677
======================================================
Running pima 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.78      0.80      0.79        49
           1       0.63      0.61      0.62        28

    accuracy                           0.73        77
   macro avg       0.70      0.70      0.70        77
weighted avg       0.73      0.73      0.73        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.81      0.87        58
           1       0.59      0.84      0.70        19

    accuracy                           0.82        77
   macro avg       0.77      0.83      0.78        77
weighted avg       0.85      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.72      0.74        53
           1       0.44      0.50      0.47        24

    accuracy                           0.65        77
   macro avg       0.60      0.61      0.60        77
weighted avg       0.66      0.65      0.65        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.78        53
           1       0.52      0.58      0.55        24

    accuracy                           0.70        77
   macro avg       0.66      0.67      0.66        77
weighted avg       0.71      0.70      0.71        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.79      0.88        62
           1       0.52      0.93      0.67        15

    accuracy                           0.82        77
   macro avg       0.75      0.86      0.77        77
weighted avg       0.89      0.82      0.83        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.74      0.80        58
           1       0.44      0.63      0.52        19

    accuracy                           0.71        77
   macro avg       0.65      0.69      0.66        77
weighted avg       0.76      0.71      0.73        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.80      0.84        55
           1       0.59      0.73      0.65        22

    accuracy                           0.78        77
   macro avg       0.74      0.76      0.75        77
weighted avg       0.80      0.78      0.79        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.71      0.77        59
           1       0.37      0.56      0.44        18

    accuracy                           0.68        77
   macro avg       0.61      0.63      0.61        77
weighted avg       0.73      0.68      0.69        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.76      0.83        59
           1       0.46      0.71      0.56        17

    accuracy                           0.75        76
   macro avg       0.68      0.73      0.69        76
weighted avg       0.80      0.75      0.77        76

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.76      0.80        55
           1       0.50      0.62      0.55        21

    accuracy                           0.72        76
   macro avg       0.67      0.69      0.68        76
weighted avg       0.75      0.72      0.73        76

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7356801093643199
F1: 0.5730684325513229
======================================================
Running pima 50 2 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 weighted_membership crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand weighted_membership default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 weighted_membership default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 weighted_membership default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.11882946387992835
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        50
           1       0.67      0.67      0.67        27

    accuracy                           0.77        77
   macro avg       0.74      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10357273988011317
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        61
           1       0.52      0.88      0.65        16

    accuracy                           0.81        77
   macro avg       0.74      0.83      0.76        77
weighted avg       0.87      0.81      0.82        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [231, 460]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10701509004489625
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.68      0.76        63
           1       0.26      0.50      0.34        14

    accuracy                           0.65        77
   macro avg       0.56      0.59      0.55        77
weighted avg       0.75      0.65      0.68        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [210, 292, 189]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10242784495596419
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        64
           1       0.37      0.77      0.50        13

    accuracy                           0.74        77
   macro avg       0.66      0.75      0.66        77
weighted avg       0.84      0.74      0.77        77

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10356113796251547
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.77      0.86        64
           1       0.44      0.92      0.60        13

    accuracy                           0.79        77
   macro avg       0.71      0.84      0.73        77
weighted avg       0.89      0.79      0.82        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.10898835947710539
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.41      0.58      0.48        19

    accuracy                           0.69        77
   macro avg       0.62      0.65      0.63        77
weighted avg       0.73      0.69      0.70        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [180, 303, 208]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1079196371950215
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.11151465654201886
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.71      0.80        63
           1       0.33      0.64      0.44        14

    accuracy                           0.70        77
   macro avg       0.62      0.68      0.62        77
weighted avg       0.80      0.70      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [291, 214, 186]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.107048724622605
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.31      0.67      0.42        12

    accuracy                           0.71        76
   macro avg       0.61      0.69      0.61        76
weighted avg       0.82      0.71      0.75        76

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.10920358985133896
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        62
           1       0.42      0.79      0.55        14

    accuracy                           0.76        76
   macro avg       0.68      0.77      0.69        76
weighted avg       0.84      0.76      0.79        76

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7382775119617226
F1: 0.5256326415560466
======================================================
Running pima 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.48      0.65      0.55        20

    accuracy                           0.73        77
   macro avg       0.67      0.70      0.68        77
weighted avg       0.76      0.73      0.74        77

Selected Base Classifiers: [LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.80      0.85        56
           1       0.59      0.76      0.67        21

    accuracy                           0.79        77
   macro avg       0.75      0.78      0.76        77
weighted avg       0.82      0.79      0.80        77

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.76      0.72      0.74        53
           1       0.44      0.50      0.47        24

    accuracy                           0.65        77
   macro avg       0.60      0.61      0.60        77
weighted avg       0.66      0.65      0.65        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.75      0.83        63
           1       0.41      0.79      0.54        14

    accuracy                           0.75        77
   macro avg       0.67      0.77      0.68        77
weighted avg       0.84      0.75      0.78        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.77      0.86        64
           1       0.44      0.92      0.60        13

    accuracy                           0.79        77
   macro avg       0.71      0.84      0.73        77
weighted avg       0.89      0.79      0.82        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.72      0.82        67
           1       0.30      0.80      0.43        10

    accuracy                           0.73        77
   macro avg       0.63      0.76      0.63        77
weighted avg       0.87      0.73      0.77        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.69      0.80        68
           1       0.22      0.67      0.33         9

    accuracy                           0.69        77
   macro avg       0.58      0.68      0.56        77
weighted avg       0.86      0.69      0.74        77

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        60
           1       0.42      0.69      0.52        16

    accuracy                           0.74        76
   macro avg       0.66      0.72      0.67        76
weighted avg       0.80      0.74      0.76        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        62
           1       0.42      0.79      0.55        14

    accuracy                           0.76        76
   macro avg       0.68      0.77      0.69        76
weighted avg       0.84      0.76      0.79        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7396103896103897
F1: 0.5275302698925348
======================================================
Running pima 50 rand majority_voting crossval...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.38095238, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.49206349, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.17470438101782285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.82      0.82      0.82        50
           1       0.67      0.67      0.67        27

    accuracy                           0.77        77
   macro avg       0.74      0.74      0.74        77
weighted avg       0.77      0.77      0.77        77

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.5879397 , 0.72131148, 0.24242424, 0.1713948 ,
        0.51415797, 0.13877028, 0.31666667],
       [0.70588235, 0.42211055, 0.59016393, 0.31313131, 0.        ,
        0.44262295, 0.09350982, 0.41666667]]),
       n_clusters=2))
Best evaluation: 0.18343726652193065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.80      0.86        59
           1       0.56      0.83      0.67        18

    accuracy                           0.81        77
   macro avg       0.75      0.81      0.76        77
weighted avg       0.85      0.81      0.82        77

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1828295974185135
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.71      0.79        62
           1       0.33      0.60      0.43        15

    accuracy                           0.69        77
   macro avg       0.61      0.65      0.61        77
weighted avg       0.77      0.69      0.72        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1835619518631066
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.73      0.82        64
           1       0.37      0.77      0.50        13

    accuracy                           0.74        77
   macro avg       0.66      0.75      0.66        77
weighted avg       0.84      0.74      0.77        77

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [220, 471]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18489989101510057
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.98      0.78      0.87        63
           1       0.48      0.93      0.63        14

    accuracy                           0.81        77
   macro avg       0.73      0.85      0.75        77
weighted avg       0.89      0.81      0.82        77

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.18319827557028862
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.70      0.79        64
           1       0.30      0.62      0.40        13

    accuracy                           0.69        77
   macro avg       0.60      0.66      0.59        77
weighted avg       0.80      0.69      0.72        77

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1829428738008196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1903142142508746
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.71      0.80        63
           1       0.33      0.64      0.44        14

    accuracy                           0.70        77
   macro avg       0.62      0.68      0.62        77
weighted avg       0.80      0.70      0.73        77

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.05882353, 0.44723618, 0.62295082, 0.34343434, 0.04373522,
        0.46497765, 0.04867635, 0.03333333],
       [0.        , 0.73366834, 0.67213115, 0.        , 0.        ,
        0.60357675, 0.72715628, 0.38333333]]),
       n_clusters=2))
Best evaluation: 0.18281386467655578
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.75      0.82        60
           1       0.42      0.69      0.52        16

    accuracy                           0.74        76
   macro avg       0.66      0.72      0.67        76
weighted avg       0.80      0.74      0.76        76

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.1898646446402335
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.76      0.84        62
           1       0.42      0.79      0.55        14

    accuracy                           0.76        76
   macro avg       0.68      0.77      0.69        76
weighted avg       0.84      0.76      0.79        76

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.746103896103896
F1: 0.5433885017421602
======================================================
Running pima 50 2 majority_voting crossval
======================================================
python cbeg.py -d pima -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 3 majority_voting crossval
======================================================
python cbeg.py -d pima -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 rand majority_voting default...
======================================================
python cbeg.py -d pima -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running pima 50 2 majority_voting default
======================================================
python cbeg.py -d pima -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.77      0.84        60
           1       0.48      0.76      0.59        17

    accuracy                           0.77        77
   macro avg       0.70      0.77      0.71        77
weighted avg       0.82      0.77      0.78        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [449, 242]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.90      0.78      0.83        58
           1       0.52      0.74      0.61        19

    accuracy                           0.77        77
   macro avg       0.71      0.76      0.72        77
weighted avg       0.81      0.77      0.78        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [467, 224]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.73      0.79        59
           1       0.41      0.61      0.49        18

    accuracy                           0.70        77
   macro avg       0.63      0.67      0.64        77
weighted avg       0.75      0.70      0.72        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.88      0.79      0.83        56
           1       0.56      0.71      0.62        21

    accuracy                           0.77        77
   macro avg       0.72      0.75      0.73        77
weighted avg       0.79      0.77      0.77        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [471, 220]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.78      0.85        60
           1       0.52      0.82      0.64        17

    accuracy                           0.79        77
   macro avg       0.73      0.80      0.75        77
weighted avg       0.85      0.79      0.81        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.84      0.70      0.76        60
           1       0.33      0.53      0.41        17

    accuracy                           0.66        77
   macro avg       0.59      0.61      0.59        77
weighted avg       0.73      0.66      0.69        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [232, 459]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.78      0.84        59
           1       0.52      0.78      0.62        18

    accuracy                           0.78        77
   macro avg       0.72      0.78      0.73        77
weighted avg       0.83      0.78      0.79        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [461, 230]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.72      0.81        64
           1       0.33      0.69      0.45        13

    accuracy                           0.71        77
   macro avg       0.63      0.71      0.63        77
weighted avg       0.82      0.71      0.75        77

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [463, 228]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.86      0.75      0.80        57
           1       0.46      0.63      0.53        19

    accuracy                           0.72        76
   macro avg       0.66      0.69      0.67        76
weighted avg       0.76      0.72      0.74        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.96      0.79      0.86        61
           1       0.50      0.87      0.63        15

    accuracy                           0.80        76
   macro avg       0.73      0.83      0.75        76
weighted avg       0.87      0.80      0.82        76

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [458, 234]
Selected clustering_algorithm: kmeans++
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/pima/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7474367737525631
F1: 0.5598650074445408
======================================================
Running pima 50 3 majority_voting default
======================================================
python cbeg.py -d pima -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6482657668430718
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.91      1.00      0.95        20

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [54, 25, 120, 76, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.6791217153048152
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.92      0.93        37
           1       0.86      0.90      0.88        20

    accuracy                           0.91        57
   macro avg       0.90      0.91      0.90        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 86, 80, 1, 31, 63, 182, 19]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6313871233400911
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [81, 194, 1, 125, 56, 33, 22]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.22125633e-04, 6.27672587e-01, 5.16182573e-01, 6.02403745e-01,
        4.73594910e-01, 4.12386025e-01, 2.55567143e-01, 3.46532334e-01,
        4.72067594e-01, 2.63636364e-01, 8.40353833e-02, 2.64655102e-01,
        1.45155587e-01, 2.85474767e-01, 1.97232713e-01, 2.21168525e-01,
        1.25259110e-01, 8.56313131e-02, 2.88122751e-01, 7.98953115e-02,
        3.80788525e-02, 6.89790110e-01,...
        5.79215270e-01, 7.21946375e-01, 7.89583461e-01, 9.99062793e-01,
        9.06063618e-01, 7.55555556e-01, 4.30286436e-01, 4.52437721e-01,
        2.61845827e-01, 5.19365115e-01, 3.04816230e-01, 2.22139982e-01,
        6.34091387e-01, 2.62626263e-01, 4.69785944e-01, 3.26982608e-01,
        1.43104902e-01, 7.28210601e-01, 4.26172708e-01, 7.78873450e-01,
        5.34506488e-01, 6.53305157e-01, 6.52375547e-01, 7.67412141e-01,
        1.00000000e+00, 4.90833826e-01, 2.81057327e-01]])))
Best evaluation: 0.6649655671825703
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [65, 135, 30, 116, 35, 25, 89, 17]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.17724616e-04, 2.84869137e-01, 4.09536693e-01, 3.02052381e-01,
        1.59618240e-01, 6.74099485e-01, 5.33157475e-01, 4.35567010e-01,
        4.64860835e-01, 6.51515152e-01, 5.04001685e-01, 7.05413724e-02,
        1.41840523e-01, 7.76987231e-02, 3.27195843e-02, 1.36587687e-01,
        2.46102082e-01, 8.97222222e-02, 2.32240955e-01, 1.90634322e-01,
        9.86070229e-02, 2.68943436e-01,...
        2.46073559e-01, 2.15656566e-01, 1.58382477e-01, 4.37443418e-02,
        2.81957214e-01, 3.95325826e-02, 2.80875162e-02, 1.25845599e-01,
        8.60546159e-02, 5.43686869e-02, 2.24095473e-01, 1.64743626e-01,
        3.16874646e-02, 2.87442191e-01, 4.38699360e-01, 2.66397729e-01,
        1.47070389e-01, 3.33025160e-01, 1.08187560e-01, 1.35782748e-01,
        3.49484536e-01, 1.58486103e-01, 7.18221173e-02]]),
       n_clusters=10))
Best evaluation: 0.7260701332681111
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [39, 67, 50, 22, 68, 56, 16, 54, 90, 50]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.37460669e-04, 1.66075063e-01, 3.23977004e-01, 1.63222998e-01,
        8.17660794e-02, 5.13305094e-01, 2.03668487e-01, 7.01733833e-02,
        5.96918489e-02, 5.84343434e-01, 3.12763269e-01, 8.81767156e-02,
        2.59414781e-01, 7.27983791e-02, 3.14727505e-02, 1.99952408e-01,
        1.49743143e-01, 7.27272727e-02, 1.63174844e-01, 2.70417065e-01,
        8.83117063e-02, 1.43253968e-01,...
        1.42644135e-01, 1.98989899e-01, 1.16470093e-01, 3.28806808e-02,
        7.17821782e-02, 2.25698535e-02, 1.94449477e-02, 1.44678247e-01,
        9.52173521e-02, 3.94949495e-02, 1.60314453e-01, 4.28885012e-02,
        2.68507386e-02, 2.76587302e-01, 3.16364606e-01, 2.49818324e-01,
        1.54736972e-01, 3.76609655e-01, 1.64168389e-01, 1.49840256e-01,
        3.59106529e-01, 1.32071752e-01, 9.32047750e-02]]),
       n_clusters=9))
Best evaluation: 0.711335173258608
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [61, 78, 37, 65, 121, 97, 13, 34, 6]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.93        24

    accuracy                           0.95        56
   macro avg       0.96      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9595551378446114
F1: 0.9444989427916258
======================================================
Running wdbc 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.75747235e-04, 1.15529654e-01, 2.64457220e-01, 1.17299758e-01,
        6.02419978e-02, 4.33962264e-01, 1.65265935e-01, 5.88331771e-02,
        8.82206759e-02, 4.49620802e-01, 2.81171019e-01, 5.44631541e-02,
        3.65717822e-01, 4.81081845e-02, 1.87673469e-02, 2.07023150e-01,
        9.19127587e-02, 5.56287031e-02, 1.96650367e-01, 1.65117921e-01,
        8.57356182e-02, 9.07097434e-02,...
        4.84890656e-01, 7.91440953e-01, 4.28812131e-01, 1.18522542e-01,
        7.72188826e-02, 1.23780804e-01, 7.11769562e-02, 1.72553286e-01,
        3.83242707e-01, 2.12179065e-01, 5.50611247e-01, 3.91594992e-01,
        1.59306539e-01, 3.43249762e-01, 1.88166311e-01, 3.58954807e-01,
        1.87896983e-01, 4.47929737e-01, 5.51183165e-01, 5.03594249e-01,
        8.22336770e-01, 6.11395899e-01, 2.90564055e-01]]),
       n_clusters=10))
Best evaluation: 0.38598519378053225
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.91      1.00      0.95        20

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [76, 34, 49, 101, 100, 44, 64, 19, 14, 11]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3778423121743061
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [104, 322, 86]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.33062614e-04, 7.91134596e-02, 4.67634855e-01, 7.59555587e-02,
        3.32131495e-02, 6.47016340e-01, 2.15477578e-01, 7.02905342e-02,
        4.60188867e-02, 3.87878788e-01, 3.70893008e-01, 1.00221985e-01,
        3.77210042e-01, 9.70211815e-02, 2.16437118e-02, 4.72637276e-01,
        2.20566588e-01, 7.57575758e-02, 1.75393067e-01, 3.61456633e-01,
        7.43888451e-02, 5.81643543e-02,...
        4.56411531e-01, 3.89898990e-01, 3.58256108e-01, 2.78673025e-01,
        1.51343706e-01, 2.28804560e-01, 1.66171708e-01, 2.89633159e-01,
        2.24472016e-01, 1.11994949e-01, 2.97973101e-01, 1.16620701e-01,
        1.50636375e-01, 5.27214514e-01, 2.89445629e-01, 4.78061656e-01,
        3.47719229e-01, 4.62457901e-01, 2.73219431e-01, 2.82188498e-01,
        5.71477663e-01, 1.86280308e-01, 2.58494031e-01]]),
       n_clusters=10))
Best evaluation: 0.38812929711821
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [66, 47, 118, 46, 88, 60, 2, 15, 19, 51]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.50839386e-05, 6.28472715e-01, 4.50456544e-01, 6.12328104e-01,
        4.75291622e-01, 3.44407331e-01, 3.43291823e-01, 3.43252109e-01,
        4.31560636e-01, 5.22727273e-01, 1.32415254e-01, 2.33967047e-01,
        2.53889675e-01, 1.78909673e-01, 1.50740600e-01, 1.46275963e-01,
        2.44599994e-01, 1.06868687e-01, 2.40386437e-01, 2.62959419e-01,
        1.21477827e-01, 5.79509072e-01,...
        2.17773065e-01, 5.51322560e-01, 3.59241764e-01, 3.02952202e-01,
        4.03727634e-01, 4.88383838e-01, 3.67372881e-01, 1.12656165e-01,
        1.74549151e-01, 9.32007727e-02, 6.14275140e-02, 6.61522249e-02,
        1.97509538e-01, 6.49494949e-02, 2.40954726e-01, 1.44762762e-01,
        1.11009770e-01, 3.53610815e-01, 5.59448937e-01, 3.25165596e-01,
        1.96691899e-01, 4.33401572e-01, 3.89741052e-01, 2.86501597e-01,
        6.30240550e-01, 4.20461266e-01, 3.56552538e-01]])))
Best evaluation: 0.4635420124576958
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [70, 101, 44, 55, 13, 23, 124, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        34
           1       0.95      0.91      0.93        22

    accuracy                           0.95        56
   macro avg       0.95      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9718358395989973
F1: 0.9617453114730482
======================================================
Running wdbc 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.96      0.98        23

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00096897, 0.20368284, 0.26208996, 0.19647176, 0.11254613,
        0.28067166, 0.11361266, 0.06298032, 0.11332008, 0.44149512,
        0.15143218, 0.03458265, 0.19399752, 0.02247562, 0.01322007,
        0.19995241, 0.09574308, 0.04647795, 0.20973105, 0.12074455,
        0.04048222, 0.16014911, 0.36593817, 0.15179706, 0.07299524,
        0.43406194, 0.14408515, 0.10511182, 0.31408935, 0.30264196,...
       [0.00955012, 0.56315197, 0.21068651, 0.5575473 , 0.42332447,
        0.3097409 , 0.30403043, 0.27952202, 0.4804672 , 0.36890574,
        0.0379107 , 0.32174543, 0.06042256, 0.29279555, 0.21012032,
        0.26151545, 0.21253042, 0.14298881, 0.68312958, 0.31725519,
        0.11232313, 0.48797603, 0.1543177 , 0.46825276, 0.31545256,
        0.27227102, 0.16911643, 0.18083067, 0.61065292, 0.17291009,
        0.04793486]]),
       n_clusters=3))
Best evaluation: 0.3877178506980459
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        38
           1       0.86      1.00      0.93        19

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [331, 78, 103]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.51337622e-04, 2.80609589e-01, 2.23875550e-01, 2.67707829e-01,
        1.58176034e-01, 2.41762210e-01, 1.05146924e-01, 9.42794547e-02,
        1.24255097e-01, 3.88383838e-01, 1.41322662e-01, 2.99474923e-02,
        1.21198727e-01, 3.40239337e-02, 1.67128006e-02, 1.21868307e-01,
        1.02277165e-01, 5.86111111e-02, 1.59499905e-01, 1.49828333e-01,
        4.34337990e-02, 2.11668445e-01,...
        6.28855201e-01, 6.00000000e-01, 2.91912384e-01, 1.77222524e-01,
        2.29358204e-01, 1.52183548e-01, 1.13892842e-01, 2.22830336e-01,
        2.14558236e-01, 1.27323232e-01, 2.10645956e-01, 1.84865200e-01,
        1.02234567e-01, 4.60690146e-01, 5.34914712e-01, 4.26764281e-01,
        2.84801416e-01, 6.09060292e-01, 3.18819066e-01, 4.46325879e-01,
        6.36238374e-01, 3.87344766e-01, 1.95329923e-01]]),
       n_clusters=10))
Best evaluation: 0.38648873288174873
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [100, 56, 21, 16, 48, 45, 45, 57, 85, 39]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.38094571118213677
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.17042065e-04, 5.33342799e-01, 3.47311464e-01, 5.23875337e-01,
        3.80275716e-01, 3.79164034e-01, 2.74891111e-01, 2.64058107e-01,
        3.67793241e-01, 3.70707071e-01, 1.57118787e-01, 1.21383306e-01,
        9.12747525e-02, 1.14168591e-01, 8.79868808e-02, 8.84182615e-02,
        8.68807643e-02, 5.69191919e-02, 1.96817579e-01, 8.17245455e-02,
        4.43665962e-02, 5.31839203e-01,...
        4.56063618e-01, 6.01515152e-01, 5.10741365e-01, 1.64149919e-01,
        3.46932461e-01, 1.48518117e-01, 8.57642352e-02, 2.41730972e-01,
        2.16510950e-01, 7.85858586e-02, 2.44553893e-01, 1.70231328e-01,
        1.24759891e-01, 4.00924938e-01, 7.95042644e-01, 3.88913791e-01,
        2.37858828e-01, 1.00000000e+00, 4.78902892e-01, 3.71086262e-01,
        6.91752577e-01, 5.65148827e-01, 3.51305260e-01]]),
       n_clusters=4))
Best evaluation: 0.4413057376951912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [83, 320, 34, 75]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.09794071, 0.6204269 , 0.47852553, 0.62822196, 0.46847803,
        0.60139025, 0.50432489, 0.53491097, 0.6361829 , 0.60050505,
        0.52085088, 0.34781821, 0.30560467, 0.33204542, 0.23901017,
        0.21249618, 0.33848049, 0.19315657, 0.36673612, 0.27407553,
        0.17388721, 0.625     , 0.46401919, 0.60590307, 0.4653197 ,
        0.41953378, 0.30251962, 0.39392971, 0.66082474, 0.34082397,
        0.260068...
       [0.00093387, 0.48364807, 0.50084545, 0.48655933, 0.33364466,
        0.59161508, 0.50187105, 0.39643861, 0.39483101, 0.43787879,
        0.31402696, 0.17352888, 0.15045969, 0.1389059 , 0.12079461,
        0.13961315, 0.40487277, 0.10737374, 0.2134874 , 0.10395677,
        0.18670453, 0.61071429, 0.58102345, 0.56565487, 0.46069977,
        0.57670211, 0.69089269, 0.52444089, 0.65257732, 0.34456929,
        0.51725043]]),
       n_clusters=9))
Best evaluation: 0.41576997512830793
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 59, 64, 84, 53, 40, 122, 42, 27]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.54712923e-05, 3.25098206e-01, 2.53635441e-01, 3.08548131e-01,
        1.88844115e-01, 2.51164635e-01, 1.28765106e-01, 3.32708529e-02,
        5.67097416e-02, 2.38654565e-01, 1.88289806e-01, 3.87470578e-02,
        1.09596004e-01, 3.47735947e-02, 2.07471825e-02, 9.81065370e-02,
        5.19497101e-02, 2.30479798e-02, 9.11915135e-02, 6.45578882e-02,
        2.80944682e-02, 2.68943436e-01,...
        4.41650099e-01, 4.32995195e-01, 2.11457456e-01, 1.49483976e-01,
        3.18643918e-01, 1.54549310e-01, 1.00127382e-01, 3.02444165e-01,
        2.27325983e-01, 9.88636364e-02, 2.95321084e-01, 1.96684865e-01,
        1.05516631e-01, 4.88082533e-01, 4.93336887e-01, 4.70591165e-01,
        3.02742823e-01, 4.96136829e-01, 2.61479951e-01, 2.76198083e-01,
        5.37457045e-01, 2.67100335e-01, 1.38396957e-01]]),
       n_clusters=4))
Best evaluation: 0.44272324705313193
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.93        24

    accuracy                           0.95        56
   macro avg       0.96      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 30, 75, 90]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9700814536340852
F1: 0.9592581465298424
======================================================
Running wdbc 100 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        39
           1       0.82      1.00      0.90        18

    accuracy                           0.93        57
   macro avg       0.91      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.91      0.84      0.88        38
           1       0.73      0.84      0.78        19

    accuracy                           0.84        57
   macro avg       0.82      0.84      0.83        57
weighted avg       0.85      0.84      0.84        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.87      0.91        39
           1       0.76      0.89      0.82        18

    accuracy                           0.88        57
   macro avg       0.85      0.88      0.86        57
weighted avg       0.89      0.88      0.88        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.92      0.93        37
           1       0.86      0.90      0.88        20

    accuracy                           0.91        57
   macro avg       0.90      0.91      0.90        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.90      0.93        39
           1       0.81      0.94      0.87        18

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [170, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.86      0.89      0.87        35
           1       0.81      0.77      0.79        22

    accuracy                           0.84        57
   macro avg       0.84      0.83      0.83        57
weighted avg       0.84      0.84      0.84        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [166, 346]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.83      0.97      0.89        30
           1       0.95      0.77      0.85        26

    accuracy                           0.88        56
   macro avg       0.89      0.87      0.87        56
weighted avg       0.89      0.88      0.87        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8927631578947368
F1: 0.8542955432229036
======================================================
Running wdbc 100 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.09846699, 0.4770221 , 0.38180588, 0.46997443, 0.32878049,
        0.53507267, 0.2644623 , 0.35332709, 0.49373757, 0.33686869,
        0.23476742, 0.25515119, 0.39091231, 0.25062432, 0.15010889,
        0.16119931, 0.11804909, 0.11368687, 0.3303656 , 0.14645129,
        0.09805425, 0.46460334, 0.56316631, 0.46212461, 0.28922532,
        0.48689163, 0.19548435, 0.33504274, 0.62783505, 0.25136612,
        0.2...
        0.24604532],
       [0.09959372, 0.19636519, 0.23368279, 0.18436874, 0.10078473,
        0.26072041, 0.05815594, 0.03207591, 0.06809145, 0.22777778,
        0.25158332, 0.01086366, 0.13412748, 0.00994204, 0.00542027,
        0.14175477, 0.03012437, 0.02373232, 0.11723811, 0.17177914,
        0.05120711, 0.13340448, 0.22041578, 0.11922905, 0.05797778,
        0.21019613, 0.03832596, 0.0391453 , 0.13896907, 0.19434545,
        0.1687687 ]])))
Best evaluation: 0.6648751628250473
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.05      1.00      0.09         1

    accuracy                           0.63        57
   macro avg       0.52      0.81      0.43        57
weighted avg       0.98      0.63      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [77, 119, 76, 27, 45, 14, 87, 67]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.36976752e-04, 3.29546011e-01, 3.40209672e-01, 3.31199317e-01,
        2.02565863e-01, 4.05254130e-01, 2.90534323e-01, 2.19962512e-01,
        2.90208748e-01, 4.43661972e-01, 2.93597304e-01, 6.44577223e-02,
        3.29473126e-01, 7.62851623e-02, 3.74450409e-02, 2.13889928e-01,
        2.00513714e-01, 1.09315339e-01, 3.48166259e-01, 7.32016539e-02,
        1.61947080e-01, 2.79657920e-01,...
        4.34592445e-01, 4.78331528e-01, 2.39258635e-01, 2.56237552e-01,
        3.47153465e-01, 1.76035433e-01, 1.81356673e-01, 2.16235510e-01,
        2.90113257e-01, 1.75148124e-01, 4.48410758e-01, 2.05889556e-01,
        1.64815253e-01, 5.11000658e-01, 5.03997868e-01, 4.61644045e-01,
        3.42248908e-01, 4.47929737e-01, 3.09505098e-01, 3.12460064e-01,
        5.86941581e-01, 2.84108833e-01, 1.83400092e-01]]),
       n_clusters=10))
Best evaluation: 0.724562962218459
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        55
           1       0.09      1.00      0.17         2

    accuracy                           0.65        57
   macro avg       0.55      0.82      0.47        57
weighted avg       0.97      0.65      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [71, 103, 46, 74, 8, 44, 23, 21, 97, 25]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.66849210e-02, 5.93923044e-01, 7.69699019e-01, 5.81922466e-01,
        4.57900318e-01, 2.85004965e-01, 2.87160297e-01, 2.78724440e-01,
        3.46941976e-01, 1.85858586e-01, 6.67649537e-02, 2.27304001e-01,
        2.12340877e-01, 1.86273493e-01, 1.92563289e-01, 1.30060849e-01,
        1.81662511e-01, 6.72727273e-02, 2.04205342e-01, 7.65182642e-02,
        4.70267955e-02, 7.10423337e-01,...
        2.71249347e-01, 2.81818182e-01, 1.16470093e-01, 9.35723339e-02,
        1.74549151e-01, 7.70725083e-02, 6.38366225e-02, 9.90243737e-02,
        1.53047736e-01, 4.93434343e-02, 1.85016102e-01, 1.06770980e-01,
        5.30381549e-02, 4.33297759e-01, 5.54371002e-01, 3.92898053e-01,
        2.66368462e-01, 4.63778644e-01, 3.17654820e-01, 2.31789137e-01,
        5.30830176e-01, 3.69012419e-01, 2.05102978e-01]]),
       n_clusters=10))
Best evaluation: 0.6578671426028366
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [11, 93, 55, 25, 64, 58, 110, 16, 16, 64]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00674102e-03, 6.59709404e-01, 5.20121745e-01, 6.85578053e-01,
        5.10498409e-01, 5.17017243e-01, 6.26403288e-01, 7.43673852e-01,
        7.32604374e-01, 5.50000000e-01, 3.96588037e-01, 3.08057215e-01,
        1.46786354e-01, 3.76996655e-01, 2.09186437e-01, 1.59295645e-01,
        4.15341441e-01, 1.98106061e-01, 4.97063838e-01, 1.78533236e-01,
        1.81655393e-01, 5.81999289e-01,...
        2.97465209e-01, 5.73737374e-01, 5.17059815e-01, 1.70921601e-01,
        2.24391430e-01, 1.46020826e-01, 8.24769611e-02, 2.41085087e-01,
        2.85089682e-01, 6.28282828e-02, 2.74294374e-01, 9.81876513e-02,
        1.53911962e-01, 3.24795446e-01, 4.29637527e-01, 2.99765925e-01,
        1.74941015e-01, 6.40019018e-01, 3.30752588e-01, 2.13897764e-01,
        5.34707904e-01, 3.21506012e-01, 3.93939394e-01]]),
       n_clusters=9))
Best evaluation: 0.6068074479812904
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [17, 112, 49, 43, 88, 50, 67, 11, 75]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.6392594287800837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        55
           1       0.10      1.00      0.17         2

    accuracy                           0.67        57
   macro avg       0.55      0.83      0.48        57
weighted avg       0.97      0.67      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.64      0.77        55
           1       0.05      0.50      0.09         2

    accuracy                           0.63        57
   macro avg       0.51      0.57      0.43        57
weighted avg       0.94      0.63      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.88464089e-04, 4.86961049e-01, 5.31281704e-01, 4.74120655e-01,
        3.33107105e-01, 2.76970299e-01, 2.80718974e-01, 2.82099344e-01,
        2.85089463e-01, 2.05555556e-01, 8.65627633e-02, 1.44305631e-01,
        2.91460396e-01, 1.19021816e-01, 9.63358100e-02, 2.17425298e-01,
        3.06636224e-01, 1.24797980e-01, 3.29986740e-01, 1.13384364e-01,
        9.82615425e-02, 4.42902882e-01,...
        4.71123260e-01, 5.23232323e-01, 4.91786015e-01, 1.59514756e-01,
        1.57310820e-01, 1.33864204e-01, 9.68027523e-02, 2.37481728e-01,
        2.81701565e-01, 1.50252525e-01, 2.63307445e-01, 9.94540440e-02,
        1.75821898e-01, 4.36143721e-01, 4.92537313e-01, 3.97878380e-01,
        2.67105781e-01, 7.55002311e-01, 4.51349070e-01, 5.87539936e-01,
        6.98969072e-01, 3.36881530e-01, 4.60186278e-01]]),
       n_clusters=9))
Best evaluation: 0.7026099751459065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 112, 90, 74, 61, 38, 15, 16, 46]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.43915101e-04, 2.03464433e-01, 1.24450457e-01, 2.01851980e-01,
        1.02441095e-01, 6.92625176e-01, 2.89000675e-01, 1.08598875e-01,
        2.38369781e-01, 3.59090909e-01, 2.26621735e-01, 8.21654898e-02,
        2.17202970e-01, 5.15478490e-02, 3.76408544e-02, 3.24880171e-01,
        2.45801664e-01, 5.52272727e-02, 3.72229589e-01, 1.11414420e-01,
        8.80007739e-02, 1.58333333e-01,...
        2.68240557e-01, 4.69696970e-01, 3.31929233e-01, 2.28136882e-02,
        2.84653465e-02, 2.78942657e-02, 1.56284334e-02, 9.50810756e-02,
        1.19175654e-01, 4.92676768e-02, 2.26558060e-01, 1.61225868e-01,
        9.67759767e-02, 3.58730159e-01, 1.89765458e-01, 3.50438817e-01,
        2.08297401e-01, 3.45572212e-01, 2.20925382e-01, 1.68849840e-01,
        4.29896907e-01, 3.13029765e-01, 2.26682409e-01]]),
       n_clusters=9))
Best evaluation: 0.5914964598291879
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [80, 18, 47, 67, 136, 64, 10, 14, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.25474992e-02, 2.10090397e-01, 3.60838688e-01, 2.33501486e-01,
        1.02905620e-01, 7.92843691e-01, 8.11361266e-01, 5.65604499e-01,
        5.22862823e-01, 7.63481046e-01, 1.00000000e+00, 1.39091074e-01,
        1.75875177e-01, 1.26655044e-01, 3.81547933e-02, 2.51453241e-01,
        5.43215069e-01, 1.42954545e-01, 3.53665467e-01, 7.28147690e-01,
        2.87204787e-01, 2.48310210e-01,...
        7.76341948e-01, 5.31233316e-01, 3.39090143e-01, 1.85659967e-01,
        1.23917079e-01, 1.60250671e-01, 1.38566076e-01, 1.19046810e-01,
        2.62925466e-01, 1.19141414e-01, 2.43985603e-01, 1.76844712e-01,
        1.08245927e-01, 6.51013874e-01, 4.45628998e-01, 6.05558046e-01,
        4.65935902e-01, 5.21891303e-01, 5.28189306e-01, 5.63338658e-01,
        8.32302405e-01, 4.46087128e-01, 2.99488390e-01]]),
       n_clusters=10))
Best evaluation: 0.7263782484534491
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        55
           1       0.05      1.00      0.09         1

    accuracy                           0.64        56
   macro avg       0.52      0.82      0.43        56
weighted avg       0.98      0.64      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [5, 133, 54, 63, 56, 7, 86, 13, 71, 25]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6520050125313284
F1: 0.1310017229147664
======================================================
Running wdbc 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.70      0.80        47
           1       0.36      0.80      0.50        10

    accuracy                           0.72        57
   macro avg       0.65      0.75      0.65        57
weighted avg       0.84      0.72      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00097922, 0.27469514, 0.40108218, 0.26547162, 0.16120312,
        0.29962986, 0.1360346 , 0.07835052, 0.12047714, 0.40899242,
        0.1474305 , 0.05453558, 0.2605198 , 0.05988786, 0.02648123,
        0.1286671 , 0.13667498, 0.05908492, 0.15645477, 0.12607512,
        0.04831279, 0.20181273, 0.45788913, 0.19546541, 0.09865026,
        0.28283695, 0.13525628, 0.09680511, 0.19292096, 0.21115931,
        0.07...
       [0.0009177 , 0.26000294, 0.40953669, 0.28154787, 0.14991848,
        0.67409949, 0.53315748, 0.43556701, 0.46486083, 0.69880823,
        0.50400168, 0.07054137, 0.14184052, 0.07769872, 0.03271958,
        0.13658769, 0.24610208, 0.11695194, 0.2997555 , 0.1713129 ,
        0.12994191, 0.24895841, 0.49866738, 0.26287428, 0.12795256,
        0.6546259 , 0.49753083, 0.43051118, 0.70790378, 0.5544164 ,
        0.34138814]]),
       n_clusters=3))
Best evaluation: 0.38790604503932147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        45
           1       0.55      1.00      0.71        12

    accuracy                           0.82        57
   macro avg       0.77      0.89      0.79        57
weighted avg       0.90      0.82      0.84        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [331, 102, 79]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.26259235e-04, 5.50380993e-01, 3.41522491e-01, 5.41151268e-01,
        4.03181336e-01, 3.77087659e-01, 2.81151281e-01, 3.49109653e-01,
        3.84244533e-01, 3.21717172e-01, 1.48062342e-01, 2.68477277e-01,
        4.21064540e-01, 2.29703623e-01, 1.62006582e-01, 2.83982714e-01,
        1.82856452e-01, 1.28308081e-01, 3.62000379e-01, 2.80861548e-01,
        1.14775507e-01, 4.75987193e-01,...
        3.21222664e-01, 3.07575758e-01, 3.26032013e-01, 3.95799384e-02,
        1.67741388e-01, 3.98152947e-02, 2.25028857e-02, 9.29979271e-02,
        1.12532858e-01, 5.51767677e-02, 1.81227505e-01, 8.11527119e-02,
        6.74101405e-02, 3.24083956e-01, 4.94197031e-01, 3.16201006e-01,
        1.68133110e-01, 5.57432676e-01, 3.08978743e-01, 3.25000000e-01,
        6.27835052e-01, 3.18154938e-01, 3.30972058e-01]]),
       n_clusters=4))
Best evaluation: 0.4363114118514645
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.73      0.85        49
           1       0.38      1.00      0.55         8

    accuracy                           0.77        57
   macro avg       0.69      0.87      0.70        57
weighted avg       0.91      0.77      0.81        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [86, 318, 35, 73]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00093717, 0.24605992, 0.36557322, 0.23101375, 0.13370095,
        0.24826216, 0.06441323, 0.05800876, 0.09252483, 0.34292929,
        0.14342881, 0.02929567, 0.26759194, 0.01940722, 0.01471429,
        0.11445763, 0.02888515, 0.02699495, 0.12875545, 0.09269995,
        0.02201401, 0.1924582 , 0.55490405, 0.1701778 , 0.08911718,
        0.27161065, 0.05950267, 0.09145367, 0.25597658, 0.22255076,
        0....
       [0.00098167, 0.69236594, 0.425093  , 0.69525257, 0.5359491 ,
        0.57840571, 0.58070057, 0.68403116, 0.81651856, 0.55656566,
        0.33909014, 0.18565997, 0.12391708, 0.15968051, 0.13856608,
        0.11904681, 0.26292547, 0.11914141, 0.2439856 , 0.17684471,
        0.10824593, 0.65101387, 0.445629  , 0.60555805, 0.4659359 ,
        0.5218913 , 0.52818931, 0.56333866, 0.83430934, 0.44608713,
        0.29948839]]),
       n_clusters=4))
Best evaluation: 0.43748806571035753
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [315, 82, 78, 37]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        48
           1       0.43      1.00      0.60         9

    accuracy                           0.79        57
   macro avg       0.71      0.88      0.73        57
weighted avg       0.91      0.79      0.82        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00093615, 0.41044082, 0.54149378, 0.39417232, 0.24801697,
        0.35542114, 0.25832771, 0.2628866 , 0.37191849, 0.33181818,
        0.23188711, 0.08159993, 0.10632514, 0.07366009, 0.04228256,
        0.37789703, 0.16664163, 0.11441919, 0.33396477, 0.2367873 ,
        0.04308832, 0.30238349, 0.36833689, 0.28432691, 0.15869544,
        0.36010038, 0.16727304, 0.22731629, 0.50721649, 0.19534792,
        0....
       [0.00093639, 0.31650276, 0.35643154, 0.29914052, 0.17459173,
        0.44750384, 0.19100055, 0.09311153, 0.13817097, 0.29191919,
        0.15037911, 0.07424155, 0.2238331 , 0.0750014 , 0.03440058,
        0.19294999, 0.09506714, 0.04727273, 0.17741997, 0.15419035,
        0.0318602 , 0.25506937, 0.37100213, 0.23497186, 0.12637633,
        0.41425081, 0.143406  , 0.11030351, 0.27185567, 0.21939681,
        0.07208448]]),
       n_clusters=9))
Best evaluation: 0.42293260226504026
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [71, 15, 87, 34, 57, 72, 40, 9, 127]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.50929166e-04, 2.53632448e-01, 5.79979709e-01, 2.58171515e-01,
        1.41753343e-01, 5.51428261e-01, 3.55561009e-01, 2.54217432e-01,
        2.26739563e-01, 4.45959596e-01, 4.08803707e-01, 1.06391454e-01,
        3.20190948e-01, 8.88187344e-02, 5.32731429e-02, 2.51045314e-01,
        2.71862889e-01, 9.50252525e-02, 2.50236787e-01, 1.53346091e-01,
        1.65042909e-01, 3.06349206e-01,...
        6.51093439e-01, 5.78282828e-01, 1.89974726e-01, 3.23193916e-01,
        1.01794554e-01, 2.64571455e-01, 2.52695654e-01, 1.21358398e-01,
        2.76594466e-01, 2.40353535e-01, 3.53097177e-01, 2.26937581e-01,
        1.41895720e-01, 7.00396825e-01, 3.99253731e-01, 6.42238247e-01,
        5.62030307e-01, 3.29723304e-01, 2.81272133e-01, 5.58386581e-01,
        7.23367698e-01, 3.07707471e-01, 1.53810836e-01]]),
       n_clusters=3))
Best evaluation: 0.3759788279897185
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.71      0.75        41
           1       0.43      0.56      0.49        16

    accuracy                           0.67        57
   macro avg       0.62      0.63      0.62        57
weighted avg       0.70      0.67      0.68        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [86, 329, 97]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.31111920e-02, 4.33006768e-01, 3.70984106e-01, 4.44406053e-01,
        2.77963945e-01, 5.40093171e-01, 5.60763143e-01, 4.03467666e-01,
        5.10934394e-01, 5.32301121e-01, 4.97051390e-01, 1.65743255e-01,
        1.57531825e-01, 1.45926589e-01, 8.84911785e-02, 1.80609851e-01,
        1.70922582e-01, 8.05050505e-02, 2.45690472e-01, 1.26751843e-01,
        1.12184404e-01, 4.63536108e-01,...
        1.09437964e-01, 4.72693032e-01, 2.27716091e-01, 1.07567948e-01,
        1.10984095e-01, 3.60384410e-01, 4.23125527e-01, 7.73492667e-02,
        4.00857496e-01, 6.21966734e-02, 3.32799151e-02, 2.94285617e-01,
        1.11214588e-01, 6.53030303e-02, 1.42186020e-01, 1.44622052e-01,
        1.06449429e-01, 1.84276058e-01, 5.36780384e-01, 1.69928781e-01,
        8.35381439e-02, 5.58211715e-01, 1.36129464e-01, 1.40175719e-01,
        2.10549828e-01, 2.35955056e-01, 2.19532992e-01]])))
Best evaluation: 0.45642559240169284
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.61      0.74        54
           1       0.00      0.00      0.00         2

    accuracy                           0.59        56
   macro avg       0.47      0.31      0.37        56
weighted avg       0.91      0.59      0.72        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 73, 76, 80, 15, 116, 21, 89]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6957706766917294
F1: 0.3228708361974082
======================================================
Running wdbc 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00987953, 0.71129727, 0.41224214, 0.71460162, 0.56776246,
        0.48451747, 0.53990553, 0.57357076, 0.74602386, 0.38585859,
        0.24983621, 0.3246424 , 0.07507514, 0.32059558, 0.23047901,
        0.07699629, 0.19495599, 0.09030303, 0.27865126, 0.10269038,
        0.10023078, 0.70188545, 0.36727079, 0.72010558, 0.50181872,
        0.38453411, 0.39666817, 0.40649573, 0.83573883, 0.27940128,
        0...
        0.66011116],
       [0.00094978, 0.5361825 , 0.29996618, 0.51696496, 0.38069989,
        0.30017153, 0.20029446, 0.19140112, 0.2889662 , 0.28333333,
        0.09368858, 0.05294224, 0.02552599, 0.04994581, 0.04131132,
        0.03919502, 0.05203984, 0.03565657, 0.12727789, 0.03951145,
        0.00664013, 0.47598719, 0.38219616, 0.4422033 , 0.30102241,
        0.34491184, 0.23853241, 0.30239316, 0.53986254, 0.38987883,
        0.15327063]])))
Best evaluation: 0.4513627864023935
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 125, 80, 21, 41, 144, 25, 55]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.45086281e-02, 3.32484451e-01, 3.97362191e-01, 3.29563238e-01,
        2.05011585e-01, 3.77448768e-01, 2.45659775e-01, 2.82099344e-01,
        2.45427435e-01, 5.49837486e-01, 1.34793597e-01, 1.11859497e-01,
        4.11023692e-01, 1.19869952e-01, 5.98956290e-02, 2.60257674e-01,
        2.07122901e-01, 1.76793943e-01, 4.30562347e-01, 2.10931985e-01,
        1.07178628e-01, 2.75272275e-01,...
        2.40854871e-01, 5.53629469e-01, 4.90522325e-01, 1.01611443e-01,
        1.87146393e-01, 2.00113085e-01, 4.36833907e-02, 1.87680593e-01,
        5.44191426e-01, 3.66688611e-01, 6.65281174e-01, 3.28204463e-01,
        3.97547029e-01, 1.86462978e-01, 2.40138593e-01, 2.20273499e-01,
        8.85768162e-02, 3.05949944e-01, 3.67523358e-01, 3.91054313e-01,
        4.61168385e-01, 3.28272871e-01, 3.16435748e-01]]),
       n_clusters=9))
Best evaluation: 0.38480385107329634
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.66      0.80        53
           1       0.18      1.00      0.31         4

    accuracy                           0.68        57
   macro avg       0.59      0.83      0.55        57
weighted avg       0.94      0.68      0.76        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [94, 97, 14, 69, 147, 18, 51, 8, 14]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.54539600e-04, 7.71877514e-01, 5.73554278e-01, 7.95452975e-01,
        6.53870626e-01, 5.54933646e-01, 5.79780382e-01, 8.57594937e-01,
        8.46837428e-01, 5.75757576e-01, 2.59688290e-01, 1.60202788e-01,
        2.65160891e-01, 1.83680205e-01, 1.42619136e-01, 2.58829928e-01,
        3.67696098e-01, 2.26212121e-01, 4.66944497e-01, 1.95137052e-01,
        1.48563492e-01, 6.11526147e-01,...
        4.96497648e-01, 2.63636364e-01, 8.40353833e-02, 2.34184320e-01,
        1.45155587e-01, 2.40166725e-01, 1.97232713e-01, 1.62525071e-01,
        1.25259110e-01, 8.56313131e-02, 2.88122751e-01, 7.98953115e-02,
        3.80788525e-02, 6.89790110e-01, 5.02665245e-01, 6.79266896e-01,
        5.43845851e-01, 5.28495014e-01, 2.79137682e-01, 4.29073482e-01,
        8.22597313e-01, 2.37137788e-01, 1.38462548e-01]]),
       n_clusters=4))
Best evaluation: 0.43748806571035753
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 315, 78, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        47
           1       0.43      0.90      0.58        10

    accuracy                           0.77        57
   macro avg       0.70      0.82      0.71        57
weighted avg       0.88      0.77      0.80        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.45086292e-02, 5.89020989e-01, 6.17427386e-01, 5.46502690e-01,
        3.95546129e-01, 3.39983750e-01, 3.10471750e-01, 3.43955014e-01,
        4.11083499e-01, 4.51010101e-01, 1.33319292e-01, 1.78862123e-01,
        6.70526874e-02, 1.28430112e-01, 9.49723383e-02, 9.98750983e-02,
        1.21428786e-01, 9.36868687e-02, 2.27315780e-01, 1.65447177e-01,
        8.43732294e-02, 5.91604411e-01,...
        2.52186879e-01, 2.93434343e-01, 3.91322662e-01, 4.85077695e-02,
        6.03341584e-02, 5.24786229e-02, 2.16623895e-02, 1.84623213e-01,
        1.70997687e-01, 6.65656566e-02, 1.95491570e-01, 1.36601565e-01,
        9.21810870e-02, 2.29455710e-01, 2.69989339e-01, 2.23517107e-01,
        1.10229060e-01, 5.42362808e-01, 3.46275868e-01, 2.86102236e-01,
        4.83505155e-01, 3.28208161e-01, 3.16542044e-01]]),
       n_clusters=10))
Best evaluation: 0.3855595883011269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [49, 110, 60, 15, 20, 23, 61, 46, 85, 43]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.82854571e-04, 2.28075157e-01, 2.55326344e-01, 2.17469422e-01,
        1.22436850e-01, 4.15336157e-01, 1.31709711e-01, 6.68462980e-02,
        8.14115308e-02, 3.97474747e-01, 2.15459141e-01, 8.41209488e-02,
        1.72339109e-01, 6.91702398e-02, 3.51928882e-02, 1.27477309e-01,
        1.30591522e-01, 5.25000000e-02, 1.02254215e-01, 9.69212585e-02,
        7.51834501e-02, 2.19047619e-01,...
        2.30863935e-01, 4.05017921e-01, 2.41856328e-01, 1.39175258e-01,
        2.39512922e-01, 4.13636364e-01, 1.80286436e-01, 6.38059026e-02,
        1.29906294e-01, 6.66258305e-02, 3.48266570e-02, 1.23024102e-01,
        1.41932286e-01, 3.87878788e-02, 2.24853192e-01, 1.03253222e-01,
        6.63391512e-02, 3.30158730e-01, 3.77665245e-01, 3.28078708e-01,
        1.92374030e-01, 3.97081160e-01, 2.67495222e-01, 1.44089457e-01,
        5.11683849e-01, 2.75379460e-01, 1.94674013e-01]])))
Best evaluation: 0.4067735553413388
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [145, 67, 104, 48, 17, 17, 28, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.67      0.79        49
           1       0.24      0.71      0.36         7

    accuracy                           0.68        56
   macro avg       0.59      0.69      0.57        56
weighted avg       0.85      0.68      0.73        56

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6678571428571429
F1: 0.19710048016499632
======================================================
Running wdbc 100 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.94        25

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.95        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.91      0.91      0.91        22

    accuracy                           0.93        57
   macro avg       0.93      0.93      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      1.00      0.94        32
           1       1.00      0.84      0.91        25

    accuracy                           0.93        57
   macro avg       0.94      0.92      0.93        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.75      1.00      0.86        27
           1       1.00      0.70      0.82        30

    accuracy                           0.84        57
   macro avg       0.88      0.85      0.84        57
weighted avg       0.88      0.84      0.84        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 167]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        33
           1       1.00      0.91      0.95        23

    accuracy                           0.96        56
   macro avg       0.97      0.96      0.96        56
weighted avg       0.97      0.96      0.96        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9209899749373432
F1: 0.9014734444782876
======================================================
Running wdbc 100 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.55065072e-03, 3.78105921e-01, 3.39871491e-01, 3.57335360e-01,
        2.31898197e-01, 2.85095242e-01, 1.04717502e-01, 4.56185567e-02,
        9.63717694e-02, 2.29797980e-01, 5.89648395e-02, 2.62538475e-02,
        1.55763791e-01, 2.49257881e-02, 1.83751153e-02, 6.53023762e-02,
        4.30423288e-02, 2.08787879e-02, 1.21841258e-01, 1.59818765e-01,
        2.15994362e-02, 2.86374956e-01,...
        1.62972167e-01, 4.45959596e-01, 3.52915484e-01, 5.29422415e-02,
        1.62393918e-01, 3.81190218e-02, 2.18304887e-02, 2.71577659e-01,
        1.00775077e-01, 6.50252525e-02, 2.19928017e-01, 2.83221703e-01,
        5.47655570e-02, 2.00640342e-01, 2.50000000e-01, 1.80586683e-01,
        9.01494298e-02, 5.73400251e-01, 1.62319764e-01, 1.61452991e-01,
        2.89037801e-01, 3.77761939e-01, 2.17400599e-01]]),
       n_clusters=7))
Best evaluation: 0.745910505040982
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [156, 29, 50, 70, 88, 23, 96]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.1008384 , 0.19486753, 0.34866419, 0.19412434, 0.1054664 ,
        0.44208721, 0.23050733, 0.09840675, 0.10720676, 0.43282774,
        0.30855097, 0.03447402, 0.11366248, 0.02996749, 0.01594702,
        0.12027059, 0.11279178, 0.06056616, 0.12953545, 0.07132875,
        0.08086428, 0.17074775, 0.44749467, 0.16526867, 0.08113339,
        0.55358912, 0.26109187, 0.22028754, 0.2790378 , 0.32334385,
        0.2...
       [0.00099245, 0.34032029, 0.24146094, 0.3292787 , 0.2126491 ,
        0.30495622, 0.14600331, 0.12164948, 0.13871769, 0.18905742,
        0.07561078, 0.03943509, 0.14272454, 0.03364275, 0.02461347,
        0.06193698, 0.08770691, 0.05924951, 0.15022005, 0.04323522,
        0.01475971, 0.28440903, 0.35767591, 0.26185756, 0.15070464,
        0.2841577 , 0.17435554, 0.19464856, 0.26900344, 0.17527603,
        0.07058901]]),
       n_clusters=10))
Best evaluation: 0.6428551227944672
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [89, 28, 51, 20, 51, 64, 23, 35, 57, 94]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.38847931e-04, 8.25879123e-02, 2.06966520e-01, 8.32699883e-02,
        3.70731707e-02, 5.63058590e-01, 1.92104779e-01, 1.00584226e-01,
        1.00575013e-01, 2.97474747e-01, 5.55391744e-01, 1.99167119e-02,
        4.99911598e-02, 2.74699886e-02, 4.04185298e-03, 2.22592379e-01,
        1.49292517e-01, 8.22979798e-02, 1.97007009e-01, 1.29425339e-01,
        1.00576261e-01, 6.04055496e-02,...
        9.81181390e-02, 2.88888889e-01, 5.45492839e-02, 7.40539562e-02,
        1.21839639e-01, 5.57603991e-02, 4.12739682e-02, 1.12791923e-01,
        2.83068465e-02, 1.34469697e-02, 1.19795416e-01, 9.93133337e-02,
        0.00000000e+00, 3.03450729e-01, 2.59328358e-01, 2.65401663e-01,
        1.61128588e-01, 1.97649079e-01, 4.22815341e-02, 3.79073482e-02,
        2.00241130e-01, 1.90222748e-01, 1.25278762e-02]]),
       n_clusters=10))
Best evaluation: 0.6559882131958903
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [30, 13, 71, 96, 25, 49, 26, 57, 64, 81]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.52452446e-05, 7.23602631e-01, 3.36827866e-01, 7.53299703e-01,
        5.79215270e-01, 7.21946375e-01, 7.89583461e-01, 9.99062793e-01,
        9.06063618e-01, 7.55555556e-01, 4.30286436e-01, 3.99601666e-01,
        2.61535740e-01, 4.37874005e-01, 3.04816230e-01, 1.63238943e-01,
        8.58461789e-01, 2.62626263e-01, 4.69785944e-01, 3.26982608e-01,
        1.40923465e-01, 7.28210601e-01,...
        4.84095427e-01, 3.39898990e-01, 3.58256108e-01, 2.37045084e-01,
        9.23964713e-02, 1.58224568e-01, 1.60643110e-01, 2.30105041e-01,
        4.91296213e-01, 1.71717172e-01, 3.73366168e-01, 9.55141555e-02,
        2.17884641e-01, 6.17218072e-01, 3.61673774e-01, 5.44798048e-01,
        4.29561541e-01, 6.78054744e-01, 5.51280186e-01, 6.78035144e-01,
        8.61512027e-01, 2.33392470e-01, 4.89702217e-01]]),
       n_clusters=7))
Best evaluation: 0.6300573087249024
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [10, 129, 41, 81, 68, 146, 37]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.6392594287800837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.69210504e-04, 3.21311941e-01, 1.20392289e-01, 3.05922189e-01,
        1.86457228e-01, 4.27392202e-01, 1.31372308e-01, 2.49062793e-02,
        9.52783300e-02, 2.68686869e-01, 1.92923336e-01, 3.89643310e-02,
        7.39038190e-02, 3.40196956e-02, 2.10833504e-02, 8.95740558e-02,
        4.43191036e-02, 1.07878788e-02, 1.29361622e-01, 1.92182135e-01,
        3.13419842e-02, 2.67460317e-01,...
        2.06495436e-01, 2.79569892e-01, 6.25483099e-01, 7.03608247e-01,
        3.87574553e-01, 3.25252525e-01, 5.84035383e-01, 9.10012674e-02,
        2.49690594e-01, 1.24487584e-01, 4.32692493e-02, 1.21868307e-01,
        5.42313816e-01, 3.62373737e-01, 4.34173139e-01, 2.50154781e-01,
        4.17520003e-01, 2.92460317e-01, 3.12100213e-01, 3.16339650e-01,
        1.61328077e-01, 1.20979991e-01, 3.80330064e-01, 5.41773163e-01,
        5.17182131e-01, 1.64202641e-01, 3.48681621e-01]])))
Best evaluation: 0.5779907894555683
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [114, 67, 64, 101, 92, 25, 35, 14]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3819003737158037
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.85      0.92        41
           1       0.73      1.00      0.84        16

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 82, 104]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00999068, 0.50257939, 0.46060196, 0.51972911, 0.35503712,
        0.36345581, 0.55524201, 0.51996105, 0.52378463, 0.32121212,
        0.49978939, 0.29599855, 0.24416549, 0.23714908, 0.18322444,
        0.17177142, 0.51069487, 0.16643939, 0.43777231, 0.12450048,
        0.35947929, 0.48523657, 0.44909382, 0.46411674, 0.30765828,
        0.32708182, 0.4377662 , 0.41253994, 0.68756459, 0.14508181,
        0...
       [0.00099628, 0.61096124, 0.35678052, 0.5991984 , 0.45408271,
        0.46104541, 0.34237163, 0.34347614, 0.4929953 , 0.37474747,
        0.25105307, 0.14354517, 0.11348568, 0.13591656, 0.09880127,
        0.11476357, 0.15605191, 0.07707071, 0.22314832, 0.03782293,
        0.08623882, 0.56207755, 0.35207889, 0.54828428, 0.35902477,
        0.46575976, 0.29456394, 0.33426518, 0.5556321 , 0.19396807,
        0.23822642]]),
       n_clusters=3))
Best evaluation: 0.38478851693344635
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [83, 327, 102]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76815585e-03, 2.88125642e-01, 2.69709544e-01, 2.69652715e-01,
        1.56394486e-01, 3.75733502e-01, 1.31310963e-01, 9.13776945e-02,
        8.02683897e-02, 4.79797980e-01, 1.62805392e-01, 4.93710433e-02,
        1.89798444e-01, 4.40954563e-02, 2.13635464e-02, 1.76018874e-01,
        1.46663863e-01, 6.53787879e-02, 1.19909074e-01, 2.53953960e-01,
        4.36065393e-02, 2.12379936e-01,...
        4.56411531e-01, 3.89898990e-01, 3.58256108e-01, 2.78673025e-01,
        1.51343706e-01, 2.28804560e-01, 1.66171708e-01, 2.89633159e-01,
        2.24472016e-01, 1.11994949e-01, 2.97973101e-01, 1.16620701e-01,
        1.50636375e-01, 5.27214514e-01, 2.89445629e-01, 4.78061656e-01,
        3.47719229e-01, 4.62457901e-01, 2.73219431e-01, 2.82188498e-01,
        5.71477663e-01, 1.86280308e-01, 2.58494031e-01]]),
       n_clusters=10))
Best evaluation: 0.38144305752174346
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [54, 36, 18, 48, 50, 15, 81, 106, 53, 51]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.87857250e-04, 2.78716456e-01, 3.32431518e-01, 2.68675282e-01,
        1.55253662e-01, 4.20658195e-01, 1.82350776e-01, 4.21040300e-02,
        1.03876740e-01, 4.04545455e-01, 2.84540859e-01, 9.23411190e-02,
        9.04128359e-02, 8.66983933e-02, 3.79685350e-02, 1.42672604e-01,
        8.53786764e-02, 1.78434343e-02, 1.23167267e-01, 2.01891147e-01,
        5.12416566e-02, 2.58730159e-01,...
        9.16998012e-01, 3.88383838e-01, 3.76158382e-01, 2.84555495e-01,
        2.46154526e-01, 3.12161334e-01, 2.18192823e-01, 2.19362953e-01,
        4.10655812e-01, 1.44696970e-01, 3.84542527e-01, 3.89486126e-02,
        1.72678026e-01, 8.75793651e-01, 5.75692964e-01, 9.01615518e-01,
        7.32043859e-01, 5.68777653e-01, 5.63019666e-01, 5.17252396e-01,
        9.85223368e-01, 1.55726395e-01, 3.28348419e-01]]),
       n_clusters=10))
Best evaluation: 0.4014795605622733
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [108, 66, 76, 62, 93, 13, 20, 7, 52, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6853070175438597
F1: 0.17421052631578945
======================================================
Running wdbc 100 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.33600300e-04, 6.55272051e-02, 2.57693608e-01, 7.73225210e-02,
        3.43688321e-02, 4.87225783e-01, 3.73964787e-01, 7.33364574e-01,
        2.17445328e-01, 5.69339112e-01, 6.42375737e-01, 7.81821474e-02,
        1.84273338e-01, 5.31498846e-02, 2.02989178e-02, 2.66376585e-01,
        6.29434915e-01, 1.00000000e+00, 8.12224939e-01, 4.67231419e-01,
        3.94451223e-01, 5.96447628e-02,...
        8.43936382e-02, 1.73889491e-01, 2.95703454e-01, 2.21980808e-02,
        1.02103960e-02, 1.73867973e-02, 8.73742524e-03, 2.07227114e-01,
        5.68089645e-02, 3.61751152e-02, 1.30660147e-01, 4.32352221e-02,
        5.57791416e-02, 1.06790439e-01, 0.00000000e+00, 9.74531036e-02,
        4.72409686e-02, 4.78306808e-01, 9.54778745e-02, 8.36261981e-02,
        1.58178694e-01, 1.03312303e-01, 1.43016613e-01]]),
       n_clusters=3))
Best evaluation: 0.3876803930725719
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [77, 104, 331]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.55086724e-03, 4.63770174e-01, 3.07406155e-01, 4.52698500e-01,
        3.15079533e-01, 3.25178297e-01, 2.22194957e-01, 2.05014606e-01,
        3.43753267e-01, 4.20707071e-01, 1.13310868e-01, 1.76534492e-01,
        2.27811174e-01, 1.58313137e-01, 1.13071024e-01, 1.49913315e-01,
        1.68594346e-01, 6.63131313e-02, 3.03845425e-01, 1.83317386e-01,
        8.97627240e-02, 4.31163287e-01,...
        2.75274438e-01, 3.63131313e-01, 3.46040438e-01, 1.71283723e-02,
        4.70960042e-02, 1.55880162e-02, 1.12775916e-02, 9.30414386e-02,
        9.21380719e-02, 3.36868687e-02, 1.66527751e-01, 1.28018236e-01,
        6.53718060e-02, 2.45464248e-01, 1.67910448e-01, 2.21773993e-01,
        1.16742037e-01, 4.49910850e-01, 2.15977336e-01, 1.47603834e-01,
        4.59869101e-01, 3.27616795e-01, 2.50688705e-01]]),
       n_clusters=10))
Best evaluation: 0.38539793427401675
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [44, 20, 85, 18, 55, 124, 48, 8, 13, 97]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.40987453e-04, 5.88042468e-01, 3.81742739e-01, 5.56285375e-01,
        4.21845175e-01, 2.66678704e-01, 1.86798356e-01, 2.17221181e-01,
        2.79671968e-01, 4.47474747e-01, 1.01095198e-02, 2.36454822e-01,
        2.16981966e-01, 2.49203599e-01, 1.39014341e-01, 1.25595596e-01,
        1.88196593e-01, 1.02020202e-01, 2.57813980e-01, 1.74734058e-01,
        6.18824537e-02, 5.11917467e-01,...
        4.36530815e-01, 6.02020202e-01, 4.06065712e-01, 5.75926992e-02,
        1.37685644e-01, 7.56161627e-02, 2.66119784e-02, 1.26705833e-01,
        2.12530417e-01, 6.77020202e-02, 2.56109112e-01, 9.36849215e-02,
        9.72941973e-02, 3.44717182e-01, 5.64765458e-01, 3.58533792e-01,
        1.74916437e-01, 5.37079839e-01, 6.18030290e-01, 4.42412141e-01,
        9.28178694e-01, 5.32032328e-01, 4.75272203e-01]]),
       n_clusters=10))
Best evaluation: 0.39065850263780805
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 123, 68, 8, 61, 54, 94, 13, 15, 33]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.46497093e-04, 5.96762743e-01, 2.85424417e-01, 6.00580471e-01,
        4.54082715e-01, 5.35975445e-01, 4.51567389e-01, 5.87628866e-01,
        6.39165010e-01, 4.88383838e-01, 2.28727885e-01, 2.26290060e-01,
        1.52006719e-01, 1.90123922e-01, 1.68599808e-01, 7.96818166e-02,
        1.54099198e-01, 1.01742424e-01, 2.46827051e-01, 1.26329712e-01,
        8.37168166e-02, 6.68801138e-01,...
        4.75198807e-01, 3.56060606e-01, 5.89721988e-03, 2.71084555e-01,
        2.47480552e-01, 2.95528436e-01, 1.95925274e-01, 2.17935208e-01,
        2.54288461e-01, 1.38611111e-01, 5.23773442e-01, 3.35988068e-01,
        5.07925321e-02, 5.44646033e-01, 4.21641791e-01, 5.37327556e-01,
        3.61482501e-01, 3.07931057e-01, 2.56822967e-01, 3.08386581e-01,
        6.59793814e-01, 2.64931993e-01, 2.36783419e-02]]),
       n_clusters=10))
Best evaluation: 0.4251409091028432
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 77, 40, 67, 58, 67, 66, 81, 16, 5]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        40
           1       0.81      1.00      0.89        17

    accuracy                           0.93        57
   macro avg       0.90      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6870614035087719
F1: 0.1772785622593068
======================================================
Running wdbc 100 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        45
           1       0.55      1.00      0.71        12

    accuracy                           0.82        57
   macro avg       0.77      0.89      0.79        57
weighted avg       0.90      0.82      0.84        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [172, 340]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.92        37
           1       0.82      0.90      0.86        20

    accuracy                           0.89        57
   macro avg       0.88      0.90      0.89        57
weighted avg       0.90      0.89      0.90        57

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.83      0.90        42
           1       0.67      0.93      0.78        15

    accuracy                           0.86        57
   macro avg       0.82      0.88      0.84        57
weighted avg       0.89      0.86      0.87        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        40
           1       0.81      1.00      0.89        17

    accuracy                           0.93        57
   macro avg       0.90      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        41
           1       0.76      1.00      0.86        16

    accuracy                           0.91        57
   macro avg       0.88      0.94      0.90        57
weighted avg       0.93      0.91      0.92        57

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.86      0.92        42
           1       0.71      1.00      0.83        15

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.90      0.82        30
           1       0.86      0.67      0.75        27

    accuracy                           0.79        57
   macro avg       0.80      0.78      0.78        57
weighted avg       0.80      0.79      0.79        57

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [166, 346]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.93        40
           1       0.76      1.00      0.86        16

    accuracy                           0.91        56
   macro avg       0.88      0.94      0.90        56
weighted avg       0.93      0.91      0.91        56

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8945802005012531
F1: 0.8448602893030138
======================================================
Running wdbc 100 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 100 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.51604017e-04, 2.80609589e-01, 2.23875550e-01, 2.67707829e-01,
        1.58176034e-01, 2.41762210e-01, 1.05146924e-01, 9.07450797e-02,
        1.18141153e-01, 3.88383838e-01, 1.46538546e-01, 2.99474923e-02,
        1.21198727e-01, 3.46793573e-02, 1.67128006e-02, 1.21868307e-01,
        1.02277165e-01, 5.86111111e-02, 1.59499905e-01, 1.49828333e-01,
        4.34337990e-02, 2.11668445e-01,...
        4.71123260e-01, 5.23232323e-01, 5.09936667e-01, 1.59514756e-01,
        1.57310820e-01, 1.33864204e-01, 9.68027523e-02, 2.37481728e-01,
        2.81701565e-01, 1.50252525e-01, 2.63307445e-01, 9.94540440e-02,
        1.75821898e-01, 4.36143721e-01, 4.92537313e-01, 3.97878380e-01,
        2.67105781e-01, 7.55002311e-01, 5.10877324e-01, 6.28717949e-01,
        6.98969072e-01, 4.06034688e-01, 7.49893117e-01]]),
       n_clusters=9))
Best evaluation: 0.6996486384392305
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [126, 70, 33, 19, 110, 87, 15, 4, 48]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.85620913e-04, 2.92325775e-01, 3.18566114e-01, 2.95490112e-01,
        1.73732086e-01, 3.42511510e-01, 2.92374701e-01, 2.26265230e-01,
        2.39165010e-01, 4.26868906e-01, 2.49578770e-01, 4.08835778e-02,
        1.18193069e-01, 4.93332705e-02, 2.34554481e-02, 7.70642826e-02,
        1.94054736e-01, 1.20770244e-01, 3.11491443e-01, 9.03459106e-02,
        1.39365906e-01, 2.36166947e-01,...
        1.13966203e-01, 2.68147346e-01, 1.42586352e-01, 8.34329169e-02,
        2.91239392e-01, 7.41648212e-02, 4.26374398e-02, 1.40157052e-01,
        6.53258029e-02, 1.91310072e-02, 1.72102689e-01, 1.52727954e-01,
        6.51576130e-02, 2.54074995e-01, 4.26172708e-01, 2.35931066e-01,
        1.30384081e-01, 2.68308790e-01, 8.42234964e-02, 3.79632588e-02,
        2.02405498e-01, 1.86711356e-01, 9.12732287e-02]]),
       n_clusters=10))
Best evaluation: 0.6599061826280312
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [67, 56, 83, 27, 44, 50, 14, 102, 16, 53]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=9, random_state=42))
Best evaluation: 0.5971321176120117
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [108, 52, 71, 62, 88, 77, 28, 15, 11]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.31587817e-04, 5.78777983e-01, 2.99628001e-01, 5.64646534e-01,
        4.27783669e-01, 4.75489754e-01, 3.29182259e-01, 3.09981256e-01,
        4.47017893e-01, 4.32828283e-01, 2.03243471e-01, 2.23067174e-01,
        1.83709567e-01, 1.92244263e-01, 1.78741796e-01, 1.61301288e-01,
        2.11575223e-01, 7.43686869e-02, 2.91343057e-01, 1.49687623e-01,
        5.67926378e-02, 6.47812166e-01,...
        5.74055666e-01, 2.49494949e-01, 1.40058972e-01, 2.00181061e-01,
        2.20853877e-01, 1.78344249e-01, 1.40247069e-01, 1.27613285e-01,
        1.88087201e-01, 8.04292929e-02, 2.77704111e-01, 3.38830416e-02,
        4.28343326e-02, 6.31447883e-01, 5.34381663e-01, 5.86632800e-01,
        4.51435313e-01, 4.45765129e-01, 2.74383677e-01, 3.51357827e-01,
        7.83505155e-01, 1.38576779e-01, 1.26000262e-01]]),
       n_clusters=10))
Best evaluation: 0.6355220110277336
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [50, 104, 50, 24, 108, 14, 2, 106, 50, 4]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.6392594287800837
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.99121012e-03, 1.27123858e-01, 2.96922557e-01, 1.22313593e-01,
        6.18127786e-02, 4.00021723e-01, 1.32507208e-01, 6.90721649e-02,
        7.52485089e-02, 5.94949495e-01, 2.98441449e-01, 9.63606735e-02,
        2.18750000e-01, 8.53790699e-02, 3.07017375e-02, 1.96756977e-01,
        1.32469132e-01, 6.85353535e-02, 1.87213487e-01, 1.64884336e-01,
        1.04272902e-01, 1.27380952e-01,...
        1.75347913e-01, 2.32828283e-01, 1.92923336e-01, 8.37588267e-02,
        8.37606082e-03, 8.38712717e-02, 4.29030181e-02, 1.02627732e-01,
        9.61937093e-02, 4.68434343e-02, 2.02121614e-01, 1.93448528e-01,
        6.52336139e-02, 3.70634921e-01, 1.57515991e-01, 3.56587847e-01,
        2.14241715e-01, 3.35666645e-01, 1.68437291e-01, 1.71805112e-01,
        4.29896907e-01, 3.04356397e-01, 1.75980585e-01]]),
       n_clusters=9))
Best evaluation: 0.6063750630920068
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [83, 25, 58, 67, 97, 69, 12, 8, 93]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.49088961e-04, 2.75876757e-01, 1.13290497e-01, 2.59138968e-01,
        1.54952280e-01, 2.46605214e-01, 5.63155635e-02, 2.15393627e-02,
        6.61033797e-02, 1.59636946e-01, 2.39469250e-01, 6.42404490e-02,
        1.39166372e-01, 4.81081845e-02, 2.79941277e-02, 2.31872727e-01,
        3.08829273e-02, 1.56060606e-02, 1.40329608e-01, 3.89486126e-02,
        8.48569020e-02, 2.02774813e-01,...
        3.84244533e-01, 2.82968500e-01, 1.48062342e-01, 2.68477277e-01,
        3.29031117e-01, 2.29703623e-01, 1.62006582e-01, 3.07203318e-01,
        1.87520654e-01, 1.28308081e-01, 3.62000379e-01, 2.11740868e-01,
        1.14775507e-01, 4.75987193e-01, 4.06183369e-01, 4.45689526e-01,
        2.99302006e-01, 4.13590438e-01, 1.78915505e-01, 2.75239617e-01,
        5.12027491e-01, 1.52966686e-01, 1.25737898e-01]]),
       n_clusters=9))
Best evaluation: 0.7980171050731669
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [122, 79, 76, 30, 8, 37, 85, 15, 61]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.28877438e-04, 3.05693596e-01, 4.01420358e-01, 2.92930689e-01,
        1.77942736e-01, 2.61713460e-01, 1.25544445e-01, 7.28678538e-02,
        1.00944334e-01, 3.65656566e-01, 1.29067482e-01, 4.59894985e-02,
        1.03054279e-01, 3.84017340e-02, 2.56407383e-02, 5.32685182e-02,
        6.58515336e-02, 3.51010101e-02, 1.30346657e-01, 8.32723589e-02,
        1.35151942e-02, 2.84596229e-01,...
        7.00795229e-01, 3.72222222e-01, 1.11378030e-01, 3.25004527e-01,
        1.24712694e-01, 2.68812138e-01, 2.93796391e-01, 1.55658293e-01,
        1.31117253e-01, 9.04545455e-02, 2.46448191e-01, 9.72026791e-02,
        7.68072081e-02, 8.08964781e-01, 4.98667377e-01, 7.56960008e-01,
        6.68698388e-01, 5.30476128e-01, 2.64119656e-01, 4.11880342e-01,
        7.17869416e-01, 2.44238536e-01, 2.38777255e-01]]),
       n_clusters=10))
Best evaluation: 0.42516829404517553
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [75, 50, 52, 86, 47, 102, 16, 1, 67, 16]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00097922, 0.27469514, 0.40108218, 0.26547162, 0.16120312,
        0.29962986, 0.1360346 , 0.07835052, 0.12047714, 0.40899242,
        0.1474305 , 0.05453558, 0.2605198 , 0.05988786, 0.02648123,
        0.1286671 , 0.13667498, 0.05908492, 0.15645477, 0.12607512,
        0.04831279, 0.20181273, 0.45788913, 0.19546541, 0.09865026,
        0.28283695, 0.13525628, 0.09680511, 0.19292096, 0.21115931,
        0.07...
       [0.00093416, 0.29918213, 0.2056138 , 0.3023901 , 0.17750794,
        0.43396226, 0.33316974, 0.18249766, 0.25193837, 0.32611051,
        0.33066554, 0.0605468 , 0.0575274 , 0.05654243, 0.03090785,
        0.10211782, 0.13817707, 0.05789993, 0.22508557, 0.03833686,
        0.10176097, 0.28842921, 0.23560768, 0.28371715, 0.14608972,
        0.46179753, 0.31716972, 0.22196486, 0.47525773, 0.20169558,
        0.31380918]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
CBEG               precision    recall  f1-score   support

           0       0.91      0.94      0.93        34
           1       0.91      0.87      0.89        23

    accuracy                           0.91        57
   macro avg       0.91      0.91      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0967805 , 0.64030479, 0.61210687, 0.62614885, 0.49862142,
        0.35171978, 0.26998344, 0.37828627, 0.43596445, 0.1959596 ,
        0.12552654, 0.14937534, 0.18316832, 0.14124459, 0.11805797,
        0.11241799, 0.13795175, 0.08729798, 0.20666793, 0.07173411,
        0.06882661, 0.5884027 , 0.67590618, 0.559241  , 0.41456941,
        0.33764776, 0.24139671, 0.33115016, 0.53840854, 0.1718904 ,
        0.1852...
       [0.00965865, 0.34118983, 0.47683463, 0.33916108, 0.19817603,
        0.37916403, 0.34114472, 0.27142162, 0.33779404, 0.59343434,
        0.30265375, 0.11196813, 0.3281471 , 0.13025848, 0.04519628,
        0.31162253, 0.2617238 , 0.09313131, 0.30820231, 0.5221478 ,
        0.13381148, 0.31768054, 0.60847548, 0.32167937, 0.15387829,
        0.55953246, 0.36732932, 0.29904153, 0.61040303, 0.62270846,
        0.31195068]]),
       n_clusters=3))
Best evaluation: 0.38478851693344635
CBEG               precision    recall  f1-score   support

           0       0.94      0.92      0.93        37
           1       0.86      0.90      0.88        20

    accuracy                           0.91        57
   macro avg       0.90      0.91      0.90        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [102, 327, 83]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00100765, 0.47061989, 0.76224066, 0.45077213, 0.30311771,
        0.28816467, 0.25434022, 0.21675258, 0.26351889, 0.26767677,
        0.13732098, 0.14059031, 0.15797383, 0.14910859, 0.07797564,
        0.19382893, 0.26330099, 0.11944444, 0.29494222, 0.07454832,
        0.10354739, 0.39309854, 0.58901919, 0.3799492 , 0.23073142,
        0.28217658, 0.27370453, 0.27180511, 0.48728522, 0.12872068,
        0...
       [0.00100797, 0.66632418, 0.81410788, 0.67297883, 0.4757158 ,
        0.58833619, 0.79019692, 0.82333646, 0.7554672 , 0.67525253,
        0.42544229, 0.25141824, 0.27289604, 0.2802772 , 0.14833451,
        0.2224638 , 0.44557936, 0.17972222, 0.31521121, 0.21610289,
        0.18276605, 0.63358236, 0.73027719, 0.66831017, 0.402035  ,
        0.61962623, 0.81575807, 0.74976038, 0.91065292, 0.49714173,
        0.45231536]]),
       n_clusters=10))
Best evaluation: 0.4361328045827827
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [63, 90, 42, 14, 34, 15, 122, 67, 50, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00099037, 0.26688438, 0.25160636, 0.25450902, 0.14833369,
        0.3605952 , 0.10710999, 0.06949391, 0.11292247, 0.37323232,
        0.17481045, 0.02089444, 0.0678925 , 0.01691561, 0.01256366,
        0.07393684, 0.04721813, 0.03171717, 0.13047926, 0.11535431,
        0.02567611, 0.25436508, 0.26998934, 0.23036503, 0.13807441,
        0.3389685 , 0.1207032 , 0.15071885, 0.33852234, 0.33609304,
        0.11...
       [0.00096208, 0.60338871, 0.34190057, 0.60058047, 0.45107196,
        0.5818399 , 0.50769891, 0.5663074 , 0.48409543, 0.33989899,
        0.35825611, 0.23704508, 0.09277758, 0.15822457, 0.16578321,
        0.23010504, 0.36288942, 0.17171717, 0.37336617, 0.09551416,
        0.21987065, 0.68849206, 0.36167377, 0.6114931 , 0.53831465,
        0.6592485 , 0.55128019, 0.67803514, 0.86151203, 0.23339247,
        0.48970222]]),
       n_clusters=3))
Best evaluation: 0.3786551513385237
CBEG               precision    recall  f1-score   support

           0       0.75      0.93      0.83        29
           1       0.90      0.68      0.78        28

    accuracy                           0.81        57
   macro avg       0.83      0.80      0.80        57
weighted avg       0.83      0.81      0.80        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [328, 97, 87]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.91453165e-04, 2.45113351e-01, 2.81366250e-01, 2.38407850e-01,
        1.32258749e-01, 2.81098226e-01, 1.80970493e-01, 6.83223993e-02,
        7.58946322e-02, 1.58569140e-01, 2.71272115e-01, 3.90729676e-02,
        1.83389321e-01, 4.33963153e-02, 1.76653630e-02, 1.08712649e-01,
        1.08210412e-01, 3.52777778e-02, 9.77647282e-02, 9.36849215e-02,
        3.32766745e-02, 1.92458200e-01,...
        9.33399602e-01, 3.37960491e-01, 1.63016007e-01, 2.62393627e-01,
        2.47701556e-01, 2.38561938e-01, 2.27677354e-01, 9.91943434e-02,
        1.73626341e-01, 7.85101010e-02, 2.35082402e-01, 1.10710868e-01,
        6.39898843e-02, 8.96122376e-01, 5.55170576e-01, 8.48598038e-01,
        7.44887928e-01, 5.02080169e-01, 3.64903804e-01, 4.26517572e-01,
        9.23711340e-01, 2.54484526e-01, 1.69093533e-01]]),
       n_clusters=7))
Best evaluation: 0.4645882821096017
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [306, 31, 2, 26, 79, 58, 11]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7028508771929823
F1: 0.2542447873458326
======================================================
Running wdbc 100 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.94737441e-04, 7.72319898e-02, 1.06865066e-01, 9.65286670e-02,
        3.35964988e-02, 1.00000000e+00, 6.27323477e-01, 2.27975633e-01,
        2.61033797e-01, 7.13976165e-01, 9.49031171e-01, 1.07224335e-01,
        1.61951909e-01, 1.06346888e-01, 2.47255313e-02, 2.74331169e-01,
        3.24210653e-01, 1.14647795e-01, 5.34963325e-01, 2.28796588e-01,
        4.35015388e-01, 5.85483517e-02,...
        8.05168986e-01, 6.17551463e-01, 2.59688290e-01, 1.60202788e-01,
        2.65160891e-01, 1.84234086e-01, 1.42619136e-01, 2.58829928e-01,
        3.67696098e-01, 2.94865043e-01, 6.02689487e-01, 1.75923125e-01,
        1.95773314e-01, 6.00906366e-01, 5.50639659e-01, 6.22794977e-01,
        4.37276697e-01, 5.44343921e-01, 3.77807531e-01, 6.30351438e-01,
        9.39175258e-01, 3.21766562e-01, 2.12817651e-01]]),
       n_clusters=7))
Best evaluation: 0.3968951662033834
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [14, 161, 78, 86, 39, 106, 28]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.48829150e-04, 9.57877798e-01, 4.11227596e-01, 9.55773616e-01,
        8.93531283e-01, 5.12503385e-01, 5.27636341e-01, 6.98880234e-01,
        9.81704130e-01, 3.73737374e-01, 1.63016007e-01, 2.62393627e-01,
        2.47701556e-01, 2.38044944e-01, 2.27677354e-01, 9.91943434e-02,
        1.73626341e-01, 7.85101010e-02, 2.35082402e-01, 1.10710868e-01,
        6.39898843e-02, 8.96122376e-01,...
        6.61265029e-01, 4.11616162e-01, 2.15669756e-01, 3.13090712e-01,
        3.38534300e-01, 2.99718039e-01, 1.80796342e-01, 2.28643301e-01,
        3.34124433e-01, 1.49090909e-01, 4.80394014e-01, 4.11127371e-01,
        1.17159322e-01, 5.78441836e-01, 5.80756930e-01, 5.45794113e-01,
        3.65169092e-01, 3.73968170e-01, 3.04945135e-01, 2.95766773e-01,
        7.41302101e-01, 3.36290164e-01, 1.39577594e-01]]),
       n_clusters=4))
Best evaluation: 0.43748806571035753
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [37, 315, 78, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00921581e-01, 3.44976099e-01, 4.34223876e-01, 3.45380416e-01,
        2.06277837e-01, 4.61948181e-01, 2.94521808e-01, 3.42783505e-01,
        3.05119284e-01, 4.37373737e-01, 2.07666386e-01, 3.30255296e-02,
        3.29191448e-01, 5.36210715e-02, 2.19238772e-02, 1.49573376e-01,
        2.39740513e-01, 1.17297980e-01, 2.41712446e-01, 9.32627906e-02,
        9.65547578e-02, 2.61828531e-01,...
        1.00000000e+00, 8.05555556e-01, 3.96166807e-01, 5.06065544e-01,
        6.09763647e-01, 4.26424162e-01, 4.22485702e-01, 7.34847197e-01,
        9.74173344e-01, 3.22727273e-01, 3.45141125e-01, 5.28901897e-01,
        3.08492399e-01, 6.43543223e-01, 3.19029851e-01, 6.49882962e-01,
        4.63969721e-01, 6.68545813e-01, 3.85278109e-01, 4.63498403e-01,
        7.72508591e-01, 3.26631185e-01, 1.64305392e-01]]),
       n_clusters=4))
Best evaluation: 0.4435668639275939
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [74, 94, 318, 26]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.38094571118213677
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00097125, 0.22334233, 0.31788975, 0.21104278, 0.11683294,
        0.38568481, 0.10168088, 0.03708997, 0.05705765, 0.44242424,
        0.23841618, 0.01759913, 0.23643034, 0.01658578, 0.00863149,
        0.14790767, 0.05150659, 0.02631313, 0.14468649, 0.21962065,
        0.02647071, 0.18571429, 0.38726013, 0.17055174, 0.09175188,
        0.33764776, 0.07898439, 0.06321885, 0.19728522, 0.37886852,...
       [0.09794071, 0.6204269 , 0.47852553, 0.62822196, 0.46847803,
        0.60139025, 0.50432489, 0.53491097, 0.6361829 , 0.60050505,
        0.52085088, 0.34781821, 0.30560467, 0.33204542, 0.23901017,
        0.21249618, 0.33848049, 0.19315657, 0.36673612, 0.27407553,
        0.17388721, 0.625     , 0.46401919, 0.60590307, 0.4653197 ,
        0.41953378, 0.30251962, 0.39392971, 0.66082474, 0.34082397,
        0.26006821]]),
       n_clusters=3))
Best evaluation: 0.37876787837667114
CBEG               precision    recall  f1-score   support

           0       0.75      0.93      0.83        29
           1       0.90      0.68      0.78        28

    accuracy                           0.81        57
   macro avg       0.83      0.80      0.80        57
weighted avg       0.83      0.81      0.80        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [329, 96, 87]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.82131778e-02, 2.47006484e-01, 1.85999324e-01, 2.36472946e-01,
        1.33361612e-01, 2.40063435e-01, 1.41310349e-01, 4.67197751e-02,
        8.40954274e-02, 2.51468233e-01, 2.38626790e-01, 5.28698171e-02,
        9.88109972e-02, 5.66366678e-02, 2.28017288e-02, 1.25437672e-01,
        8.95845225e-02, 2.65404040e-02, 9.74048115e-02, 7.66589745e-02,
        4.04281193e-02, 2.07043757e-01,...
        3.95178926e-01, 2.21569674e-01, 9.79359730e-02, 2.45265254e-01,
        9.66451556e-02, 2.22824294e-01, 1.66694683e-01, 9.28374749e-02,
        1.07158951e-01, 5.72979798e-02, 2.59518848e-01, 8.41166207e-02,
        2.77489877e-02, 6.02276770e-01, 3.88059701e-01, 5.75178047e-01,
        4.13094770e-01, 3.17836624e-01, 2.00162994e-01, 2.14616613e-01,
        6.14776632e-01, 1.94362310e-01, 7.11662075e-02]]),
       n_clusters=4))
Best evaluation: 0.4447845785095722
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [321, 74, 27, 91]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6449561403508771
F1: 0.07755102040816327
======================================================
Running wdbc 100 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.89      0.92        37
           1       0.82      0.90      0.86        20

    accuracy                           0.89        57
   macro avg       0.88      0.90      0.89        57
weighted avg       0.90      0.89      0.90        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        36
           1       0.81      0.81      0.81        21

    accuracy                           0.86        57
   macro avg       0.85      0.85      0.85        57
weighted avg       0.86      0.86      0.86        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.75      0.90      0.82        30
           1       0.86      0.67      0.75        27

    accuracy                           0.79        57
   macro avg       0.80      0.78      0.78        57
weighted avg       0.80      0.79      0.79        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [166, 346]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.90      0.90      0.90        21

    accuracy                           0.93        56
   macro avg       0.92      0.92      0.92        56
weighted avg       0.93      0.93      0.93        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8963659147869674
F1: 0.8639780226705922
======================================================
Running wdbc 100 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.97712274e-04, 1.35642955e-01, 2.01893811e-01, 1.32748255e-01,
        6.34994698e-02, 3.81782071e-01, 1.98791485e-01, 5.45923149e-02,
        1.20079523e-01, 1.65151515e-01, 4.13845818e-01, 5.00814775e-02,
        1.89135431e-01, 5.74376855e-02, 1.57602382e-02, 2.38603529e-01,
        1.36449665e-01, 2.68181818e-02, 1.28831218e-01, 1.45747735e-01,
        8.97972721e-02, 1.17751690e-01,...
        8.85188867e-02, 3.53030303e-01, 2.59226905e-01, 3.97609995e-02,
        2.04384724e-01, 3.66583424e-02, 1.95331324e-02, 1.32406432e-01,
        1.06708325e-01, 3.86111111e-02, 1.89372987e-01, 1.57708111e-01,
        4.27773862e-02, 2.07043757e-01, 3.72334755e-01, 1.86314059e-01,
        9.69573339e-02, 3.87175593e-01, 1.71983615e-01, 1.07264957e-01,
        2.85635739e-01, 2.80114041e-01, 1.85335614e-01]]),
       n_clusters=10))
Best evaluation: 0.650147280585292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        22

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [89, 41, 49, 90, 57, 13, 47, 15, 2, 109]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.65864010e-03, 1.00000000e+00, 2.96246195e-01, 1.00000000e+00,
        9.99141852e-01, 5.55836418e-01, 4.05557941e-01, 7.50000000e-01,
        7.92743539e-01, 3.18526544e-01, 1.11415333e-01, 1.00000000e+00,
        2.46596535e-01, 1.00000000e+00, 9.68995028e-01, 3.98986980e-01,
        1.91275873e-01, 2.10302831e-01, 3.44009780e-01, 5.51656078e-01,
        1.63039717e-01, 7.10182004e-01,...
        1.26292247e-01, 3.24485374e-01, 7.41364785e-02, 3.86384211e-02,
        5.81241160e-02, 4.33491966e-02, 2.59956145e-02, 1.69799776e-01,
        7.29864512e-02, 4.87820935e-02, 2.58190709e-01, 9.02018412e-02,
        4.02545845e-02, 2.53344054e-01, 1.48187633e-01, 2.39997967e-01,
        1.33138150e-01, 2.82176583e-01, 7.16108314e-02, 8.79392971e-02,
        2.73367698e-01, 1.51419558e-01, 4.07774640e-02]]),
       n_clusters=5))
Best evaluation: 0.646382890285295
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.91      0.91      0.91        22

    accuracy                           0.93        57
   macro avg       0.93      0.93      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [29, 72, 87, 132, 192]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.6791217153048152
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.83      0.83      0.83        36
           1       0.71      0.71      0.71        21

    accuracy                           0.79        57
   macro avg       0.77      0.77      0.77        57
weighted avg       0.79      0.79      0.79        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [31, 182, 1, 86, 80, 50, 19, 63]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=7))
Best evaluation: 0.6313871233400911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [1, 81, 125, 44, 58, 194, 9]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.6392594287800837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        36
           1       0.90      0.90      0.90        21

    accuracy                           0.93        57
   macro avg       0.92      0.92      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5704704571130247
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [52, 127, 188, 9, 80, 56]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.69186564e-05, 3.23205074e-01, 4.74805546e-01, 3.30108493e-01,
        1.92704136e-01, 6.91743483e-01, 4.82853813e-01, 3.65042174e-01,
        4.56063618e-01, 5.78750667e-01, 5.10741365e-01, 1.64149919e-01,
        3.46932461e-01, 1.48518117e-01, 8.57642352e-02, 2.41730972e-01,
        2.16510950e-01, 7.85858586e-02, 2.44553893e-01, 1.70231328e-01,
        1.24759891e-01, 4.00924938e-01,...
        4.49900596e-01, 3.78537106e-01, 3.55518113e-01, 6.36610538e-02,
        1.23121464e-01, 8.04316072e-02, 3.97610749e-02, 9.68827549e-02,
        2.44524890e-01, 9.77777778e-02, 2.29020648e-01, 8.43980413e-02,
        1.10076973e-01, 3.77801494e-01, 3.48347548e-01, 3.80945266e-01,
        2.07874558e-01, 4.31420458e-01, 4.30101580e-01, 4.01437700e-01,
        5.95189003e-01, 2.37532032e-01, 3.36219336e-01]]),
       n_clusters=10))
Best evaluation: 0.7314208571138926
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        21

    accuracy                           0.96        56
   macro avg       0.96      0.96      0.96        56
weighted avg       0.96      0.96      0.96        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [17, 74, 123, 65, 84, 15, 13, 14, 58, 50]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9402882205513785
F1: 0.9201298701298702
======================================================
Running wdbc 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.79267435e-04, 6.36991812e-01, 4.08183970e-01, 6.22002626e-01,
        4.87592789e-01, 3.50907285e-01, 2.87467027e-01, 2.29592315e-01,
        3.86928429e-01, 2.81818182e-01, 1.22515833e-01, 1.68966142e-01,
        1.23010962e-01, 1.63077793e-01, 1.22596648e-01, 1.52802801e-01,
        1.26235467e-01, 5.99747475e-02, 2.76756962e-01, 9.24185287e-02,
        3.49349806e-02, 5.82710779e-01,...
        3.41003976e-01, 5.36868687e-01, 4.93120769e-01, 7.04689480e-02,
        1.56647808e-01, 7.06780380e-02, 3.42324775e-02, 1.79148112e-01,
        2.72839247e-01, 1.18257576e-01, 2.83955295e-01, 1.25485451e-01,
        1.63142766e-01, 2.58626823e-01, 4.83208955e-01, 2.73370188e-01,
        1.27998427e-01, 7.03493363e-01, 5.56780620e-01, 5.36923077e-01,
        6.79381443e-01, 4.37633642e-01, 7.40273621e-01]]),
       n_clusters=9))
Best evaluation: 0.41475839501663725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.97      0.96        34
           1       0.95      0.91      0.93        23

    accuracy                           0.95        57
   macro avg       0.95      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [78, 84, 50, 61, 104, 18, 86, 19, 12]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00095027, 0.20172388, 0.25972269, 0.19455115, 0.11091564,
        0.43396226, 0.11115882, 0.05513121, 0.07718688, 0.35644637,
        0.16512216, 0.02694188, 0.34604844, 0.01196815, 0.01432206,
        0.20797498, 0.04899811, 0.05121791, 0.15256724, 0.31480601,
        0.04976964, 0.14224106, 0.38539446, 0.12749733, 0.0659736 ,
        0.42547712, 0.07054361, 0.0703115 , 0.14797251, 0.32216088,
        0....
       [0.00099981, 0.19584701, 0.49814001, 0.20237587, 0.10126148,
        0.64069694, 0.41660021, 0.10578725, 0.22519881, 0.58017335,
        0.50737152, 0.06670288, 0.35754066, 0.06601329, 0.0264252 ,
        0.37961043, 0.24557635, 0.06138907, 0.43178484, 0.08732045,
        0.22440952, 0.15722535, 0.53757996, 0.16079508, 0.06552699,
        0.69755002, 0.28893675, 0.11142173, 0.44948454, 0.24388801,
        0.29214   ]]),
       n_clusters=4))
Best evaluation: 0.4418131128650842
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        36
           1       0.95      1.00      0.98        21

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [316, 91, 35, 70]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.25992833e-04, 5.50380993e-01, 3.56442340e-01, 5.41151268e-01,
        4.03181336e-01, 3.77087659e-01, 2.67529599e-01, 3.62706913e-01,
        4.04129639e-01, 3.21717172e-01, 1.48062342e-01, 2.68477277e-01,
        3.29031117e-01, 2.29180615e-01, 1.62006582e-01, 3.07203318e-01,
        1.87520654e-01, 1.28308081e-01, 3.62000379e-01, 2.11740868e-01,
        1.14775507e-01, 4.75987193e-01,...
        1.50130685e-01, 4.25252525e-01, 8.39090143e-01, 1.50172008e-01,
        1.08734088e-01, 1.13001330e-01, 3.48114860e-02, 5.26804229e-01,
        6.86664464e-01, 1.43207071e-01, 3.34533056e-01, 2.46637024e-01,
        7.26724984e-01, 6.41408751e-02, 9.72814499e-02, 6.05109816e-02,
        2.43806528e-02, 3.27081820e-01, 2.09865044e-01, 1.14536741e-01,
        1.64863934e-01, 1.35817071e-01, 3.49993441e-01]]),
       n_clusters=10))
Best evaluation: 0.473747184323174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 63, 33, 53, 110, 77, 17, 59, 50, 12]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.35989164e-04, 3.73746269e-01, 5.93775934e-01, 3.54831947e-01,
        2.20233298e-01, 3.35018507e-01, 2.04527330e-01, 7.26804124e-02,
        1.46968191e-01, 3.15656566e-01, 1.83235046e-01, 1.05936036e-01,
        1.65929986e-01, 8.50611971e-02, 5.03513274e-02, 1.45949947e-01,
        1.19626281e-01, 2.83080808e-02, 1.63023300e-01, 1.82473124e-01,
        6.90338985e-02, 2.90999644e-01,...
        4.06163022e-01, 5.33333333e-01, 4.90522325e-01, 1.13541067e-01,
        1.26060820e-01, 1.30553848e-01, 5.01832282e-02, 1.71207846e-01,
        1.53197945e-01, 8.71717172e-02, 2.52699375e-01, 1.29003208e-01,
        1.07451322e-01, 3.01672003e-01, 4.70149254e-01, 3.13212809e-01,
        1.62013370e-01, 5.69438024e-01, 3.47634155e-01, 4.07827476e-01,
        7.04810997e-01, 3.98186477e-01, 3.66391185e-01]]),
       n_clusters=9))
Best evaluation: 0.4297931276126046
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [65, 12, 133, 34, 15, 76, 16, 89, 72]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.92      0.96        39
           1       0.86      1.00      0.92        18

    accuracy                           0.95        57
   macro avg       0.93      0.96      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.93        24

    accuracy                           0.95        56
   macro avg       0.96      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9648182957393482
F1: 0.9521280742324418
======================================================
Running wdbc 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       1.00      1.00      1.00        22

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0094391 , 0.50732161, 0.2177883 , 0.51415564, 0.35853428,
        0.48632301, 0.59879762, 0.3945642 , 0.53677932, 0.5915493 ,
        0.35320135, 0.31472026, 0.04205711, 0.26169722, 0.23907075,
        0.21168032, 0.42162105, 0.15332456, 0.50611247, 0.23585599,
        0.28040719, 0.50113296, 0.18363539, 0.48604545, 0.34398571,
        0.5060424 , 0.5201366 , 0.30239617, 0.72233677, 0.43079653,
        0.3650...
       [0.00096893, 0.25755424, 0.21339195, 0.2505335 , 0.14730112,
        0.43215672, 0.18419115, 0.14421275, 0.16749503, 0.36294691,
        0.3104465 , 0.03545175, 0.08915311, 0.02233426, 0.02029892,
        0.23836557, 0.13352059, 0.07685978, 0.27677262, 0.24075435,
        0.17442136, 0.1850011 , 0.2108209 , 0.17447003, 0.08976776,
        0.50934425, 0.1741615 , 0.17899361, 0.3628866 , 0.35764984,
        0.26679362]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.91      1.00      0.95        20

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [105, 325, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00097924, 0.4348999 , 0.21508285, 0.43196738, 0.27359491,
        0.41680961, 0.38163303, 0.1619036 , 0.28212232, 0.46969697,
        0.33192923, 0.02281369, 0.02846535, 0.02723424, 0.01514387,
        0.09508108, 0.11917565, 0.04926768, 0.22655806, 0.16122587,
        0.09677598, 0.32159374, 0.18976546, 0.31221674, 0.16621608,
        0.34557221, 0.22092538, 0.16884984, 0.43093352, 0.31302977,
        0....
       [0.00099088, 0.43868617, 0.33141698, 0.45615369, 0.28517497,
        0.45111492, 0.52119502, 0.5443038 , 0.48060638, 0.5510101 ,
        0.33319292, 0.0735832 , 0.13823815, 0.10838056, 0.04915596,
        0.25441071, 0.39390753, 0.20401515, 0.41958704, 0.27928181,
        0.18863922, 0.33653504, 0.29397655, 0.35703969, 0.18543551,
        0.43934491, 0.40642858, 0.47100639, 0.61143645, 0.3455549 ,
        0.23822642]]),
       n_clusters=3))
Best evaluation: 0.38126360032273676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [325, 104, 83]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.38094571118213677
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76815585e-03, 2.78716456e-01, 2.19817382e-01, 2.66671274e-01,
        1.56527277e-01, 4.52047355e-01, 1.31310963e-01, 9.13776945e-02,
        8.02683897e-02, 4.79797980e-01, 1.62805392e-01, 4.45410103e-02,
        1.89798444e-01, 3.71766480e-02, 2.20471166e-02, 1.29346976e-01,
        1.46663863e-01, 6.53787879e-02, 1.19909074e-01, 2.53953960e-01,
        4.36065393e-02, 2.36904762e-01,...
        5.23856859e-01, 4.60101010e-01, 2.46419545e-01, 2.53413000e-01,
        2.29800212e-01, 2.25368704e-01, 1.67903500e-01, 2.48971683e-01,
        3.55153664e-01, 1.31464646e-01, 3.48740292e-01, 1.39275061e-01,
        1.40721087e-01, 4.97619048e-01, 3.48880597e-01, 4.61121359e-01,
        3.43969447e-01, 4.66420128e-01, 3.12900816e-01, 2.86182109e-01,
        5.20618557e-01, 1.77015573e-01, 1.46530237e-01]]),
       n_clusters=4))
Best evaluation: 0.43894298589061526
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      1.00      0.94        32
           1       1.00      0.84      0.91        25

    accuracy                           0.93        57
   macro avg       0.94      0.92      0.93        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [319, 37, 74, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        21

    accuracy                           0.96        56
   macro avg       0.96      0.96      0.96        56
weighted avg       0.96      0.96      0.96        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9648496240601503
F1: 0.9523732779506041
======================================================
Running wdbc 75 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6482657668430718
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.71      0.82        48
           1       0.36      0.89      0.52         9

    accuracy                           0.74        57
   macro avg       0.67      0.80      0.67        57
weighted avg       0.88      0.74      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.73      0.84        48
           1       0.41      1.00      0.58         9

    accuracy                           0.77        57
   macro avg       0.70      0.86      0.71        57
weighted avg       0.91      0.77      0.80        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 25, 120, 76, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=9, random_state=42))
Best evaluation: 0.5971321176120117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [108, 52, 71, 62, 88, 77, 28, 15, 11]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.51615341e-02, 4.34426617e-01, 4.00067636e-01, 4.31276346e-01,
        2.82629905e-01, 4.34865036e-01, 3.34396663e-01, 2.44376757e-01,
        2.78976143e-01, 5.55555556e-01, 1.88500421e-01, 1.16494659e-01,
        1.99628557e-01, 9.83367102e-02, 6.88795998e-02, 1.07556855e-01,
        1.75580591e-01, 5.60353535e-02, 1.74862663e-01, 1.05082456e-01,
        4.86531794e-02, 4.10530060e-01,...
        1.02990456e-01, 6.41599711e-01, 2.81332434e-01, 1.85098407e-01,
        2.75844930e-01, 4.83838384e-01, 4.03959562e-01, 5.23990585e-02,
        1.37898251e-01, 4.95688640e-02, 1.72544537e-02, 1.67318217e-01,
        1.57786635e-01, 5.30555556e-02, 2.20496306e-01, 1.85709461e-01,
        9.53424980e-02, 1.74670936e-01, 2.26812367e-01, 1.71920912e-01,
        7.14952812e-02, 6.10133804e-01, 2.09185901e-01, 1.79472843e-01,
        4.52920962e-01, 3.50482949e-01, 2.43408107e-01]])))
Best evaluation: 0.5760101788330365
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [71, 19, 69, 24, 35, 74, 133, 87]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.6392594287800837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.75191991e-04, 2.51739316e-01, 3.14846128e-01, 2.35574597e-01,
        1.36234345e-01, 3.31269686e-01, 6.94435924e-02, 1.81724461e-02,
        4.24204771e-02, 2.41919192e-01, 1.99873631e-01, 2.62538475e-02,
        2.58972772e-01, 2.08264619e-02, 1.24094542e-02, 2.09674678e-01,
        4.64145162e-02, 1.76868687e-02, 1.23546126e-01, 1.61929420e-01,
        4.58521620e-02, 2.15079365e-01,...
        7.31113320e-01, 4.70202020e-01, 3.67101938e-01, 3.18667391e-01,
        1.19386492e-01, 2.96517929e-01, 2.56550719e-01, 1.11364177e-01,
        2.24321807e-01, 9.01767677e-02, 3.02519417e-01, 1.53486801e-01,
        1.33535094e-01, 8.72619048e-01, 3.97388060e-01, 8.68075354e-01,
        7.56683504e-01, 4.16231922e-01, 3.79844961e-01, 3.72044728e-01,
        8.50515464e-01, 3.13818253e-01, 2.73317591e-01]]),
       n_clusters=9))
Best evaluation: 0.6219405065473111
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [126, 12, 49, 15, 25, 100, 40, 103, 42]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.38589811e-04, 2.06304132e-01, 3.90598580e-01, 1.98258586e-01,
        1.07317073e-01, 2.48587571e-01, 1.42230538e-01, 1.20267104e-01,
        9.43836978e-02, 1.70848905e-01, 3.22872789e-01, 4.45047981e-02,
        1.38326556e-01, 3.95797013e-02, 1.79455284e-02, 2.51555223e-01,
        1.00024033e-01, 6.16919192e-02, 1.21898087e-01, 1.09725896e-01,
        5.46619129e-02, 1.80718605e-01,...
        9.16998012e-01, 3.53443673e-01, 3.76158382e-01, 2.84555495e-01,
        2.46154526e-01, 3.12161334e-01, 2.11427760e-01, 2.19362953e-01,
        4.10655812e-01, 1.44696970e-01, 3.84542527e-01, 3.89486126e-02,
        1.72678026e-01, 7.85129847e-01, 5.75692964e-01, 8.03277056e-01,
        5.84152576e-01, 5.68777653e-01, 5.63019666e-01, 5.17252396e-01,
        9.85223368e-01, 1.55726395e-01, 3.28348419e-01]]),
       n_clusters=10))
Best evaluation: 0.6576980520922052
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        54
           1       0.10      1.00      0.17         2

    accuracy                           0.66        56
   macro avg       0.55      0.82      0.48        56
weighted avg       0.97      0.66      0.76        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [104, 88, 65, 151, 20, 17, 6, 2, 47, 13]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6783521303258145
F1: 0.2225302621642032
======================================================
Running wdbc 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.58857297e-04, 1.22391027e-01, 2.09671965e-01, 1.13468316e-01,
        5.77306469e-02, 2.88977160e-01, 6.59162015e-02, 3.87066542e-02,
        8.28528827e-02, 2.47979798e-01, 3.07272330e-01, 3.75520550e-02,
        1.03849894e-01, 2.15803609e-02, 1.09040377e-02, 3.37457932e-01,
        6.11950611e-02, 2.99494949e-02, 1.82288312e-01, 2.24404795e-01,
        9.13864820e-02, 9.17822839e-02,...
        5.47189820e-02, 6.57849598e-01, 6.16587939e-01, 2.78350515e-01,
        3.49801193e-01, 5.03535354e-01, 1.00000000e+00, 5.89896795e-02,
        2.27590170e-01, 4.85322527e-02, 2.02989178e-02, 6.81816637e-01,
        3.50196774e-01, 1.31035354e-01, 2.74673234e-01, 2.59441662e-01,
        3.65697940e-01, 9.49839915e-02, 1.60447761e-01, 9.49250461e-02,
        3.51209202e-02, 8.54718352e-01, 3.72288905e-01, 2.48974359e-01,
        3.69415808e-01, 3.04822998e-01, 8.69602394e-01]])))
Best evaluation: 0.4593691205033148
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [82, 52, 80, 63, 112, 82, 26, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00098317, 0.20760076, 0.04058167, 0.20073979, 0.11683687,
        0.32581024, 0.10134348, 0.06105904, 0.08926441, 0.29306609,
        0.11478517, 0.05095057, 0.15134371, 0.04202987, 0.02268966,
        0.151681  , 0.07351218, 0.04529296, 0.14259169, 0.02047226,
        0.04380566, 0.18719392, 0.21641791, 0.16852219, 0.09078503,
        0.4373638 , 0.12633039, 0.12092652, 0.23628866, 0.17626183,
        0.1...
       [0.00094942, 0.37166365, 0.42948935, 0.36278276, 0.23178581,
        0.34251151, 0.26323538, 0.12593721, 0.16217694, 0.36132178,
        0.27822241, 0.03400326, 0.02992397, 0.02765867, 0.02377297,
        0.05360846, 0.08785712, 0.05839368, 0.14691932, 0.03142153,
        0.07649373, 0.33338206, 0.42670576, 0.30150984, 0.18596169,
        0.38915671, 0.29359374, 0.2899361 , 0.42130584, 0.31723186,
        0.27913849]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.79      0.87        43
           1       0.59      0.93      0.72        14

    accuracy                           0.82        57
   macro avg       0.78      0.86      0.80        57
weighted avg       0.88      0.82      0.84        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.90299049e-04, 3.75739505e-01, 1.76530267e-01, 3.63900214e-01,
        2.30498409e-01, 2.55935723e-01, 2.02778971e-01, 1.34834469e-01,
        1.68374281e-01, 3.16666667e-01, 1.41743892e-01, 4.81984429e-02,
        1.61775106e-02, 4.97251115e-02, 3.08331372e-02, 5.29625727e-02,
        1.16021270e-01, 5.83333333e-02, 1.59102103e-01, 5.06275680e-02,
        5.12762047e-02, 3.29064390e-01,...
        4.27182436e-01, 5.33333333e-01, 4.90522325e-01, 1.01068260e-01,
        1.26060820e-01, 1.09465028e-01, 5.01832282e-02, 1.25811606e-01,
        1.53197945e-01, 8.71717172e-02, 2.52699375e-01, 1.29003208e-01,
        1.07451322e-01, 3.01672003e-01, 4.70149254e-01, 3.13212809e-01,
        1.62013370e-01, 5.69438024e-01, 3.47634155e-01, 4.07827476e-01,
        7.06510506e-01, 3.98186477e-01, 3.66391185e-01]]),
       n_clusters=9))
Best evaluation: 0.4193779991584644
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [67, 23, 88, 32, 58, 124, 67, 2, 51]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        48
           1       0.43      1.00      0.60         9

    accuracy                           0.79        57
   macro avg       0.71      0.88      0.73        57
weighted avg       0.91      0.79      0.82        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.33050543e-04, 1.56025246e-01, 2.14522822e-01, 1.45063238e-01,
        7.14316013e-02, 5.48614246e-01, 1.87810564e-01, 2.53983130e-02,
        6.41153082e-02, 8.50000000e-01, 4.13647852e-01, 1.65008633e-01,
        2.38861386e-01, 1.42793271e-01, 5.19576091e-02, 2.68353611e-01,
        6.56262204e-02, 1.93560606e-02, 1.55199848e-01, 4.77683346e-01,
        1.74750909e-01, 1.09925293e-01,...
        8.75745527e-02, 3.06565657e-01, 9.54085931e-02, 6.07169284e-02,
        1.92671499e-01, 5.02989996e-02, 2.68734661e-02, 2.00814174e-01,
        5.04851744e-02, 1.43459596e-02, 1.20022732e-01, 6.00551584e-02,
        2.13921479e-02, 2.28032729e-01, 5.29317697e-01, 2.02450321e-01,
        1.08951042e-01, 3.34345902e-01, 7.95665124e-02, 3.56389776e-02,
        2.03470790e-01, 1.46067416e-01, 5.16200971e-02]]),
       n_clusters=10))
Best evaluation: 0.4321818703873629
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [76, 25, 69, 35, 116, 44, 17, 63, 15, 52]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.64      0.77        55
           1       0.05      0.50      0.09         2

    accuracy                           0.63        57
   macro avg       0.51      0.57      0.43        57
weighted avg       0.94      0.63      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.15020749e-04, 6.43144493e-01, 2.72573554e-01, 6.15783291e-01,
        5.01590668e-01, 2.89879931e-01, 1.81767990e-01, 2.03608247e-01,
        3.48757455e-01, 3.79797980e-01, 1.41322662e-01, 1.56436719e-01,
        8.25892857e-02, 1.24440466e-01, 1.25659790e-01, 1.19386749e-01,
        8.13230390e-02, 4.69696970e-02, 2.53835954e-01, 8.45387516e-02,
        9.11100977e-02, 6.06901459e-01,...
        7.92743539e-01, 2.96969697e-01, 1.11415333e-01, 1.00000000e+00,
        2.46596535e-01, 1.00000000e+00, 9.68995028e-01, 3.98986980e-01,
        1.91275873e-01, 1.61338384e-01, 2.66527751e-01, 5.62109529e-01,
        1.23723450e-01, 7.17893988e-01, 1.71908316e-01, 6.87733453e-01,
        5.68668895e-01, 2.84157697e-01, 1.20606184e-01, 2.55670927e-01,
        5.48109966e-01, 1.63611275e-02, 1.37741047e-03]]),
       n_clusters=10))
Best evaluation: 0.4342858144916281
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.61      0.73        54
           1       0.00      0.00      0.00         3

    accuracy                           0.58        57
   macro avg       0.46      0.31      0.37        57
weighted avg       0.87      0.58      0.69        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [57, 95, 98, 136, 53, 14, 16, 38, 3, 2]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00093593, 0.25457901, 0.40886033, 0.24870431, 0.13695606,
        0.38112306, 0.23026195, 0.14093252, 0.1861332 , 0.43939394,
        0.29654591, 0.06746334, 0.25234264, 0.06813363, 0.02727073,
        0.18353333, 0.17032175, 0.06825758, 0.24493275, 0.16460292,
        0.12327433, 0.23412698, 0.49253731, 0.22947062, 0.11996427,
        0.39113782, 0.2124846 , 0.19440895, 0.41408935, 0.27735068,
        0....
       [0.09304206, 0.35775474, 0.60297599, 0.36583512, 0.21876459,
        0.66547192, 0.42978958, 0.38402062, 0.36600398, 0.62777778,
        0.43828981, 0.09360855, 0.14869165, 0.09998586, 0.04963011,
        0.13237244, 0.30152913, 0.11972222, 0.2064785 , 0.15039117,
        0.15792601, 0.3781746 , 0.66924307, 0.41192912, 0.23346064,
        0.63811662, 0.61162694, 0.56118211, 0.58831615, 0.52296472,
        0.51856225]]),
       n_clusters=4))
Best evaluation: 0.44149309316828966
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [321, 77, 34, 80]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.24      1.00      0.38         5

    accuracy                           0.71        56
   macro avg       0.62      0.84      0.60        56
weighted avg       0.93      0.71      0.78        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6854636591478698
F1: 0.2589318604101213
======================================================
Running wdbc 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.70      0.80        47
           1       0.36      0.80      0.50        10

    accuracy                           0.72        57
   macro avg       0.65      0.75      0.65        57
weighted avg       0.84      0.72      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00976961, 0.30163083, 0.18498478, 0.29214682, 0.17892388,
        0.38394872, 0.17636955, 0.10494377, 0.18444334, 0.5687974 ,
        0.18049705, 0.04939345, 0.12360767, 0.05055836, 0.02354884,
        0.08573274, 0.09882236, 0.04795918, 0.25501222, 0.08271023,
        0.03178664, 0.23031942, 0.25906183, 0.22306949, 0.11075824,
        0.31255366, 0.14078645, 0.11629393, 0.34340206, 0.27385647,
        0...
       [0.00098411, 0.22425192, 0.27764626, 0.21688718, 0.1268772 ,
        0.30892841, 0.14072756, 0.0752343 , 0.13185885, 0.4907909 ,
        0.12657961, 0.08064458, 0.31400283, 0.06229091, 0.03546521,
        0.14192474, 0.15657764, 0.06777485, 0.26283619, 0.23398309,
        0.06247155, 0.19815803, 0.44936034, 0.17543592, 0.095921  ,
        0.34887407, 0.1476749 , 0.10998403, 0.32756014, 0.37243691,
        0.09028827]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        45
           1       0.55      1.00      0.71        12

    accuracy                           0.82        57
   macro avg       0.77      0.89      0.79        57
weighted avg       0.90      0.82      0.84        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3778423121743061
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        46
           1       0.52      1.00      0.69        11

    accuracy                           0.82        57
   macro avg       0.76      0.89      0.78        57
weighted avg       0.91      0.82      0.84        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [104, 322, 86]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        48
           1       0.43      1.00      0.60         9

    accuracy                           0.79        57
   macro avg       0.71      0.88      0.73        57
weighted avg       0.91      0.79      0.82        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.29380011e-04, 5.91467293e-01, 6.26556017e-01, 5.90524771e-01,
        4.07423118e-01, 3.44678162e-01, 6.12293724e-01, 4.93673852e-01,
        4.95079523e-01, 6.31313131e-01, 2.83698399e-01, 3.56285456e-01,
        2.88587341e-01, 4.51182026e-01, 1.83224442e-01, 2.23666559e-01,
        7.38636705e-01, 2.45530303e-01, 4.99715855e-01, 6.39500197e-01,
        2.33240745e-01, 5.74884383e-01,...
        2.99254473e-01, 3.40909091e-01, 4.36815501e-01, 9.37268766e-02,
        3.18864922e-01, 1.09204717e-01, 2.55473498e-02, 5.17971967e-01,
        2.86658455e-01, 1.28813131e-01, 4.34741428e-01, 1.90775032e-01,
        1.72608930e-01, 1.92102455e-01, 3.58475480e-01, 1.92190846e-01,
        8.41034212e-02, 3.79911510e-01, 1.91819231e-01, 1.76996805e-01,
        3.79725086e-01, 1.30297654e-01, 1.95592287e-01]]),
       n_clusters=4))
Best evaluation: 0.43288321018232256
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        53
           1       0.19      1.00      0.32         4

    accuracy                           0.70        57
   macro avg       0.60      0.84      0.56        57
weighted avg       0.94      0.70      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [35, 318, 83, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.51640717e-02, 4.34426617e-01, 4.00067636e-01, 4.31276346e-01,
        2.82629905e-01, 4.34865036e-01, 3.34396663e-01, 2.44376757e-01,
        2.78976143e-01, 5.55555556e-01, 1.88500421e-01, 1.16494659e-01,
        1.99964639e-01, 9.83367102e-02, 6.88795998e-02, 1.07556855e-01,
        1.29690269e-01, 5.60353535e-02, 1.74862663e-01, 1.05082456e-01,
        5.10689164e-02, 4.10530060e-01,...
        4.72067594e-01, 2.63636364e-01, 8.40353833e-02, 2.34184320e-01,
        1.45155587e-01, 2.40682279e-01, 1.97232713e-01, 1.62525071e-01,
        1.25259110e-01, 8.56313131e-02, 2.88122751e-01, 7.98953115e-02,
        3.80788525e-02, 6.89790110e-01, 5.02665245e-01, 6.79266896e-01,
        5.43845851e-01, 5.28495014e-01, 2.79137682e-01, 4.29073482e-01,
        8.20618557e-01, 2.37137788e-01, 1.38462548e-01]]),
       n_clusters=10))
Best evaluation: 0.42885297662728195
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 100, 10, 16, 54, 101, 17, 118, 6, 47]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.74      0.84        47
           1       0.43      0.90      0.58        10

    accuracy                           0.77        57
   macro avg       0.70      0.82      0.71        57
weighted avg       0.88      0.77      0.80        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.24      1.00      0.38         5

    accuracy                           0.71        56
   macro avg       0.62      0.84      0.60        56
weighted avg       0.93      0.71      0.78        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7310776942355889
F1: 0.4163258283462269
======================================================
Running wdbc 75 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.87064985e-04, 6.24686450e-01, 3.32431518e-01, 6.22002626e-01,
        4.69353128e-01, 5.47711474e-01, 3.97276241e-01, 4.99765698e-01,
        6.25745527e-01, 3.35353535e-01, 2.30836427e-01, 1.16458446e-01,
        1.41619519e-01, 1.06064176e-01, 8.53346482e-02, 2.50671380e-01,
        1.86994923e-01, 1.40050505e-01, 3.61810949e-01, 2.33973096e-01,
        1.07451322e-01, 5.01600854e-01,...
        6.17296223e-01, 6.64141414e-01, 5.69338283e-01, 1.48071700e-01,
        2.13003890e-01, 1.28162842e-01, 8.29625811e-02, 2.58897916e-01,
        4.75696218e-01, 2.51338384e-01, 4.32468271e-01, 6.69049361e-01,
        2.22323563e-01, 3.35467805e-01, 3.23827292e-01, 3.43592808e-01,
        1.79438655e-01, 5.53589117e-01, 5.24165120e-01, 5.87350427e-01,
        7.33676976e-01, 6.36730815e-01, 5.33988884e-01]]),
       n_clusters=9))
Best evaluation: 0.7017371389930406
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 123, 13, 73, 96, 63, 67, 6, 39]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 25, 120, 76, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76621798e-04, 1.55189550e-01, 1.49826990e-01, 1.54861447e-01,
        7.55461294e-02, 4.16990160e-01, 2.28466128e-01, 8.39034677e-02,
        1.01242545e-01, 2.89393939e-01, 4.23125527e-01, 8.20206410e-02,
        6.07726681e-01, 7.71332988e-02, 2.33994150e-02, 5.16214032e-01,
        3.30075233e-01, 6.59343434e-02, 2.45501042e-01, 5.38803240e-01,
        2.02562083e-01, 1.04944859e-01,...
        1.15059642e-01, 3.32323232e-01, 2.10825611e-01, 5.57667934e-02,
        2.07817184e-01, 4.81081845e-02, 2.53045398e-02, 9.22601272e-02,
        1.02713237e-01, 5.22979798e-02, 1.54934647e-01, 1.79140692e-01,
        6.74792366e-02, 2.24475276e-01, 3.32793522e-01, 2.06534190e-01,
        1.07378097e-01, 3.23514548e-01, 1.68350202e-01, 1.38258786e-01,
        2.72371134e-01, 2.39306130e-01, 1.58336613e-01]]),
       n_clusters=10))
Best evaluation: 0.7292096239707456
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [35, 71, 95, 87, 26, 26, 54, 13, 47, 58]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.06791936e-05, 2.25235458e-01, 1.68413933e-01, 2.24725313e-01,
        1.19830329e-01, 2.56026000e-01, 2.36887308e-01, 1.63729309e-01,
        1.37950863e-01, 2.21717172e-01, 3.71103623e-01, 2.92956726e-02,
        6.22126945e-02, 2.70456324e-02, 1.16511455e-02, 1.79114118e-01,
        2.77195301e-01, 1.01439394e-01, 2.89448759e-01, 2.07097428e-01,
        2.04773158e-01, 1.60796869e-01,...
        6.99947726e-02, 3.80303030e-01, 1.13732098e-01, 1.59333695e-02,
        4.77369165e-02, 2.92617146e-02, 1.35002372e-02, 5.42203488e-02,
        8.18487698e-02, 2.50101010e-02, 9.15324872e-02, 7.42668993e-02,
        4.14645606e-02, 2.56492351e-01, 2.60660981e-01, 2.52950844e-01,
        1.31168895e-01, 1.49706135e-01, 1.68146229e-01, 1.10543131e-01,
        2.14330003e-01, 2.19593929e-01, 1.43906598e-01]]),
       n_clusters=10))
Best evaluation: 0.6576797661722628
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [16, 36, 65, 24, 52, 21, 56, 92, 51, 99]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', random_state=42))
Best evaluation: 0.5747148273456741
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 110, 24, 15, 84, 75, 68, 101]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.93837640e-04, 2.77361906e-01, 3.51037344e-01, 2.71818881e-01,
        1.45111347e-01, 4.96253498e-01, 3.49733145e-01, 1.87839738e-01,
        2.52186879e-01, 2.93434343e-01, 3.91322662e-01, 4.85077695e-02,
        6.03341584e-02, 5.24786229e-02, 2.16623895e-02, 1.84623213e-01,
        1.70997687e-01, 6.65656566e-02, 1.95491570e-01, 1.36601565e-01,
        9.21810870e-02, 2.29455710e-01,...
        4.38568588e-01, 4.70707071e-01, 2.25989890e-01, 1.39480391e-01,
        1.13397277e-01, 1.28765439e-01, 8.03290263e-02, 2.55262062e-01,
        1.91275873e-01, 6.33585859e-02, 2.80356128e-01, 8.80565093e-02,
        8.43386814e-02, 4.67805052e-01, 3.56876333e-01, 4.36724937e-01,
        2.86030279e-01, 5.08683880e-01, 3.35894675e-01, 2.63658147e-01,
        6.78350515e-01, 2.94697418e-01, 1.96707333e-01]]),
       n_clusters=10))
Best evaluation: 0.6461432917666652
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [29, 41, 67, 84, 127, 7, 31, 11, 50, 65]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.87788012e-03, 2.87235553e-01, 3.00304363e-01, 2.85398383e-01,
        1.56309650e-01, 5.01670127e-01, 3.40531256e-01, 2.25000000e-01,
        2.78479125e-01, 4.92424242e-01, 3.16975569e-01, 7.20984972e-02,
        2.54110679e-01, 8.63685624e-02, 2.75832185e-02, 2.07159126e-01,
        2.78396972e-01, 1.29090909e-01, 3.55370335e-01, 2.91523611e-01,
        1.66528474e-01, 2.22696549e-01,...
        1.50795334e-01, 5.37780988e-01, 3.27648611e-01, 2.64292409e-01,
        3.41600398e-01, 4.26767677e-01, 3.35720303e-01, 1.13706319e-01,
        1.80737270e-01, 1.02247562e-01, 5.53943048e-02, 2.06275283e-01,
        1.81962928e-01, 7.50757576e-02, 2.44364463e-01, 1.19153487e-01,
        9.34939126e-02, 3.25862682e-01, 5.71695096e-01, 3.05742318e-01,
        1.72802792e-01, 7.52360827e-01, 3.67523358e-01, 3.21405751e-01,
        5.89690722e-01, 3.58367830e-01, 3.15230224e-01]])))
Best evaluation: 0.6566775552298794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [32, 73, 79, 134, 35, 92, 6, 61]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.82794219e-04, 1.93052203e-01, 1.73148461e-01, 1.83263078e-01,
        9.96391424e-02, 2.69143043e-01, 8.68044905e-02, 6.35426429e-02,
        3.60139165e-02, 2.39898990e-01, 2.56529065e-01, 2.67970306e-02,
        7.24672914e-02, 2.38420581e-02, 1.19082957e-02, 8.65485944e-02,
        9.34148466e-02, 4.89898990e-02, 7.89543474e-02, 5.66781111e-02,
        9.12828379e-02, 1.88492063e-01,...
        3.21172962e-01, 4.41919192e-01, 2.75273799e-01, 8.53883759e-02,
        1.23917079e-01, 7.00654950e-02, 4.89361948e-02, 1.03783527e-01,
        1.61384324e-01, 6.02020202e-02, 1.63610532e-01, 1.38430799e-01,
        7.72563327e-02, 4.61507937e-01, 4.86940299e-01, 4.21991168e-01,
        2.78058396e-01, 5.54909859e-01, 4.08174947e-01, 3.17571885e-01,
        5.08247423e-01, 4.78612261e-01, 3.36875246e-01]]),
       n_clusters=9))
Best evaluation: 0.603275793212432
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [103, 49, 26, 39, 74, 19, 87, 64, 51]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76351858e-04, 6.01022292e-01, 4.04802164e-01, 5.95052173e-01,
        4.45599152e-01, 3.51471900e-01, 3.51266793e-01, 4.36504217e-01,
        5.48210736e-01, 4.88521089e-01, 1.51432182e-01, 1.85080572e-01,
        4.25167963e-01, 2.08076144e-01, 1.13668710e-01, 1.03443587e-01,
        2.36038093e-01, 1.09722222e-01, 3.42110248e-01, 4.17600045e-01,
        8.26803753e-02, 5.27214514e-01,...
        3.16451292e-01, 5.49386012e-01, 6.22156698e-01, 3.61759913e-02,
        1.47365629e-01, 4.53281817e-02, 1.34255264e-02, 1.93493558e-01,
        3.24736384e-01, 1.15858586e-01, 2.53646524e-01, 1.33646648e-01,
        1.22306980e-01, 1.88900747e-01, 5.54371002e-01, 2.05936551e-01,
        7.93600079e-02, 9.72264413e-01, 8.83478379e-01, 6.71086262e-01,
        8.67353952e-01, 5.10348906e-01, 5.59228650e-01]]),
       n_clusters=10))
Best evaluation: 0.7237444780802205
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 108, 13, 11, 41, 69, 63, 77, 76, 20]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.93243233e-02, 5.21037437e-01, 3.70307744e-01, 5.11436666e-01,
        3.59787911e-01, 4.60142638e-01, 3.40531256e-01, 2.81396439e-01,
        4.38568588e-01, 4.70707071e-01, 2.34330640e-01, 1.23918160e-01,
        1.13397277e-01, 1.08561466e-01, 8.03290263e-02, 1.87578611e-01,
        1.91275873e-01, 6.33585859e-02, 2.80356128e-01, 8.80565093e-02,
        8.43386814e-02, 4.67805052e-01,...
        2.40308151e-01, 2.19696970e-01, 1.30377812e-01, 8.23465508e-02,
        2.38419378e-01, 7.47773642e-02, 5.00151289e-02, 1.88462454e-01,
        1.18649923e-01, 4.62626263e-02, 1.95681000e-01, 1.27455395e-01,
        3.82170446e-02, 3.62860192e-01, 3.57942431e-01, 3.32636087e-01,
        2.02467558e-01, 4.13590438e-01, 1.54412976e-01, 1.42136752e-01,
        3.13505155e-01, 1.96958898e-01, 1.03142369e-01]]),
       n_clusters=10))
Best evaluation: 0.43415345658826465
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [66, 108, 95, 28, 13, 64, 14, 14, 46, 64]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.08964386e-05, 2.37474901e-01, 2.23537369e-01, 2.37089202e-01,
        1.31253754e-01, 5.70280762e-01, 2.73357463e-01, 1.38894096e-01,
        1.62972167e-01, 4.78331528e-01, 3.40353833e-01, 5.29422415e-02,
        1.62393918e-01, 3.81190218e-02, 2.18304887e-02, 2.71577659e-01,
        1.00775077e-01, 8.47597103e-02, 2.83863081e-01, 2.66110559e-01,
        7.21687032e-02, 1.78788100e-01,...
        2.45427435e-01, 5.49837486e-01, 1.34793597e-01, 1.11859497e-01,
        4.11023692e-01, 1.19869952e-01, 5.98956290e-02, 2.60257674e-01,
        2.07122901e-01, 1.76793943e-01, 4.30562347e-01, 2.10931985e-01,
        1.07178628e-01, 2.75272275e-01, 4.59221748e-01, 2.74058258e-01,
        1.45221318e-01, 3.92458562e-01, 1.65235614e-01, 2.67492013e-01,
        4.20962199e-01, 2.86671924e-01, 8.70050561e-02]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.85      0.92        41
           1       0.73      1.00      0.84        16

    accuracy                           0.89        57
   macro avg       0.86      0.93      0.88        57
weighted avg       0.92      0.89      0.90        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.66178869e-04, 4.08396043e-01, 3.27020629e-01, 3.88432036e-01,
        2.60911983e-01, 2.32644218e-01, 1.12815165e-01, 1.02458617e-01,
        1.48823837e-01, 2.45959596e-01, 9.41449031e-02, 4.28390368e-02,
        1.41133310e-01, 3.59571117e-02, 2.87225578e-02, 3.78352653e-02,
        5.14690420e-02, 3.31060606e-02, 9.80109869e-02, 3.16316767e-02,
        1.55535287e-02, 3.55033796e-01,...
        6.91061160e-01, 5.38888889e-01, 2.64321820e-01, 2.12601847e-01,
        1.39210573e-01, 1.85519082e-01, 1.51248230e-01, 9.73926641e-02,
        1.79559588e-01, 1.01136364e-01, 2.69179769e-01, 1.63195812e-01,
        6.19860979e-02, 5.82355034e-01, 3.58742004e-01, 5.46790179e-01,
        3.99085726e-01, 3.67364459e-01, 2.77682374e-01, 3.54073482e-01,
        7.39924216e-01, 2.98048492e-01, 1.35445363e-01]]),
       n_clusters=5))
Best evaluation: 0.401773965421633
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [185, 80, 134, 29, 84]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.40457799e-02, 5.94451783e-02, 2.95850622e-01, 5.53420446e-02,
        2.47720042e-02, 3.01254852e-01, 1.22845224e-01, 3.72071228e-02,
        2.94085487e-02, 3.58080808e-01, 3.17396799e-01, 1.72243690e-02,
        1.31829031e-01, 1.88341810e-02, 2.62048046e-03, 3.35615488e-01,
        1.06708325e-01, 4.01010101e-02, 1.12085622e-01, 2.51280464e-01,
        5.82894573e-02, 3.67840626e-02,...
        1.87872763e-01, 4.14646465e-01, 1.91870261e-01, 4.82611198e-02,
        3.01449788e-02, 8.48935338e-02, 2.44266882e-02, 1.11301291e-01,
        2.23946285e-01, 9.20202020e-02, 2.18791438e-01, 8.48201722e-02,
        7.97783398e-02, 3.01672003e-01, 1.94296375e-01, 3.17695104e-01,
        1.53116398e-01, 2.80195470e-01, 3.25416460e-01, 2.71725240e-01,
        4.73883162e-01, 2.73802484e-01, 1.87459006e-01]]),
       n_clusters=9))
Best evaluation: 0.42115896524744423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [87, 45, 15, 50, 60, 19, 117, 49, 70]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.64410830e-04, 6.30839131e-01, 5.86743321e-01, 6.15783291e-01,
        4.85884101e-01, 5.14499837e-01, 2.74277652e-01, 3.55904405e-01,
        4.63866799e-01, 3.80808081e-01, 1.21314238e-01, 1.03639326e-01,
        1.48691655e-01, 8.62272063e-02, 8.77759745e-02, 1.13199850e-01,
        1.01601226e-01, 5.34595960e-02, 1.55048305e-01, 6.94827489e-02,
        3.44513080e-02, 6.50793651e-01,...
        9.43836978e-02, 2.15656566e-01, 3.22872789e-01, 4.45047981e-02,
        1.38326556e-01, 3.95797013e-02, 1.85197322e-02, 2.51555223e-01,
        1.00024033e-01, 6.16919192e-02, 1.21898087e-01, 1.09725896e-01,
        5.46619129e-02, 2.01587302e-01, 4.56556503e-01, 1.87713120e-01,
        1.02531724e-01, 6.51984415e-01, 1.86580124e-01, 2.49201278e-01,
        2.84467354e-01, 2.49162231e-01, 2.18286764e-01]]),
       n_clusters=10))
Best evaluation: 0.38409811439290054
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [41, 61, 47, 33, 67, 19, 108, 53, 13, 70]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.43707708e-04, 2.10563680e-01, 1.92086574e-01, 2.02266602e-01,
        1.08716861e-01, 3.35811280e-01, 1.51861849e-01, 8.20759138e-02,
        1.42892644e-01, 3.02722904e-01, 1.83024431e-01, 2.33206591e-02,
        1.40028289e-01, 1.81878151e-02, 1.09600708e-02, 1.16259306e-01,
        9.73202752e-02, 3.62121212e-02, 1.62947528e-01, 1.00298306e-01,
        2.39487031e-02, 1.56172181e-01,...
        2.95278330e-01, 5.45114789e-01, 7.27464195e-01, 0.00000000e+00,
        1.92450495e-01, 7.56726193e-02, 7.95669763e-04, 2.30682938e-01,
        5.57109382e-01, 3.87626263e-01, 5.52945634e-01, 1.16620701e-01,
        3.90572530e-01, 1.03877624e-01, 2.87846482e-01, 1.29986553e-01,
        4.09703107e-02, 2.84818068e-01, 3.24640296e-01, 4.81629393e-01,
        5.03436426e-01, 2.03429923e-01, 4.26078972e-01]]),
       n_clusters=4))
Best evaluation: 0.4416853903465228
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [325, 2, 100, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6554824561403508
F1: 0.08421052631578947
======================================================
Running wdbc 75 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.99125182e-03, 2.39433953e-01, 6.23266824e-01, 2.28456914e-01,
        1.29968187e-01, 3.14976979e-01, 1.24593583e-01, 5.54592315e-02,
        1.18141153e-01, 4.01010101e-01, 1.53308583e-01, 1.79105559e-01,
        5.04508487e-01, 1.57470669e-01, 7.12703447e-02, 1.97300880e-01,
        9.98738246e-02, 3.69949495e-02, 2.24095473e-01, 1.77126133e-01,
        1.03236461e-01, 2.01707577e-01,...
        2.95278330e-01, 5.69696970e-01, 7.54313169e-01, 0.00000000e+00,
        1.92450495e-01, 7.56726193e-02, 7.95669763e-04, 2.30682938e-01,
        5.57109382e-01, 3.87626263e-01, 5.52945634e-01, 1.16620701e-01,
        3.90572530e-01, 1.03877624e-01, 2.87846482e-01, 1.29986553e-01,
        4.09703107e-02, 2.84818068e-01, 3.67456979e-01, 5.15384615e-01,
        5.03436426e-01, 2.45188881e-01, 6.94313809e-01]]),
       n_clusters=10))
Best evaluation: 0.4346708268530852
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [68, 121, 49, 36, 91, 66, 15, 51, 2, 13]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0010035 , 0.0975562 , 0.32566791, 0.09339878, 0.04947224,
        0.29141464, 0.09484081, 0.05475633, 0.04778827, 0.28169014,
        0.26095198, 0.06670288, 0.22162306, 0.06111294, 0.02136355,
        0.19468335, 0.06742873, 0.07692561, 0.23508557, 0.17995707,
        0.14838016, 0.08230393, 0.36167377, 0.07427177, 0.03488487,
        0.32179885, 0.06613888, 0.07468051, 0.13216495, 0.19440063,
        0....
       [0.00096356, 0.37362261, 0.25566452, 0.39322806, 0.23294431,
        0.73007132, 0.64112631, 0.57357076, 0.61729622, 0.7248104 ,
        0.54759899, 0.19833424, 0.15443777, 0.15568016, 0.098353  ,
        0.28680695, 0.32766545, 0.16402238, 0.5200489 , 0.13399893,
        0.35352285, 0.33082377, 0.28358209, 0.33201159, 0.17497023,
        0.69556891, 0.41040642, 0.35375399, 0.76597938, 0.33359621,
        0.41952853]]),
       n_clusters=3))
Best evaluation: 0.3876803930725719
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.93        40
           1       0.77      1.00      0.87        17

    accuracy                           0.91        57
   macro avg       0.89      0.94      0.90        57
weighted avg       0.93      0.91      0.91        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [331, 104, 77]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3778423121743061
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        40
           1       0.81      1.00      0.89        17

    accuracy                           0.93        57
   macro avg       0.90      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [104, 322, 86]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.39807835e-04, 5.36670091e-01, 4.27385892e-01, 4.91999161e-01,
        3.55673383e-01, 2.83379977e-01, 1.46739464e-01, 1.70876289e-01,
        2.78131213e-01, 5.39898990e-01, 6.10783488e-03, 1.79314314e-01,
        1.88693423e-01, 1.45308221e-01, 8.82296908e-02, 1.06906601e-01,
        4.63394118e-02, 5.78535354e-02, 1.86834628e-01, 5.94613610e-01,
        3.47967884e-02, 4.50017787e-01,...
        4.95079523e-01, 6.31313131e-01, 2.83698399e-01, 3.56285456e-01,
        2.88587341e-01, 4.51182026e-01, 1.83224442e-01, 2.23666559e-01,
        7.38636705e-01, 2.45530303e-01, 4.99715855e-01, 6.39500197e-01,
        2.33240745e-01, 5.74884383e-01, 5.63699360e-01, 6.32451815e-01,
        3.60253637e-01, 3.53496665e-01, 6.95743711e-01, 5.78434505e-01,
        8.56701031e-01, 6.12063868e-01, 3.19821593e-01]]),
       n_clusters=4))
Best evaluation: 0.4328832101823226
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [83, 76, 318, 35]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.33863657e-04, 9.02550996e-02, 1.66723030e-01, 1.03655587e-01,
        4.26299046e-02, 4.08052722e-01, 4.10158886e-01, 2.01640112e-01,
        1.42743539e-01, 4.25252525e-01, 8.38135593e-01, 1.50172008e-01,
        1.08734088e-01, 1.13603166e-01, 3.40429032e-02, 5.26804229e-01,
        6.86664464e-01, 1.43207071e-01, 3.34533056e-01, 2.46637024e-01,
        7.26724984e-01, 6.41408751e-02,...
        4.20725646e-01, 3.31818182e-01, 6.35593220e-03, 3.96704689e-01,
        1.52669731e-01, 3.28699995e-01, 4.05389441e-01, 1.31046674e-01,
        6.66025776e-02, 5.29292929e-02, 2.26747490e-01, 6.68092531e-02,
        3.13765322e-02, 8.11810744e-01, 4.31865828e-01, 7.42517058e-01,
        7.26946520e-01, 4.30099716e-01, 1.31472480e-01, 2.28514377e-01,
        6.25429553e-01, 1.86280308e-01, 6.49350649e-02]]),
       n_clusters=7))
Best evaluation: 0.4469931513951819
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 88, 105, 166, 75, 46, 17]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00095337, 0.57735813, 0.43219479, 0.57846728, 0.42644874,
        0.35407842, 0.37856573, 0.26101218, 0.33658052, 0.35707071,
        0.11225779, 0.11739996, 0.15753182, 0.1449371 , 0.09139974,
        0.12955094, 0.26082254, 0.06833333, 0.23129381, 0.08819722,
        0.08644611, 0.61230159, 0.53411514, 0.64838728, 0.46285573,
        0.4030245 , 0.51693493, 0.30870607, 0.58694158, 0.32091465,
        0....
       [0.0009612 , 0.27966302, 0.14879946, 0.28443093, 0.15652728,
        0.3798197 , 0.3534139 , 0.32193065, 0.19781312, 0.27070707,
        0.29759899, 0.03295311, 0.01768034, 0.07708618, 0.01840408,
        0.12876908, 0.40307027, 0.2060101 , 0.25951885, 0.06723138,
        0.23009687, 0.25634921, 0.15138593, 0.3051596 , 0.13979919,
        0.35811926, 0.54099601, 0.61717252, 0.53642612, 0.21170905,
        0.41164896]]),
       n_clusters=3))
Best evaluation: 0.37710158851848685
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.90      0.95        40
           1       0.81      1.00      0.89        17

    accuracy                           0.93        57
   macro avg       0.90      0.95      0.92        57
weighted avg       0.94      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [98, 327, 87]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7168859649122806
F1: 0.26612685560053984
======================================================
Running wdbc 75 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 75 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.89      0.93        38
           1       0.82      0.95      0.88        19

    accuracy                           0.91        57
   macro avg       0.89      0.92      0.90        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.82      0.85        38
           1       0.68      0.79      0.73        19

    accuracy                           0.81        57
   macro avg       0.78      0.80      0.79        57
weighted avg       0.82      0.81      0.81        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [168, 344]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        33
           1       0.95      0.83      0.89        24

    accuracy                           0.91        57
   macro avg       0.92      0.90      0.91        57
weighted avg       0.92      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.89      0.89        36
           1       0.81      0.81      0.81        21

    accuracy                           0.86        57
   macro avg       0.85      0.85      0.85        57
weighted avg       0.86      0.86      0.86        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [169, 343]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [175, 337]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.75      0.90      0.82        30
           1       0.86      0.67      0.75        27

    accuracy                           0.79        57
   macro avg       0.80      0.78      0.78        57
weighted avg       0.80      0.79      0.79        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [345, 167]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        35
           1       0.90      0.90      0.90        21

    accuracy                           0.93        56
   macro avg       0.92      0.92      0.92        56
weighted avg       0.93      0.93      0.93        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8875939849624059
F1: 0.8514344686636235
======================================================
Running wdbc 75 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.88190835e-04, 3.34090586e-01, 2.12039229e-01, 3.17808030e-01,
        1.98388123e-01, 2.88435497e-01, 1.21372922e-01, 8.28022493e-02,
        1.46322068e-01, 3.30303030e-01, 1.96986242e-01, 1.00561289e-01,
        1.51564710e-01, 8.89129718e-02, 4.84462026e-02, 2.12904103e-01,
        8.03466819e-02, 4.06060606e-02, 1.71358212e-01, 1.71216300e-01,
        6.68573719e-02, 2.74991106e-01,...
        3.84244533e-01, 3.21717172e-01, 1.53526971e-01, 2.68477277e-01,
        3.29031117e-01, 2.29703623e-01, 1.62006582e-01, 3.07203318e-01,
        1.87520654e-01, 1.28308081e-01, 3.62000379e-01, 2.11740868e-01,
        1.14775507e-01, 4.75987193e-01, 4.06183369e-01, 4.45689526e-01,
        2.99302006e-01, 4.13590438e-01, 2.02512601e-01, 2.94529915e-01,
        5.12027491e-01, 1.84366833e-01, 2.04895254e-01]]),
       n_clusters=10))
Best evaluation: 0.735820455445649
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        22

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [126, 97, 44, 12, 51, 9, 12, 17, 91, 53]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        37
           1       0.91      1.00      0.95        20

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [54, 25, 120, 76, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=8))
Best evaluation: 0.6791217153048154
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.91      0.90        35
           1       0.86      0.82      0.84        22

    accuracy                           0.88        57
   macro avg       0.87      0.87      0.87        57
weighted avg       0.88      0.88      0.88        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [31, 19, 182, 80, 1, 86, 63, 50]
Selected clustering_algorithm: fcm
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.83526131e-04, 2.53632448e-01, 1.77206628e-01, 2.38407850e-01,
        1.38112407e-01, 3.08657579e-01, 8.07619164e-02, 4.94142455e-02,
        1.02087475e-01, 2.58080808e-01, 1.49957877e-01, 9.84247691e-02,
        1.20652679e-01, 8.69339867e-02, 4.36086799e-02, 2.03589761e-01,
        6.34379957e-02, 3.30050505e-02, 1.95112711e-01, 3.07001745e-01,
        1.60607100e-02, 1.86766275e-01,...
        8.39463221e-01, 5.05555556e-01, 1.32055602e-01, 8.81948217e-01,
        2.08693537e-01, 8.43094756e-01, 1.00000000e+00, 2.01822076e-01,
        5.23528694e-01, 2.03409091e-01, 4.92138663e-01, 1.27877526e-01,
        1.24332824e-01, 1.00000000e+00, 5.15724947e-01, 1.00000000e+00,
        1.00000000e+00, 4.38293826e-01, 3.86442355e-01, 5.45766773e-01,
        9.02061856e-01, 2.12103292e-01, 1.26131444e-01]]),
       n_clusters=9))
Best evaluation: 0.7061376702211979
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [122, 15, 84, 45, 90, 69, 70, 15, 2]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.40987453e-04, 5.88042468e-01, 3.81742739e-01, 5.56285375e-01,
        4.21845175e-01, 2.66678704e-01, 1.86798356e-01, 2.17221181e-01,
        2.79671968e-01, 4.47474747e-01, 1.01095198e-02, 2.36454822e-01,
        2.16981966e-01, 2.49203599e-01, 1.39014341e-01, 1.25595596e-01,
        1.88196593e-01, 1.02020202e-01, 2.57813980e-01, 1.74734058e-01,
        6.18824537e-02, 5.11917467e-01,...
        6.57057654e-01, 5.38888889e-01, 2.64321820e-01, 2.40154567e-01,
        1.39210573e-01, 2.20700833e-01, 1.51248230e-01, 1.32534579e-01,
        1.79559588e-01, 1.01136364e-01, 2.69179769e-01, 1.63195812e-01,
        6.19860979e-02, 5.82355034e-01, 3.58742004e-01, 5.46790179e-01,
        3.99085726e-01, 3.67364459e-01, 2.77682374e-01, 3.54073482e-01,
        7.38144330e-01, 2.98048492e-01, 1.35445363e-01]]),
       n_clusters=9))
Best evaluation: 0.7027095723439842
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [66, 88, 16, 71, 64, 135, 33, 14, 25]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00976888, 0.23233471, 0.25870815, 0.22396517, 0.12400764,
        0.75887911, 0.16170787, 0.13891753, 0.36799205, 0.48232323,
        0.18513058, 0.19181604, 0.427157  , 0.15379541, 0.08102961,
        0.42380256, 0.09491693, 0.03199495, 0.36181095, 0.26591434,
        0.07279964, 0.17738095, 0.18576759, 0.1623903 , 0.08845633,
        0.42745823, 0.05470986, 0.05713259, 0.30742268, 0.12911492,
        0.0...
       [0.00094802, 0.13834067, 0.28238079, 0.14380485, 0.06745914,
        0.48180732, 0.33746396, 0.30623243, 0.18469185, 0.30757576,
        0.65711879, 0.1157342 , 0.42008487, 0.11190689, 0.03985752,
        0.37893055, 0.644606  , 0.30227273, 0.46599735, 0.43504812,
        0.58818733, 0.13214286, 0.32969083, 0.12667002, 0.06313909,
        0.38915671, 0.25973358, 0.2784345 , 0.34054983, 0.206781  ,
        0.4011544 ]]),
       n_clusters=10))
Best evaluation: 0.6566362163240212
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [50, 19, 93, 46, 46, 45, 55, 87, 57, 14]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.54230103e-05, 5.52747409e-01, 2.50591816e-01, 5.36314007e-01,
        3.95970308e-01, 4.25116463e-01, 2.77958407e-01, 3.41377694e-01,
        4.30666004e-01, 4.26588361e-01, 2.56318450e-01, 2.17743980e-01,
        2.69801980e-01, 1.94977147e-01, 1.56272530e-01, 2.17187341e-01,
        1.40880824e-01, 8.43939394e-02, 3.03277136e-01, 1.76844712e-01,
        1.26970966e-01, 5.09427250e-01,...
        7.97216700e-01, 9.28457021e-01, 6.62594777e-01, 2.97012493e-01,
        3.36987270e-01, 3.71860717e-01, 2.04703790e-01, 2.94625557e-01,
        4.96425031e-01, 2.75505051e-01, 4.91191514e-01, 1.00000000e+00,
        1.75925542e-01, 5.49270722e-01, 5.25053305e-01, 5.97091489e-01,
        3.53372002e-01, 6.12362148e-01, 5.71557470e-01, 6.13498403e-01,
        8.61855670e-01, 7.63847822e-01, 2.92535747e-01]]),
       n_clusters=10))
Best evaluation: 0.6661498379594759
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      1.00      0.96        32
           1       1.00      0.88      0.93        24

    accuracy                           0.95        56
   macro avg       0.96      0.94      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [64, 91, 128, 102, 16, 33, 2, 47, 20, 10]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9595551378446114
F1: 0.9459033205403029
======================================================
Running wdbc 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00618906e-03, 3.89938000e-01, 7.07135610e-01, 4.11927303e-01,
        2.43223754e-01, 4.70975896e-01, 5.80700571e-01, 5.97469541e-01,
        4.68638171e-01, 5.39393939e-01, 4.70845163e-01, 5.38475466e-02,
        1.86704385e-01, 7.56255006e-02, 2.96004094e-02, 9.89903797e-02,
        3.46892180e-01, 1.85833333e-01, 3.04603145e-01, 1.89790060e-01,
        1.81280489e-01, 3.41159730e-01,...
        1.31809145e-01, 2.67171717e-01, 1.28849094e-01, 3.71899330e-02,
        6.51299505e-02, 4.00037695e-02, 2.32499935e-02, 1.06197097e-01,
        5.24679304e-02, 2.32651515e-02, 2.03826482e-01, 5.38639050e-02,
        4.17754930e-02, 2.48310210e-01, 1.94296375e-01, 2.29692714e-01,
        1.23795714e-01, 2.12837615e-01, 8.17144551e-02, 5.35042735e-02,
        2.82336770e-01, 1.35661677e-01, 1.28901240e-01]]),
       n_clusters=9))
Best evaluation: 0.419824190766292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        35
           1       0.95      0.95      0.95        22

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [21, 70, 70, 44, 92, 14, 69, 22, 110]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.33298537e-04, 7.25794603e-02, 1.40344944e-01, 8.02390098e-02,
        3.88312023e-02, 2.21901237e-01, 2.08974910e-01, 1.40299906e-01,
        1.08349901e-01, 6.93932828e-01, 4.14279697e-01, 1.08021003e-01,
        4.20968883e-01, 8.72166989e-02, 3.12253688e-02, 2.38807492e-01,
        2.78847598e-01, 1.41935484e-01, 3.81418093e-01, 4.66511072e-01,
        2.24318467e-01, 4.86806520e-02,...
        1.53330020e-01, 3.79739978e-01, 2.38837405e-01, 4.32735832e-02,
        1.42503536e-01, 4.68830985e-02, 2.43332997e-02, 8.07356291e-02,
        7.12590501e-02, 5.91178407e-02, 1.68215159e-01, 5.31760096e-02,
        2.59592446e-02, 3.00124260e-01, 6.29530917e-01, 2.98459661e-01,
        1.55096268e-01, 5.01419798e-01, 2.53330229e-01, 3.03194888e-01,
        4.56701031e-01, 3.75394322e-01, 1.56215116e-01]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.94      0.96        36
           1       0.91      0.95      0.93        21

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.40962345e-02, 2.14823229e-01, 3.05715252e-01, 2.04201506e-01,
        1.12619300e-01, 3.84670940e-01, 1.08428931e-01, 7.39045764e-02,
        1.19079979e-01, 4.34343434e-01, 1.91870261e-01, 7.72768423e-02,
        1.32359441e-01, 6.65579058e-02, 3.11319803e-02, 2.24869973e-01,
        4.85925436e-02, 3.40656566e-02, 1.64235651e-01, 3.41897901e-01,
        5.15180410e-02, 1.74670936e-01,...
        8.46837428e-01, 5.75757576e-01, 2.59688290e-01, 1.60202788e-01,
        2.65160891e-01, 1.83680205e-01, 1.42619136e-01, 2.58829928e-01,
        3.67696098e-01, 2.26212121e-01, 4.66944497e-01, 1.95137052e-01,
        1.48563492e-01, 6.11526147e-01, 5.50639659e-01, 6.30459684e-01,
        4.42587495e-01, 5.44343921e-01, 3.77807531e-01, 6.30351438e-01,
        9.41439890e-01, 3.21900256e-01, 2.13695396e-01]]),
       n_clusters=10))
Best evaluation: 0.38179314101361866
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [111, 17, 69, 33, 45, 90, 67, 51, 14, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.49095545e-04, 9.90214785e-01, 5.04564315e-01, 9.66459367e-01,
        8.93531283e-01, 5.12503385e-01, 5.27636341e-01, 6.72680412e-01,
        9.33399602e-01, 3.73737374e-01, 1.63016007e-01, 2.96678451e-01,
        2.47701556e-01, 2.82959817e-01, 2.27677354e-01, 1.34986353e-01,
        1.73626341e-01, 7.85101010e-02, 2.35082402e-01, 1.10710868e-01,
        6.39898843e-02, 8.96122376e-01,...
        3.24403579e-01, 4.07575758e-01, 1.22999158e-01, 1.25750226e-01,
        8.35617044e-02, 1.15240597e-01, 7.21295186e-02, 1.28602489e-01,
        7.36623907e-02, 5.17171717e-02, 1.87061944e-01, 5.00647267e-02,
        2.34995785e-02, 4.85592316e-01, 4.61353945e-01, 4.48677723e-01,
        3.07412505e-01, 5.58872086e-01, 2.22574730e-01, 3.10623003e-01,
        6.81786942e-01, 3.25448453e-01, 1.35510954e-01]]),
       n_clusters=4))
Best evaluation: 0.4397543764209014
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 319, 76, 92]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      0.94      0.94        36
           1       0.90      0.90      0.90        21

    accuracy                           0.93        57
   macro avg       0.92      0.92      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       1.00      1.00      1.00        21

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.94      0.96        36
           1       0.90      0.95      0.93        20

    accuracy                           0.95        56
   macro avg       0.94      0.95      0.94        56
weighted avg       0.95      0.95      0.95        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.963063909774436
F1: 0.9501448730887189
======================================================
Running wdbc 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.46414794e-04, 1.85479672e-01, 1.09908691e-01, 1.72068274e-01,
        9.47189820e-02, 2.03304144e-01, 5.45978774e-02, 7.23992502e-03,
        3.27435388e-02, 1.92929293e-01, 1.63136056e-01, 6.16693826e-02,
        8.86669024e-02, 4.95217453e-02, 2.19238772e-02, 1.50559200e-01,
        2.91555262e-02, 4.63383838e-03, 6.77401023e-02, 1.19434907e-01,
        6.11569448e-02, 1.57595162e-01,...
        8.83200795e-02, 2.30303030e-01, 1.88469098e-01, 2.53847547e-02,
        8.95951202e-02, 2.57268058e-02, 1.13709801e-02, 1.69833770e-01,
        1.10839066e-01, 5.25252525e-02, 1.42015533e-01, 1.87960826e-01,
        6.47153932e-02, 1.72180719e-01, 3.19829424e-01, 1.60715175e-01,
        7.61649626e-02, 4.16231922e-01, 1.68579304e-01, 1.58974359e-01,
        2.84810997e-01, 3.90829176e-01, 2.52137666e-01]]),
       n_clusters=10))
Best evaluation: 0.4018624622313368
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.94      0.96        36
           1       0.91      0.95      0.93        21

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [66, 52, 80, 93, 55, 6, 28, 110, 16, 6]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00999092, 0.09682159, 0.28373351, 0.09346991, 0.04972968,
        0.27516476, 0.10704865, 0.03465323, 0.02867296, 0.33586132,
        0.29823083, 0.08332428, 0.21035184, 0.07152617, 0.02648123,
        0.31502193, 0.07749271, 0.0339368 , 0.09618582, 0.25055107,
        0.09488646, 0.09034427, 0.3358209 , 0.08448986, 0.0388547 ,
        0.44660899, 0.09528383, 0.0511901 , 0.08591065, 0.29396688,
        0.15...
       [0.00100154, 0.33199471, 0.51673994, 0.34066012, 0.20852999,
        0.32265054, 0.31783326, 0.2364105 , 0.19333996, 0.43986999,
        0.28327717, 0.05167481, 0.15885785, 0.08754653, 0.03045958,
        0.18441717, 0.33254724, 0.12603687, 0.28410758, 0.1605077 ,
        0.23747564, 0.27563775, 0.52531983, 0.29998475, 0.14522132,
        0.41491118, 0.38120325, 0.32268371, 0.41408935, 0.31959779,
        0.30921269]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.94      0.93        34
           1       0.91      0.87      0.89        23

    accuracy                           0.91        57
   macro avg       0.91      0.91      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [325, 105, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.90397745e-05, 3.52075347e-01, 2.13148789e-01, 3.48006358e-01,
        2.11113468e-01, 4.05163853e-01, 3.06774307e-01, 1.87605436e-01,
        2.09890656e-01, 4.30303030e-01, 2.98230834e-01, 8.60401955e-02,
        1.16069913e-01, 9.04678886e-02, 4.73255410e-02, 6.71046622e-02,
        2.07858718e-01, 9.69696970e-02, 2.35461262e-01, 2.02471164e-01,
        8.56169589e-02, 3.10921380e-01,...
        7.31113320e-01, 6.86363636e-01, 6.05518113e-01, 3.56147022e-01,
        1.54165960e-01, 3.69033596e-01, 2.73811258e-01, 1.31117591e-01,
        3.47675016e-01, 1.35681818e-01, 3.00625118e-01, 4.13378626e-01,
        1.83042439e-01, 6.20775525e-01, 1.30634278e-01, 6.68310175e-01,
        4.50697994e-01, 5.63930402e-01, 6.13296148e-01, 5.68610224e-01,
        9.12027491e-01, 5.98462448e-01, 4.18863964e-01]]),
       n_clusters=5))
Best evaluation: 0.4040677683021954
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.95      0.96        37
           1       0.90      0.95      0.93        20

    accuracy                           0.95        57
   macro avg       0.94      0.95      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [73, 88, 191, 129, 31]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.50378739e-05, 3.44502816e-01, 3.36151505e-01, 3.73436528e-01,
        2.06320255e-01, 2.32373386e-01, 6.25483099e-01, 7.31012658e-01,
        4.07631992e-01, 3.25252525e-01, 5.84035383e-01, 9.10012674e-02,
        2.49690594e-01, 1.23893138e-01, 4.19276874e-02, 1.21868307e-01,
        5.42313816e-01, 3.62373737e-01, 4.34173139e-01, 2.50154781e-01,
        4.17520003e-01, 2.62184276e-01,...
        4.94040774e-01, 4.04040404e-01, 1.99031171e-01, 1.56943690e-01,
        1.24270686e-01, 1.15358864e-01, 1.13108379e-01, 1.51714995e-01,
        1.24057440e-01, 7.35606061e-02, 1.98143588e-01, 1.08459504e-01,
        6.32298274e-02, 4.95553184e-01, 3.77931770e-01, 4.57144280e-01,
        3.21421549e-01, 5.15287592e-01, 2.19567095e-01, 3.00239617e-01,
        5.20151567e-01, 2.97457126e-01, 1.54729109e-01]]),
       n_clusters=10))
Best evaluation: 0.3832771097403626
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [9, 62, 123, 19, 47, 94, 63, 33, 22, 40]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.97      0.97        36
           1       0.95      0.95      0.95        21

    accuracy                           0.96        57
   macro avg       0.96      0.96      0.96        57
weighted avg       0.96      0.96      0.96        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.38094571118213677
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.98        20

    accuracy                           0.98        57
   macro avg       0.98      0.99      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.94      0.93        35
           1       0.90      0.86      0.88        22

    accuracy                           0.91        57
   macro avg       0.91      0.90      0.91        57
weighted avg       0.91      0.91      0.91        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.95      0.97        38
           1       0.90      1.00      0.95        19

    accuracy                           0.96        57
   macro avg       0.95      0.97      0.96        57
weighted avg       0.97      0.96      0.97        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.09780948, 0.35160206, 0.33885695, 0.36099786, 0.21545319,
        0.37949386, 0.45463468, 0.31911903, 0.32813121, 0.33030303,
        0.46251053, 0.27868912, 0.31157178, 0.16976865, 0.13552095,
        0.2056294 , 0.78219725, 0.25151515, 0.52491002, 0.46276805,
        0.75885466, 0.31111111, 0.26945629, 0.2867125 , 0.17928422,
        0.18926237, 0.21335778, 0.17731629, 0.35085911, 0.13936527,
        0....
       [0.00096401, 0.41076246, 0.45620561, 0.45891784, 0.26745914,
        0.63288802, 0.89571192, 0.74414246, 0.68439364, 0.72474747,
        0.65459141, 0.42748506, 0.46273868, 0.44117231, 0.25385217,
        0.36193358, 0.43333734, 0.20787879, 0.57283576, 0.21793212,
        0.17782568, 0.47301587, 0.52292111, 0.52149366, 0.32056178,
        0.52321205, 0.47531313, 0.4936901 , 0.84604811, 0.3374729 ,
        0.30735931]]),
       n_clusters=5))
Best evaluation: 0.40616066936616435
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.94      1.00      0.97        34
           1       1.00      0.91      0.95        23

    accuracy                           0.96        57
   macro avg       0.97      0.96      0.96        57
weighted avg       0.97      0.96      0.96        57

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [15, 317, 72, 73, 35]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        34
           1       1.00      0.95      0.98        22

    accuracy                           0.98        56
   macro avg       0.99      0.98      0.98        56
weighted avg       0.98      0.98      0.98        56

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9543546365914788
F1: 0.9391332947005097
======================================================
Running wdbc 50 2 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 meta_classifier crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand meta_classifier default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 meta_classifier default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.76351858e-04, 6.01022292e-01, 4.04802164e-01, 5.95052173e-01,
        4.45599152e-01, 4.09316602e-01, 3.51266793e-01, 4.36504217e-01,
        5.48210736e-01, 5.16161616e-01, 1.57021184e-01, 1.85080572e-01,
        4.25167963e-01, 2.08076144e-01, 1.13668710e-01, 1.03443587e-01,
        2.36038093e-01, 1.09722222e-01, 3.42110248e-01, 4.17600045e-01,
        8.26803753e-02, 5.27214514e-01,...
        1.53479125e-01, 3.62626263e-01, 2.70583097e-01, 3.72261452e-02,
        9.08327440e-02, 4.39146209e-02, 1.83751153e-02, 1.22752150e-01,
        1.00474660e-01, 3.81313131e-02, 1.43663573e-01, 1.85146620e-01,
        3.42785678e-02, 2.33013163e-01, 2.61194030e-01, 2.32880124e-01,
        1.12711365e-01, 3.96420788e-01, 2.49843511e-01, 1.78632479e-01,
        3.47766323e-01, 4.71370872e-01, 2.79392903e-01]]),
       n_clusters=9))
Best evaluation: 0.703674178550799
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.05      1.00      0.09         1

    accuracy                           0.63        57
   macro avg       0.52      0.81      0.43        57
weighted avg       0.98      0.63      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [43, 74, 111, 47, 58, 17, 60, 16, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.81377580e-04, 1.75277927e-01, 1.95806561e-01, 1.81106843e-01,
        9.50828113e-02, 2.80039722e-01, 2.82252623e-01, 2.35941893e-01,
        1.37027833e-01, 4.06283857e-01, 4.75147430e-01, 7.93047257e-02,
        1.56205799e-01, 8.53790699e-02, 3.01980956e-02, 2.94625557e-01,
        4.83957701e-01, 3.11784068e-01, 5.00488998e-01, 3.81927936e-02,
        5.20605321e-01, 1.22871135e-01,...
        4.34592445e-01, 4.78331528e-01, 2.39258635e-01, 2.56237552e-01,
        3.47153465e-01, 1.76035433e-01, 1.81356673e-01, 2.16235510e-01,
        2.90113257e-01, 1.75148124e-01, 4.48410758e-01, 2.05889556e-01,
        1.64815253e-01, 5.11000658e-01, 5.03997868e-01, 4.61644045e-01,
        3.42248908e-01, 4.47929737e-01, 3.09505098e-01, 3.12460064e-01,
        5.86941581e-01, 2.84108833e-01, 1.83400092e-01]]),
       n_clusters=10))
Best evaluation: 0.817660228408213
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        55
           1       0.09      1.00      0.17         2

    accuracy                           0.65        57
   macro avg       0.55      0.82      0.47        57
weighted avg       0.97      0.65      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [13, 12, 128, 101, 28, 49, 11, 62, 67, 41]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.69      0.80        51
           1       0.24      0.83      0.37         6

    accuracy                           0.70        57
   macro avg       0.61      0.76      0.59        57
weighted avg       0.89      0.70      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00093834, 0.13232997, 0.24619547, 0.12929307, 0.06222694,
        0.46104541, 0.19833139, 0.10550146, 0.09294302, 0.26464646,
        0.43576243, 0.10555857, 0.23510431, 0.09315089, 0.03001132,
        0.41258456, 0.20329258, 0.06873737, 0.1937867 , 0.35076265,
        0.12932023, 0.11099253, 0.25186567, 0.10593157, 0.04468148,
        0.49877831, 0.14476429, 0.10383387, 0.18374096, 0.19081411,
        0...
       [0.00091675, 0.5333428 , 0.34731146, 0.52387534, 0.38027572,
        0.37916403, 0.27489111, 0.27434275, 0.38682697, 0.37070707,
        0.15711879, 0.12138331, 0.09127475, 0.11356714, 0.08798688,
        0.08841826, 0.08688076, 0.05691919, 0.19681758, 0.08172455,
        0.0443666 , 0.5318392 , 0.41684435, 0.51192788, 0.34919387,
        0.48226904, 0.22344791, 0.30223642, 0.66551843, 0.29528878,
        0.18785255]]),
       n_clusters=9))
Best evaluation: 0.619888673203349
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), KNeighborsClassifier(n_neighbors=7), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [79, 14, 129, 26, 46, 109, 16, 25, 68]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00093666, 0.13280326, 0.34595874, 0.12659802, 0.0640509 ,
        0.44930938, 0.10315318, 0.01600047, 0.03944831, 0.14646465,
        0.3989048 , 0.08093427, 0.37164209, 0.0647882 , 0.02474421,
        0.32012102, 0.12585919, 0.01340404, 0.09945065, 0.1425114 ,
        0.16274414, 0.10636784, 0.38033049, 0.09163803, 0.04446028,
        0.41044624, 0.06543063, 0.01636581, 0.08182131, 0.07273802,
        0.22...
       [0.00097575, 0.1452506 , 0.26445722, 0.14249188, 0.07096501,
        0.43396226, 0.16526593, 0.05883318, 0.08822068, 0.41919192,
        0.28117102, 0.05446315, 0.36545137, 0.04810818, 0.01876735,
        0.20702315, 0.12443568, 0.04267677, 0.1523584 , 0.18458378,
        0.06268076, 0.11490573, 0.39498934, 0.10742567, 0.04885961,
        0.46885825, 0.10954585, 0.08426518, 0.22333333, 0.26197516,
        0.14167651]]),
       n_clusters=9))
Best evaluation: 0.6231207604850517
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [52, 25, 105, 73, 36, 62, 59, 14, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.80717345e-02, 2.82743774e-01, 1.51867220e-01, 2.69023828e-01,
        1.52958643e-01, 3.18768620e-01, 1.84344519e-01, 9.49390815e-02,
        1.26640159e-01, 2.73232323e-01, 2.40943555e-01, 8.71906602e-02,
        6.61244696e-02, 8.88056782e-02, 3.43258660e-02, 2.21168525e-01,
        1.90975456e-01, 7.92171717e-02, 2.02500474e-01, 1.32661676e-01,
        1.20821414e-01, 2.22696549e-01,...
        7.97216700e-01, 9.32323232e-01, 6.62594777e-01, 3.35977966e-01,
        3.36987270e-01, 4.41066339e-01, 2.04703790e-01, 4.00934450e-01,
        4.96425031e-01, 2.75505051e-01, 4.91191514e-01, 1.00000000e+00,
        1.75925542e-01, 5.49270722e-01, 5.25053305e-01, 5.97091489e-01,
        3.53372002e-01, 6.12362148e-01, 5.71557470e-01, 6.13498403e-01,
        8.61855670e-01, 7.63847822e-01, 2.92535747e-01]]),
       n_clusters=10))
Best evaluation: 0.6490035560587941
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        54
           1       0.14      1.00      0.25         3

    accuracy                           0.68        57
   macro avg       0.57      0.83      0.53        57
weighted avg       0.95      0.68      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [92, 32, 75, 73, 61, 28, 61, 13, 65, 12]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.55090539e-03, 3.78105921e-01, 3.39871491e-01, 3.57335360e-01,
        2.31898197e-01, 2.85095242e-01, 1.04717502e-01, 4.56185567e-02,
        9.63717694e-02, 2.29797980e-01, 5.68660489e-02, 2.62538475e-02,
        1.55763791e-01, 2.49257881e-02, 1.83751153e-02, 6.53023762e-02,
        4.30423288e-02, 2.08787879e-02, 1.21841258e-01, 1.59818765e-01,
        2.15994362e-02, 2.86374956e-01,...
        6.77932406e-02, 4.93434343e-01, 5.80244313e-01, 3.91453920e-02,
        2.47259547e-01, 3.24176601e-02, 9.20436759e-03, 4.67654757e-01,
        4.68035569e-01, 2.33636364e-01, 2.58382269e-01, 1.85287330e-01,
        2.29958681e-01, 2.66097474e-02, 5.29584222e-01, 2.03197370e-02,
        9.43767204e-03, 5.83966189e-01, 2.70793919e-01, 2.71006390e-01,
        1.71821306e-01, 2.41474473e-01, 3.38187065e-01]]),
       n_clusters=10))
Best evaluation: 0.7234676676294056
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [71, 63, 99, 85, 2, 50, 30, 14, 82, 16]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.94690257e-04, 7.62411851e-01, 3.42238755e-01, 7.48462442e-01,
        6.53152197e-01, 4.43032475e-01, 3.31636096e-01, 3.92689784e-01,
        4.98508946e-01, 2.24747475e-01, 1.02780118e-01, 4.27122940e-01,
        8.50866337e-02, 4.18319747e-01, 3.34230278e-01, 1.37335554e-01,
        2.35136840e-01, 1.00404040e-01, 4.08410684e-01, 1.98795520e-01,
        6.91720907e-02, 9.07142857e-01,...
        4.35364042e-01, 5.52514391e-01, 3.04950617e-01, 3.23102156e-01,
        4.26988072e-01, 3.61616162e-01, 1.37110362e-01, 1.75411914e-01,
        6.05551627e-02, 1.43240824e-01, 1.23743731e-01, 9.98062345e-02,
        1.18274401e-01, 6.94191919e-02, 2.40007577e-01, 8.11617043e-02,
        5.71839200e-02, 7.05158730e-01, 3.34488273e-01, 6.29940187e-01,
        5.50326475e-01, 5.18589447e-01, 2.80204907e-01, 3.44808307e-01,
        6.86941581e-01, 3.57579342e-01, 2.26026499e-01]])))
Best evaluation: 0.6663837155704995
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        55
           1       0.10      1.00      0.17         2

    accuracy                           0.67        57
   macro avg       0.55      0.83      0.48        57
weighted avg       0.97      0.67      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [16, 117, 63, 61, 18, 159, 2, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6499323509896758
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        52
           1       0.19      1.00      0.32         4

    accuracy                           0.70        56
   macro avg       0.60      0.84      0.56        56
weighted avg       0.94      0.70      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [86, 75, 125, 34, 193]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6591165413533834
F1: 0.16179066022544283
======================================================
Running wdbc 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00098706, 0.62468645, 0.33243152, 0.62200263, 0.46935313,
        0.54771147, 0.39727624, 0.4997657 , 0.62574553, 0.33535354,
        0.23083643, 0.11645845, 0.14161952, 0.10606418, 0.08533465,
        0.25067138, 0.18699492, 0.14005051, 0.36181095, 0.2339731 ,
        0.10745132, 0.50160085, 0.3478145 , 0.47606953, 0.31798073,
        0.6295318 , 0.29311121, 0.45367521, 0.7467354 , 0.34853885,
        0.274...
       [0.00093132, 0.53192295, 0.30402435, 0.5287126 , 0.37730647,
        0.56125305, 0.39604932, 0.41518276, 0.52683897, 0.52121212,
        0.28696222, 0.26152453, 0.27245403, 0.19412901, 0.17184973,
        0.07431077, 0.2054706 , 0.07113636, 0.17469218, 0.26535149,
        0.14617968, 0.45072928, 0.32276119, 0.42178395, 0.27914864,
        0.37528891, 0.22227957, 0.22418803, 0.45532646, 0.3459254 ,
        0.26539119]]),
       n_clusters=4))
Best evaluation: 0.4058982201620478
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.67      0.77        48
           1       0.27      0.67      0.39         9

    accuracy                           0.67        57
   macro avg       0.59      0.67      0.58        57
weighted avg       0.81      0.67      0.71        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [52, 280, 103, 77]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.09807173, 0.24824918, 0.1237741 , 0.24448712, 0.14318201,
        0.31876862, 0.18434452, 0.09493908, 0.12664016, 0.29306609,
        0.24094356, 0.07785624, 0.06612447, 0.0748716 , 0.03432587,
        0.16252507, 0.19097546, 0.10325872, 0.26136919, 0.11195632,
        0.15921549, 0.20144726, 0.11673774, 0.19089014, 0.09805478,
        0.318497  , 0.18774437, 0.14129393, 0.2890378 , 0.19676656,
        0.179...
       [0.00099115, 0.41916842, 0.33141698, 0.44017641, 0.2769244 ,
        0.45111492, 0.52119502, 0.52389878, 0.45695825, 0.59100758,
        0.33319292, 0.0735832 , 0.13823815, 0.10898553, 0.04915596,
        0.25441071, 0.39390753, 0.26593153, 0.54156479, 0.26207662,
        0.24858412, 0.31839778, 0.29397655, 0.34370393, 0.17767467,
        0.43934491, 0.40642858, 0.47100639, 0.60996564, 0.34542587,
        0.23737606]]),
       n_clusters=4))
Best evaluation: 0.44319207847033537
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.74      0.85        47
           1       0.45      1.00      0.62        10

    accuracy                           0.79        57
   macro avg       0.73      0.87      0.74        57
weighted avg       0.90      0.79      0.81        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [316, 89, 32, 75]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.82        52
           1       0.24      1.00      0.38         5

    accuracy                           0.72        57
   macro avg       0.62      0.85      0.60        57
weighted avg       0.93      0.72      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.80149018e-05, 5.87770363e-01, 2.86438958e-01, 5.76394168e-01,
        4.24814422e-01, 4.61045409e-01, 3.82859947e-01, 3.95813048e-01,
        4.94720335e-01, 4.20707071e-01, 1.88711036e-01, 1.30146659e-01,
        1.40315594e-01, 1.00506398e-01, 8.65860537e-02, 1.33970153e-01,
        1.48241055e-01, 7.72474747e-02, 2.83955295e-01, 1.17464963e-01,
        3.69733151e-02, 5.64212024e-01,...
        5.49921589e-01, 7.76262626e-01, 1.00000000e+00, 1.39091074e-01,
        1.75875177e-01, 1.26062069e-01, 3.81547933e-02, 2.51453241e-01,
        5.43215069e-01, 1.42954545e-01, 3.53665467e-01, 7.28147690e-01,
        2.87204787e-01, 2.48310210e-01, 3.85927505e-01, 2.41346681e-01,
        9.40080613e-02, 9.15472496e-01, 8.14011701e-01, 5.48642173e-01,
        8.87013434e-01, 1.00000000e+00, 7.73711137e-01]]),
       n_clusters=3))
Best evaluation: 0.3795983221278526
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.80      0.88        44
           1       0.57      0.92      0.71        13

    accuracy                           0.82        57
   macro avg       0.77      0.86      0.79        57
weighted avg       0.88      0.82      0.84        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [105, 325, 82]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.71      0.82        49
           1       0.33      0.88      0.48         8

    accuracy                           0.74        57
   macro avg       0.65      0.79      0.65        57
weighted avg       0.88      0.74      0.78        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.50839386e-05, 6.49689319e-01, 5.52697095e-01, 6.19174062e-01,
        4.75291622e-01, 3.44407331e-01, 3.43291823e-01, 3.43252109e-01,
        4.31560636e-01, 5.22727273e-01, 1.37531592e-01, 2.64408452e-01,
        2.53889675e-01, 2.12205891e-01, 1.51416330e-01, 1.99056298e-01,
        2.44599994e-01, 1.06868687e-01, 2.40386437e-01, 2.62959419e-01,
        1.21477827e-01, 5.79509072e-01,...
        5.96918489e-02, 5.84343434e-01, 3.12763269e-01, 9.89065198e-02,
        2.59414781e-01, 8.63466160e-02, 3.04969387e-02, 2.72100662e-01,
        1.49743143e-01, 7.27272727e-02, 1.63174844e-01, 2.70417065e-01,
        8.83117063e-02, 1.28424048e-01, 3.00906183e-01, 1.18581603e-01,
        5.34801416e-02, 3.35006274e-01, 1.17695569e-01, 6.37939297e-02,
        1.10068729e-01, 2.48570865e-01, 1.34330316e-01]]),
       n_clusters=7))
Best evaluation: 0.38167641594254925
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.64      0.77        55
           1       0.05      0.50      0.09         2

    accuracy                           0.63        57
   macro avg       0.51      0.57      0.43        57
weighted avg       0.94      0.63      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [70, 125, 20, 44, 93, 63, 97]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.45452146e-05, 2.92914951e-01, 3.02671627e-01, 2.91548614e-01,
        1.65896076e-01, 5.70280762e-01, 3.18139991e-01, 2.87253983e-01,
        3.64811133e-01, 5.39393939e-01, 3.75105307e-01, 6.35886294e-02,
        1.17905764e-01, 5.37153089e-02, 3.25888405e-02, 1.63816841e-01,
        1.58530357e-01, 7.33585859e-02, 2.30157227e-01, 1.34350200e-01,
        9.49449304e-02, 2.75346852e-01,...
        4.37127237e-01, 5.41414141e-01, 2.16090986e-01, 2.13000181e-01,
        2.46375530e-01, 1.89652735e-01, 1.37837646e-01, 1.61743210e-01,
        1.06933638e-01, 7.08585859e-02, 2.68990339e-01, 2.22575561e-01,
        9.88143112e-02, 5.33617930e-01, 4.17377399e-01, 5.06947557e-01,
        3.48456547e-01, 4.53212706e-01, 1.76198931e-01, 2.52156550e-01,
        5.64261168e-01, 4.19869899e-01, 2.01692247e-01]]),
       n_clusters=9))
Best evaluation: 0.40942628217441496
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.62      0.76        56
           1       0.00      0.00      0.00         1

    accuracy                           0.61        57
   macro avg       0.49      0.31      0.38        57
weighted avg       0.96      0.61      0.75        57

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [56, 83, 32, 65, 23, 82, 16, 110, 45]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.37329401267586876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        48
           1       0.43      1.00      0.60         9

    accuracy                           0.79        57
   macro avg       0.71      0.88      0.73        57
weighted avg       0.91      0.79      0.82        57

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 89, 97]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.69      0.81        51
           1       0.24      1.00      0.38         5

    accuracy                           0.71        56
   macro avg       0.62      0.84      0.60        56
weighted avg       0.93      0.71      0.78        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7100250626566417
F1: 0.365692503879428
======================================================
Running wdbc 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.71476468e-04, 2.15769795e-01, 3.41562394e-02, 2.06896552e-01,
        1.12661718e-01, 3.00984021e-01, 1.23642721e-01, 3.20290534e-02,
        4.42693837e-02, 3.90404040e-01, 2.41100677e-01, 7.13380409e-03,
        0.00000000e+00, 1.64915422e-02, 4.92344013e-03, 8.19594112e-02,
        8.37263797e-02, 2.53282828e-02, 8.84068952e-02, 1.75015478e-01,
        3.65241905e-02, 1.56883671e-01,...
        1.42992048e-01, 2.59090909e-01, 1.54400524e-01, 6.92739453e-02,
        6.80914074e-02, 4.02864816e-02, 3.19724766e-02, 1.37437536e-01,
        1.08135308e-01, 3.68939394e-02, 1.56866831e-01, 1.07333821e-01,
        4.39865677e-02, 2.98114550e-01, 2.27078891e-01, 2.58429205e-01,
        1.45571176e-01, 3.34345902e-01, 1.40246648e-01, 1.04273504e-01,
        2.73917526e-01, 2.28082680e-01, 1.41406584e-01]]),
       n_clusters=10))
Best evaluation: 0.4188226939981221
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.61      0.75        56
           1       0.00      0.00      0.00         1

    accuracy                           0.60        57
   macro avg       0.49      0.30      0.37        57
weighted avg       0.95      0.60      0.73        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [61, 49, 77, 67, 47, 13, 56, 17, 49, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.99531629e-04, 6.29756599e-01, 3.77071356e-01, 6.39351259e-01,
        4.88114649e-01, 4.69170353e-01, 4.73958653e-01, 4.88519213e-01,
        6.57057654e-01, 5.78006501e-01, 2.64321820e-01, 2.12601847e-01,
        1.39210573e-01, 1.86071715e-01, 1.51248230e-01, 9.73926641e-02,
        1.79559588e-01, 1.31830151e-01, 3.47432763e-01, 1.43219374e-01,
        8.16837543e-02, 5.70937797e-01,...
        3.05119284e-01, 4.69122427e-01, 2.07666386e-01, 3.30255296e-02,
        3.29473126e-01, 5.36210715e-02, 2.19238772e-02, 1.49573376e-01,
        1.77081143e-01, 1.52896643e-01, 3.11980440e-01, 7.16168907e-02,
        1.30260594e-01, 2.41649002e-01, 5.93017058e-01, 2.53215393e-01,
        1.25223303e-01, 4.41326025e-01, 2.38680133e-01, 3.38178914e-01,
        4.68041237e-01, 2.23186120e-01, 1.85829667e-01]]),
       n_clusters=10))
Best evaluation: 0.39862747069960647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.05      1.00      0.09         1

    accuracy                           0.63        57
   macro avg       0.52      0.81      0.43        57
weighted avg       0.98      0.63      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [25, 68, 83, 44, 29, 117, 2, 72, 14, 58]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.69      0.80        51
           1       0.24      0.83      0.37         6

    accuracy                           0.70        57
   macro avg       0.61      0.76      0.59        57
weighted avg       0.89      0.70      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3778423121743061
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        46
           1       0.52      1.00      0.69        11

    accuracy                           0.82        57
   macro avg       0.76      0.89      0.78        57
weighted avg       0.91      0.82      0.84        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [104, 322, 86]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.73      0.83        48
           1       0.38      0.89      0.53         9

    accuracy                           0.75        57
   macro avg       0.68      0.81      0.68        57
weighted avg       0.88      0.75      0.79        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[1.00182393e-03, 3.79617398e-01, 6.51867220e-01, 3.55740340e-01,
        2.22735949e-01, 2.71914778e-01, 1.61830563e-01, 9.61808810e-02,
        1.50447316e-01, 3.93939394e-01, 1.44060657e-01, 7.75713229e-02,
        2.26485149e-01, 7.93606438e-02, 3.84909917e-02, 1.41647777e-01,
        7.11088413e-02, 4.91666667e-02, 2.40386437e-01, 1.52220409e-01,
        5.98095712e-02, 3.05229456e-01,...
        8.56361829e-02, 1.47979798e-01, 2.01558551e-01, 2.99268273e-02,
        1.24469590e-01, 3.86743419e-02, 1.44714773e-02, 1.27862331e-01,
        7.14843633e-02, 2.72474747e-02, 1.50710362e-01, 7.55332921e-02,
        5.72184680e-02, 2.39772323e-01, 2.97707889e-01, 2.27451566e-01,
        1.15881832e-01, 2.49158027e-01, 1.27009537e-01, 8.38658147e-02,
        2.95051546e-01, 1.53952296e-01, 1.65354847e-01]]),
       n_clusters=10))
Best evaluation: 0.38477262497101705
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.64      0.78        56
           1       0.05      1.00      0.09         1

    accuracy                           0.65        57
   macro avg       0.52      0.82      0.44        57
weighted avg       0.98      0.65      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [69, 37, 69, 89, 55, 57, 8, 13, 17, 98]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00944037, 0.57357187, 0.56070342, 0.58952388, 0.41965612,
        0.74801781, 0.48990859, 0.45384255, 0.73011928, 0.28989899,
        0.46925021, 0.14756473, 0.56351662, 0.23766668, 0.11622635,
        0.19825271, 0.43746808, 0.05388889, 0.34911915, 0.31910283,
        0.32804057, 0.49206349, 0.55170576, 0.50807759, 0.34273746,
        0.44925048, 0.24682986, 0.1942492 , 0.63264605, 0.14705303,
        0...
       [0.00091639, 0.25883856, 0.20257017, 0.26798424, 0.14162598,
        0.81644401, 0.4619962 , 0.36972821, 0.40203777, 0.51868687,
        0.55117944, 0.08075321, 0.11713225, 0.06879329, 0.03929853,
        0.19706292, 0.23431069, 0.09272727, 0.2153817 , 0.19372995,
        0.14465956, 0.29920635, 0.31263326, 0.29621555, 0.17136873,
        0.71273856, 0.48278371, 0.42771565, 0.59828179, 0.47703528,
        0.454939  ]]),
       n_clusters=3))
Best evaluation: 0.3759870348601293
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.76      0.85        46
           1       0.48      0.91      0.62        11

    accuracy                           0.79        57
   macro avg       0.72      0.83      0.74        57
weighted avg       0.88      0.79      0.81        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [96, 330, 86]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.67      0.80        52
           1       0.19      1.00      0.32         4

    accuracy                           0.70        56
   macro avg       0.60      0.84      0.56        56
weighted avg       0.94      0.70      0.77        56

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6906954887218044
F1: 0.27140693163519247
======================================================
Running wdbc 50 2 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 weighted_membership crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand weighted_membership default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 weighted_membership default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.55757186e-01, 5.85924559e-02, 3.71660467e-01, 6.55103310e-02,
        2.56203606e-02, 3.73927959e-01, 3.40837985e-01, 3.09512652e-01,
        1.07753479e-01, 5.86868687e-01, 7.13037781e-01, 2.96940069e-02,
        3.54004597e-01, 2.28996843e-02, 6.36535811e-03, 3.64313152e-01,
        3.89851894e-01, 1.95782828e-01, 1.93597272e-01, 2.13992233e-01,
        3.76062352e-01, 4.13376023e-02,...
        1.26023330e-01, 5.26044958e-01, 4.05557941e-01, 2.85379569e-01,
        2.57554672e-01, 6.26767677e-01, 6.12142389e-01, 1.34347275e-01,
        1.48028642e-01, 1.28068605e-01, 6.38739779e-02, 1.30468777e-01,
        2.39492895e-01, 1.06186869e-01, 1.97764728e-01, 2.08926662e-01,
        1.64870168e-01, 3.16257560e-01, 4.29104478e-01, 3.43592808e-01,
        1.72901101e-01, 6.11041405e-01, 6.04221346e-01, 5.94529915e-01,
        5.31271478e-01, 7.59325255e-01, 9.10218042e-01]])))
Best evaluation: 0.6691047596877858
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [1, 90, 36, 139, 99, 19, 73, 55]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=7, random_state=42))
Best evaluation: 0.6174897203037595
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [54, 25, 120, 76, 92, 73, 72]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6513786804825331
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.69466438e-04, 1.67021629e-01, 4.52485627e-01, 1.59353189e-01,
        8.08907741e-02, 4.41184436e-01, 1.49039936e-01, 6.07351509e-02,
        9.80135912e-02, 3.20707071e-01, 3.28559393e-01, 6.34799928e-02,
        1.73002122e-01, 7.15558783e-02, 2.56967714e-02, 2.87486827e-01,
        9.14621324e-02, 4.69949495e-02, 2.36787270e-01, 3.76512636e-01,
        3.71806033e-02, 1.06723586e-01,...
        4.96497648e-01, 2.63636364e-01, 8.40353833e-02, 2.34184320e-01,
        1.45155587e-01, 2.40166725e-01, 1.97232713e-01, 1.62525071e-01,
        1.25259110e-01, 8.56313131e-02, 2.88122751e-01, 7.98953115e-02,
        3.80788525e-02, 6.89790110e-01, 5.02665245e-01, 6.79266896e-01,
        5.43845851e-01, 5.28495014e-01, 2.79137682e-01, 4.29073482e-01,
        8.22597313e-01, 2.37137788e-01, 1.38462548e-01]]),
       n_clusters=10))
Best evaluation: 0.6349089668892665
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [62, 25, 111, 60, 2, 40, 68, 53, 22, 69]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.46954675e-04, 1.93998769e-01, 1.69090294e-01, 1.82572041e-01,
        9.72216331e-02, 4.33059493e-01, 1.16710631e-01, 5.53655108e-02,
        1.28379722e-01, 2.55555556e-01, 3.52358888e-01, 3.46912910e-02,
        3.19020982e-01, 2.92135890e-02, 2.29324727e-02, 4.50317843e-01,
        1.92764469e-01, 3.66919192e-02, 2.99867399e-01, 3.22761299e-01,
        1.32195195e-01, 1.21664888e-01,...
        2.90208748e-01, 4.13636364e-01, 2.93597304e-01, 6.44577223e-02,
        3.29191448e-01, 7.62851623e-02, 3.74450409e-02, 2.13889928e-01,
        2.71464595e-01, 8.38636364e-02, 2.69748058e-01, 9.48106039e-02,
        1.20661409e-01, 2.98826041e-01, 5.02132196e-01, 2.94287564e-01,
        1.57589461e-01, 4.88555322e-01, 2.67107140e-01, 2.55111821e-01,
        5.37800687e-01, 2.27281687e-01, 2.52459662e-01]]),
       n_clusters=10))
Best evaluation: 0.6496841554376342
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [92, 40, 105, 10, 67, 72, 30, 7, 13, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0009443 , 0.2176721 , 0.3153527 , 0.20872056, 0.10795334,
        0.51069784, 0.23151954, 0.04758669, 0.09249503, 0.29545455,
        0.32982308, 0.06984297, 0.34207037, 0.06594758, 0.02722834,
        0.22903271, 0.11339262, 0.02924242, 0.18033719, 0.21019305,
        0.09090281, 0.17253646, 0.39285714, 0.16061557, 0.07810657,
        0.46311827, 0.14738384, 0.0615655 , 0.22      , 0.20086734,
        0.17001181...
       [0.00094802, 0.14301091, 0.34647303, 0.14541262, 0.06740191,
        0.40046944, 0.33746396, 0.30623243, 0.18469185, 0.30757576,
        0.65711879, 0.13018992, 0.42008487, 0.13273347, 0.03862174,
        0.51565897, 0.644606  , 0.30227273, 0.46599735, 0.43504812,
        0.58818733, 0.11846318, 0.32969083, 0.11285423, 0.05038341,
        0.38915671, 0.25973358, 0.2784345 , 0.34054983, 0.206781  ,
        0.4011544 ]]),
       n_clusters=10))
Best evaluation: 0.6392695774102121
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [80, 14, 34, 48, 15, 50, 71, 124, 61, 15]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.7477178239000553
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.6487881933326375
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0094391 , 0.52387714, 0.2177883 , 0.52802156, 0.3661643 ,
        0.58509829, 0.59879762, 0.3945642 , 0.53677932, 0.55151515,
        0.35320135, 0.31472026, 0.04205711, 0.26169722, 0.2467203 ,
        0.21168032, 0.42162105, 0.11762626, 0.39211972, 0.25367254,
        0.2127883 , 0.57380952, 0.18363539, 0.55726983, 0.43883208,
        0.5060424 , 0.5201366 , 0.30239617, 0.72233677, 0.43090873,
        0.365735...
       [0.00093371, 0.56599934, 0.39228948, 0.55151683, 0.41880705,
        0.40686434, 0.2561806 , 0.25304592, 0.39517893, 0.26363636,
        0.09793597, 0.24526525, 0.09664516, 0.22282429, 0.17202842,
        0.09283747, 0.10715895, 0.05729798, 0.25951885, 0.08411662,
        0.02774899, 0.6718254 , 0.3880597 , 0.64559226, 0.51767895,
        0.31783662, 0.20016299, 0.21461661, 0.61477663, 0.19436231,
        0.07116621]]),
       n_clusters=6))
Best evaluation: 0.5774061581241082
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [23, 133, 82, 178, 20, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[8.61329758e-05, 4.01296796e-01, 7.37233683e-02, 4.05707968e-01,
        2.51707317e-01, 6.26325701e-01, 4.17520398e-01, 4.76101218e-01,
        5.45228628e-01, 4.26588361e-01, 4.36604886e-01, 1.12040558e-01,
        6.58813649e-02, 9.64990812e-02, 7.06726585e-02, 1.25097733e-01,
        1.57403791e-01, 1.08661616e-01, 2.50047357e-01, 1.41245005e-01,
        1.13082653e-01, 3.86339381e-01,...
        3.90506958e-01, 7.37319808e-01, 9.05644482e-01, 2.58193011e-01,
        5.09149576e-01, 1.56245583e-01, 8.04037370e-02, 3.14681987e-01,
        7.03037222e-01, 1.00000000e+00, 1.00000000e+00, 3.88050881e-01,
        1.00000000e+00, 1.09925293e-01, 1.99093817e-01, 1.02744161e-01,
        4.79994101e-02, 3.83213366e-01, 2.42463933e-01, 6.56230032e-01,
        5.39862543e-01, 3.04159275e-01, 4.64777647e-01]]),
       n_clusters=7))
Best evaluation: 0.7464621741233566
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [86, 103, 29, 79, 169, 45, 2]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6274122807017544
F1: 0.0
======================================================
Running wdbc 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.0009884 , 0.30995641, 0.20121745, 0.29641485, 0.1871192 ,
        0.24401914, 0.11174161, 0.04889878, 0.13180915, 0.28656555,
        0.12426285, 0.03718993, 0.06512995, 0.04000377, 0.02324999,
        0.1061971 , 0.05246793, 0.03032587, 0.26308068, 0.03127746,
        0.05505072, 0.22776113, 0.19429638, 0.21371562, 0.1154476 ,
        0.21283761, 0.07219295, 0.05      , 0.28233677, 0.1123817 ,
        0.07807473]...
       [0.00096208, 0.58959792, 0.34190057, 0.58884621, 0.44434909,
        0.4836147 , 0.50769891, 0.5663074 , 0.48409543, 0.36457205,
        0.35825611, 0.23704508, 0.09277758, 0.15822457, 0.16064311,
        0.23010504, 0.36288942, 0.22383147, 0.48190709, 0.073922  ,
        0.28974013, 0.60675389, 0.36167377, 0.53535662, 0.42412664,
        0.6592485 , 0.55128019, 0.67803514, 0.86151203, 0.23324132,
        0.48913258]]),
       n_clusters=3))
Best evaluation: 0.38199018353026415
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.93        40
           1       0.77      1.00      0.87        17

    accuracy                           0.91        57
   macro avg       0.89      0.94      0.90        57
weighted avg       0.93      0.91      0.91        57

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [325, 82, 105]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00097636, 0.24038052, 0.31078796, 0.22714394, 0.12801697,
        0.28193554, 0.11827495, 0.0182814 , 0.0443701 , 0.25      ,
        0.22156698, 0.04761905, 0.17499116, 0.03713588, 0.02095264,
        0.18584492, 0.06540091, 0.01472727, 0.10409168, 0.16797996,
        0.06423172, 0.20313056, 0.40085288, 0.17993924, 0.09275462,
        0.38123225, 0.10469482, 0.03599042, 0.1754392 , 0.25921545,
        0.1691591...
       [0.09289741, 0.31941881, 0.43625296, 0.34420565, 0.18443266,
        0.54590593, 0.64388688, 0.51801363, 0.41949817, 0.50959596,
        0.56571188, 0.03642948, 0.17874823, 0.06080552, 0.02317528,
        0.16031546, 0.42890618, 0.13891414, 0.30839174, 0.16502505,
        0.24868372, 0.25257915, 0.53278252, 0.29080133, 0.12595851,
        0.6202866 , 0.72300647, 0.55455272, 0.76059249, 0.40035482,
        0.57759412]]),
       n_clusters=4))
Best evaluation: 0.4379774175360944
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [316, 83, 37, 76]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.00091476, 0.52103744, 0.0226581 , 0.54598853, 0.36373277,
        0.59375282, 0.7920373 , 0.70313964, 0.73111332, 0.68636364,
        0.60551811, 0.35614702, 0.12009994, 0.3690336 , 0.27381126,
        0.15929565, 0.47573921, 0.13568182, 0.30062512, 0.31164518,
        0.18096267, 0.62077552, 0.14152452, 0.66831017, 0.45069799,
        0.61828432, 0.61929156, 0.56861022, 0.91202749, 0.59846245,
        0.4...
       [0.10092158, 0.3449761 , 0.43422388, 0.34538042, 0.20627784,
        0.46194818, 0.29452181, 0.34278351, 0.30511928, 0.43737374,
        0.20766639, 0.03302553, 0.32919145, 0.05362107, 0.02192388,
        0.14957338, 0.23974051, 0.11729798, 0.24171245, 0.09326279,
        0.09655476, 0.26182853, 0.59301706, 0.26838986, 0.13347916,
        0.45391564, 0.23868013, 0.33817891, 0.46804124, 0.22333925,
        0.1867375 ]]),
       n_clusters=4))
Best evaluation: 0.4435668639275939
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [26, 318, 94, 74]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.83172794e-04, 2.42135134e-01, 4.97925311e-02, 2.26049892e-01,
        1.26914104e-01, 3.25810237e-01, 1.01343476e-01, 6.10590440e-02,
        8.92644135e-02, 2.73232323e-01, 1.14785173e-01, 5.66472087e-02,
        1.51343706e-01, 4.98518974e-02, 2.26896626e-02, 2.06411620e-01,
        7.35121819e-02, 3.47474747e-02, 1.10475469e-01, 4.33106321e-02,
        3.32421265e-02, 2.08822483e-01,...
        4.68080594e-01, 4.99864584e-01, 5.04324888e-01, 5.34910965e-01,
        6.36182903e-01, 6.00505051e-01, 5.20850885e-01, 3.93652882e-01,
        3.05604668e-01, 3.93841167e-01, 2.31599670e-01, 2.89170560e-01,
        3.38480488e-01, 1.93156566e-01, 3.66736124e-01, 2.74075533e-01,
        1.73887208e-01, 5.60298826e-01, 4.64019190e-01, 5.39817720e-01,
        3.71313409e-01, 4.19533778e-01, 3.02519622e-01, 3.93929712e-01,
        6.60824742e-01, 3.40823970e-01, 2.60068215e-01]])))
Best evaluation: 0.4080419383598585
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [138, 9, 75, 18, 47, 95, 101, 29]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.95873167e-04, 2.06304132e-01, 3.00980724e-01, 2.00193490e-01,
        1.05068929e-01, 4.71878668e-01, 2.01245322e-01, 1.00796626e-01,
        1.28926441e-01, 4.37878788e-01, 2.51483051e-01, 4.76190476e-02,
        1.43608557e-01, 3.45851199e-02, 2.04907920e-02, 2.33334466e-01,
        1.06332803e-01, 5.30050505e-02, 2.09698807e-01, 2.31581021e-01,
        1.11313793e-02, 1.61508360e-01,...
        4.36530815e-01, 6.02020202e-01, 4.02542373e-01, 5.17834510e-02,
        1.37685644e-01, 6.37515903e-02, 2.58368662e-02, 9.31094265e-02,
        2.12530417e-01, 6.77020202e-02, 2.56109112e-01, 9.36849215e-02,
        9.72941973e-02, 3.44717182e-01, 6.34621144e-01, 3.58533792e-01,
        1.74916437e-01, 5.37079839e-01, 6.18030290e-01, 4.42412141e-01,
        9.28178694e-01, 5.32032328e-01, 4.75272203e-01]]),
       n_clusters=9))
Best evaluation: 0.47583904980513064
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [101, 87, 3, 56, 25, 15, 65, 123, 37]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.79407145e-02, 6.20426901e-01, 4.78525533e-01, 6.28221961e-01,
        4.68478030e-01, 6.01390247e-01, 5.04324888e-01, 5.34910965e-01,
        6.36182903e-01, 6.00505051e-01, 5.20850885e-01, 3.47818215e-01,
        3.05604668e-01, 3.32045422e-01, 2.39010174e-01, 2.12496176e-01,
        3.38480488e-01, 1.93156566e-01, 3.66736124e-01, 2.74075533e-01,
        1.73887208e-01, 6.25000000e-01,...
        4.24602386e-01, 4.89898990e-01, 6.83866891e-01, 6.73909107e-02,
        2.73780057e-01, 6.04061631e-02, 3.30340518e-02, 1.84791107e-01,
        5.25114910e-01, 1.95530303e-01, 2.71263497e-01, 1.40822874e-01,
        3.17330680e-01, 2.84126984e-01, 7.63859275e-01, 2.64072894e-01,
        1.62067266e-01, 7.53681569e-01, 1.00000000e+00, 8.82587859e-01,
        7.59450172e-01, 5.52138774e-01, 1.00000000e+00]]),
       n_clusters=9))
Best evaluation: 0.38533359935197536
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), KNeighborsClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [19, 101, 65, 54, 70, 13, 116, 67, 7]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.98904511e-03, 5.96762743e-01, 5.17078120e-01, 5.79849354e-01,
        4.44326617e-01, 4.03310536e-01, 2.43328630e-01, 3.87769447e-01,
        4.50447316e-01, 2.64815804e-01, 8.31929233e-02, 1.28879232e-01,
        2.24275106e-01, 1.01729256e-01, 9.22267173e-02, 3.46296359e-01,
        1.27962868e-01, 1.23914141e-01, 2.83955295e-01, 1.19997749e-01,
        3.15147244e-02, 4.80611882e-01,...
        4.00636267e-01, 4.35028249e-01, 5.19354641e-01, 5.43345829e-01,
        6.18290258e-01, 5.42445275e-01, 2.52948610e-01, 2.60438168e-01,
        2.44386492e-01, 2.26970739e-01, 1.83411219e-01, 1.54162559e-01,
        2.36488719e-01, 1.31212121e-01, 2.19359727e-01, 1.71497720e-01,
        1.26625485e-01, 5.41444326e-01, 5.86087420e-01, 5.48284277e-01,
        3.64923319e-01, 5.14627220e-01, 3.86539376e-01, 4.89856230e-01,
        6.35051546e-01, 3.70392273e-01, 2.80598190e-01]])))
Best evaluation: 0.46154135668464313
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [41, 107, 168, 15, 9, 84, 38, 51]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6572368421052632
F1: 0.08717948717948718
======================================================
Running wdbc 50 rand majority_voting crossval...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4009148599951627
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.61      0.76        57
           1       0.00      0.00      0.00         0

    accuracy                           0.61        57
   macro avg       0.50      0.31      0.38        57
weighted avg       1.00      0.61      0.76        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [129, 32, 190, 74, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=3, random_state=42))
Best evaluation: 0.3819003737158037
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.78      0.88        45
           1       0.55      1.00      0.71        12

    accuracy                           0.82        57
   macro avg       0.77      0.89      0.79        57
weighted avg       0.90      0.82      0.84        57

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [326, 82, 104]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.4038986315404423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [88, 31, 73, 190, 130]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[9.90882823e-04, 4.38686166e-01, 3.31416977e-01, 4.56153687e-01,
        2.85174973e-01, 4.51114923e-01, 5.21195019e-01, 5.44303797e-01,
        4.80606377e-01, 5.51010101e-01, 3.33192923e-01, 7.35831975e-02,
        1.38238154e-01, 1.08380563e-01, 4.91559550e-02, 2.54410715e-01,
        3.93907531e-01, 2.04015152e-01, 4.19587043e-01, 2.79281815e-01,
        1.88639222e-01, 3.36535041e-01,...
        8.16518557e-01, 5.56565657e-01, 3.39090143e-01, 1.85659967e-01,
        1.23917079e-01, 1.59680507e-01, 1.38566076e-01, 1.19046810e-01,
        2.62925466e-01, 1.19141414e-01, 2.43985603e-01, 1.76844712e-01,
        1.08245927e-01, 6.51013874e-01, 4.45628998e-01, 6.05558046e-01,
        4.65935902e-01, 5.21891303e-01, 5.28189306e-01, 5.63338658e-01,
        8.34309335e-01, 4.46087128e-01, 2.99488390e-01]]),
       n_clusters=10))
Best evaluation: 0.4802218881716285
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 160, 19, 60, 81, 5, 15, 15, 108, 14]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.4376641701748208
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 316, 73, 88]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.38094571118213677
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [20, 73, 67, 64, 14, 56, 47, 89, 51, 31]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=10, random_state=42))
Best evaluation: 0.4453196657351912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [32, 53, 66, 17, 16, 12, 65, 80, 62, 109]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=5, random_state=42))
Best evaluation: 0.40268846450182877
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.63      0.77        57
           1       0.00      0.00      0.00         0

    accuracy                           0.63        57
   macro avg       0.50      0.32      0.39        57
weighted avg       1.00      0.63      0.77        57

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [84, 136, 183, 33, 76]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.09271506, 0.25931185, 0.48461278, 0.27765877, 0.14111654,
        0.71652004, 0.67548003, 0.53256795, 0.42460239, 0.48989899,
        0.68386689, 0.06739091, 0.27378006, 0.06040616, 0.03303405,
        0.18479111, 0.52511491, 0.1955303 , 0.2712635 , 0.14082287,
        0.31733068, 0.28412698, 0.76385928, 0.26407289, 0.16206727,
        0.75368157, 1.        , 0.88258786, 0.75945017, 0.55213877,
        1.        ],
       [0.009...
       [0.09576638, 0.44862511, 0.35170781, 0.4526985 , 0.29267671,
        0.49614424, 0.41782713, 0.42010309, 0.44065606, 0.37070707,
        0.2794861 , 0.06959986, 0.20416372, 0.08127974, 0.04777968,
        0.16704627, 0.29056388, 0.13563131, 0.34343626, 0.12576687,
        0.12745464, 0.39126984, 0.43789979, 0.4085751 , 0.24516447,
        0.46443901, 0.42631778, 0.46821086, 0.69931271, 0.29351469,
        0.26334776]]),
       n_clusters=3))
Best evaluation: 0.37710158851848685
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.97      0.92      0.95        38
           1       0.86      0.95      0.90        19

    accuracy                           0.93        57
   macro avg       0.91      0.93      0.92        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [87, 327, 98]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.44110740058072867
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        56
           1       0.00      0.00      0.00         0

    accuracy                           0.62        56
   macro avg       0.50      0.31      0.38        56
weighted avg       1.00      0.62      0.77        56

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [318, 33, 75, 87]
Selected clustering_algorithm: kmeans
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6782894736842104
F1: 0.16058823529411764
======================================================
Running wdbc 50 2 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 3 majority_voting crossval
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 rand majority_voting default...
======================================================
python cbeg.py -d wdbc -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running wdbc 50 2 majority_voting default
======================================================
python cbeg.py -d wdbc -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       1.00      1.00      1.00        22

    accuracy                           1.00        57
   macro avg       1.00      1.00      1.00        57
weighted avg       1.00      1.00      1.00        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [340, 172]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.91      0.89      0.90        36
           1       0.82      0.86      0.84        21

    accuracy                           0.88        57
   macro avg       0.87      0.87      0.87        57
weighted avg       0.88      0.88      0.88        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      1.00      0.96        33
           1       1.00      0.88      0.93        24

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [339, 173]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.92      0.92        36
           1       0.86      0.86      0.86        21

    accuracy                           0.89        57
   macro avg       0.89      0.89      0.89        57
weighted avg       0.89      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 170]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.97      1.00      0.99        35
           1       1.00      0.95      0.98        22

    accuracy                           0.98        57
   macro avg       0.99      0.98      0.98        57
weighted avg       0.98      0.98      0.98        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [344, 168]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.94      0.91        34
           1       0.90      0.83      0.86        23

    accuracy                           0.89        57
   macro avg       0.90      0.88      0.89        57
weighted avg       0.90      0.89      0.89        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [343, 169]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      0.97      0.94        34
           1       0.95      0.87      0.91        23

    accuracy                           0.93        57
   macro avg       0.93      0.92      0.93        57
weighted avg       0.93      0.93      0.93        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [173, 339]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.92      1.00      0.96        33
           1       1.00      0.88      0.93        24

    accuracy                           0.95        57
   macro avg       0.96      0.94      0.94        57
weighted avg       0.95      0.95      0.95        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [170, 342]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.81      0.94      0.87        31
           1       0.90      0.73      0.81        26

    accuracy                           0.84        57
   macro avg       0.86      0.83      0.84        57
weighted avg       0.85      0.84      0.84        57

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [346, 166]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.89      0.97      0.93        32
           1       0.95      0.83      0.89        24

    accuracy                           0.91        56
   macro avg       0.92      0.90      0.91        56
weighted avg       0.91      0.91      0.91        56

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [342, 171]
Selected clustering_algorithm: kmeans++
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/wdbc/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9226503759398497
F1: 0.900788981209565
======================================================
Running wdbc 50 3 majority_voting default
======================================================
python cbeg.py -d wdbc -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5180056361878502
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [25, 45, 38, 27]
Selected clustering_algorithm: fcm
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5224329967946728
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      1.00      0.75         3
           1       1.00      0.83      0.91         6
           2       1.00      0.83      0.91         6

    accuracy                           0.87        15
   macro avg       0.87      0.89      0.86        15
weighted avg       0.92      0.87      0.88        15

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5198551780484884
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 32, 45, 29]
Selected clustering_algorithm: fcm
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5198074319598898
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       1.00      1.00      1.00         5
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 29, 36, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5220969719295161
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      0.80      0.80         5
           2       0.80      0.80      0.80         5

    accuracy                           0.87        15
   macro avg       0.87      0.87      0.87        15
weighted avg       0.87      0.87      0.87        15

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 28, 27, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73         6
           1       0.60      1.00      0.75         3
           2       0.60      0.50      0.55         6

    accuracy                           0.67        15
   macro avg       0.67      0.72      0.67        15
weighted avg       0.68      0.67      0.66        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9133333333333333
F1: 0.9127609427609427
======================================================
Running iris 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.75      0.67         4
           2       0.60      0.60      0.60         5

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.40      1.00      0.57         2
           2       1.00      0.71      0.83         7

    accuracy                           0.80        15
   macro avg       0.80      0.85      0.77        15
weighted avg       0.92      0.80      0.83        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7933333333333333
F1: 0.7446512746512746
======================================================
Running iris 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.75      0.67         4
           2       0.60      0.60      0.60         5

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.40      1.00      0.57         2
           2       1.00      0.71      0.83         7

    accuracy                           0.80        15
   macro avg       0.80      0.85      0.77        15
weighted avg       0.92      0.80      0.83        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7933333333333333
F1: 0.7446512746512746
======================================================
Running iris 100 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c meta_classifier -p crossval
Variation 24...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.40      0.40      0.40         5
           2       0.40      0.50      0.44         4

    accuracy                           0.60        15
   macro avg       0.60      0.58      0.58        15
weighted avg       0.64      0.60      0.62        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      0.67      0.73         6
           2       0.60      0.75      0.67         4

    accuracy                           0.80        15
   macro avg       0.80      0.81      0.80        15
weighted avg       0.81      0.80      0.80        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9
F1: 0.8974242424242425
======================================================
Running iris 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2210411650040133
======================================================
Running iris 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24608220211161388
======================================================
Running iris 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24608220211161388
======================================================
Running iris 100 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c weighted_membership -p crossval
Variation 24...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2486965811965812
======================================================
Running iris 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 100 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 100 -n 3 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/classifier_selection_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.17933006535947715
======================================================
Running iris 100 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 100 2 majority_voting default
======================================================
python cbeg.py -d iris -m 100 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 100 3 majority_voting default
======================================================
python cbeg.py -d iris -m 100 -n 3 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.40      0.33      0.36         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.76      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_100.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2399612370200606
======================================================
Running iris 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5180056361878502
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 38, 25, 27]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5224329967946728
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      1.00      0.75         3
           1       1.00      0.83      0.91         6
           2       1.00      0.83      0.91         6

    accuracy                           0.87        15
   macro avg       0.87      0.89      0.86        15
weighted avg       0.92      0.87      0.88        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      1.00      0.89         4
           1       1.00      0.83      0.91         6
           2       0.80      0.80      0.80         5

    accuracy                           0.87        15
   macro avg       0.87      0.88      0.87        15
weighted avg       0.88      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5198074319598898
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [36, 29, 25, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.522096971929516
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73         6
           1       0.80      0.67      0.73         6
           2       0.60      1.00      0.75         3

    accuracy                           0.73        15
   macro avg       0.73      0.78      0.73        15
weighted avg       0.76      0.73      0.73        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [28, 27, 45, 35]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.519222986167031
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      1.00      0.89         4
           1       1.00      1.00      1.00         5
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 36, 25]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5188027710784833
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 45, 26, 37]
Selected clustering_algorithm: fcm
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       1.00      1.00      1.00         5
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9199999999999999
F1: 0.9187542087542088
======================================================
Running iris 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.75      0.67         4
           2       0.60      0.60      0.60         5

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.40      1.00      0.57         2
           2       1.00      0.71      0.83         7

    accuracy                           0.80        15
   macro avg       0.80      0.85      0.77        15
weighted avg       0.92      0.80      0.83        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8133333333333332
F1: 0.7696632996632996
======================================================
Running iris 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.00      0.00      0.00         0
           2       1.00      0.83      0.91         6

    accuracy                           0.67        15
   macro avg       0.67      0.46      0.54        15
weighted avg       1.00      0.67      0.79        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      1.00      0.33         1
           2       1.00      1.00      1.00         5

    accuracy                           0.73        15
   macro avg       0.73      0.85      0.68        15
weighted avg       0.95      0.73      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.75      0.67         4
           2       0.60      0.60      0.60         5

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.40      1.00      0.57         2
           2       1.00      0.71      0.83         7

    accuracy                           0.80        15
   macro avg       0.80      0.85      0.77        15
weighted avg       0.92      0.80      0.83        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         5

    accuracy                           0.67        15
   macro avg       0.67      0.50      0.56        15
weighted avg       1.00      0.67      0.78        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8133333333333332
F1: 0.7696632996632996
======================================================
Running iris 75 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.40      1.00      0.57         2
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.46      0.38        15
weighted avg       0.92      0.47      0.56        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.22048094091437748
======================================================
Running iris 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24608220211161388
======================================================
Running iris 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24608220211161388
======================================================
Running iris 75 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 75 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 75 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 75 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 2 majority_voting default
======================================================
python cbeg.py -d iris -m 75 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 75 3 majority_voting default
======================================================
python cbeg.py -d iris -m 75 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.40      0.33      0.36         6
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.76      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_75.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.2399612370200606
======================================================
Running iris 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5180056361878502
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [38, 45, 25, 27]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5224329967946728
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      1.00      0.89         4
           1       1.00      0.83      0.91         6
           2       1.00      1.00      1.00         5

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [38, 25, 27, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5198551780484884
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [29, 29, 45, 32]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5198074319598898
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 25, 36, 45]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5220969719295161
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73         6
           1       0.80      0.67      0.73         6
           2       0.60      1.00      0.75         3

    accuracy                           0.73        15
   macro avg       0.73      0.78      0.73        15
weighted avg       0.76      0.73      0.73        15

Selected Base Classifiers: [GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [35, 27, 45, 28]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5199110934123669
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73         6
           1       0.60      1.00      0.75         3
           2       0.60      0.50      0.55         6

    accuracy                           0.67        15
   macro avg       0.67      0.72      0.67        15
weighted avg       0.68      0.67      0.66        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 26, 34]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5192229861670309
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [29, 25, 45, 36]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.5188027710784833
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [27, 26, 45, 37]
Selected clustering_algorithm: fcm
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9133333333333333
F1: 0.9139730639730639
======================================================
Running iris 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.60      0.60         5
           2       0.60      0.75      0.67         4

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9466666666666667
F1: 0.9451683501683501
======================================================
Running iris 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.60      0.60      0.60         5
           2       0.60      0.75      0.67         4

    accuracy                           0.73        15
   macro avg       0.73      0.73      0.73        15
weighted avg       0.76      0.73      0.74        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.60      1.00      0.75         3
           2       1.00      0.71      0.83         7

    accuracy                           0.87        15
   macro avg       0.87      0.90      0.86        15
weighted avg       0.92      0.87      0.87        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.80      1.00      0.89         4
           2       1.00      0.83      0.91         6

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         5

    accuracy                           1.00        15
   macro avg       1.00      1.00      1.00        15
weighted avg       1.00      1.00      1.00        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       1.00      0.83      0.91         6
           2       0.80      1.00      0.89         4

    accuracy                           0.93        15
   macro avg       0.93      0.94      0.93        15
weighted avg       0.95      0.93      0.93        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.9466666666666667
F1: 0.9451683501683501
======================================================
Running iris 50 2 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c meta_classifier -p crossval
3 - 2
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 meta_classifier crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c meta_classifier -p crossval
Variation 234...
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand meta_classifier default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 meta_classifier default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c meta_classifier -p default
3 - 2
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 meta_classifier default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c meta_classifier -p default
Variation 34...
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.13      0.19        15
weighted avg       0.87      0.33      0.48        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.38      0.56        13
           1       0.40      1.00      0.57         2
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.46      0.38        15
weighted avg       0.92      0.47      0.56        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.40      0.67      0.50         3
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.36      0.36        15
weighted avg       0.88      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.36      0.53        14
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.12      0.18        15
weighted avg       0.93      0.33      0.49        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.21753976444378922
======================================================
Running iris 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      0.17      0.18         6
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.24      0.30        15
weighted avg       0.68      0.40      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.23625901875901872
======================================================
Running iris 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.40      0.40      0.40         5
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.36        15
weighted avg       0.80      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.20      0.17      0.18         6
           2       0.00      0.00      0.00         0

    accuracy                           0.40        15
   macro avg       0.40      0.24      0.30        15
weighted avg       0.68      0.40      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3533333333333334
F1: 0.23625901875901872
======================================================
Running iris 50 2 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c weighted_membership -p crossval
3 - 2
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 weighted_membership crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c weighted_membership -p crossval
Variation 234...
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand weighted_membership default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 weighted_membership default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c weighted_membership -p default
3 - 2
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 weighted_membership default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c weighted_membership -p default
Variation 34...
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5177951156607956
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 40, 23, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5186466162867166
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 38, 26, 26]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5195578284339674
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 34, 29, 27]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5191967688852149
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [45, 38, 27, 25]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.517389717752147
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [25, 38, 27, 45]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5218447216427734
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [45, 28, 25, 37]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5194369409141065
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 30, 22, 38]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.5189821622559554
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 39, 29, 22]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.5       , 0.41666667, 0.61016949, 0.54166667],
       [0.69444444, 0.5       , 0.83050847, 0.91666667],
       [0.22222222, 0.54166667, 0.11864407, 0.16666667],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.5185134337912912
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [39, 26, 45, 25]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=4, random_state=42))
Best evaluation: 0.7570695237024794
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [45, 29, 40, 21]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 rand majority_voting crossval...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5705526401758314
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5676924959526224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5661361239866269
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.573523757265276
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5688344967010059
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5757132072982837
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5663460171753292
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5697700534745302
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.5729004025206117
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [45, 90]
Selected clustering_algorithm: kmeans
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.61111111, 0.41666667, 0.71186441, 0.79166667],
       [0.11111111, 0.5       , 0.05084746, 0.04166667],
       [0.61111111, 0.33333333, 0.61016949, 0.58333333],
       [0.36111111, 0.20833333, 0.49152542, 0.41666667]]),
       n_clusters=4))
Best evaluation: 0.6034572969573229
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.33      0.50        15
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.11      0.17        15
weighted avg       1.00      0.33      0.50        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [29, 45, 39, 22]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.33333333333333337
F1: 0.16666666666666669
======================================================
Running iris 50 2 majority_voting crossval
======================================================
python cbeg.py -d iris -m 50 -n 2 -c majority_voting -p crossval
3 - 2
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 majority_voting crossval
======================================================
python cbeg.py -d iris -m 50 -n 3 -c majority_voting -p crossval
Variation 23...
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 rand majority_voting default...
======================================================
python cbeg.py -d iris -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 2 majority_voting default
======================================================
python cbeg.py -d iris -m 50 -n 2 -c majority_voting -p default
3 - 2
naive_bayes_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running iris 50 3 majority_voting default
======================================================
python cbeg.py -d iris -m 50 -n 3 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [56, 45, 34]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB()]
Number of samples by cluster: [55, 45, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 50, 40]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.50      0.67        10
           1       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.17      0.22        15
weighted avg       0.67      0.33      0.44        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.40      0.50      0.44         4
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.32      0.36        15
weighted avg       0.84      0.47      0.58        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77         8
           1       0.40      0.29      0.33         7
           2       0.00      0.00      0.00         0

    accuracy                           0.47        15
   macro avg       0.47      0.30      0.37        15
weighted avg       0.72      0.47      0.57        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 55, 35]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.45      0.62        11
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.15      0.21        15
weighted avg       0.73      0.33      0.46        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 33, 57]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         0

    accuracy                           0.33        15
   macro avg       0.33      0.14      0.20        15
weighted avg       0.80      0.33      0.47        15

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [45, 53, 37]
Selected clustering_algorithm: kmeans++
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/iris/mutual_info_50.0/cbeg/naive_bayes_3_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.36000000000000004
F1: 0.24200812803753985
======================================================
Running heart 100 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4640879328595911
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [87, 111, 1, 44]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.47798167494818194
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [96, 41, 2, 104]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.41269732774020423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression(), SVC(probability=True), GaussianNB()]
Number of samples by cluster: [1, 81, 37, 88, 36]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4783426710031421
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.72        21
           1       0.33      0.67      0.44         6

    accuracy                           0.63        27
   macro avg       0.60      0.64      0.58        27
weighted avg       0.75      0.63      0.66        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [100, 38, 100, 5]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4031915759791622
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [34, 71, 42, 6, 90]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7703703703703704
F1: 0.7184282577326055
======================================================
Running heart 100 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        17
           1       0.50      0.60      0.55        10

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.65      0.63      0.63        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.27869364894211224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [87, 44, 1, 111]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.2809461353458795
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [87, 110, 44, 1, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [120, 123]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.30780307599942014
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [43, 90, 2, 105, 3]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.26198914765982956
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier(), GaussianNB(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [41, 74, 35, 90, 3]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier(), RandomForestClassifier(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7703703703703704
F1: 0.7316524002313477
======================================================
Running heart 100 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c meta_classifier -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.27869364894211224
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [44, 1, 111, 87]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.28501161327712027
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [49, 78, 1, 1, 114]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.26419907928172104
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      1.00      0.93        13
           1       1.00      0.86      0.92        14

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [LogisticRegression(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent'), SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [80, 39, 2, 88, 34]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26182973569847356
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [SVC(probability=True), GradientBoostingClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), SVC(probability=True), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8296296296296296
F1: 0.8042143573013139
======================================================
Running heart 100 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c meta_classifier -p crossval
Variation 24...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c meta_classifier -p default
Variation 14...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c meta_classifier -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.59      0.70        22
           1       0.25      0.60      0.35         5

    accuracy                           0.59        27
   macro avg       0.56      0.60      0.53        27
weighted avg       0.75      0.59      0.64        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.92      0.79      0.85        14

    accuracy                           0.85        27
   macro avg       0.86      0.85      0.85        27
weighted avg       0.86      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7703703703703704
F1: 0.7162763592379962
======================================================
Running heart 100 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67        15
           1       0.58      0.58      0.58        12

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.63      0.63      0.63        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [GaussianNB(), AdaBoostClassifier(), LogisticRegression(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.774074074074074
F1: 0.7205469450034667
======================================================
Running heart 100 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      0.40      0.54        25

    accuracy                           0.37        27
   macro avg       0.42      0.20      0.27        27
weighted avg       0.77      0.37      0.50        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        17
           1       0.50      0.60      0.55        10

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.65      0.63      0.63        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), LogisticRegression(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7518518518518518
F1: 0.7380279706366663
======================================================
Running heart 100 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c weighted_membership -p crossval
Variation 124...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.07      0.50      0.12         2
           1       0.92      0.44      0.59        25

    accuracy                           0.44        27
   macro avg       0.49      0.47      0.36        27
weighted avg       0.85      0.44      0.56        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.20      0.75      0.32         4
           1       0.92      0.48      0.63        23

    accuracy                           0.52        27
   macro avg       0.56      0.61      0.47        27
weighted avg       0.81      0.52      0.58        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7407407407407408
F1: 0.7429548690418255
======================================================
Running heart 100 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c weighted_membership -p crossval
Variation 24...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c weighted_membership -p default
Variation 14...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c weighted_membership -p default
Variation 4...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.13      0.50      0.21         4
           1       0.83      0.43      0.57        23

    accuracy                           0.44        27
   macro avg       0.48      0.47      0.39        27
weighted avg       0.73      0.44      0.52        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.27      0.33      0.30        12
           1       0.33      0.27      0.30        15

    accuracy                           0.30        27
   macro avg       0.30      0.30      0.30        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.07      1.00      0.12         1
           1       1.00      0.46      0.63        26

    accuracy                           0.48        27
   macro avg       0.53      0.73      0.38        27
weighted avg       0.97      0.48      0.61        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.20      0.60      0.30         5
           1       0.83      0.45      0.59        22

    accuracy                           0.48        27
   macro avg       0.52      0.53      0.44        27
weighted avg       0.72      0.48      0.53        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5925925925925927
F1: 0.5098337134714843
======================================================
Running heart 100 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier(), SVC(probability=True), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7185185185185186
F1: 0.5459780467210809
======================================================
Running heart 100 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.62      0.77        24
           1       0.25      1.00      0.40         3

    accuracy                           0.67        27
   macro avg       0.62      0.81      0.58        27
weighted avg       0.92      0.67      0.73        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier(), LogisticRegression(), SVC(probability=True), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.625925925925926
F1: 0.26855921855921855
======================================================
Running heart 100 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c majority_voting -p crossval
Variation 12...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier(), RandomForestClassifier(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6407407407407407
F1: 0.40294548588666235
======================================================
Running heart 100 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 100 -n 2 -c majority_voting -p crossval
Variation 2...
Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True)]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.65      0.69        17
           1       0.50      0.60      0.55        10

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.65      0.63      0.63        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/classifier_selection_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7
F1: 0.5127031791737673
======================================================
Running heart 100 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 100 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 100 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
CBEG               precision    recall  f1-score   support

           0       0.47      0.41      0.44        17
           1       0.17      0.20      0.18        10

    accuracy                           0.33        27
   macro avg       0.32      0.31      0.31        27
weighted avg       0.36      0.33      0.34        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5555555555555556
F1: 0.3742291531997414
======================================================
Running heart 100 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e dbc_rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
CBEG               precision    recall  f1-score   support

           0       0.67      0.45      0.54        22
           1       0.00      0.00      0.00         5

    accuracy                           0.37        27
   macro avg       0.33      0.23      0.27        27
weighted avg       0.54      0.37      0.44        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
CBEG               precision    recall  f1-score   support

           0       0.40      0.38      0.39        16
           1       0.17      0.18      0.17        11

    accuracy                           0.30        27
   macro avg       0.28      0.28      0.28        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
CBEG               precision    recall  f1-score   support

           0       0.27      0.33      0.30        12
           1       0.33      0.27      0.30        15

    accuracy                           0.30        27
   macro avg       0.30      0.30      0.30        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
CBEG               precision    recall  f1-score   support

           0       0.67      0.56      0.61        18
           1       0.33      0.44      0.38         9

    accuracy                           0.52        27
   macro avg       0.50      0.50      0.49        27
weighted avg       0.56      0.52      0.53        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
CBEG               precision    recall  f1-score   support

           0       0.27      0.29      0.28        14
           1       0.17      0.15      0.16        13

    accuracy                           0.22        27
   macro avg       0.22      0.22      0.22        27
weighted avg       0.22      0.22      0.22        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
CBEG               precision    recall  f1-score   support

           0       0.47      0.41      0.44        17
           1       0.17      0.20      0.18        10

    accuracy                           0.33        27
   macro avg       0.32      0.31      0.31        27
weighted avg       0.36      0.33      0.34        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3888888888888889
F1: 0.26072656168308345
======================================================
Running heart 100 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 100 -e rand -c majority_voting -p default
Variation 1...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
CBEG               precision    recall  f1-score   support

           0       0.67      0.45      0.54        22
           1       0.00      0.00      0.00         5

    accuracy                           0.37        27
   macro avg       0.33      0.23      0.27        27
weighted avg       0.54      0.37      0.44        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
CBEG               precision    recall  f1-score   support

           0       0.40      0.38      0.39        16
           1       0.17      0.18      0.17        11

    accuracy                           0.30        27
   macro avg       0.28      0.28      0.28        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
CBEG               precision    recall  f1-score   support

           0       0.27      0.33      0.30        12
           1       0.33      0.27      0.30        15

    accuracy                           0.30        27
   macro avg       0.30      0.30      0.30        27
weighted avg       0.30      0.30      0.30        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
CBEG               precision    recall  f1-score   support

           0       0.67      0.56      0.61        18
           1       0.33      0.44      0.38         9

    accuracy                           0.52        27
   macro avg       0.50      0.50      0.49        27
weighted avg       0.56      0.52      0.53        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
CBEG               precision    recall  f1-score   support

           0       0.27      0.29      0.28        14
           1       0.17      0.15      0.16        13

    accuracy                           0.22        27
   macro avg       0.22      0.22      0.22        27
weighted avg       0.22      0.22      0.22        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
CBEG               precision    recall  f1-score   support

           0       0.47      0.41      0.44        17
           1       0.17      0.20      0.18        10

    accuracy                           0.33        27
   macro avg       0.32      0.31      0.31        27
weighted avg       0.36      0.33      0.34        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
CBEG               precision    recall  f1-score   support

           0       0.60      0.47      0.53        19
           1       0.17      0.25      0.20         8

    accuracy                           0.41        27
   macro avg       0.38      0.36      0.36        27
weighted avg       0.47      0.41      0.43        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.3888888888888889
F1: 0.26072656168308345
======================================================
Running heart 100 2 majority_voting default
======================================================
python cbeg.py -d heart -m 100 -n 2 -c majority_voting -p default
Variation 0...
Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.33      0.38      0.36        13
           1       0.33      0.29      0.31        14

    accuracy                           0.33        27
   macro avg       0.33      0.34      0.33        27
weighted avg       0.33      0.33      0.33        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
CBEG               precision    recall  f1-score   support

           0       0.40      0.43      0.41        14
           1       0.33      0.31      0.32        13

    accuracy                           0.37        27
   macro avg       0.37      0.37      0.37        27
weighted avg       0.37      0.37      0.37        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_100.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5518518518518518
F1: 0.398816565787154
======================================================
Running heart 100 3 majority_voting default
======================================================
python cbeg.py -d heart -m 100 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4063467388107692
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.73      0.73        15
           1       0.67      0.67      0.67        12

    accuracy                           0.70        27
   macro avg       0.70      0.70      0.70        27
weighted avg       0.70      0.70      0.70        27

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), AdaBoostClassifier(), LogisticRegression(), AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [1, 71, 46, 82, 43]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4647109319864955
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [46, 85, 111, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4020455425417019
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [17, 101, 1, 82, 42]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.47926858727939964
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [96, 38, 104, 5]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.92      0.79      0.85        14

    accuracy                           0.85        27
   macro avg       0.86      0.85      0.85        27
weighted avg       0.86      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.4116800930319992
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), GaussianNB(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [91, 31, 86, 34, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4790136203969821
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67        15
           1       0.58      0.58      0.58        12

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.63      0.63      0.63        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [100, 36, 99, 8]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4671925528532278
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.67      0.67        15
           1       0.58      0.58      0.58        12

    accuracy                           0.63        27
   macro avg       0.62      0.62      0.62        27
weighted avg       0.63      0.63      0.63        27

Selected Base Classifiers: [DecisionTreeClassifier(), AdaBoostClassifier(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [48, 113, 81, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7518518518518518
F1: 0.7118017409321757
======================================================
Running heart 75 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26702487342502257
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.73      0.73        15
           1       0.67      0.67      0.67        12

    accuracy                           0.70        27
   macro avg       0.70      0.70      0.70        27
weighted avg       0.70      0.70      0.70        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.2786131139316157
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.68      0.76        19
           1       0.50      0.75      0.60         8

    accuracy                           0.70        27
   macro avg       0.68      0.72      0.68        27
weighted avg       0.76      0.70      0.72        27

Selected Base Classifiers: [RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent'), LogisticRegression()]
Number of samples by cluster: [111, 86, 1, 45]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.29232291681889333
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.67      0.73        18
           1       0.50      0.67      0.57         9

    accuracy                           0.67        27
   macro avg       0.65      0.67      0.65        27
weighted avg       0.70      0.67      0.68        27

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), GaussianNB(), DecisionTreeClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [110, 2, 87, 43, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [123, 120]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26182973569847356
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.71      0.69        14
           1       0.67      0.62      0.64        13

    accuracy                           0.67        27
   macro avg       0.67      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), GaussianNB(), LogisticRegression(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.762962962962963
F1: 0.7204562812388899
======================================================
Running heart 75 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.28689883654650244
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [80, 2, 43, 47, 71]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.27869364894211224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [1, 111, 87, 44]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.28010200879623853
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [GradientBoostingClassifier(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [41, 96, 104, 2]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      1.00      0.89        12
           1       1.00      0.80      0.89        15

    accuracy                           0.89        27
   macro avg       0.90      0.90      0.89        27
weighted avg       0.91      0.89      0.89        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [123, 120]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.26596818181870097
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [99, 8, 37, 99]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [GradientBoostingClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), GaussianNB(), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8333333333333334
F1: 0.8051189116841291
======================================================
Running heart 75 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GradientBoostingClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.73      0.73        15
           1       0.67      0.67      0.67        12

    accuracy                           0.70        27
   macro avg       0.70      0.70      0.70        27
weighted avg       0.70      0.70      0.70        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), GaussianNB(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7518518518518519
F1: 0.6620404876926617
======================================================
Running heart 75 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [SVC(probability=True), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [KNeighborsClassifier(), RandomForestClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.61      0.67        18
           1       0.42      0.56      0.48         9

    accuracy                           0.59        27
   macro avg       0.57      0.58      0.57        27
weighted avg       0.63      0.59      0.60        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), LogisticRegression(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.774074074074074
F1: 0.7309175607001694
======================================================
Running heart 75 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.59      0.70        22
           1       0.25      0.60      0.35         5

    accuracy                           0.59        27
   macro avg       0.56      0.60      0.53        27
weighted avg       0.75      0.59      0.64        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.79      0.88        19
           1       0.67      1.00      0.80         8

    accuracy                           0.85        27
   macro avg       0.83      0.89      0.84        27
weighted avg       0.90      0.85      0.86        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.61      0.67        18
           1       0.42      0.56      0.48         9

    accuracy                           0.59        27
   macro avg       0.57      0.58      0.57        27
weighted avg       0.63      0.59      0.60        27

Selected Base Classifiers: [GaussianNB(), GaussianNB(), LogisticRegression(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.774074074074074
F1: 0.7112570596969574
======================================================
Running heart 75 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [GradientBoostingClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.63      0.71        19
           1       0.42      0.62      0.50         8

    accuracy                           0.63        27
   macro avg       0.61      0.63      0.60        27
weighted avg       0.69      0.63      0.64        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True)]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6777777777777778
F1: 0.4496112221112221
======================================================
Running heart 75 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.52      0.65        25
           1       0.00      0.00      0.00         2

    accuracy                           0.48        27
   macro avg       0.43      0.26      0.33        27
weighted avg       0.80      0.48      0.60        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.48      0.56        21
           1       0.08      0.17      0.11         6

    accuracy                           0.41        27
   macro avg       0.38      0.32      0.33        27
weighted avg       0.54      0.41      0.46        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.74      0.82        19
           1       0.58      0.88      0.70         8

    accuracy                           0.78        27
   macro avg       0.76      0.81      0.76        27
weighted avg       0.83      0.78      0.79        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.52      0.63        23
           1       0.08      0.25      0.12         4

    accuracy                           0.48        27
   macro avg       0.44      0.39      0.38        27
weighted avg       0.69      0.48      0.56        27

Selected Base Classifiers: [GaussianNB(), GradientBoostingClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True)]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), SVC(probability=True), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5888888888888888
F1: 0.25349044746103566
======================================================
Running heart 75 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.56      0.71        27
           1       0.00      0.00      0.00         0

    accuracy                           0.56        27
   macro avg       0.50      0.28      0.36        27
weighted avg       1.00      0.56      0.71        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.59      0.70        22
           1       0.25      0.60      0.35         5

    accuracy                           0.59        27
   macro avg       0.56      0.60      0.53        27
weighted avg       0.75      0.59      0.64        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression(), RandomForestClassifier(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6666666666666667
F1: 0.3927102824935642
======================================================
Running heart 75 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 75 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 75 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 75 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 75 2 majority_voting default
======================================================
python cbeg.py -d heart -m 75 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.13      0.18      0.15        11
           1       0.25      0.19      0.21        16

    accuracy                           0.19        27
   macro avg       0.19      0.18      0.18        27
weighted avg       0.20      0.19      0.19        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.64      0.76        22
           1       0.33      0.80      0.47         5

    accuracy                           0.67        27
   macro avg       0.63      0.72      0.61        27
weighted avg       0.82      0.67      0.70        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.33      0.38      0.36        13
           1       0.33      0.29      0.31        14

    accuracy                           0.33        27
   macro avg       0.33      0.34      0.33        27
weighted avg       0.33      0.33      0.33        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.40      0.43      0.41        14
           1       0.33      0.31      0.32        13

    accuracy                           0.37        27
   macro avg       0.37      0.37      0.37        27
weighted avg       0.37      0.37      0.37        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_75.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.5592592592592592
F1: 0.43606352934990705
======================================================
Running heart 75 3 majority_voting default
======================================================
python cbeg.py -d heart -m 75 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.40235906035731056
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB(), AdaBoostClassifier()]
Number of samples by cluster: [39, 1, 88, 71, 44]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.4640879328595911
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression(), DummyClassifier(strategy='most_frequent'), SVC(probability=True)]
Number of samples by cluster: [44, 111, 1, 87]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.93      0.93        15
           1       0.92      0.92      0.92        12

    accuracy                           0.93        27
   macro avg       0.93      0.93      0.93        27
weighted avg       0.93      0.93      0.93        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5733858750568099
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), DummyClassifier(strategy='most_frequent'), AdaBoostClassifier()]
Number of samples by cluster: [48, 1, 114, 1, 79]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.5092846741715039
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [79, 1, 87, 1, 39, 36]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.47843914112752356
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(n_neighbors=7), LogisticRegression(), GradientBoostingClassifier()]
Number of samples by cluster: [9, 99, 36, 99]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.3115847375562811
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [116, 127]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.32089265837321423
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.71      0.69        14
           1       0.67      0.62      0.64        13

    accuracy                           0.67        27
   macro avg       0.67      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [KNeighborsClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.5730102142865647
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), GaussianNB(), GaussianNB()]
Number of samples by cluster: [111, 1, 1, 49, 81]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.788888888888889
F1: 0.7577271644365465
======================================================
Running heart 50 dbc_rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.30800335544104196
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.73      0.73        15
           1       0.67      0.67      0.67        12

    accuracy                           0.70        27
   macro avg       0.70      0.70      0.70        27
weighted avg       0.70      0.70      0.70        27

Selected Base Classifiers: [GaussianNB(), DummyClassifier(strategy='most_frequent'), DummyClassifier(strategy='most_frequent'), LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [82, 1, 1, 45, 43, 71]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.28871205996142074
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier(), SVC(probability=True), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [80, 112, 50, 1]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.93      0.90        14
           1       0.92      0.85      0.88        13

    accuracy                           0.89        27
   macro avg       0.89      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.28010200879623853
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.71      0.75        17
           1       0.58      0.70      0.64        10

    accuracy                           0.70        27
   macro avg       0.69      0.70      0.69        27
weighted avg       0.72      0.70      0.71        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [96, 104, 41, 2]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=6))
Best evaluation: 0.30104929842798506
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [DummyClassifier(strategy='most_frequent'), RandomForestClassifier(), GaussianNB(), GradientBoostingClassifier(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [1, 85, 38, 80, 2, 37]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26182973569847356
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.76      0.81        17
           1       0.67      0.80      0.73        10

    accuracy                           0.78        27
   macro avg       0.77      0.78      0.77        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.79      0.76        14
           1       0.75      0.69      0.72        13

    accuracy                           0.74        27
   macro avg       0.74      0.74      0.74        27
weighted avg       0.74      0.74      0.74        27

Selected Base Classifiers: [LogisticRegression(), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.80      0.80        15
           1       0.75      0.75      0.75        12

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.78      0.78      0.78        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), RandomForestClassifier(), LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7629629629629628
F1: 0.7341452991452991
======================================================
Running heart 50 rand meta_classifier crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c meta_classifier -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=5))
Best evaluation: 0.2867081071752111
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.92      0.79      0.85        14

    accuracy                           0.85        27
   macro avg       0.86      0.85      0.85        27
weighted avg       0.86      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), DummyClassifier(strategy='most_frequent'), GaussianNB(), LogisticRegression()]
Number of samples by cluster: [81, 46, 2, 71, 43]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.27869364894211224
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.83      0.91        18
           1       0.75      1.00      0.86         9

    accuracy                           0.89        27
   macro avg       0.88      0.92      0.88        27
weighted avg       0.92      0.89      0.89        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression(), DummyClassifier(strategy='most_frequent'), RandomForestClassifier()]
Number of samples by cluster: [87, 44, 1, 111]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2685841280896463
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=4))
Best evaluation: 0.27418369114330854
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB(), GaussianNB(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [95, 103, 38, 7]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.2659853103634084
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.60      0.90      0.72        10
           1       0.92      0.65      0.76        17

    accuracy                           0.74        27
   macro avg       0.76      0.77      0.74        27
weighted avg       0.80      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26345339456272493
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [123, 120]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.26182973569847356
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.77      0.71        13
           1       0.75      0.64      0.69        14

    accuracy                           0.70        27
   macro avg       0.71      0.71      0.70        27
weighted avg       0.71      0.70      0.70        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [119, 124]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.25905783262976834
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [KNeighborsClassifier(n_neighbors=7), LogisticRegression()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('fcm', FuzzyCMeans(n_clusters=2))
Best evaluation: 0.263569843807783
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), LogisticRegression()]
Number of samples by cluster: [124, 119]
Selected clustering_algorithm: fcm
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True), SVC(probability=True), SVC(probability=True), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_meta_classifier_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7814814814814814
F1: 0.7635211087984701
======================================================
Running heart 50 2 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c meta_classifier -p crossval
Variation 234...
classifier_selection_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 meta_classifier crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c meta_classifier -p crossval
2 - 3
classifier_selection_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand meta_classifier default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c meta_classifier -p default
Variation 134...
naive_bayes_compare_clusters_rand_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 meta_classifier default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c meta_classifier -p default
Variation 34...
naive_bayes_2_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 meta_classifier default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c meta_classifier -p default
2 - 3
naive_bayes_3_clusters_meta_classifier_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.13      0.67      0.22         3
           1       0.92      0.46      0.61        24

    accuracy                           0.48        27
   macro avg       0.53      0.56      0.42        27
weighted avg       0.83      0.48      0.57        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.91      0.77        11
           1       0.92      0.69      0.79        16

    accuracy                           0.78        27
   macro avg       0.79      0.80      0.78        27
weighted avg       0.81      0.78      0.78        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.62      0.65        16
           1       0.50      0.55      0.52        11

    accuracy                           0.59        27
   macro avg       0.58      0.59      0.58        27
weighted avg       0.60      0.59      0.59        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), GradientBoostingClassifier(), LogisticRegression(), AdaBoostClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7555555555555555
F1: 0.7396806575067444
======================================================
Running heart 50 dbc_rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.83      0.67      0.74        15

    accuracy                           0.74        27
   macro avg       0.75      0.75      0.74        27
weighted avg       0.76      0.74      0.74        27

Selected Base Classifiers: [AdaBoostClassifier(), RandomForestClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.88      0.94        17
           1       0.83      1.00      0.91        10

    accuracy                           0.93        27
   macro avg       0.92      0.94      0.92        27
weighted avg       0.94      0.93      0.93        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.92      0.81        12
           1       0.92      0.73      0.81        15

    accuracy                           0.81        27
   macro avg       0.82      0.82      0.81        27
weighted avg       0.84      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), LogisticRegression()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.94      0.97        16
           1       0.92      1.00      0.96        11

    accuracy                           0.96        27
   macro avg       0.96      0.97      0.96        27
weighted avg       0.97      0.96      0.96        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.81      0.84        16
           1       0.75      0.82      0.78        11

    accuracy                           0.81        27
   macro avg       0.81      0.82      0.81        27
weighted avg       0.82      0.81      0.82        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.8037037037037036
F1: 0.7765681661333835
======================================================
Running heart 50 rand weighted_membership crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c weighted_membership -p crossval
Variation 1234...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.07      0.50      0.12         2
           1       0.92      0.44      0.59        25

    accuracy                           0.44        27
   macro avg       0.49      0.47      0.36        27
weighted avg       0.85      0.44      0.56        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.75      0.77        16
           1       0.67      0.73      0.70        11

    accuracy                           0.74        27
   macro avg       0.73      0.74      0.73        27
weighted avg       0.75      0.74      0.74        27

Selected Base Classifiers: [RandomForestClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.69      0.71        16
           1       0.58      0.64      0.61        11

    accuracy                           0.67        27
   macro avg       0.66      0.66      0.66        27
weighted avg       0.67      0.67      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.83      0.71      0.77        14

    accuracy                           0.78        27
   macro avg       0.78      0.78      0.78        27
weighted avg       0.79      0.78      0.78        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.94      0.97        16
           1       0.92      1.00      0.96        11

    accuracy                           0.96        27
   macro avg       0.96      0.97      0.96        27
weighted avg       0.97      0.96      0.96        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [AdaBoostClassifier(), SVC(probability=True)]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.87      0.87        15
           1       0.83      0.83      0.83        12

    accuracy                           0.85        27
   macro avg       0.85      0.85      0.85        27
weighted avg       0.85      0.85      0.85        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.62      0.65        16
           1       0.50      0.55      0.52        11

    accuracy                           0.59        27
   macro avg       0.58      0.59      0.58        27
weighted avg       0.60      0.59      0.59        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), LogisticRegression(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_weighted_membership_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.7555555555555555
F1: 0.7449332610202175
======================================================
Running heart 50 2 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c weighted_membership -p crossval
Variation 234...
classifier_selection_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 weighted_membership crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c weighted_membership -p crossval
2 - 3
classifier_selection_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_dbc_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand weighted_membership default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c weighted_membership -p default
Variation 134...
naive_bayes_compare_clusters_rand_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 weighted_membership default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c weighted_membership -p default
Variation 34...
naive_bayes_2_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 weighted_membership default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c weighted_membership -p default
2 - 3
naive_bayes_3_clusters_weighted_membership_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.89361702, 0.        , 0.33333333, 0.62264151, 0.38061466,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.74468085, 1.        , 0.66666667, 0.43396226, 0.45862884,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.320396572252105
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [RandomForestClassifier(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3059798700689984
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.47      0.44      0.45        16
           1       0.25      0.27      0.26        11

    accuracy                           0.37        27
   macro avg       0.36      0.36      0.36        27
weighted avg       0.38      0.37      0.37        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.64912281, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.61403509, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.34146222482464755
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.83      0.91      0.87        11

    accuracy                           0.89        27
   macro avg       0.88      0.89      0.89        27
weighted avg       0.89      0.89      0.89        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.67346939, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.46938776, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32638441081679953
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), LogisticRegression()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.32350857381773324
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), RandomForestClassifier()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3252016747178303
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.75      0.86        20
           1       0.58      1.00      0.74         7

    accuracy                           0.81        27
   macro avg       0.79      0.88      0.80        27
weighted avg       0.89      0.81      0.83        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.875     , 0.        , 0.33333333, 0.62264151, 0.40182648,
        0.        , 0.        , 0.69465649, 0.        , 0.06451613,
        0.        , 0.66666667, 0.        ],
       [0.72916667, 1.        , 0.66666667, 0.43396226, 0.47716895,
        0.        , 0.        , 0.66412214, 0.        , 0.        ,
        0.        , 0.        , 0.        ]]),
       n_clusters=2))
Best evaluation: 0.3296631969059076
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [AdaBoostClassifier(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.30410777112867676
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.3144411039845146
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.3585628802010614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.57      0.68        23
           1       0.17      0.50      0.25         4

    accuracy                           0.56        27
   macro avg       0.52      0.53      0.47        27
weighted avg       0.76      0.56      0.62        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), RandomForestClassifier(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6888888888888889
F1: 0.5389457338999672
======================================================
Running heart 50 dbc_rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.57      0.68        23
           1       0.17      0.50      0.25         4

    accuracy                           0.56        27
   macro avg       0.52      0.53      0.47        27
weighted avg       0.76      0.56      0.62        27

Selected Base Classifiers: [GradientBoostingClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.47      0.44      0.45        16
           1       0.25      0.27      0.26        11

    accuracy                           0.37        27
   macro avg       0.36      0.36      0.36        27
weighted avg       0.38      0.37      0.37        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [LogisticRegression(), AdaBoostClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), LogisticRegression()]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [AdaBoostClassifier(), GradientBoostingClassifier()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [SVC(probability=True), RandomForestClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), KNeighborsClassifier(n_neighbors=7)]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.65      0.79        23
           1       0.33      1.00      0.50         4

    accuracy                           0.70        27
   macro avg       0.67      0.83      0.64        27
weighted avg       0.90      0.70      0.75        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB(), LogisticRegression(), LogisticRegression(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_dbc_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6370370370370371
F1: 0.3997625198644851
======================================================
Running heart 50 rand majority_voting crossval...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c majority_voting -p crossval
Variation 123...
Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2657157829965441
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.72        21
           1       0.33      0.67      0.44         6

    accuracy                           0.63        27
   macro avg       0.60      0.64      0.58        27
weighted avg       0.75      0.63      0.66        27

Selected Base Classifiers: [AdaBoostClassifier(), AdaBoostClassifier()]
Number of samples by cluster: [127, 116]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25776130923469986
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.47      0.44      0.45        16
           1       0.25      0.27      0.26        11

    accuracy                           0.37        27
   macro avg       0.36      0.36      0.36        27
weighted avg       0.38      0.37      0.37        27

Selected Base Classifiers: [LogisticRegression(), GaussianNB()]
Number of samples by cluster: [117, 126]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2673252678195482
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.70      0.80        20
           1       0.50      0.86      0.63         7

    accuracy                           0.74        27
   macro avg       0.72      0.78      0.72        27
weighted avg       0.82      0.74      0.76        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26317656539705725
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.60      0.75        25
           1       0.17      1.00      0.29         2

    accuracy                           0.63        27
   macro avg       0.58      0.80      0.52        27
weighted avg       0.94      0.63      0.72        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [115, 128]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26395773638645614
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.61      0.74        23
           1       0.25      0.75      0.38         4

    accuracy                           0.63        27
   macro avg       0.59      0.68      0.56        27
weighted avg       0.83      0.63      0.68        27

Selected Base Classifiers: [LogisticRegression(), RandomForestClassifier()]
Number of samples by cluster: [114, 129]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2616620876789151
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.08      1.00      0.15         1

    accuracy                           0.59        27
   macro avg       0.54      0.79      0.44        27
weighted avg       0.97      0.59      0.71        27

Selected Base Classifiers: [SVC(probability=True), SVC(probability=True)]
Number of samples by cluster: [125, 118]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.2596832483773659
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.68      0.81        22
           1       0.42      1.00      0.59         5

    accuracy                           0.74        27
   macro avg       0.71      0.84      0.70        27
weighted avg       0.89      0.74      0.77        27

Selected Base Classifiers: [AdaBoostClassifier(), LogisticRegression()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.25660933027246174
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.72      0.79        18
           1       0.58      0.78      0.67         9

    accuracy                           0.74        27
   macro avg       0.73      0.75      0.73        27
weighted avg       0.77      0.74      0.75        27

Selected Base Classifiers: [AdaBoostClassifier(), KNeighborsClassifier()]
Number of samples by cluster: [129, 114]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans', KMeans(init='random', n_clusters=2, random_state=42))
Best evaluation: 0.26180457066526325
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       1.00      0.71      0.83        21
           1       0.50      1.00      0.67         6

    accuracy                           0.78        27
   macro avg       0.75      0.86      0.75        27
weighted avg       0.89      0.78      0.80        27

Selected Base Classifiers: [SVC(probability=True), AdaBoostClassifier()]
Number of samples by cluster: [118, 125]
Selected clustering_algorithm: kmeans
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Best clusterer: ('kmeans++', KMeans(init=array([[0.48837209, 1.        , 1.        , 0.62264151, 0.37214612,
        0.        , 1.        , 0.59677419, 1.        , 0.14285714,
        0.5       , 0.33333333, 1.        ],
       [0.86046512, 0.        , 1.        , 0.16981132, 0.05251142,
        0.        , 0.        , 0.43548387, 0.        , 0.28571429,
        0.5       , 0.        , 0.        ],
       [0.23255814, 1.        , 1.        , 0.1509434 , 0.16210046,
        0.        , 1.        , 0.85483871, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ],
       [0.39534884, 1.        , 0.66666667, 0.1509434 , 0.11187215,
        0.        , 0.        , 0.41935484, 0.        , 0.10714286,
        0.        , 0.        , 0.        ],
       [0.62790698, 0.        , 1.        , 0.33962264, 0.46575342,
        0.        , 1.        , 0.79032258, 0.        , 0.        ,
        0.        , 0.        , 0.        ],
       [0.1627907 , 0.        , 0.33333333, 0.10377358, 0.16438356,
        0.        , 0.        , 0.78225806, 0.        , 0.        ,
        0.        , 0.33333333, 0.        ]]),
       n_clusters=6))
Best evaluation: 0.28212616593780876
Performing feature selection...
Performing classifier selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.62      0.72        21
           1       0.33      0.67      0.44         6

    accuracy                           0.63        27
   macro avg       0.60      0.64      0.58        27
weighted avg       0.75      0.63      0.66        27

Selected Base Classifiers: [LogisticRegression(), SVC(probability=True), RandomForestClassifier(), GaussianNB(), RandomForestClassifier(), DummyClassifier(strategy='most_frequent')]
Number of samples by cluster: [60, 12, 52, 59, 34, 26]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/classifier_selection_compare_clusters_rand_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6481481481481481
F1: 0.45174664684861215
======================================================
Running heart 50 2 majority_voting crossval
======================================================
python cbeg.py -d heart -m 50 -n 2 -c majority_voting -p crossval
Variation 23...
classifier_selection_2_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 3 majority_voting crossval
======================================================
python cbeg.py -d heart -m 50 -n 3 -c majority_voting -p crossval
2 - 3
classifier_selection_3_clusters_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 dbc_rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e dbc_rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_dbc_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 rand majority_voting default...
======================================================
python cbeg.py -d heart -n compare -m 50 -e rand -c majority_voting -p default
Variation 13...
naive_bayes_compare_clusters_rand_majority_voting_fusion
Skipping experiment variation...
======================================================
Running heart 50 2 majority_voting default
======================================================
python cbeg.py -d heart -m 50 -n 2 -c majority_voting -p default
Variation 3...
Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.56      0.70        25
           1       0.08      0.50      0.14         2

    accuracy                           0.56        27
   macro avg       0.51      0.53      0.42        27
weighted avg       0.87      0.56      0.66        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [73, 170]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_1.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_1.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.67      0.78        21
           1       0.42      0.83      0.56         6

    accuracy                           0.70        27
   macro avg       0.68      0.75      0.67        27
weighted avg       0.82      0.70      0.73        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_2.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_2.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.78      0.85        18
           1       0.67      0.89      0.76         9

    accuracy                           0.81        27
   macro avg       0.80      0.83      0.81        27
weighted avg       0.84      0.81      0.82        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [79, 164]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_3.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_3.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.87      0.65      0.74        20
           1       0.42      0.71      0.53         7

    accuracy                           0.67        27
   macro avg       0.64      0.68      0.63        27
weighted avg       0.75      0.67      0.69        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [80, 163]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_4.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_4.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.80      0.86      0.83        14
           1       0.83      0.77      0.80        13

    accuracy                           0.81        27
   macro avg       0.82      0.81      0.81        27
weighted avg       0.82      0.81      0.81        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [78, 165]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_5.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_5.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.58      0.72        24
           1       0.17      0.67      0.27         3

    accuracy                           0.59        27
   macro avg       0.55      0.62      0.49        27
weighted avg       0.85      0.59      0.67        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [74, 169]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_6.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_6.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.93      0.82      0.88        17
           1       0.75      0.90      0.82        10

    accuracy                           0.85        27
   macro avg       0.84      0.86      0.85        27
weighted avg       0.87      0.85      0.85        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [77, 166]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_7.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_7.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.67      0.53      0.59        19
           1       0.25      0.38      0.30         8

    accuracy                           0.48        27
   macro avg       0.46      0.45      0.44        27
weighted avg       0.54      0.48      0.50        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [130, 113]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_8.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_8.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.53      0.42      0.47        19
           1       0.08      0.12      0.10         8

    accuracy                           0.33        27
   macro avg       0.31      0.27      0.29        27
weighted avg       0.40      0.33      0.36        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [126, 117]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_9.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_9.txt saved successfully.
-------------------------------------------------- 

Performing pre-clustering...
Performing feature selection...
CBEG               precision    recall  f1-score   support

           0       0.53      0.50      0.52        16
           1       0.33      0.36      0.35        11

    accuracy                           0.44        27
   macro avg       0.43      0.43      0.43        27
weighted avg       0.45      0.44      0.45        27

Selected Base Classifiers: [GaussianNB(), GaussianNB()]
Number of samples by cluster: [128, 115]
Selected clustering_algorithm: kmeans++
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/training_summary/run_10.txt saved successfully.
results/heart/mutual_info_50.0/cbeg/naive_bayes_2_clusters_majority_voting_fusion/test_summary/run_10.txt saved successfully.
-------------------------------------------------- 

Accuracy: 0.6259259259259259
F1: 0.461930782159615
======================================================
Running heart 50 3 majority_voting default
======================================================
python cbeg.py -d heart -m 50 -n 3 -c majority_voting -p default
2 - 3
naive_bayes_3_clusters_majority_voting_fusion
Skipping experiment variation...
